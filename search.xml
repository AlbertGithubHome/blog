<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[2020年终总结！新的起航，新的征程]]></title>
    <url>%2Fblog%2F2020%2F12%2F27%2F2020%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93%EF%BC%81%E6%96%B0%E7%9A%84%E8%B5%B7%E8%88%AA%EF%BC%8C%E6%96%B0%E7%9A%84%E5%BE%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[奇变偶不变，符号看象限，真正的知识就是这么朴实无华~ 前言从2019年开始意识到年终总结的意义，通过反思自己的得失进而确定今后的方向，既然去年开了头，今年也不能中断，依旧写写每天的流水账，细数最近一年发生的故事。 今年最直观的、印象最深的感受就是时间不够用，一首《时间都去哪了》旋律时常出现在脑海中，对比之前长久不变的工作环境，今年确实紧张了许多，习惯了原来的安逸，对各种可能发生的问题轻车熟路的就能解决掉，但来到新环境，一切变得不是那么轻松了。 回顾2020毕竟到了年终时刻，之前的flag可不能忘，依旧是从工作、学习、生活三个方面来回忆一下去年flag的完成情况。 工作 2020 flag：新的一年不能再碌碌无为，真的需要去闯一闯了 完成度：95% 年初如愿的换了一份新工作，之前的公司呆的时间太长了，工作内容单一，熟悉了安逸的环境，虽然每天也在学习，但是进步缓慢，在2019年末开始寻找新的发展环境，在2020初就成功找到了新的工作机会，提前完成flag内容。 与老东家分手过程可以说不太愉快，给不了梦想，撑不起现实，一味的拖着可不是解决问题的办法，不过事情已经过去，不想再提，毕竟也为之奋斗过，近2000个日日夜夜，梦开始的地方，也是认清现实的地方。 离开原公司来到新公司算是无缝衔接吧，中间在家只待了3天，如果能早点意识到离职流程这么狗血，我真应该在家躺一个月，不过新公司的入职流程还真是暖心，提前先网上入职，帮我把社保问题解决了，感谢流程中出现的每一个人。 新的工作内容刚开始肯定要吃力一些，首先是熟悉开发环境，大体和原来相同，不过复杂的申请制度较原来规范了许多，同时也麻烦了许多，版本控制是一个重要的改变，之前主要使用SVN，如今换成了 Git + SVN，以前经常使用的 git 三部曲——add、commit、push 已经不够用了，随着不断的使用学习，渐渐熟悉了 checkout、merge、rebase、cherry-pick reset 等等子命令，还是那句话多用才能学会，如果只停留在纸面上，只是眼睛学会了，闭上眼睛就忘记了。 选择这份新的工作也是想拓宽自己的知识面，之前一直在做分区分服的游戏，想学习一下分布式游戏的开发和一些需要需要注意的问题，所以说这份工作是用来补充我这方面知识短板的，从学习了一年的结果来看，确实达到了这个目的，虽然现在的规模还没有那么大，有些逻辑来不太完善，但是这已经给我做出了示范，在今后的一段时间内，将沿着这条路不断的前行，去探索自己未知的领域。 新的工作认识新的伙伴，大家相处起来还是很友好的，一年来的工作算是中规中矩，不过年底这俩月有点滑铁卢的味道，接连在同一个位置摔倒几次，还是老大给背了锅，内心愧疚不已，无以为报，愿以更饱满的热情投入工作中，实践当初并肩战斗的诺言，得一伙伴不易，愿共同进步。 今年的工作强度明显高于以往，倒不是工作时间长了，而是在新环境中，长时间聚精会神的盯在一件事上本来就很累，头发掉的明显比之前多了，眼睛的视力也下降的厉害，这两点要注意一下了，可以调整一下工作的节奏，注意劳逸结合，我可不想“聪明绝顶”。 学习 2020 flag：看两本有关分布式知识的图书，多看一些开源项目的代码 完成度：85% 有关分布式架构的书今年只看了一本，另外基本都是和育儿知识相关，他们分别是： 从零开始学架构 ——照着做，你也能称为架构师 你就是孩子最好的玩具 正面管教 小狗钱钱2 今年的1本技术书籍对比去年的7本少了很多，一方面换了新工作后需要花很多时间来熟悉新的业务逻辑，用来读书的时间被侵占了一部分，另一方面宝宝一天天长大，需要花些时间去陪伴她，虽然技术书读的少了，可是故事书我可没少读，一年读了好几十本： 这些故事书中描述的故事小时候没觉得有什么不妥，不过以现在成年人的身份来看，有些故事太离奇了，比如大灰狼和七只小羊的故事，山羊妈妈居然剪开狼的肚皮救出了被吃掉的六只小山羊，然后在狼的肚子里装满石头缝上了，整个过程大灰狼都没有醒，我感觉山羊妈妈可能是个麻醉科的护士。 虽然故事内容离奇，但是并不妨碍小娃娃听到津津有味，小孩子的世界还真是单纯，有故事听就老老实实的等着，而我化身为一个播报员，一遍一遍的重复着书中的故事。 博客总结今年也没有丢，一共写了45篇，比去年还要多几篇，总体来看类别很多，总结的内容并不难懂，写到博客中主要是为了方便日后的查找，这一年的总结绝大部分都是晚上和周末花时间写的，只有尝试过才明白，想写好一篇总结需要花费很多很多时间，今年的成长可以对比两年数据来看一下。 C++11的使用在这一年里变得更加熟练，之前的项目中无法使用C++11的特性，所以很多知识都是自己额外花时间来测试学习，来到新项目可以参考已有的代码，进一步巩固C++11的使用，知识还是越用掌握的越好。 语言方面还有Python今年用的比较多，得益于工作中的多次锻炼，一些常用的函数，类型可以很熟练的写出来了，虽然没有用来写过什么大的软件，但是也在不断尝试着使代码更规范，比如使用class、装饰器、继承、记录运行日志等等。 Go语言今年算是简单入门吧，之前只能算是听说过，今年快速的浏览了一遍Go语言的语法，编写了一些测试程序，但是对于Go语言的条条框框还是不太习惯，需要慢慢适应下。 刷题今年一直在坚持着，之前使用的国际账号一时找不到了，今年新注册了国内版LeetCode账号，本着刷简单冲中等的态度，一直在默默的洗刷刷，不过今年参加了几次竞赛，一直是两题选手，只有一次题比较简单全答出来了，当时还是很开心的，继续加油吧。 阅读开源项目源码方面，今年也有了很大的进步，在新项目中接触了好几个之前没有使用过的开源库，虽然没有完全整明白，但最起码开阔了眼界，比如 easyloging++、nolhmann json库等等。 生活 2020 flag：尽最大可能陪陪家人、投资达到2019的水平 完成度：55% 多陪陪家人这一项今年应该算完成了，因为疫情今年也没有出去疯，就是出门买买菜，其他的闲暇时间都和家人在一起，天气好的时候去附近的公园逛逛，对比2019年，每天晚上回家的时间晚了一点，但是多了每周多了一整天可以和家人一起度过。 现在每天还是很充实的，早上起来妈妈已经做好早饭，赶紧洗漱和家人一起吃个早饭，然后和宝宝告别去上班。晚上回来大多数情况宝宝已经睡了，不过有时候也能挺到我回家，和我玩一会再睡。周末陪宝宝出去玩，透透新鲜空气，等宝宝睡觉的时候对近期所学的知识做一个总结，基本上周末的时间陪娃、总结55开吧。 这个flag完成度不高主要是投资理财这块今天基本上是停滞了，未达到2019年水平，每天除了工作就是学习，账户情况没怎么看，整个一个过山车行情，所以基本上处于不赔不赚的情况。 目前的生活状况就是每天都相似，但确实很满足，早上起床一家人吃早饭，和宝宝告别后送媳妇上班，然后自己骑个自行车来公司上班，努力完成一天的工作再骑个小车回家，如果宝宝没睡还可以陪她玩一会儿，等宝宝睡着开始一天的总结，温暖而又充实。 2020年初养了一年的栀子花开花了，正好在我过年回老家的时候开的花，之前我好好浇水通风的时候它却连个花骨朵都没有，好像再告诉我只要我不管它就能好好开花，可是在10月份的时候枯死了。还有一盆文竹在夏天涨势良好，修剪了几次，但没有熬过寒冷的冬天，在11月份左右干枯了。 在上两盆花相继离开之后，我赶紧又补充了新的生机，一盆栀子花和一盆茉莉花，目前涨势良好，茉莉花已经开花了，希望它俩在新的一年了花香不断。 展望2021工作 脚踏实地做好本职工作 额外挤出时间去尝试技术提升（优化、解决痛点） 在熟悉业务的同时更多参与设计的工作，拓宽自己的认知范围 学习 博客总结继续，基本保持在1周一篇，可以适当偷懒，一年懒10次可以产出40篇 开源代码还是要继续学习，libevent需要详细看一下，今年的出镜率太高 读2本技术类书籍，可以是开阔眼界的，也可以是现有技能提升的 读2本经济学、金融理财相关的书籍 生活 陪娃娃，陪家人，工作内容适应后可以多拿出一点时间和家人在一起（需要比2020多一些） 投资理财还是要多花一点时间研究下，目标7%（靠工资是不可能财富自由的，必须开源才行） 注重身体的保养，身体是本钱，可不能把身体搞垮了，愿丢掉体检时的小毛病~ 总结 2020年在工作上是一个新的开始，同时也面临着新的挑战 2020年的flag完成度大概70%，大部分愿望已经实现，未实现部分还需努力 2021年已经悄然开始，新的flag已经在路上，为了新的目标加油努力吧 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 人生旅途中运气与实力都很重要，但是强大的实力可以帮助你提升运气，减少不确定性（记一次事故后提心吊胆的等待），比如买一注彩票中一千万很难，但是如果你的实力可以强大到买下大部分甚至是所有的组合，那么要中一千万只需要等到开奖就可以了~ 2020-12-27 00:32:07]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>总结</tag>
        <tag>工作</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[system_clock::now()和time()时间函数混用带来的踩坑经历]]></title>
    <url>%2Fblog%2F2020%2F12%2F13%2F%E6%97%B6system-clock-now-%E5%92%8Ctime-%E6%97%B6%E9%97%B4%E5%87%BD%E6%95%B0%E6%B7%B7%E7%94%A8%E5%B8%A6%E6%9D%A5%E7%9A%84%E8%B8%A9%E5%9D%91%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[前言时间是一个可怕的东西，听说能用来杀猪。在编程世界中，时间也控制着一个维度，常常伴随着程序运行而流逝，有时也会影响着程序的运行的逻辑，所以在程序中处理时间时还是要仔细一些，最近连续踩坑，总结一下给自己提个醒，有些逻辑还是需要抱着怀疑的态度去看待。 时间函数混用我们在写一个小程序时基本不会去混用时间函数，比如只用 time(NULL) 去控制时间，或者只使用 chrono::system_clock::now() 来记录时间消耗，关于 chrono 的用法，之前简单总结过，可传送至 C++11中的时间库std::chrono。 但是当程序变得复杂起来，这个时间函数混用的高压线还是有可能触碰到的，当程序逻辑对时间要求越发精确时，混用所带来的后果将越发严重。在此记录一个结果：连续调用 time(NULL) 和 chrono::system_clock::now() 两个函数得到的时间戳可能是不同的。 可能你会说，函数是先后调用的，肯定是不同的，后面的函数调用时的时间戳要比前面的大，但事实却是两个函数所取得的时间戳大小不确定，可能是第一个函数的时间戳比较大，也可能是第二个时间戳更大一些。 测试的例子下面展示一段代码，先后调用两个时间函数，打印所获得的时间戳，可以看看有什么特点： 12345678910111213141516171819#include &lt;stdint.h&gt;#include &lt;sys/time.h&gt;#include &lt;time.h&gt;#include &lt;iostream&gt;#include &lt;chrono&gt;using namespace std;int main()&#123; int64_t t1, t2; while (true) &#123; t1 = chrono::duration_cast&lt;chrono::milliseconds&gt;(chrono::system_clock::now().time_since_epoch()).count(); t2 = time(0); if (t1/1000 != t2) cout &lt;&lt; t1 &lt;&lt; " " &lt;&lt; t2 &lt;&lt; endl; &#125; return 0;&#125; 编译运行结果如下： 1234567891011albert@home-pc:testtime$ g++ testtime.cpp -std=c++11albert@home-pc:testtime$ ./a.out1607779917993 16077799181607779957999 16077799581607780080001 16077800791607780103001 16077801021607780150001 16077801491607780202001 16077802011607780327999 16077803281607780440001 1607780439... 运行之后很快就出现了一些不一致，对比可以发现，两个时间戳一个是毫秒，一个是秒，同时把单位转化成秒来比较时，两者大小不定，从仅有的这几行结果来看，最大的误差是7毫秒。 再加一个时间函数除了上面提到的两个函数，还有一个 gettimeofday() 函数也是在获取时间时常常使用的，把它也放到测试函数中对比一下： 1234567891011121314151617181920212223#include &lt;stdint.h&gt;#include &lt;sys/time.h&gt;#include &lt;time.h&gt;#include &lt;iostream&gt;#include &lt;chrono&gt;using namespace std;int main()&#123; int64_t t1, t2, t = 0; struct timeval tv; while (true) &#123; t1 = chrono::duration_cast&lt;chrono::milliseconds&gt;(chrono::system_clock::now().time_since_epoch()).count(); t2 = time(0); gettimeofday(&amp;tv, NULL); if (t1/1000 != t2 || t2 != tv.tv_sec) if (t != t1) cout &lt;&lt; t1 &lt;&lt; " " &lt;&lt; t2 &lt;&lt; " " &lt;&lt; tv.tv_sec &lt;&lt; "," &lt;&lt; tv.tv_usec &lt;&lt; endl; t = t1; &#125; return 0;&#125; 运行后查看结果： 1234567891011121314151617181920albert@DESKTOP-6746UC3:/mnt/d/data/cpp/testtime$ g++ testtime.cpp --std=c++11albert@DESKTOP-6746UC3:/mnt/d/data/cpp/testtime$ ./a.out1607876993000 1607876992 1607876993,21607876994000 1607876993 1607876994,31607876995000 1607876994 1607876995,31607876996000 1607876995 1607876996,21607876997000 1607876996 1607876997,11607876998000 1607876997 1607876998,21607876999000 1607876998 1607876999,21607877000000 1607876999 1607877000,31607877001000 1607877000 1607877001,11607877002000 1607877001 1607877002,31607877003000 1607877002 1607877003,21607877004000 1607877003 1607877004,21607877005000 1607877004 1607877005,11607877006000 1607877005 1607877006,31607877007000 1607877006 1607877007,21607877008000 1607877007 1607877008,111607877009000 1607877008 1607877009,3... 真是各不相同，这要是在发射火箭时混用两个时间函数，那估计探月卫星就凉凉了…… 总结 常用来获取时间戳的函数有 time()、chrono::system_clock::now() 和 gettimeofday() 时间函数不要混用，否则会给精密计算带来巨大的麻烦，造成计算结果的不可控 测试发现 chrono::system_clock::now() 和 gettimeofday() 时间非常接近，有微秒级别的误差，但也不建议混用 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 有的人走了只留下一撮灰烬，有的人离开却千古留名，但在时间长河中就是那么一瞬，意义何在，有差吗？ 2020-12-14 00:12:01]]></content>
      <tags>
        <tag>C++</tag>
        <tag>时间</tag>
        <tag>time</tag>
        <tag>system_clock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++中有符号数隐式类型转换成无符号数需注意的问题]]></title>
    <url>%2Fblog%2F2020%2F12%2F07%2FC-C-%E4%B8%AD%E6%9C%89%E7%AC%A6%E5%8F%B7%E6%95%B0%E9%9A%90%E5%BC%8F%E7%B1%BB%E5%9E%8B%E8%BD%AC%E6%8D%A2%E6%88%90%E6%97%A0%E7%AC%A6%E5%8F%B7%E6%95%B0%E9%9C%80%E6%B3%A8%E6%84%8F%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[前言隐式类型转换转换是一个挺基础的概念，即使对于初学者来说都不会陌生，一般情况下是指数据类型的转换是由编译系统自动进行的，不需要人工干预的类型转换方式。与之相对的是强制类型转换，在进行转换时必须使用强制类型转换运算符进行转换，这种也被称为显式转换。 举例隐式转换12short sn = 999;int n = sn; 显示转换12float f = 110.741f;int n = (int)f; 这两种转换方式平时经常用到，不管是函数传参时进行转换，还是数学计算时进行强转，一直也没有发现有什么问题，直到昨天遇到了一个有符号数隐式转换成无符号数时，才发现这里也是一个知识盲点，当时脑瓜儿嗡嗡的，怎么连隐式类型转换也这么陌生了呢？ 其实隐式类型转换一般发生在小类型转换成大类型时，有个常用的关系链 char -&gt; short -&gt; int -&gt; long -&gt; float -&gt; double，当关系链条中出现无符号数字时，情况有些难以理解了（实际上是有符号数字的锅）。 问题看一下这几行代码，如果你能准确说出程序的输出值，那么你已经掌握了这个知识点，后面的内容可以不用看了： 1234567891011#include &lt;iostream&gt;using namespace std;int main()&#123; char c = 128; unsigned int n = c; cout &lt;&lt; n &lt;&lt; endl; return 0;&#125; 这段代码的输出值是 4294967168，发生了啥？也就是说老板给你发工资时，本来想发128块，但是发工资的函数参数是 unsigned int 类型的，结果就给你发了 4294967168，一下就实现了40多个小目标。 查找原因针对上面的代码我们改写一下，把变量 c 换成无符号类型： 1234567891011#include &lt;iostream&gt;using namespace std;int main()&#123; unsigned char c = 128; unsigned int n = c; cout &lt;&lt; n &lt;&lt; endl; return 0;&#125; 这次的输出值变成了 128, 符合我们的预期，回过头来再看看刚才出错的代码，区别就是变量c是否有符号，结果差了好几十亿。 这里导致结果差异的原因实际上是符号位引起的，如果是无符号数字，从小类型到大类型隐式类型转换的结果数字都不会变，但是如果是有符号的数字，在转换成大类型数字的时候就要考虑符号位了，就以第一段代码为例来解释这个现象。 char c = 128; 这一句实际上已经超出了变量 c 的范围，因为变量c是有符号数字，所以它的范围是-128~127，这里赋值成128，实际在内存中的bit排列是 10000000，而有符号数的第一位bit表示正负号，这里是1表示这是一个负数，计算机存储负数是以补码的形式存储的，那么把这个数据按位取反再加1，得到 1000000 还是原来的数字，好神奇哦！ 不过这里就可以计算出 c 实际上代表-128，那么它在隐式类型转换成更大的有符号数字时，需要保证值不变，一个int的-128怎么表示呢？根据补码的定义应该是11111111 11111111 11111111 10000000，这个数字再转换成 unsigned int 就是前面提到的 4294967168 啦。 总结 有符号数字在转换成范围更大的无符号数字时需要注意转换所得数值是否正确，失之毫厘差之千里。 总结一个规律，有符号的整形数字在进行隐式类型转换时实际上是在数字的二进制表示前面补充符号位。 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 一个人不能做完所有的事情，但是所有人都可以做一些事情，怕什么真理无穷，进一寸有进有一寸的欢喜~ 2020-12-8 00:04:05]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>符号</tag>
        <tag>隐式类型</tag>
        <tag>转换</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单聊聊01世界中编码和解码这对磨人的小妖儿]]></title>
    <url>%2Fblog%2F2020%2F11%2F28%2F%E7%AE%80%E5%8D%95%E8%81%8A%E8%81%8A01%E4%B8%96%E7%95%8C%E4%B8%AD%E7%BC%96%E7%A0%81%E5%92%8C%E8%A7%A3%E7%A0%81%E8%BF%99%E5%AF%B9%E7%A3%A8%E4%BA%BA%E7%9A%84%E5%B0%8F%E5%A6%96%E5%84%BF%2F</url>
    <content type="text"><![CDATA[前言在程序员生活的01世界中有两大Boss级难题，分别是缓存失效和命名问题，对比这两大难题来说，编码和解码只能算是小妖儿了，只不过这两个小妖儿出镜率很高，有时确实很磨人的，得多花些时间捋顺一下。 编码问题不仅仅出现在计算机中，广义的说，编码问题涉及到人类社会的方方面面，比如古人规定指定长度是一寸，然后规定十寸为一尺，其实就是当时人们对长度的一种编码，但是由于每个地方的编码不统一，导致人们在交流的时候出现了很多问题，直到秦始皇统一了文字、度量衡，相当于统一了描述当时社会的编码，使得知识和文明得以快速传播。 计算机中的编码今天想说的编码和解码特指计算中使用的编码和解码，通俗点说：编码是给计算机看的，解码是为了让人能看懂的。可能大家对这句话还不太理解，不过没关系，这个说法本身不太严谨，也可以举出一些反例，但是大部分情况下确实是这样的。 为什么要编码，想想谍战片里近代社会中的发电报过程，滴答、滴滴答、滴滴滴答答就这个样子，怎么来表达“敌人发动进攻了”，这时候就用到了编码，提前约定好“滴答”代表“敌”，“滴滴答”代表“人”，这样在收到“滴答、滴滴答”你就知道了“敌人”这个信息，那个密码本记录的内容和规则其实就是对所有电传信息的一种编码。 计算机中的编码也是一样的，从我们开始接触到计算机的时候就听说过计算机只认识0和1，虽然现代计算机技术发展迅速，但是计算机只认识0和1这一点一直未变，所以你想让他看懂你的信息，保存你的数据，就要把这些信息和数据编码成0和1，计算机才能进行处理和存储。 所以计算机中为什么要对数据进行编码，这里可以给一个狭义的理解：计算机编码是为了让数据便于传输、存储和处理。 那有为什么要进行解码呢？其实就是为了人能看懂，给你一串二进制 01010111100011111111...，相信你即使有最强大脑也不能迅速把所有数据解开，这可能是一篇优美的散文、一幅美丽的图画，或者是一部励志的电影，这一切都需要解码后才能知道。 本来想画一幅“编码”和“解码”这两个小妖的画像，但是作为灵魂画手的我还没构思好，此处留空，后面补充。。。 补上了&gt;&gt; 初识编码问题自从接触计算机就开始接触编码问题，比如你抄同学发来的作业文档，打开后却发现是一堆乱码，那时仅仅知道是编码错了，但是不知道怎么解决，或者直接让同学再发一份算了，后来在工作中需要做游戏多语言版本时才真正开始处理编码问题。 解决第一个编码问题大概是14年，当时做上线游戏的多语言版本、配置文件中的中文保存为 ANSI 编码，相同的配置文件放到日韩的系统上居然变成了其他的含义，查询解决方案决定使用 UTF-8 编码来保存配置文件，所以当时利用工具将所有的配置文件转换成了UTF-8编码，也是那个时候第一次接触到了Python，转换之后将其中的中文翻译成日韩的语言，从此知道了 UTF-8 这个编码方式，也清楚了在中日韩、越南、缅甸这个圈做产品，千万要远离 ANSI 编码。 其实 ANSI 并不是某一种特定的字符编码，而是一个编码集合，在不同的系统中，可以表示不同的编码，比如英文系统中的 ASCII编码，简体中文系统中的 GBK编码，韩文系统中 EUC-KR 编码等等 编码变迁小八卦计算机是美国人发明用于科学计算的，所以他们也是第一批考虑编码的，而英文只有26个字母，所以他们发明了ASCII码，只使用了0-127这128个空间就表示了所有可能用的字符，但后来计算机技术飞速发展，已经不仅仅用于科学计算，已经融入到社会的方方面面，并且迅速在全球流行。 随着计算机火遍全球，其它国家发现自己国家经常使用的字符，在 ASCII 码中找不到啊，于是就有人想啊，ASCII 码中的一个字节中不是才用了一半吗，我们使用这个最高位来扩展把，于是很多国家就开始用最高位来扩展这个 ASCII 编码以便能够表示自己国家的一些字符，但是对于我博大精深的中国文化来说，这一个字节远远不够啊，我们的汉字那可就有好几万个，你就给我一个字节，我肯定不干。 既然一个字节搞不定，那我们就用两个字节好了，我们规定一个小于等于127的字符的意义与原来相同，此处为了兼容ASCII码，但两个大于127的字符连在一起时，就表示一个汉字，前一个字节从0xA1用到0xF7，后面一个字节从0xA1到0xFE，我们将常用的6000多汉字在这个范围内定义代码点，并将这种编码方式称为 GB2312。 在 GB2312 这种编码中我们考虑了数学符号、希腊字母、全角标点等等，但是只有简体字没有繁体字啊，这下对面海岸的同胞们不乐意了，自己搞了一套 Big5 编码，用来处理繁体字。 后来随着电脑深入各个领域，常用汉字已经不能满足使用需求了，所以又把 GB2312 编码中没有使用的位置拿出来又进行代码点定义，处理了20000多个汉字，发明了 GBK 编码，但没过多久（2000年）发现还是不够用，又提出了变长的 GB18030 编码，每个字符占用1、2、4个字节。 大统一的Unicode刚刚简单提到了在中日韩这个圈里，每个国家都对 ASCII编码进行了扩充，也就是对 ANSI 编码进行了自己的定义，通常是用两个字节来表示一个文字和符号，这样就出现了一种情况，相同的两个字节在不同的系统上显示了不同的文字，如果每个国家的人只使用自己的语言也是没问题的，但是当中日韩文字混排的时候就出现了问题，这两个字节到底应该转换成中日韩哪个国家的符号呢？ 为了解决这种混乱的局面，大佬们设计了一种名为 Unicode 的字符集，又称万国码或者统一码。Unicode 的诞生是为整合全世界的所有语言文字。理论上任何字符在Unicode中都对应一个值，这个值被称为代码点，通常写成 \uABCD 的格式。 UCS-4 和 UCS-2起初使用两个字节来表示代码点，其取值范围为 \u0000～\uFFFF，这种文字和代码点之间的对应关系被描述为UCS-2，也就是 Universal Character Set Coded in 2 octets 的缩写，最多可以记录65536个字符的代码点。 后来为了能表示更多的文字，人们又提出了UCS-4，即用四个字节表示代码点。它的范围为 \u00000000～\u7FFFFFFF，其中 \u00000000～\u0000FFFF和UCS-2是一样的。 从这里可以看出 UCS-4 与 UCS-2 只是一种扩展的关系，UCS-4 是兼容 UCS-2 的，在 UCS-2 的每个代码点加入两个值为0的字节就变成了 UCS-4。 UCS-2 LE 和 UCS-2 BE这里的 LE 和 BE 指的是计算机中常提到的小端字节序和大端字节序，因为 UCS-4 是 UCS-2 的扩展，所以 UCS-4 也存在大端和小端的问题。 小端字节序，是指数据的高字节保存在内存的高地址中，而数据的低字节保存在内存的低地址中，而大端字节序，是指数据的高字节保存在内存的低地址中，而数据的低字节保存在内存的高地址中，这和我们平时的阅读习惯一致。 如果没接触过大端和小端可能会有点懵，举个例子就明白了，C++中一个int类型的数字通常占4个字节，假如一个int类型的变量值是256，那么他再内存中是怎样表示的呢？我们知道计算机中除了1就是0，这在计算机中对应一个bit，而计算机中表示数据的单位是字节，每个字节有8个bit大小，那么int变量值 256 翻译成二进制是 00000000 00000000 00000001 00000000 一共占用4个字节。 对照前面大端和小端的定义，这4个字节在内存中如果从高到低排列，就是小端字节序，如果这4个字节在内存中如果从低到高排列，就是大端字节序。因为UCS-2是两个字节表示一个代码点，所以在表示的时候存在字节排列顺序问题，对于值为 256 的这个代码点，可以是0x0100，也可以是0x0001。 Unicode 和 UCS-2Unicode 是一个字符集，这一点应该很好理解，它表示的是字符和代码点的对应关系，比如简体字“汉”对应的Unicode代码点是 \u6C49，而 UCS-2 究竟是一种字符集还是一种编码方式呢？ 我个人偏向于它是一种编码方式，因为它存在大端、小端这种说法，如果是一种字符集只会考虑对应关系，不会考虑字节序，这只是我个人观点，有些软件上确实是这样标注的，但有些文章也会把UCS-2当成一种字符集，这样也能说的通，不用太纠结这里的区别。 其实 UCS-2 编码对应的字符集是UCS，这些是历史原因导致的，一方面国际标准化组织（ISO）于1984年创建ISO/IEC JTC1/SC2/WG2工作组，试图制定一份通用字符集（Universal Character Set，简称UCS），并最终制定了ISO 10646标准。而另一方面统一码联盟，也很想做这个统一编码的武林盟主，由Xerox、Apple等软件制造商于1988年组成，并且开发了Unicode标准。 然后1991年左右，两个项目的参与者都认识到，世界不需要两个不兼容的字符集。于是，它们开始合并双方的工作成果，并为创立一个单一编码表而协同工作。从Unicode 2.0开始，Unicode采用了与ISO 10646-1相同的字库和字码。ISO也承诺，ISO 10646将不会替超出\u10FFFF的UCS-4编码赋值，以使得两者保持一致。两个项目仍都独立存在，并独立地公布各自的标准。不过由于Unicode这一名字名字起的好，比较好记，因而它使用更为广泛。 从这段历史我们可以看到，虽然 UCS-4 将 UCS-2 从2个字节扩展成了4个字节，但是范围并没到使用到 \u00000000～\uFFFFFFFF，而是将范围集中到 \u000000～\u10FFFF 内，保证了 UCS 和 Unicode 各个字符代码点的统一，也奠定了UTF-8实现标准Unicode时最多需要4个字节的基础。 UTF-8 的诞生按理说 Unicode 已经给世界范围内的所有字符定义了代码点，无论是什么字符，使用4个字节都能表示出来，为什么要搞出一个UTF-8呢？是因为使用者发现，对于ASCII码范围内的字符，本来1个字节就能正确表示，现在居然要4个字节表示，即使使用 UCS-2编码，占用的空间也扩大了1倍，有些太浪费了。 为了解决这种空间浪费问题，就出现了一类变长的通用转换格式，即UTF（Universal Transformation Format），常见的UTF格式有：UTF-7，UTF-7.5，UTF-8，UTF-16 以及 UTF-32。 这类格式中最常见的就是 UTF-8 编码了，UTF-8 是针对于 Unicode 字符集中各个代码点的编码方式，是一种 Unicode 字符的实现方式，采用变长字节来表示Unicode编码，最长使用4个字节来表示标准的Unicode代码点，在有些资料中可能会看到5、6个字节的编码方式，这些都是非标准的Unicode代码点，根据规范，这些字节值将无法出现在合法 UTF-8序列中。 Unicode 和 UTF-8UTF-8在对标准Unicode字符编码时最多使用4个字节，其代码点范围与UTF-8编码后的形式对应如下： Unicode/UCS-4（十六进制） 字节数 UTF-8编码格式（二进制） 000000-00007F 1 0xxxxxxx 000080-0007FF 2 110xxxxx 10xxxxxx 000800-00FFFF 3 1110xxxx 10xxxxxx 10xxxxxx 010000-10FFFF 4 11110xxx 10xxxxxx 10xxxxxx 10xxxxxx UTF-8编码示例只看上面这种对应关系，可能还不太清楚是怎样表示，接下来可以举一个例子试一下，比如一个常用的简体中文字——“好”，查询它的Unicode代码点是 \u597D，对照上面的表格发现在 000800-00FFFF 这个范围，应该采用3个字节的表现形式。 先把这个数值翻译成二进制为 0101100101111101，然后按照3个字节的形式分成3组，0101、100101 和 111101，把这些内容天填充到xxx这样的空位中就得到了“好”这个字的UTF-8编码—— 11100101 10100101 10111101，表示成十六进制就是 0xE5A5BD。 这个过程还是比较简单的，其他编码要转换成UTF-8编码都要经过Unicode这一步中转，先通过转换表查到其他编码对应字符的Unicode编码，然后再转换成UTF-8的表示格式。 优点和缺点根据 UTF-8 的编码规则，任何一个 byte 漏传，多传，传错只影响当前字符，前后字符都不受影响，而 Unicode 如果从一个字的中间截断会导致接下来所有的字符解析都是错的，这使得UTF-8编码的数据在不够可靠的网络传输中是有利的。 兼容ASCII，并且是字节顺序无关的。它的字节顺序在所有系统中都是一样的，因此它实际上并不需要BOM，不过在文件开头常常保存 0xEFBBBF 三个字节来表明文件编码是UTF-8。 缺点是因为UTF-8是一种变长编码，无法从直接从Unicode字符直接判断出UTF-8文本的字节数。除了ASCII字符集内的字符，其他情况实际上都增加了固定的头数据，占用了无效空间。 编码和解码在编程中的应用编码和解码在网站页面和数据库存储时用的非常多，一不小心就搞出一堆乱码，这种编码和解码操作在Python3中很直观，Python2中 string 和 bytes 混合在一起，编码和解码操作不太明显，而在python3中 string 和 bytes 是完全不同的两个类型，string编码成bytes，而bytes解码成string。 相比于python3中的编码、解码对应两个类型，C++中的编码和解码操作的前后都是字符串，这在一定程度上会给人造成误解，接下来我们使用Python3来简单测试一下编码和解码操作。 编码操作编码通常是把人类可以理解的字符转换成计算机可以认识二进制数据，这个过程在python3中对应的是把string转化成bytes，测试如下： 12345word = '好好'print(type(word), word)result = word.encode('utf-8')print(type(result), result) 运行结果如下： 12&lt;class &apos;str&apos;&gt; 好好&lt;class &apos;bytes&apos;&gt; b&apos;\xe5\xa5\xbd\xe5\xa5\xbd&apos; 解码操作解码操作通常是把计算机中存储和传输的数据转换成人类能看懂的字符，这个过程在python3中对应的是把bytes转化成string，测试如下： 12345data = b'\xe5\xa5\xbd\xe5\xa5\xbd'print(type(data), data)result = data.decode('utf-8')print(type(result), result) 运行结果如下： 12&lt;class &apos;bytes&apos;&gt; b&apos;\xe5\xa5\xbd\xe5\xa5\xbd&apos;&lt;class &apos;str&apos;&gt; 好好 乱码产生从上面的两个例子来看编码和解码非常简单，那怎么还能出现乱码呢？计算机说到底还是一种工具，你在把可见字符编码后交给计算机存储和传输时，你要记住这些二进制的编码方式，在你想看这些数据时还要用相反的方式进行解码，否则就会出现乱码，比如下面这种使用 utf-8 编码，却使用 gbk 这种方式来解码，就得不到你想要的数据。 12345678word = '好好'print(type(word), word)result = word.encode('utf-8')print(type(result), result)new_word = result.decode('gbk')print(type(new_word), new_word) 运行结果如下： 123&lt;class &apos;str&apos;&gt; 好好&lt;class &apos;bytes&apos;&gt; b&apos;\xe5\xa5\xbd\xe5\xa5\xbd&apos;&lt;class &apos;str&apos;&gt; 濂藉ソ 虽然结果是可以看得见的字符，但是这不是我们想要的数据，所以 濂藉ソ 对于我们来说也是一种乱码，在处理字符编码时我们必须清楚知道要用什么方式来进行编码和解码，如果编码和解码的方式不一致，那么就会产生乱码现象。 总结 Unicode 是一种字符集，描述了人类范围内用于交流的所有字符的代码点，给与唯一的数字进行对应 Unicode 规定的代码点范围是 \u000000-\u10FFFF，这与 UCS-4 规定的范围达成了统一，共定义了17个Plan UTF-8 是Unicode字符集的一种实现，采用变长的方式，标准规范最多使用4个字节表示一个Unicode字符 编码是为了把人类用来交流的字符转换成二进制数据便于存储和传输 解码是为了把存储在计算机中的二进制数据转换成人们能看得懂的字符 编码和解码不一致时就会造成乱码，比如使用UTF-8编码，使用GBK来解码就会造成乱码现象 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 对未知的事物充满恐惧，过于保守的看待当下的一切，有时候太稳反而会失去很多~ 2020-11-29 19:23:13]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>编码</tag>
        <tag>解码</tag>
        <tag>encode</tag>
        <tag>decode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下使用netstat命令查看网络信息]]></title>
    <url>%2Fblog%2F2020%2F11%2F22%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E4%BD%BF%E7%94%A8netstat%E5%91%BD%E4%BB%A4%E6%9F%A5%E7%9C%8B%E7%BD%91%E7%BB%9C%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[前言netstat 这个命令一直以为是 net status 的缩写，今天一查发现并没有找到官方的这种说法，然后参考了 man 手册，发现这个词更像是 net statistics 的缩写，命令的作用是显示网络连接、路由表、接口连接、无效连接和多播成员关系的，man 手册中描述这个命令如下： netstat - Print network connections, routing tables, interface statistics, masquerade connections, and multicast memberships 这个命令很强大，但是我经常使用的参数很简单，通常用来查询端口占用问题，命令为 netstat -anp | grep xxxPORT，因为在我测试自己项目程序的时候，总有一些进程企图占用我使用的端口，比如那个 被我 kill 了 n 次的 TIM 客户端，使用 netstat 可以方便的找到是哪个进程占用了你的端口。 虽然这个命令经常使用，但是其中的这些参数含义却不是很清楚，所以特地总结一下，综合其他常见的用法，记录下来以备后续查找使用。 参数选项 -a：显示所有连接，包括 LISTEN 状态的连接 -l：仅显示 LISTEN 状态的连接 -t：仅显示tcp相关选项 -u：仅显示udp相关选项 -n：拒绝显示别名，能显示数字的全部转化成数字 -o：显示信息中包括与网络计时器相关的信息 -e：显示扩展信息，例如uid等 -p：显示建立相关链接的程序名 -r：显示路由信息，路由表 -s：按各个协议进行统计 -c：每隔一个固定时间，执行该netstat命令。 无参数执行该命令无参数执行时显示数据会少一些，便于我们看清命令执行的结果，内容如下： 123456789101112131415161718[root@node1 ~]# netstatActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 192.168.0.201:ssh 178.129.126.124.b:19450 ESTABLISHEDtcp 0 52 192.168.0.201:ssh 178.129.126.124.b:17626 ESTABLISHEDtcp 0 0 192.168.0.201:57784 101.200.35.175:https TIME_WAITtcp 0 0 192.168.0.201:42298 100.125.2.72:https ESTABLISHEDActive UNIX domain sockets (w/o servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 11550 /run/systemd/shutdowndunix 2 [ ] DGRAM 13355412 /var/run/chrony/chronyd.sockunix 3 [ ] DGRAM 1228 /run/systemd/notifyunix 2 [ ] DGRAM 1230 /run/systemd/cgroups-agentunix 5 [ ] DGRAM 1241 /run/systemd/journal/socketunix 16 [ ] DGRAM 1243 /dev/logunix 3 [ ] STREAM CONNECTED 15663unix 3 [ ] STREAM CONNECTED 15662... 输出结果可以分为 Active Internet connections 和 Active UNIX domain sockets 两个部分： Active Internet connections 指有效的网络连接，默认显示6列内容： Proto：协议名字，包括tcp, udp, udpl, raw等 Recv-Q：表示网络接收队列，表示收到的数据已经在本地接收缓冲，还有多少没有被应用程序取走 Send-Q：表示网络发送队列，表示存在本地缓冲区，但对方没有收到的数据或者没有 ACK 的 Local Address：本地IP地址和端口 Foreign Address：外部IP地址和端口 State：网络连接状态，包括 ESTABLISHED、SYN_SENT、SYN_RECV、FIN_WAIT1、FIN_WAIT2、TIME_WAIT、CLOSE、CLOSE_WAIT、LAST_ACK、LISTEN、CLOSING、UNKNOWN 等状态 Active UNIX domain sockets 是指本地套接口，我们知道 socket 也可用于同一台主机的进程间（IPC）通讯，但是 socket 用于IPC更有效率：不需要经过网络协议栈，不需要打包拆包、计算校验和、维护序号和应答等，只是将应用层数据从一个进程拷贝到另一个进程并且它是是全双工的，API接口语义丰富，相比其它进程间通信机制有明显的优越性。 常用命令组合查询端口占用12[root@node1 /]# netstat -anp | grep 8889tcp 0 0 0.0.0.0:8889 0.0.0.0:* LISTEN 27584/tinyproxy 这是我目前最常用的命令，在windows可以改为 netstat -ano | findstr 8889 显示tcp连接123456789101112[root@node1 /]# netstat -atActive Internet connections (servers and established)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 0.0.0.0:ddi-tcp-2 0.0.0.0:* LISTENtcp 0 0 localhost:smtp 0.0.0.0:* LISTENtcp 0 0 0.0.0.0:ssh 0.0.0.0:* LISTENtcp 0 52 192.168.0.201:ssh 178.129.126.124.b:19450 ESTABLISHEDtcp 0 0 192.168.0.201:ssh 178.129.126.124.b:17626 ESTABLISHEDtcp 0 0 192.168.0.201:42298 100.125.2.72:https ESTABLISHEDtcp6 0 0 [::]:squid [::]:* LISTENtcp6 0 0 localhost:smtp [::]:* LISTENtcp6 0 0 [::]:ssh [::]:* LISTEN 显示处于 LISTEN 状态的端口123456789101112131415161718192021[root@node1 /]# netstat -lActive Internet connections (only servers)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 0 0.0.0.0:ddi-tcp-2 0.0.0.0:* LISTENtcp 0 0 localhost:smtp 0.0.0.0:* LISTENtcp 0 0 0.0.0.0:ssh 0.0.0.0:* LISTENtcp6 0 0 [::]:squid [::]:* LISTENtcp6 0 0 localhost:smtp [::]:* LISTENtcp6 0 0 [::]:ssh [::]:* LISTENudp 0 0 0.0.0.0:bootpc 0.0.0.0:*udp 0 0 0.0.0.0:ntp 0.0.0.0:*udp 0 0 localhost:323 0.0.0.0:*udp 0 0 0.0.0.0:56034 0.0.0.0:*udp6 0 0 [::]:42035 [::]:*udp6 0 0 localhost:323 [::]:*Active UNIX domain sockets (only servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ACC ] STREAM LISTENING 11533 /run/lvm/lvmpolld.socketunix 2 [ ACC ] STREAM LISTENING 6848304 /var/run/rpcbind.sockunix 2 [ ACC ] STREAM LISTENING 11584 /run/lvm/lvmetad.socket... 分类统计每种协议的信息1234567891011121314151617181920212223242526272829303132333435363738394041[root@node1 /]# netstat -sIp: 7902622 total packets received 60675 forwarded 127 with unknown protocol 0 incoming packets discarded 7841813 incoming packets delivered 7270606 requests sent out 8 dropped because of missing routeIcmp: 928210 ICMP messages received 25426 input ICMP message failed. InCsumErrors: 8 ICMP input histogram: destination unreachable: 71154 timeout in transit: 484 echo requests: 856165 echo replies: 337 timestamp request: 54 896502 ICMP messages sent 0 ICMP messages failed ICMP output histogram: destination unreachable: 40039 echo request: 244 echo replies: 856165 timestamp replies: 54Tcp: 274517 active connections openings 66347 passive connection openings 187800 failed connection attempts 90950 connection resets received 3 connections established 6359177 segments received 5808198 segments send out 494062 segments retransmited 4 bad segments received. 452720 resets sentUdp: 539313 packets received 14902 packets to unknown port received.... 每秒显示一次信息12345678910[root@node1 /]# netstat -cActive Internet connections (w/o servers)Proto Recv-Q Send-Q Local Address Foreign Address Statetcp 0 52 192.168.0.201:ssh 178.129.126.124.b:19450 ESTABLISHEDtcp 0 0 192.168.0.201:ssh 178.129.126.124.b:17626 ESTABLISHEDtcp 0 0 192.168.0.201:42298 100.125.2.72:https ESTABLISHEDActive UNIX domain sockets (w/o servers)Proto RefCnt Flags Type State I-Node Pathunix 2 [ ] DGRAM 11550 /run/systemd/shutdownd... 显示核心路由信息1234567[root@node1 /]# netstat -rKernel IP routing tableDestination Gateway Genmask Flags MSS Window irtt Ifacedefault 192.168.0.1 0.0.0.0 UG 0 0 0 eth0169.254.169.254 192.168.0.254 255.255.255.255 UGH 0 0 0 eth0172.17.0.0 0.0.0.0 255.255.0.0 U 0 0 0 docker0192.168.0.0 0.0.0.0 255.255.255.0 U 0 0 0 eth0 显示网络接口列表123456[root@node1 /]# netstat -iKernel Interface tableIface MTU RX-OK RX-ERR RX-DRP RX-OVR TX-OK TX-ERR TX-DRP TX-OVR Flgdocker0 1500 36248 0 0 0 33647 0 0 0 BMUeth0 1500 9119246 0 0 0 8277212 0 0 0 BMRUlo 65536 27700 0 0 0 27700 0 0 0 LRU 总结 netstat -anp | grep 8889 命令可用于查询8889端口被哪个进程占用了，在Windows上翻译为 netstat -ano | findstr 8889 netstat 命令查询出的网络连接信息中，Recv-Q 和 Send-Q 通常应该为0，如果长时间不为0可能是有问题的，需要尽快排查 如果 Recv-Q 数值一直处于不为0的状态，可能是遭受了拒绝服务 DOS 攻击，导致本地消息处理过慢 如果 Send-Q 数值一直处于不为0的状态，可能是有应用向外发送数据包过快，或者是对方接收处理数据包不够快 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 以史为鉴可以知兴替，以铜为鉴可以正衣冠，以人为鉴可以明得失。人的成长需要对比，总有人比你更加优秀~ 2020-11-23 01:17:59]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>linux</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[学习cmake从成功编译一个小程序开始]]></title>
    <url>%2Fblog%2F2020%2F11%2F14%2F%E5%AD%A6%E4%B9%A0cmake%E4%BB%8E%E6%88%90%E5%8A%9F%E7%BC%96%E8%AF%91%E4%B8%80%E4%B8%AA%E5%B0%8F%E7%A8%8B%E5%BA%8F%E5%BC%80%E5%A7%8B%2F</url>
    <content type="text"><![CDATA[前言在 Windows上开发我使用最多的IDE还是 Visual Studio，编写、编译一条龙服务，导致了不少编译流程知识的缺失，这种大型的IDE确实好用，诸多配置通过在界面上勾选一下就可以了，但是在编译细节的掌握上还是漏掉了一些知识。 在 linux 开发环境下通常会使用 gcc 或者 g++ 进行编译，可是编译选项有点多，当工程非常大的时候需要写的编译参数太多了，这时可以使用make命令来帮助我们编译 C++ 程序，编译时依赖一些规则，这些规则就写在一个叫 Makefile 的文件中。 后来发现写 Makefile 还是太麻烦了，这个文件也相当大。于是“懒惰”的程序员们又开发出了各种各样的工具用来生成 Makefile 文件，我使用过的目前就只有 automake 和 cmake。 生成Makefile之前使用的生成 Makefile 文件的工具是 automake，被称为是“八股文”一样的操作，每次操作都是固定的几个步骤，比如每次都要运行 autoscan、aclocal、autoconf、automake、./confiugre等命令，需要个人发挥的地方并不多，之前使用的时候也不是完全从0开始一点点写的，往往是写一个项目模板之后，对照着在Makefile.am文件中修改几个参数就好了。 现在新的工作内容中使用 cmake 来生成 Makefile，这个 cmake 之前还确实接触过一些，大概是2012年的时候，那时在编译 OpenCV 库还有增强现实插件的时候用过几次，当时感觉安装起来太麻烦了，对那个红绿蓝的图标记忆犹新，感觉和当时的新闻联播的图标有些亲戚关系。 其实当时根本分不清什么是编译器，什么是 Makefile，对于各种库文件的编译完全是按照文档来操作，现在回过头来看看 cmake 生成 Makefile 还是比较简单的，最起码要比 automake 省了很多步骤，只要编写一个 CMakeLists.txt 文件就好了。 编写CMakeLists.txt生成Makefile为了练习使用编写CMakeLists.txt生成Makefile，进而编译C++项目，我们可以从头来实现一个小例子，目标是编写一个计算加法的静态库和一个计算减法静态库，然后实现一个测试工程来使用这两个函数库，整个工程使用 cmake 来生成 Makefile，然后使用 make 命令完成编译。 实现简单的代码文件加法和减法都是常用的简单计算，用来举例子很容易理解，接下来展示要用到的几个文件内容，每个文件只有几行，只为了说明问题，文件内容如下： 123//myadd.hint add(int a, int b); 1234567//myadd.cpp#include "myadd.h"int add(int a, int b) &#123; return a + b;&#125; 123//mysub.hint sub(int a, int b); 1234567//mysub.cpp#include "mysub.h"int sub(int a, int b) &#123; return a - b;&#125; 123456789101112//test.cpp#include "myadd.h"#include "mysub.h"#include &lt;iostream&gt;int main() &#123; std::cout &lt;&lt; "happy birthday!" &lt;&lt; std::endl; std::cout &lt;&lt; "519 + 1 = " &lt;&lt; add(519, 1) &lt;&lt; std::endl; std::cout &lt;&lt; "1320 - 6 = " &lt;&lt; sub(1320, 6) &lt;&lt; std::endl; return 0;&#125; 使用常规方法编译首先使用最简单 g++ 命令来编译这个样例程序： 查看目录下文件 12albert@home-pc:testcmake$ lsmyadd.cpp myadd.h mysub.cpp mysub.h test.cpp 将 myadd.h 和 myadd.cpp 编译成静态库 libmyadd.a 12345albert@home-pc:testcmake$ g++ -c myadd.cppalbert@home-pc:testcmake$ ar crv libmyadd.a myadd.oa - myadd.oalbert@home-pc:testcmake$ lslibmyadd.a myadd.cpp myadd.h myadd.o mysub.cpp mysub.h test.cpp 将 mysub.h 和 mysub.cpp 编译成静态库 libmysub.so 1234albert@home-pc:testcmake$ g++ -c mysub.cppalbert@home-pc:testcmake$ g++ -shared -fPIC -o libmysub.so mysub.oalbert@home-pc:testcmake$ lslibmyadd.a libmysub.so myadd.cpp myadd.h myadd.o mysub.cpp mysub.h mysub.o test.cpp 编译链接静态库 libmyadd.a、动态库 libmysub.so 和测试文件生成可执行程序 test 123albert@home-pc:testcmake$ g++ test.cpp libmyadd.a -L. -lmysub -o test -Wl,-rpath=.albert@home-pc:testcmake$ lslibmyadd.a libmysub.so myadd.cpp myadd.h myadd.o mysub.cpp mysub.h mysub.o test test.cpp 运行查看结果，成功计算表达式的值 1234albert@home-pc:testcmake$ ./testhappy birthday!519 + 1 = 5201320 - 6 = 1314 使用cmake方式上面展示了最原始的编译方法，每次都要敲这些命令，接下来编写一个 CMakeLists 文件，使用 cmake 生成Makefile，以后只要运行 make 命令就可以完成编译了。 调整一下目录结构如下： 123456789albert@home-pc:testcmake$ tree.|-- myadd| |-- myadd.cpp| `-- myadd.h|-- mysub| |-- mysub.cpp| `-- mysub.h`-- test.cpp 进入 myadd 目录新建 CMakeLists.txt 编写内容如下： 1234aux_source_directory(. SRC_LIST) #将此目录的源文件集合设置为变量SRC_LISTadd_library(myadd STATIC $&#123;SRC_LIST&#125;) #库的名称，库的类型，静态库的源文件列表set(LIBRARY_OUTPUT_PATH $&#123;PROJECT_SOURCE_DIR&#125;/lib) #库的输出路径为根目录下的lib文件夹 进入 mysub 目录新建 CMakeLists.txt 编写内容如下： 1234aux_source_directory(. SRC_LIST) #将此目录的源文件集合设置为变量SRC_LISTadd_library(mysub SHARED $&#123;SRC_LIST&#125;) #库的名称，库的类型，动态库的源文件列表set(LIBRARY_OUTPUT_PATH $&#123;PROJECT_SOURCE_DIR&#125;/lib) #库的输出路径为根目录下的lib文件夹 在工程主目录下新建 CMakeLists.txt 编写内容如下： 12345678910111213141516171819202122232425262728293031323334# 指定cmake版本cmake_minimum_required(VERSION 3.5)# 指定项目的名称，一般和项目的文件夹名称对应project(testcmake)# 指定子目录add_subdirectory(myadd)add_subdirectory(mysub)# 添加c++ 11标准支持set(CMAKE_CXX_FLAGS "-std=c++11" )# 特殊宏，之前编译mysqlcppconn8用到过add_definitions(-DGLIBCXX_USE_CXX11_ABI)# 头文件目录include_directories(myadd mysub)# 源文件目录aux_source_directory(. DIR_SRCS)# 设置环境变量，编译用到的源文件全部都要放到这set(TEST_MATH $&#123;DIR_SRCS&#125;)# 库文件目录link_directories(lib)# 添加要编译的可执行文件add_executable($&#123;PROJECT_NAME&#125; $&#123;TEST_MATH&#125;)# 添加可执行文件所需要的库target_link_libraries($&#123;PROJECT_NAME&#125; myadd)target_link_libraries($&#123;PROJECT_NAME&#125; mysub) 新建build目录和lib目录，整个工程目录关系如下： 12345678910111213141516albert@home-pc:testcmake$ tree.|-- CMakeLists.txt|-- build|-- lib|-- myadd| |-- CMakeLists.txt| |-- myadd.cpp| `-- myadd.h|-- mysub| |-- CMakeLists.txt| |-- mysub.cpp| `-- mysub.h`-- test.cpp4 directories, 8 files 进入 build 目录下依次运行 cmake .. 和 make 命令 123456789101112131415161718192021222324252627282930313233343536albert@home-pc:testcmake/build$ cmake ..-- The C compiler identification is GNU 5.4.0-- The CXX compiler identification is GNU 5.4.0-- Check for working C compiler: /usr/bin/cc-- Check for working C compiler: /usr/bin/cc -- works-- Detecting C compiler ABI info-- Detecting C compiler ABI info - done-- Detecting C compile features-- Detecting C compile features - done-- Check for working CXX compiler: /usr/bin/c++-- Check for working CXX compiler: /usr/bin/c++ -- works-- Detecting CXX compiler ABI info-- Detecting CXX compiler ABI info - done-- Detecting CXX compile features-- Detecting CXX compile features - done-- Configuring done-- Generating done-- Build files have been written to: testcmake/buildalbert@home-pc:testcmake/build$ makeScanning dependencies of target mysub[ 16%] Building CXX object mysub/CMakeFiles/mysub.dir/mysub.cpp.o[ 33%] Linking CXX shared library ../../lib/libmysub.so[ 33%] Built target mysubScanning dependencies of target myadd[ 50%] Building CXX object myadd/CMakeFiles/myadd.dir/myadd.cpp.o[ 66%] Linking CXX static library ../../lib/libmyadd.a[ 66%] Built target myaddScanning dependencies of target testcmake[ 83%] Building CXX object CMakeFiles/testcmake.dir/test.cpp.o[100%] Linking CXX executable testcmake[100%] Built target testcmakealbert@home-pc:testcmake/build$ ./testcmakehappy birthday!519 + 1 = 5201320 - 6 = 1314albert@home-pc:testcmake/build$ 至此，使用cmake方式编译工程的例子就写完了。 总结 cmake 和 automake 本身不提供编译功能，只是可以按照编写的 CMakeLists.txt 文件生成 Makefile make 可以根据 Makefile 文件调用 gcc/g++ 命令对源代码进行编译工作 -Wl,-rpath=. 这个选项可以指定可执行文件查找动态库的路径，感觉比 export LD_LIBRARY_PATH 要方便一点 -DGLIBCXX_USE_CXX11_ABI 这个宏可坑了我不少时间，编译使用libmysqlcppconn8的时候，如果不禁用会报编译错误 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 有你，真好~ 2020-11-15 23:55:35]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>编译</tag>
        <tag>linux</tag>
        <tag>cmake</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下sed命令的基础用法]]></title>
    <url>%2Fblog%2F2020%2F11%2F07%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8Bsed%E5%91%BD%E4%BB%A4%E7%9A%84%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前言每次看到sed这个词就想起“种子”，心里明知道是把它和seed弄混了，但是先入为主的思想怕是改不过来了，不过现在还好，虽然把第一印象的意思弄错了，但还是很快能反应过来这是一个很“厉害”的linux命令，也有一些网友评论到，每次看到这个命令就双腿发抖，我虽然没抖，但是谈到这个命令还是有些挠头，心里有些发怵。 一味地逃避困难是不可取的，虽然心里感觉这是个很难的命令，但是今天还是要硬着头皮学一下，边学边记录，易于下次复习，那些打败不了我的困难终将使我更加强大。 sed功能其实sed并不是一个单词，而是 stream editor 的缩写，本意为面向字符流的编辑器，说白了sed就是用来编辑文件的命令，编辑文件是我们每天经常做的工作，但是如果每天的编辑工作都类似，我们就要考虑使用sed工具来提高工作效率了，比如说把今天新增的100个文件的第一行都加上版本信息，虽然手动编辑也能做，但是你想体验一下敲个命令瞬间搞定这件事情的快感吗，我们来学习sed命令吧？ 命令格式1sed [OPTION]... &#123;script-only-if-no-other-script&#125; [input-file] sed 的选项不是太多，最常用的有下面两种形式： sed -e &#39;sed命令脚本&#39; input-file sed -f &#39;sed命令脚本文件&#39; input-file 命令选项 -e ：命令行模式，选项后直接跟sed编辑脚本，在只有一组脚本的情况下可以省略 -f ：脚本文件模式，选项后跟写有sed编辑脚本的文件名，运行后会执行脚本文件内的编辑动作 -i ：直接修改文件内容，如果不加这个选项是不修改源文件的，只将修改后的文件输出 -n ：只打印模式匹配的行，便于查看所作修改 以上列举只是一些常见选项，还有些比如 -l 指定每行长度，-s 指定换行的分隔符等等，用到了再来分析学习。 寻找匹配既然是编辑文件，首先要找到需要编辑的位置，在sed命令中可以使用行号，或者字符查找等方式找到需要修改的位置，然后再执行编辑动作，常见的范围： x：指定的行号，表示第x行 x,y：指定的行号范围，表示第x行到y行 /pattern：查询到包含指定模式的行 x,y!：指定的行号范围，表示不包括第x行到y行 sed操作sed几乎可以实现文件的所有编辑工作，接下来尝试一些常见的用法： 打印内容使用编辑命令 p，可以向匹配行后面插入内容。 打印文件第2行和第3行的内容，命令为sed -n &#39;2,3p&#39; data.txt 123456789albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed -n '2,3p' data.txtabcxyz 追加内容使用编辑命令 a，可以向匹配行后面插入内容。 在第2行后面添加文本newline，命令为sed &#39;2anewline&#39; data.txt 12345678910111213albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed '2anewline' data.txt1234abcnewlinexyz1==123 在最后一行后面添加文本endline，命令为sed &#39;$aendline&#39; data.txt 1234567891011121314albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed '$aendline' data.txt1234abcxyz1==123endlinealbert@DESKTOP-6746UC3:/mnt/d/data/shell$ 插入内容使用编辑命令 i，可以在匹配的那一行插入内容。 在第1行插入文本firstline，命令为sed &#39;1ifirstline&#39; data.txt 12345678910111213albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed '1ifirstline' data.txtfirstline1234abcxyz1==123 在包含文本 “123” 的行插入文本insertline，命令为sed &#39;/123/iinsertline&#39; data.txt 1234567891011121314albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed '/123/iinsertline' data.txtinsertline1234abcxyz1==insertline123 更改行内容使用编辑命令 c，可以修改匹配行的内容。 将包含文本 “123” 的行替换为 “456”，命令为sed &#39;/123/c456&#39; data.txt 123456789101112albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed '/123/c456' data.txt456abcxyz1==456 将3、4、5行内容更改为newworld，命令为sed &#39;3,5cneworld&#39; data.txt 12345678910albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed '3,5cneworld' data.txt1234abcneworld 替换行内容使用编辑命令 s，可以替换匹配行的内容，需要注意和 c 的区别，c 是整行的内容都改变，而 s 是只替换命令中指定的部分。 将文件中的文本 “123” 替换为 “456”，命令为sed &#39;s/123/456/g&#39; data.txt 123456789101112albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed 's/123/456/g' data.txt4564abcxyz1==456 综合运用 删除空行并给所有内容是 “123” 的文本加上小括号 12345678910111213albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed -e 's/123/(&amp;)/g' -e '/^$/d' data.txt(123)4abcxyz1==(123) 删除内容使用编辑命令 c，可以删除匹配行。 删除空行，命令为sed &#39;/^$/d&#39; data.txt 12345678910111213albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed '/^$/d' data.txt1234abcxyz1==123 从第一行开始，每两行删除掉一行，命令为sed &#39;1~2d&#39; data.txt 123456789albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed '1~2d' data.txtabc1== 删除2行和3行以外的行，命令为sed &#39;2,3!d&#39; data.txt 123456789albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed '2,3!d' data.txtabcxyz 删除指定行数范围内的匹配行，命令为sed &#39;1,3{/123/d}&#39; data.txt 1234567891011albert@DESKTOP-6746UC3:/mnt/d/data/shell$ cat data.txt1234abcxyz1==123albert@DESKTOP-6746UC3:/mnt/d/data/shell$ sed '1,3&#123;/123/d&#125;' data.txtabcxyz1==123 总结 sed 是 stream editor 的缩写，表示为面向字符流的编辑器 sed 命令常用的几个选项，-e、-f、-i、-n sed 命令常用的几个编辑动作，也就是选项后的常用命令有 p（打印）、a（追加）、i（插入）、c（改变）、s（替换）、d（删除） ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 不能打败我的困难终将使我更加强大，绊不倒我的石头最后只会被拿来踩踏，拥抱一个个困难，生活本来就是一条打怪升级之路，那有什么一帆风顺~ 2020-11-7 22:47:01]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>sed</tag>
        <tag>文件</tag>
        <tag>编辑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于数据一致性的思考]]></title>
    <url>%2Fblog%2F2020%2F10%2F24%2F%E5%85%B3%E4%BA%8E%E6%95%B0%E6%8D%AE%E4%B8%80%E8%87%B4%E6%80%A7%E7%9A%84%E6%80%9D%E8%80%83%2F</url>
    <content type="text"><![CDATA[前言也不知道是谁这么有才，居然发明了1024这个程序员的节日，其他的节日都是买买买，唯独这个节日促销活动少的可怜，连早上买菜都是占了第二天重阳节的便宜，除了程序员们自嗨，也没人来给码农们庆祝了。 今天也嗨了一把，程序员的节日必须在工位上，飞速的敲着代码才是对1024最大的尊重，在这一天的结尾之际还是聊聊最近开发中的一些问题，其中数据一致性的问题确实需要梳理一下。 什么是一致性关于一致性常常在两个地方听到，一个是数据库，另一个是分布式，两者都叫一致性，但是含义却不同。 数据库一致性数据库中的一致性其实代表不破坏完整性，所有的数据从一个状态转化到另一个状态时不发生逻辑问题，比如说A通过手机银行给B转了100万，这件事情发生后A账户少了100万，B账户多了100万，这样就保证了数据的一致，如果转账结束A账户的钱少了100万，B账户却只多了100块，那完蛋了，A和B肯定一起去找银行打架去了。 分布式一致性很多资料对于分布式一致性理解的都是数据冗余副本，当所有副本的数据一样时，那么此时的状态就是一致的。按照我自己的理解，这里的冗余副本不一定指的是数据形式完全一样，比如玩家在游戏服拥有金币资产200万，然后全服排行榜上的展示面板上显示资产也是200万，可能具体数据的形式不同，但这应该也是一种数据一致性的表现。 两个概念容易混淆，因为经常在分布式的架构下更新数据库，两种一致性也常常在同一个操作中有所体现。其实我也经常混着用，反正知道这个意思就好了，最近遇到的问题也是两个概念的集合，不过还是先来理解一下分布式的一致性吧 分布式一致性分类 强一致性： 要求无论更新操作是在哪一个节点副本上执行，之后获取的数据都是最新的。 弱一致性： 能容忍部分或全部节点都看不到最新数据，数据改变时尽量通知可能多的节点。 最终一致性： 是弱一致性的一种特例表现，需要保证用户最终能够读取到最新的数据。 我们当然希望能实现强一致性，但这样需要付出相当大的代价，往往要通过牺牲可用性才能达到。 一致性的保证如果要想达到强一致性，那么就得保证任何数据在改变之后必须通知所有节点，等待所有节点更新完毕后才能给用户提供服，这就要在开始更新时加一把大锁，先锁住数据，等待所有节点完成更新时释放锁，这样才能提供数据的强一致性保证。 如果节点太多的话，这个锁的机制将会消耗大量的时间来等待，可能导致应用长时间不能提供正常服务，在一些应用上显然是不合适的，所以是否要保证强一致性需要根据具体的业务逻辑来选择。 还有一个经常听到的观点就是在分布式系统中一致性和可用性我们只能选择一个，这一般是从CAP理论中得到的结论，但是这样说是不准确的，关于CAP理论最初版的大意为：“对于一个分布式计算系统，不可能同时满足一致性（Consistence）、可用性（Availability）、分区容错性（Partition Tolerance ）三个设计约束”。 通过CAP理论告诉我们分布式系统只能选择CP或者AP，但其实这里的前提是分布式系统发生了“分区”现象。如果当前系统没有发生分区现象，我们没有必要放弃C或者A，应该C和A都可以保证。 还有一点个人的理解，由于数据传输是需要时间的，那么当一个节点修改了数据同步到另一个节点时不可能瞬间完成，所以数据不一致总是时刻存在，而我们前面提到的数据一致总是指对用户而言的，虽然数据在传输过程中是不一致的，但是我们可以规定在数据完成同步前，用户看到的都是旧数据，这样就对用户而言数据就是一致的。 而数据同步过程中的不一致，如果在不一致期间还发生了中断、崩溃等问题，就必须通过日志来恢复了，个人觉得，总是有那么一种极限情况，连日志都救不了你，毕竟记录日志的也是一种程序，但是这类事情发生的概率也比较小了。 总结 程序世界的一致性常常指数据库中的一致性和分布式中的一致性 CAP理论告诉我们分布式系统在发生了分区现象时，才需要选择CP或者AP，否则应该可以保证CA ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 欲穷千里目，更上一层楼。最近越来越发现古诗的精妙之处了，随着阅历的增加，之前背诵的古诗有些突然就明白了，不知道应该开心还是难过~ 2020-10-26 00:27:02]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>游戏</tag>
        <tag>架构设计</tag>
        <tag>一致性</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下使用sort命令完成常见排序操作]]></title>
    <url>%2Fblog%2F2020%2F10%2F14%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E4%BD%BF%E7%94%A8sort%E5%91%BD%E4%BB%A4%E5%AE%8C%E6%88%90%E5%B8%B8%E8%A7%81%E6%8E%92%E5%BA%8F%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言linux 系统下的命令常常给人一种短小精悍的感觉，使用起来就像一把把锋利的小刀，在自己专注的领域做到极致，今天要聊的就是 linux 环境下的排序命令 sort，处理文本按列排序非常方便，最近使用 sort命令来排序日志查找问题，为了防止一段时间不用又会忘记，所以记录下来便于下次查找。 命令作用sort 命令默认会将待排序内容以空格划分为多个列，然后对内容进行按列排序，命令本身不会修改待排序内容，而是将排序结果重新输出，如果想修改待排序源文件的内容，可以通过重定向命令来实现。 命令格式为： 1sort [选项] 文件名 常见选项sort 作为一个强大的命令，参数选项还挺多的，不过我只列举一些常见的参数，方便日常使用即可。 -k： 指定排序依据的列数，可以分多次指定 -o： 将排序后的结果存入指定文件 -c： 检查指定文件是否已经排好序 -u： 删除所有重复行 -b： 忽略每行或字段前面开始出的空格字符 -f： 排序比较时忽略大小写 -n： 转化为数字，按照数值的大小排序 -r： 反向排序，从大到小 -t： 指定排序时划分列数的分隔字符 数据文件为了展示 sort 命令的作用，专门利用 ls 命令产生了一段数据，并保存在了 data.txt 文件中，之后会利用这个文件来展示 sort 的用法，文件内容展示如下： 123456789101112131415albert@home-pc:~$ cat data.txt-rwxrwxr-x 1 albert albert 9272 Jul 18 22:27 a.out*-rw------- 1 albert albert 7064 Oct 17 22:14 .bash_history-rw-r--r-- 1 albert albert 220 Jul 16 00:52 .bash_logout-rw-r--r-- 1 albert albert 3771 Jul 16 00:52 .bashrcdrwxrwxrwx 1 albert albert 4096 Jul 16 01:10 .cache/drwx------ 1 albert albert 4096 Jul 16 00:52 .config/-rw------- 1 albert albert 35 Jul 19 14:14 .lesshst-rwxrwxr-x 1 albert albert 20328 Jul 18 19:49 mainpro*-rw-rw-r-- 1 albert albert 195 Jul 18 22:27 mainpro.cpp-rw-r--r-- 1 albert albert 655 Jul 16 00:52 .profile-rw-r--r-- 1 albert albert 0 Jul 16 00:52 .sudo_as_admin_successful-rw------- 1 root root 2257 Jul 16 01:10 .viminfodrwxrwxrwx 1 albert albert 4096 Jul 19 21:19 .vscode-server/-rw------- 1 albert albert 61 Sep 20 09:42 .Xauthority 这个文件中的内容在使用 sort 命令排序时默认以空格分割，所以共有9列，在指定列数时从1开始，接下来我们用这些数据来测试一下排序命令的用法。 核心参数对于我来说 sort 命令的核心参数是 -k，其完整的参数列表为 -k START_F[.START_C][OPTIONS][,END_F[.END_C][OPTIONS]]，参数列表很长，但是不要恐惧，逐步分析就可以了。 -k 后面这已打算都是用来指定排序依据的范围的，其中 START_F 和 END_F 表示开始和结束的字段，也就是列数，.START_C 和 .END_C 表示指定字段开始和结束的字符数，OPTIONS 是由一个或多个单个字母排序的选项[bdfgiMhnRrV]，这些选项中常用的已经列举在前面了，写在此处的选项会覆盖全局排序选项。 这样文字叙述有些枯燥，可以看下这个参数 -k 6.2b,6.3b，这个排序选项的含义是把内容按照第6列的第2个字符到第6列的第3个字符排序，查找字符位置的时候要去掉前面的空白。 用法展示看了以上的参数可能还是不太清楚具体怎样用，所以举了下面这些例子，可以方便的处理常用的排序工作。 按照指定列排序这是最普通的排序要求了，也是我用的最多的情况，需要使用-k参数 按照第3列排序 123456789101112131415albert@home-pc:~$ sort -k3,3 data.txtdrwx------ 1 albert albert 4096 Jul 16 00:52 .config/drwxrwxrwx 1 albert albert 4096 Jul 16 01:10 .cache/drwxrwxrwx 1 albert albert 4096 Jul 19 21:19 .vscode-server/-rw------- 1 albert albert 35 Jul 19 14:14 .lesshst-rw------- 1 albert albert 61 Sep 20 09:42 .Xauthority-rw------- 1 albert albert 7064 Oct 17 22:14 .bash_history-rw-r--r-- 1 albert albert 0 Jul 16 00:52 .sudo_as_admin_successful-rw-r--r-- 1 albert albert 220 Jul 16 00:52 .bash_logout-rw-r--r-- 1 albert albert 3771 Jul 16 00:52 .bashrc-rw-r--r-- 1 albert albert 655 Jul 16 00:52 .profile-rw-rw-r-- 1 albert albert 195 Jul 18 22:27 mainpro.cpp-rwxrwxr-x 1 albert albert 20328 Jul 18 19:49 mainpro*-rwxrwxr-x 1 albert albert 9272 Jul 18 22:27 a.out*-rw------- 1 root root 2257 Jul 16 01:10 .viminfo root 已经被排到了所有albert的后面 将排序结果存入指定文件12345678910111213141516albert@home-pc:~$ sort -k3,3 data.txt -o dst.txtalbert@home-pc:~$ cat dst.txtdrwx------ 1 albert albert 4096 Jul 16 00:52 .config/drwxrwxrwx 1 albert albert 4096 Jul 16 01:10 .cache/drwxrwxrwx 1 albert albert 4096 Jul 19 21:19 .vscode-server/-rw------- 1 albert albert 35 Jul 19 14:14 .lesshst-rw------- 1 albert albert 61 Sep 20 09:42 .Xauthority-rw------- 1 albert albert 7064 Oct 17 22:14 .bash_history-rw-r--r-- 1 albert albert 0 Jul 16 00:52 .sudo_as_admin_successful-rw-r--r-- 1 albert albert 220 Jul 16 00:52 .bash_logout-rw-r--r-- 1 albert albert 3771 Jul 16 00:52 .bashrc-rw-r--r-- 1 albert albert 655 Jul 16 00:52 .profile-rw-rw-r-- 1 albert albert 195 Jul 18 22:27 mainpro.cpp-rwxrwxr-x 1 albert albert 20328 Jul 18 19:49 mainpro*-rwxrwxr-x 1 albert albert 9272 Jul 18 22:27 a.out*-rw------- 1 root root 2257 Jul 16 01:10 .viminfo 排序结果已经被存储到了文件 dst.txt 中，其实这个命令还可以改写成 sort data.txt &gt; dst.txt 查看文件是否已经排序好 测试没排好序的文件 12albert@home-pc:~$ sort -k3,3 data.txt -csort: data.txt:2: disorder: -rw------- 1 albert albert 7064 Oct 17 22:14 .bash_history 测试已经排序的文件 12albert@home-pc:~$ sort -k3,3 dst.txt -calbert@home-pc:~$ 对于已经拍好序的文件使用 -c 参数没有任何输出，如果是未排序的文件则会给出提示 去掉排序结果中的重复行123albert@home-pc:~$ sort -k3,3 data.txt -u-rwxrwxr-x 1 albert albert 9272 Jul 18 22:27 a.out*-rw------- 1 root root 2257 Jul 16 01:10 .viminfo 这里的重复行参考是你指定排序依据的列数，也就是第3列如果重复就会认为是重复行，结果中只能出现一次 按照数值结果进行排序123456789101112131415albert@home-pc:~$ sort -k5n,5 data.txt-rw-r--r-- 1 albert albert 0 Jul 16 00:52 .sudo_as_admin_successful-rw------- 1 albert albert 35 Jul 19 14:14 .lesshst-rw------- 1 albert albert 61 Sep 20 09:42 .Xauthority-rw-rw-r-- 1 albert albert 195 Jul 18 22:27 mainpro.cpp-rw-r--r-- 1 albert albert 220 Jul 16 00:52 .bash_logout-rw-r--r-- 1 albert albert 655 Jul 16 00:52 .profile-rw------- 1 root root 2257 Jul 16 01:10 .viminfo-rw-r--r-- 1 albert albert 3771 Jul 16 00:52 .bashrcdrwx------ 1 albert albert 4096 Jul 16 00:52 .config/drwxrwxrwx 1 albert albert 4096 Jul 16 01:10 .cache/drwxrwxrwx 1 albert albert 4096 Jul 19 21:19 .vscode-server/-rw------- 1 albert albert 7064 Oct 17 22:14 .bash_history-rwxrwxr-x 1 albert albert 9272 Jul 18 22:27 a.out*-rwxrwxr-x 1 albert albert 20328 Jul 18 19:49 mainpro* 这里使用了 -k5n,5 作为排序选项，其中的 n 表示以数值方式排序，如果不加 n 的排序结果如下： 123456789101112131415albert@home-pc:~$ sort -k5,5 data.txt-rw-r--r-- 1 albert albert 0 Jul 16 00:52 .sudo_as_admin_successful-rw-rw-r-- 1 albert albert 195 Jul 18 22:27 mainpro.cpp-rwxrwxr-x 1 albert albert 20328 Jul 18 19:49 mainpro*-rw-r--r-- 1 albert albert 220 Jul 16 00:52 .bash_logout-rw------- 1 root root 2257 Jul 16 01:10 .viminfo-rw------- 1 albert albert 35 Jul 19 14:14 .lesshst-rw-r--r-- 1 albert albert 3771 Jul 16 00:52 .bashrcdrwx------ 1 albert albert 4096 Jul 16 00:52 .config/drwxrwxrwx 1 albert albert 4096 Jul 16 01:10 .cache/drwxrwxrwx 1 albert albert 4096 Jul 19 21:19 .vscode-server/-rw------- 1 albert albert 61 Sep 20 09:42 .Xauthority-rw-r--r-- 1 albert albert 655 Jul 16 00:52 .profile-rw------- 1 albert albert 7064 Oct 17 22:14 .bash_history-rwxrwxr-x 1 albert albert 9272 Jul 18 22:27 a.out* 数据看起来很乱，其实也是按照第5列排好序的，仔细分析你会发现是把这些数字当成字符串排的序 反向排序123456789101112131415albert@home-pc:~$ sort -k3,3 data.txt -r-rw------- 1 root root 2257 Jul 16 01:10 .viminfo-rwxrwxr-x 1 albert albert 9272 Jul 18 22:27 a.out*-rwxrwxr-x 1 albert albert 20328 Jul 18 19:49 mainpro*-rw-rw-r-- 1 albert albert 195 Jul 18 22:27 mainpro.cpp-rw-r--r-- 1 albert albert 655 Jul 16 00:52 .profile-rw-r--r-- 1 albert albert 3771 Jul 16 00:52 .bashrc-rw-r--r-- 1 albert albert 220 Jul 16 00:52 .bash_logout-rw-r--r-- 1 albert albert 0 Jul 16 00:52 .sudo_as_admin_successful-rw------- 1 albert albert 7064 Oct 17 22:14 .bash_history-rw------- 1 albert albert 61 Sep 20 09:42 .Xauthority-rw------- 1 albert albert 35 Jul 19 14:14 .lesshstdrwxrwxrwx 1 albert albert 4096 Jul 19 21:19 .vscode-server/drwxrwxrwx 1 albert albert 4096 Jul 16 01:10 .cache/drwx------ 1 albert albert 4096 Jul 16 00:52 .config/ 按照第3列反向排序，root就排到了所有albert的前面 自定义分割字符sort 命令默认是以空格作为列的分割符号的，可以使用 -t 选项自定义分割符，比如我们使用 : 作为分隔符，然后以第二列进行排序 123456789101112131415albert@home-pc:~$ sort -t ":" -k2,2 data.txtdrwxrwxrwx 1 albert albert 4096 Jul 16 01:10 .cache/-rw------- 1 root root 2257 Jul 16 01:10 .viminfo-rw------- 1 albert albert 7064 Oct 17 22:14 .bash_history-rw------- 1 albert albert 35 Jul 19 14:14 .lesshstdrwxrwxrwx 1 albert albert 4096 Jul 19 21:19 .vscode-server/-rwxrwxr-x 1 albert albert 9272 Jul 18 22:27 a.out*-rw-rw-r-- 1 albert albert 195 Jul 18 22:27 mainpro.cpp-rw------- 1 albert albert 61 Sep 20 09:42 .Xauthority-rwxrwxr-x 1 albert albert 20328 Jul 18 19:49 mainpro*-rw-r--r-- 1 albert albert 220 Jul 16 00:52 .bash_logout-rw-r--r-- 1 albert albert 3771 Jul 16 00:52 .bashrcdrwx------ 1 albert albert 4096 Jul 16 00:52 .config/-rw-r--r-- 1 albert albert 655 Jul 16 00:52 .profile-rw-r--r-- 1 albert albert 0 Jul 16 00:52 .sudo_as_admin_successful 结果是以分钟数进行的排序 综合排序学习了上面这么多参数，可以做一个综合的例子，以第6列的月份从小到大排序，以第5列文件大小逆序排列，通过组合上面的参数，可以使用下面的命令： 123456789101112131415albert@home-pc:~$ sort -k6,6 -k5rn,5 data.txt-rwxrwxr-x 1 albert albert 20328 Jul 18 19:49 mainpro*-rwxrwxr-x 1 albert albert 9272 Jul 18 22:27 a.out*drwx------ 1 albert albert 4096 Jul 16 00:52 .config/drwxrwxrwx 1 albert albert 4096 Jul 16 01:10 .cache/drwxrwxrwx 1 albert albert 4096 Jul 19 21:19 .vscode-server/-rw-r--r-- 1 albert albert 3771 Jul 16 00:52 .bashrc-rw------- 1 root root 2257 Jul 16 01:10 .viminfo-rw-r--r-- 1 albert albert 655 Jul 16 00:52 .profile-rw-r--r-- 1 albert albert 220 Jul 16 00:52 .bash_logout-rw-rw-r-- 1 albert albert 195 Jul 18 22:27 mainpro.cpp-rw------- 1 albert albert 35 Jul 19 14:14 .lesshst-rw-r--r-- 1 albert albert 0 Jul 16 00:52 .sudo_as_admin_successful-rw------- 1 albert albert 7064 Oct 17 22:14 .bash_history-rw------- 1 albert albert 61 Sep 20 09:42 .Xauthority 总结 sort 命令中的 -k 选项是最重要的参数，可以指定排序依据的列数 sort 命令中的 -n 选项也是常用的参数，可以进行数值比较 在实际问题中常常需要综合运用这些参数，参考综合例子中的方式逐步确定参数选项就可以了。 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 业精于勤，荒于嬉；行成于思，毁于随。没有人能随随便便成功~ 2020-10-18 15:43:51]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>linux</tag>
        <tag>sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Go语言在解决实际问题时的优点与不便]]></title>
    <url>%2Fblog%2F2020%2F10%2F14%2FGo%E8%AF%AD%E8%A8%80%E5%9C%A8%E8%A7%A3%E5%86%B3%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98%E6%97%B6%E7%9A%84%E4%BC%98%E7%82%B9%E4%B8%8E%E4%B8%8D%E4%BE%BF%2F</url>
    <content type="text"><![CDATA[前言Go语言，全称golang，是Google开发的一种静态强类型、编译型、并发型并具有垃圾回收功能的编程语言。 从2007年末由 Robert Griesemer、Rob Pike、Ken Thompson 主持开发，其中的 Ken Thompson 可是和 Dennis Ritchie 一起发明了C语言的大佬。Go 语言于2009年11月正式宣布成为开放源代码项目， 并在2012年初，发布了Go 1.0稳定版本，此后便开启了稳步发展的道路。 Go 语言作为一个从2007年开始诞生的语言，在庞大的语言家族中算是一个晚辈，和C++、Python这种老牌语言相比查了将近20年，和 C 语言相比资历就更低了，但是这个新晋的语言在 Google 光环的强大加持下也在飞速发展着，由于前辈们在发展的途中趟了很多坑，所以 Go 在发明之初就避免了其他语言的很多不便，可以说是站在巨人的肩膀上发展起来的。 但是即便这样，Go 语言的特点也不能被所有人喜欢，和许多人一样，我在学习这门语言的过程中也发现一些很方便特性和一些不太方便的特点，下面简单说几个点，有不对的地方希望小伙伴能及时指出，防止我在错误的思想上越走越远（怎么有种新闻发言稿的感觉~）。 不便之处这里的不便之处只是我在使用过程中感觉不太方便，可能很多人并没有这个感觉，或许还有很多其他的解决方法和替代方案，烦请小伙伴能指点一下。 三目运算符这个三目运算符是个很常用的逻辑处理部件，也是我在逻辑中经常使用到的，在Python、Lua等语言中也不存在，但是我都找到了简单的替代方式，但是在Go 中不得不写成中规中矩的 if 条件判断，这让很多算法的解题代码看起来并不那么优雅，比如一个简单的约瑟夫环问题： N个人围成一圈，从第一个人从开始报数，报到m的人出圈，剩下的人继续从1开始报数，报到m的人出圈；如此往复，直到所有人出圈，输出最后一个出圈人最初始的编号。 这个问题的解法最简单的是模拟法，使用数组模拟一个环来按照规则运行，最后一个出圈的人的编号就可以输出到结果，还有一种思路就是找规律，可以找到出圈前后的序号对应关系，进而写出一行代码的解决方案。 1234// 索引从0开始，只要对结果加1就好了int joseph_ring(int n, int m) &#123; return n == 1 ? 0 : (joseph_ring(n - 1, m) + m) % n&#125; 但是在没有三目运算符的 Go 中要实现这个算法，就不得不多写几行了，和 C 语言相比就没有那么简洁了。 1234567func joseph_ring(n int, m int) int &#123; if n == 1 &#123; return 0 &#125; return (joseph_ring(n - 1, m) + m) % n&#125; if 单行语句也要加大括号Go 语言本身带有自己的格式化命令，可以保证编写时不同的缩进样式格式化之后得到相同的代码，if 后面的条件语句可以不加小括号，但是后面的语句块必须加大括号，这样的规定对于我经常写的代码有点不太友好，比如下面这些C++代码： 12345678if (a &gt; 0) break;if (b &lt; 0) continue;if (c == 0) return; 有时候为了看起来紧凑，可能会写成这样： 123if (a &gt; 0) break;if (b &lt; 0) continue;if (c == 0) return; 但是放到 Go 语言中，就不得不写成好几行了，并且还要加大括号，看起来代码有些松散。 1234567891011if a &gt; 0 &#123; break;&#125;if b &lt; 0 &#123; continue;&#125;if c == 0 &#123; return;&#125; 优秀特性上面提到了 Go 语言中不方便的地方，现在可以来说说 Go 语言相对于 C、C++ 更优越的特性： 多个变量同时赋值在 C++ 中交换两个变量的通常使用中间变量来完成，比如交换 a、b 两个变量的值： 123456int a = 1;int b = 6;int tmp = a;a = b;b = tmp; 针对于这种整形的变量，一些大牛们发明了特殊的算法来处理，避免使用中间变量： 123456int a = 1,;int b = 6;a = a ^ bb = b ^ aa = a ^ b 但是在 Go语言中这种情况非常好处理，直接从左到右依次赋值就好了 1234var a int = 1var b int = 6b, a = a, b defer 声明defer 可以用于在当前函数返回前执行一些清理代码，而不管此函数如何退出。defer 在函数中可以随时出现，这使得清理代码可以尽可能在需要清理的地方运行，比如我们常常要释放申请的资源，常见的需要释放的资源有文件描述符： 12345file, err := os.Open(fileName)if err != nil &#123; return&#125;defer file.Close() 有了 defer 终于不再在担心，资源没回收的问题，也不用在各个提前返回的条件分支中添加释放资源的重复代码了。 goroutine 并发goroutine 是Go并行设计的核心，说到底其实就是协程，但是它比线程更小并且在Go语言内部帮你实现了这些 goroutine 之间的内存共享。执行 goroutine 只需要极少的栈内存，可同时运行成千上万个并发任务。goroutine 一定程度上比 thread 更易用、更高效、更轻便。 使用起来也非常方便，创建 goroutine 只需在函数调用语句前添加 go 关键字，就可以创建并发执行单元。开发人员无需了解任何执行细节，调度器会自动将其安排到合适的系统线程上执行，这是解放生产力的又一创举，简单示例代码如下： 12345678910111213141516171819202122package mainimport ( "fmt" "time")func new_task() &#123; for i := 0; i &lt; 10; i++ &#123; fmt.Println("this is a newTask") time.Sleep(time.Second) //延时1s &#125;&#125;func main() &#123; for i := 0; i &lt; 3; i++ &#123; go new_task() //新建一个协程， 新建一个任务 &#125; time.Sleep(time.Second * 15) //延时15s fmt.Println("this is a main goroutine")&#125; 总结 Go 语言作为编程语言中的新晋小弟，吸收了前人的经验，现阶段发展迅猛 虽然 Go 出于一些目的规定了语言的标准，但是类似于没有三目运算符这种特点还是有些不方便 Go 这门语言还很年轻，相信随着不断发展它会越来越优秀，但没有任何语言是完美无缺的 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 陪伴是最长情的告白，而守护是最沉默的陪伴。国庆中秋双节合并，放假了，陪家人待在一起真的很开心，什么都不用做，就静静的待在一起很满足，聊聊天、抬抬杠，假期嗖嗖嗖地溜掉了~]]></content>
      <categories>
        <category>Go</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Go</tag>
        <tag>优点</tag>
        <tag>缺点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Spreadsheet Compare工具对比Excel文件差异]]></title>
    <url>%2Fblog%2F2020%2F10%2F04%2F%E4%BD%BF%E7%94%A8Spreadsheet-Compare%E5%B7%A5%E5%85%B7%E5%AF%B9%E6%AF%94Excel%E6%96%87%E4%BB%B6%E5%B7%AE%E5%BC%82%2F</url>
    <content type="text"><![CDATA[前言与 Spreadsheet Compare 这个工具的相遇是通过 TortoiseSVN 来牵线的，在使用 SVN 管理 Excel 表格时发现，TortoiseSVN自带的比较工具不能对比Excel文件的版本差异，这对于通过日志查找问题来说非常不方便，通过搜索发现了 Spreadsheet Compare 这款优秀的工具，特此记录一下，方便日后查找并快速配置。 Spreadsheet CompareSpreadsheet Compare 是 Microsoft Office 自带的一款工具软件（2013版本以后），可以用来比较不同 Excel 表格的差异，既能显示数据的不同，也可以显示出表结构的不同。这是一款带界面的工具软件，布局分为左右两部分，与 Beyond Compare 这个工具界面类似，但是功能更加强大。 Beyond Compare 也可以用来对比表格差异，但是只能比较两个Excel的当前工作表，如果每个 Excel 文件中包含多个工作表时就会对比错误的情况，而 Spreadsheet Compare 在这一点上更加优秀，可以对比多个表格数据。 Spreadsheet Compare 使用起来也非常简单，可以操作的按钮很少，界面简洁， 启动软件后单击左上角的 Compare Files 按钮，选择要对比的文件即可，非常方便，数据差异、结构差异等都会用不同的颜色标记出来，还可以导出对比结果。 命令模式这种模式对于是提供给 TortoiseSVN 使用的前提，因为 TortoiseSVN 无法像人一样一步步操作选择待比较的 Excel 表格，而是需要一个命令脚本，将要比较的参数传给 Spreadsheet Compare 工具进而完成比较工作。 找到工具想要编写命令脚本，首先要找到这个比较的工具，我找到的路径是在 &quot;C:\Program Files (x86)\Microsoft Office\Root\Office16\DCF\SPREADSHEETCOMPARE.EXE&quot;，相信大家的路径都差不多，在 Office 工具目录下应该就能找到了，可以在开始菜单中找到工具，然后通过属性找到可执行程序所在目录，工具的可执行文件名字叫做 SPREADSHEETCOMPARE.EXE。 编写脚本编写脚本之前有一点需要强调一下，SPREADSHEETCOMPARE.EXE 有点奇怪，大多数软件在比较差异的时候会将两个文件作为参数使用，但是 SPREADSHEETCOMPARE.EXE 在比较之前，需要将两个待比较的文件名分成两行写入一个文件，再将这个文件作为参数传给工具使用，比如要比较 ExcelA.xlsx 和 ExcelB.xlsx 两个文件，需要将两个文件写入一个临时文件 ExcelCompare.txt 中: ExcelA.xlsxExcelB.xlsx 然后再把这个文件作为参数传给工具： 1SPREADSHEETCOMPARE.EXE ExcelCompare.txt 脚本内容有了上面的说明，我们就可以写出一个较为通用的版本，比如我的脚本名字是 SC.bat，内容如下： 1234567@echo offchcp 65001set batpath=%~dp0echo %~1&gt; "%batpath%ExcelCompare.txt"echo %~2&gt;&gt; "%batpath%ExcelCompare.txt""C:\\Program Files (x86)\\Microsoft Office\\Root\\Office16\\DCF\\SPREADSHEETCOMPARE.EXE" "%batpath%ExcelCompare.txt" 脚本执行直接在 cmd 命令行中输入以下命令就可以对比 ExcelA.xlsx 和 ExcelB.xlsx 两个文件了： 12D:\data\bat&gt;D:\data\bat&gt;SC.bat ExcelA.xlsx ExcelB.xlsx 供给SVN调用个人比较懒，不喜欢截图，在 TortoiseSVN 工具的设置中找到“差异查看器”选项，选择该选项然后点击界面上的高级设置，点击增加按钮，增加根据扩展名指定差异比较程序，填写 .xlsx 和所需命令 D:\data\bat&gt;SC.bat %base %mine 命令中的 %base 和 %mine 参数是 TortoiseSVN 提供的，代表原始文件和自己修改的文件，这次再通过 SVN 查看表格差异就可以启动 Spreadsheet Compare 程序方便地查看两个表格的差异啦。 总结 Spreadsheet Compare 是一款强大的表格比较工具，在表格比较时比 Beyond Compare 还要优秀 脚本调用 SPREADSHEETCOMPARE.EXE 程序时参数是一个包含了待比较文件名的临时文件，这一点和其他的比较工具有些不同 脚本中我们生成的临时文件无需手动处理，再打开待比较文件后会自动删除 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 急需找到一个看得见摸得着的目标为之努力，不然真的有点止步不前了，至今还未找到可以废寝忘食之事，长此以往终将碌碌无为，继续找寻，此事可以不伟大，但应该有趣~ 2020-10-12 00:16:52]]></content>
      <categories>
        <category>Tools</category>
      </categories>
      <tags>
        <tag>Excel</tag>
        <tag>Spreadsheet-Compare</tag>
        <tag>SVN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[东拉西扯01世界的沧海桑田]]></title>
    <url>%2Fblog%2F2020%2F09%2F26%2F%E4%B8%9C%E6%8B%89%E8%A5%BF%E6%89%AF01%E4%B8%96%E7%95%8C%E7%9A%84%E6%B2%A7%E6%B5%B7%E6%A1%91%E7%94%B0%2F</url>
    <content type="text"><![CDATA[前言此篇非技术总结，但却与技术相关，写这篇总结的起因是前两天看了一节关于虚幻四的公开课，这节课也不是讲开发技术，更多的是讲创作艺术，课程开始前看到虚幻编辑器的画面，还是有一种很熟悉的感觉，毕竟使用了3年多的时间，外观几乎没有变化，使用方式依旧是原来的步骤，但随着课程的进行，我发现它变了。 其中有一段内容提到，虚幻四已经不再将自己作为一款游戏开发引擎，而是定位成一个艺术创作和开发的平台，也就是说它不仅仅可以做游戏，同时可以用来出影视剧、国漫、特定素材等等，它已经将自己的势力范围扩张，变得丰富而强大，后来又提到虚幻五带来的种种提升。 什么？虚幻五已经出了，这是我之前不知道的，我知道今年 Redis 出了最新的 6.0 版本，MySQL 一跃发行了 8.0 版本，IOS 也更新到的 14.0.1 版本，似乎各种技术都在飞速的发展着，但是人的精力毕竟有限，很难把它们成长历程尽收眼底，一不留神就发现某种技术已经悄悄从你身边跨了过去。 技术的发展记得我第一篇博客记录的是处理 Ubuntu 黑屏的解决方案，我去翻了翻当时记录的版本是 12.04，时间已经过去了7年，Ubuntu 20.04 已经发行，当年解决黑屏的经验或许已经毫无用处。 10年接触的第一种计算机编程语言是 C 语言，当时开发环境是 Turbe C 2.0，后来使用 VC++6.0，接着就是VS系列，期间用过 Dev-C++、CodeBlocks等编辑器，但是 VS 还是用的最多的，直到目前使用的 VS2017，可是刚刚一个好学的小朋友问我 VS2019 相关的问题，我发现这款用了这么久的工具，之前一直无变化的菜单布局在 VS2019 版本上发生了改变。 之前一直号称单线程内存数据库 Redis 在今年5月份发布的 6.0 版本中，加入了网络多线程，使得整体性能提升近一倍，这被认为是 Redis 最大的一次改版。 MySQL 直接从 5.7 版本跳到了 8.0 版本，因为之前一直是 5.6 、5.7 这样的小版本提升，一跃跳到 8.0 一时让人好奇到底改了什么？其实 6.0 是一个过渡版本，而 7.0 是作为集群的保留版本，所以这次直接到了 8.0。其中一个亮点增加了 MySQL 文档存储，可以存储 json 格式，开始支持向 NoSQL 格式转化。 差点忘了C++，这个庞然大物目前已经从最开始的 C++98，发展到现在的 C++20，我在想它如果真的存活到 2098 年，应该怎么命名它呢？新标准的内容很长，需要慢慢来消化，可以发现一些很好玩的东西，比如三向比较运算符 &lt;=&gt;，也叫飞船运算符，感兴趣的可以去了解下。 经历的和未经历的变化还有很多，想好了再来补充。。。 技术公司的发展当年找工作的听说过的巨头就是 BAT，而今天晚上问一个即将毕业进入工作岗位的同学，哪些是他心目中的大厂，他给出了四个名字，“阿里、腾讯、字节、美团”，很明显百度已经掉队，但是瘦死的骆驼比马大，短时间内百度的技术底蕴不会消失殆尽，这些手握资源和技术的大厂很早就给自己挖好了护城河，一般企业很难追赶的上。 相比早期的 BAT，我感觉后来的字节、美团能够赶上他们实属不易，记得当年开玩笑说 TX 除了发明了一套钻石收费系统，其他的都是抄的，任何公司有了好点子，不是被他合并了就是被他抄走了，所以说能在某个它无法掌控的赛道上超越它也是非常厉害了。 有些东西是其他公司无法做到的，比如疫情期间的健康宝，每天上班、去商场、去公园都要看，都要打开微信和支付宝的APP，这个日活的数据放到其他任意一款软件上都是庞大的数字，可是他们就在这两大巨头这自然的发生着。 总结 技术每时每刻都在发展，有时你发现它陌生了，其实只是你关注的少了 好的赛道大多数已被别人占领，从夹缝中寻找到机会还需好好把握，才能做出一定的成绩 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 年年岁岁花相似，岁岁年年人不同 2020-9-27 00:20:42]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>技术</tag>
        <tag>计算机</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++求解组合数的具体实现]]></title>
    <url>%2Fblog%2F2020%2F09%2F19%2FC-%E6%B1%82%E8%A7%A3%E7%BB%84%E5%90%88%E6%95%B0%E7%9A%84%E5%85%B7%E4%BD%93%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[前言很少写关于具体算法的总结笔记，因为很难把一个算法从头到尾的叙述清晰并且完整，容易造成误解。这次想总结一下组合数的具体实现，原因是最近总是碰见组合数，所以决定来写写，免得每次从头推导公式耽误时间。排列组合经常会作为一个问题解决方案中一部分，通常是求某个问题有多少个解，达到某种状态有多少种操作方式等等。 问题起因今天下午解一道简单题，难度简直刷新了我的认知，其中需要用到组合数，但这仅仅是解题的一小部分，没办法，从头推导的，简单优化下，写出了如下代码： 1234567int C(int a, int b)&#123; int ans = 1; for (int i = a; i &gt; a - b; i--) ans *= i; for (int i = b; i &gt; 1; i--) ans /= i; return ans;&#125; 因为时间紧迫，范围也比较小，同时可以控制 a 和 b 的大小，所以临时写下的这段代码可以运行，不然这段代码会出现各种错误的。 组合公式既然是想做总结，还是从头来看看组合公式，根据原始公式实现算法，并尝试优化它，当熟悉这个套路之后，就可以直接拿来用了，可以节省不少时间，组合公式的常见表示方式如下： $$C^m_n = \frac{n!}{m!(n-m)!} = C^{n-m}_n,(n \geq m \geq 0)$$ 这个公式写出来清晰多了，n!表示n的阶乘，计算方式为 n*(n-1)*(n-2)*(n-3)*…*3*2*1， 相信很多人都清楚，我们只要把这个数据公式翻译成代码就可以了： 12345678int C2(int n, int m)&#123; int a = 1, b = 1, c = 1; for (int i = n; i &gt;= 1; --i) a *= i; for (int i = m; i &gt;= 1; --i) b *= i; for (int i = n-m; i &gt;= 1; --i) c *= i; return a/(b*c);&#125; 代码比较简单，依次计算公式中三个数的阶乘，然后再做乘除法就可以了，但是你有没有思考过一个问题，int 类型的整数最大能表示的阶乘是多少？是12!，它的值是 479,001,600，它是 int 表示范围内最大的阶乘数，看来这种实现方式局限性很大，如果 n 大于12就没有办法计算了。 公式变形实际上根据阶乘的定义，n! 和 (n-m)! 是可以约分的，将这两个式子约分后，公式可以化简为： $$C^m_n = \frac{n!}{m!(n-m)!} = \frac{n(n-1)(n-2)…(n-m+1))}{m!},(n \geq m \geq 0)$$ 公式写成这样之后可以少计算一个阶乘，并且计算的范围也会缩小，代码实现和一开始展示的代码思想是一样的： 1234567int C3(int n, int m)&#123; int a = 1, b = 1; for (int i = n; i &gt; n - m; --i) a *= i; for (int i = m; i &gt;= 1; i--) b *= i; return a/b;&#125; 这段代码虽然经过了化简，但是当 n 和 m 非常接近的时候，分子还是接近于 n!，所以表示的范围还是比较小。 递推公式直接给出的公式经过化简后还是受制于计算阶乘的范围，得想个办法看看能不能绕过阶乘计算，方法总是有的，并且前辈们已经给我们整理好了，我们总是站在巨人的肩膀上，下面就是递推公式： $$\begin{cases} {C^m_n} = 1,\qquad\qquad\qquad (m=0 或 m=n) \ {C^mn} = {C^m{n-1}} + {C^{m-1}_{n-1}},\qquad(n &gt; m &gt; 0) \end{cases}$$ 递归实现有了上面的分段函数表示，就满足了递归的条件，既有递归调用缩小规模，也有递归出口，这样实现起来很简单，代码如下： 12345int C4(int n, int m)&#123; if (n == m || m == 0) return 1; return C4(n-1, m) + C4(n-1, m-1);&#125; 这两行代码是不是很秀？不过使用递归常常会出现一问题，那就是相同子问题多次计算，导致效率低下，这个计算组合数的方式同样存在重复计算子问题的缺点，我们以调用C4(5, 3)为例，看看下面的调用关系图： 1234567891011121314151617181920graph TB A(5,3)--&gt;B(4,3) B(4,3)--&gt;C(3,3); B(4,3)--&gt;D(3,2); D(3,2)--&gt;E(2,2); D(3,2)--&gt;F(2,1); F(2,1)--&gt;G(1,1); F(2,1)--&gt;H(1,0); A(5,3)--&gt;O(4,2) O(4,2)--&gt;P(3,2) O(4,2)--&gt;Q(3,1) P(3,2)--&gt;R(2,2) P(3,2)--&gt;S(2,1) Q(3,1)--&gt;T(2,1) Q(3,1)--&gt;U(2,0) S(2,1)--&gt;V(1,1) S(2,1)--&gt;W(1,0) T(2,1)--&gt;X(1,1) T(2,1)--&gt;Y(1,0) 从这个图可以清晰看出C4(3, 2) 和 C4(2, 1) 都被计算了多次，当 m 和 n 的数字比较大的时候，会进行更多次的重复计算，严重影响计算的效率，有没有什么办法解决重复计算的问题呢？ 备忘递归解决重复计算的常用方法是利用一个备忘录，将已经计算式子结果存储起来，下次再遇到重复的计算时直接取上次的结果就可以了，我们可以将中间结果简单存储到map中。 假设 n 不超过10000，这比12已经大太多了，我们可以使用 n * 10000 + m 作为map的键，然后将结果存储到map中，每次计算一个式子前先看查询备忘录，看之前有没有计算过，如果计算过直接取结果就可以了，代码简单实现如下： 1234567891011121314int C5(int n, int m, map&lt;int, int&gt;&amp; memo)&#123; if (n == m || m == 0) return 1; auto itora = memo.find((n-1)*10000+m); int a = itora != memo.end() ? itora-&gt;second : C4(n-1, m); if (itora == memo.end()) memo[(n-1)*10000+m] = a; auto itorb = memo.find((n-1)*10000+m-1); int b = itorb != memo.end() ? itorb-&gt;second : C4(n-1, m-1); if (itorb == memo.end()) memo[(n-1)*10000+m-1] = b; return a + b;&#125; 使用 map 作为备忘录可以避免重复计算，这是解决递归效率低下的常用方法，那么有了递推公式不使用递归实现可不可以呢？当然可以了，针对于这个问题，有了递推公式我们还可以使用动态规划（dp）的方式来实现。 动态规划动态规划常常适用于有重叠子问题和最优子结构性质的问题，试图只解决每个子问题一次，具有天然剪枝的功能。基本思想非常简单，若要解一个给定问题，我们需要解其不同子问题，再根据子问题的解以得出原问题的解。 再回顾一下递推公式： $$\begin{cases} {C^m_n} = 1,\qquad\qquad\qquad (m=0 或 m=n) \ {C^mn} = {C^m{n-1}} + {C^{m-1}_{n-1}},\qquad(n &gt; m &gt; 0) \end{cases}$$ 翻译成人话就是，当m等于0或者等于n的时候，组合数结果为1，否则组合数结果等于另外两个组合数的和，我们可以采用正向推导的方式，将 n 和 m 逐步扩大，最终得到我们想要的结果，定义dp表格如下： n\m (0) (1) (2) (3) (4) (5) (0) 1 (1) 1 1 (2) 1 2 1 (3) 1 3 3 1 (4) 1 4 6 4 (5) 1 5 10 ==&gt;10 从表格可以清晰的看出求解 C(5,3) 只需要计算5行3列（从0开始）的数据，其余的值可以不用计算，这样我们就可以对照着表格写代码啦，定义一个dp数组，然后双重for循环就搞定了： 123456789101112int C6(int n, int m)&#123; if (n == m || m == 0) return 1; vector&lt;vector&lt;int&gt;&gt; dp(n+1, vector&lt;int&gt;(m+1)); for (int i = 0; i &lt;= n; i++) for (int j = 0; j &lt;= i &amp;&amp; j &lt;= m; j++) if (i == j || j == 0) dp[i][j] = 1; else dp[i][j] = dp[i-1][j] + dp[i-1][j-1]; return dp[n][m];&#125; 至此，我们就采用了非递归的方式求解出了组合数的结果，但是这里的空间有点浪费，每次都要花费O(mn)的空间复杂度，有没有办法降低一点呢？我们可以找找规律进行压缩。 压缩DP观察之前的动态规划实现的代码，我们发现求解第 i行的数据时只与第 i-1 行有关，所以我们可以考虑将二维数据压缩成一维，还是逐行求解，只不过可以用一维数组来记录求解的结果，优化代码如下： 123456789101112int C7(int n, int m)&#123; if (n == m || m == 0) return 1; vector&lt;int&gt; dp(m+1); for (int i = 0; i &lt;= n; i++) for (int j = min(i, m); j &gt;= 0; j--) if (i == j || j == 0) dp[j] = 1; else dp[j] = dp[j] + dp[j-1]; return dp[m];&#125; 这样我们就将空间复杂度降低到了O(m)，需要注意的是在计算dp时，因为采用了压缩结构，为防止前面的修改影响后续结果，所以采用里倒序遍历，这是一个易错的点。 其他优化代码实现到这里，我们的时间复杂度是O(nm)，空间复杂是O(m)，其实还有进一步的优化空间： 减小m： 因为题目是求解C(n, m)，但是我们知道组合公式中，C(n, m) 和 C(n, n-m) 相等，所以当 n-m 小于 m 的时候求解C(n, n-m)可以降低时间复杂度和空间复杂度。 部分剪枝： 观察函数int C7(int n, int m)，实际上当i为n时，j没必要遍历到0，只需要计算j等于m的情况就可以了，可以提前计算出结果。 缩小计算范围： 从上面的剪枝操作得到启示，其实每一行没必要全部计算出来，以 C(5,3) 为例，我们只需要计算出表格中有数字的位置的结果就可以了： n\m (0) (1) (2) (3) (4) (5) (0) 1 (1) 1 1 (2) 1 2 1 (3) 3 3 1 (4) 6 4 (5) ==&gt;10 这样来看每行最多需要计算3个值，那么时间复杂度可以降低到 O(3n)，去掉常数，时间复杂度降为 O(n)。 总结 计算组合数可以采用逆向递归和正向递推两种方式，递归时注意写好递归出口 采用正向递推方法时利用动态规划思想，使用子问题的解拼凑出最终问题的解 计算组合数若使用了计算阶乘应注意范围，避免在计算时产生溢出，int最多能表示 12! 使用动态规划方法时可以逐步优化空间和时间，这其实就是优化算法的过程，也是提升的过程 关于组合数的求解方式，我们可以找到时间复杂度O(n)、空间复杂度O(m)的非递归解法 补充感谢 @小胡同的诗 同学的补充和提醒，让我再次感受到数学力量的深不可测，原来求解组合数还有这样一个递推公式： $$\begin{cases} {C^m_n} = 1,\qquad\qquad\qquad (m=0 或 m=n) \ C_n^m=\frac{n-m+1}{m}C_n^{m-1},\qquad(n &gt; m &gt; 0) \end{cases}$$ 这个公式厉害就厉害在它是一个线性的，不存在分叉的情况，也就是说即使递归也不会出现重复的计算，我们简单实现一下。 反向递归12345int C8(int n, int m)&#123; if (n == m || m == 0) return 1; return C8(n, m-1) * (n-m+1) / m;&#125; 代码非常紧凑，也不存在重复计算的情况，当然我们也可以使用正向计算的方式来实现。 正向递推12345678910int C9(int n, int m)&#123; if (n == m || m == 0) return 1; int ans = 1; m = min(m, n-m); for (int i = 1; i &lt;= m; i++) ans = ans * (n-i+1) / i; return ans;&#125; 这段代码将时间复杂度降到了O(m)，空间复杂度降到了O(1)，不过特定的场景还是要选择特定的实现，虽然C9函数在时间复杂度和空间复杂度上都优于 C5 函数，但是如果一个实际问题中需要用到多个组合数的时候，C5 这种采用缓存的方式可能会是更好的选择。 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 想讲故事？没人倾听？那是因为你还未到达一个指定的高度，当你在某个领域站稳了脚跟，做出了成绩，自然有的是时间去讲故事或者“编”故事，到时候随便一句话都会被很多人奉为圭臬，甚至会出现一些鸡汤莫名其妙的从你嘴里“说”出来。在你拥有了讲故事权利的同时，批判的声音也将随之而来~ 2020-9-20 12:32:37]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>combination</tag>
        <tag>dp</tag>
        <tag>recursion</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中优先队列priority_queue的基础用法]]></title>
    <url>%2Fblog%2F2020%2F09%2F11%2FC-%E4%B8%AD%E4%BC%98%E5%85%88%E9%98%9F%E5%88%97priority-queue%E7%9A%84%E5%9F%BA%E7%A1%80%E7%94%A8%E6%B3%95%2F</url>
    <content type="text"><![CDATA[前言学习优先队列之前先看个单词队列 queue， 这个单词的读法很多人都能读对吧，音标是 /kjuː/ ，再看一个双端队列 deque，它的音标是 /dek/，应该有人读错了吧，反正我是没读对，刚开始看见一次错一次，现在还好了，基本能记住怎么读了，可是这些队列怎么用呢？ 队列就不用多说了，一个先进先出的经典数据结构，那么优先队列是个什么鬼，其实它就是在队列的基础上加上优先两个字，想想怎样才能优先呢？没错——排队！只有排好了队伍才会有落后和优先之分，否则一团乱糟糟的，怎么才能分出优先的，所以优先队列一定应用了排序。 可是排序要怎样实现呢？其实排序这个底层逻辑你是不用管的，你只要把想要的数据放到优先队列里，然后取出的必定是当前状态下最优的，当然，究竟什么是最优的条件是需要你来设定的，也就是说我们需要定义排序的规则。 头文件优先队列 priority_queue 是队列 queue 的一个变种，头文件是#include &lt;queue&gt;，使用优先队列必须要包含这个头文件。 结构定义优先队列的结构定义是一个模板类，需要提供三个类型参数： 12345template&lt; class T, class Container = std::vector&lt;T&gt;, class Compare = std::less&lt;typename Container::value_type&gt;&gt; class priority_queue; 从定义可以看出，虽然要结构是三个参数，但是后两个参数带了默认值，所以针对于普通的数据类型，一般情况下指提供第1个参数就可以了，比如 priority_queue&lt;int&gt; 实际上等价于 priority_queue&lt;int, vector&lt;int&gt;, less&lt;int&gt;&gt;。 这三个参数的含义分别为：数据类型，容器类型和比较函数，实际上优先队列就是维护了一个装有 T 类型元素的容器 Container，并在入队和出队时对容器内元素使用 Compare 比较函数进行了排序。 这3个参数还要满足一定的要求，并且在使用过程中有些注意事项： 如果类型 T 和 Container 容器中元素类型不一致，那么行为未定义，所以要避免这种情况。 Container 必须是序列容器，其实C++中序列容器很多的，比如std::array、std::vector、std::deque、std::list等 Container 还必须要支持随机访问，并且有 front()、push_back()、pop_back() 等函数 这样来看只有 std::vector、std::deque 满足容器条件了，而优先队列中使用的默认参数也是 std::vector。 队列排序一直在说优先队列里使用了排序，而常用的容器是 std::verctor，那么究竟用的是什么排序，又是在什么时候进行的排序呢？实际上这里的排序并不是我们通常拿到数据后使用的冒泡排序、快速排序等，优先队列中的排序本质上是堆排序，但是它不是每次都进行完整的堆排序，而是通过 Container 维护了一个堆结构，每次入队和出队时都进行一次堆调整，所花时间为 log(n)，所以用在数据量大的地方，速度比较快。 优先队列使用当我们大概了解了优先队列的原理后，可以通过使用来进一步熟悉这个结构，下面来看几个例子。 实现排序1234567891011121314151617#include &lt;iostream&gt;#include &lt;queue&gt;using namespace std;void common_sort()&#123; int source_data[10] = &#123;3, 5, 8, 1, 10, 2, 9, 15, 13, 16&#125;; // 默认大根堆，实现由大到小排序 priority_queue&lt;int&gt; q; for (auto n : source_data) q.push(n); while (!q.empty()) &#123; cout &lt;&lt; q.top() &lt;&lt; endl; q.pop(); &#125;&#125; priority_queue&lt;int&gt; 默认构建的是一个大根堆，所以每次从头取数据得到的是一个从大到小的队列排序 123456789101112albert@home-pc:/mnt/c++/datastruct$ g++ priorityqueue.cpp -o commonsort -std=c++11albert@home-pc:/mnt/c++/datastruct$ ./commonsort16151310985321 如果是完整排序使用优先队列就有些麻烦了，还不如直接调用 std::sort 函数，但是如果只取部分数据的话，优先队列还是非常方便快速的，比如下面这个问题。 取出数组中最大的k个数这是一个经典的算法题，最容易想到的办法就是遍历，先找到最大的，然后排出这个数再找到最大的，这样找k次就好了，所需时间大概表示为 O(kN)。 还有一个方法是排序，使用 std::sort 排序后，然后依次取出前 k 个数就行了，排序使用快速排序的话可以达到所需时间为 O(Nlog(N))，其实这样已经很优秀了，但是还可以通过优先队列来加速，下面来写一下代码： 1234567891011121314151617181920212223242526#include &lt;iostream&gt;#include &lt;queue&gt;using namespace std;void max_k_num()&#123; int source_data[10] = &#123;3, 5, 8, 1, 10, 2, 9, 15, 13, 16&#125;; int k = 5; // 小根堆 priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; q; for (auto n : source_data) &#123; if (q.size() == k) &#123; if (n &gt; q.top()) &#123; q.pop(); q.push(n); &#125; &#125; else q.push(n); &#125; while (!q.empty()) &#123; cout &lt;&lt; q.top() &lt;&lt; endl; q.pop(); &#125;&#125; 这里是定义了一个小根堆，堆顶是最小值，当有新元素大于堆顶元素时，并且队列中元素等于k个，需要移除堆顶元素，然后插入新的元素，这样就能保证优先队列中始终拥有最大的k个数，运行结果如下： 1234567albert@home-pc:/mnt/c++/datastruct$ g++ priorityqueue.cpp -o max_k_num -std=c++11albert@home-pc:/mnt/c++/datastruct$ ./max_k_num910131516 因为这里控制堆的规模最大为k，所以这个算法的执行时间大概是O(Nlog(k))，绝大多数情况是由于快速排序的。 自定义结构使用优先队列时常常要用到自定义结构，这时候就需要自己来写比较函数了，比如输出成绩最好的三个人的信息： 12345678910111213141516171819202122232425262728293031323334353637#include &lt;iostream&gt;#include &lt;queue&gt;using namespace std;struct student &#123; string name; int score;&#125;;struct cmp_custom &#123; bool operator()(student&amp; x, student&amp; y) &#123; return x.score &gt; y.score; &#125;&#125;;void max_k_score()&#123; vector&lt;student&gt; stu_list = &#123;&#123;"Andy", 89&#125;, &#123;"Bella", 79&#125;, &#123;"Cary", 92&#125;, &#123;"Dick", 60&#125;, &#123;"Ray", 70&#125;&#125;; int k = 3; // 小根堆 priority_queue&lt;student, vector&lt;student&gt;, cmp_custom&gt; q; for (auto stu : stu_list) &#123; if (q.size() == k) &#123; if (stu.score &gt; q.top().score) &#123; q.pop(); q.push(stu); &#125; &#125; else q.push(stu); &#125; while (!q.empty()) &#123; cout &lt;&lt; q.top().name &lt;&lt; ":" &lt;&lt; q.top().score &lt;&lt; endl; q.pop(); &#125;&#125; 输出结果如下，每个人的名字后面跟着分数，结果是分数最大的3个人的信息： 12345albert@home-pc:/mnt/c++/datastruct$ g++ priorityqueue.cpp -o max_k_score -std=c++11albert@home-pc:/mnt/c++/datastruct$ ./max_k_scoreBella:79Andy:89Cary:92 自定义比较函数的另一种写法看到上个例子中自定义比较函数的写法比较怪，一般我们在排序时定义的比较函数使用lambda表达式就可以，而这里是不能直接这样写的，需要多转化一步，写成下面这种形式： 12auto cmp = [](student&amp; x, student&amp; y) &#123; return x.score &gt; y.score; &#125;;priority_queue&lt;student, vector&lt;student&gt;, decltype(cmp)&gt; q(cmp); 虽然看起来还是有点怪，但总比下面这样要好看的多： 123456struct cmp_custom &#123; bool operator()(student&amp; x, student&amp; y) &#123; return x.score &gt; y.score; &#125;&#125;;priority_queue&lt;student, vector&lt;student&gt;, cmp_custom&gt; q; 常用函数优先队列的常用函数与队列类似，常用的有以下这些，如果想了解详细的用法，请戳在线文档 函数名 含义 top 访问队列的头部元素 empty 判断优先队列内是否有元素 size 返回优先队列内元素个数 push 向优先队列中插入元素 emplace 在优先队列中构造元素 pop 从优先队列头部弹出元素 swap 与其他容器交换元素 总结 优先队列在一些需要部分排序的场景可以加快访问速度，降低时间复杂度 优先队列加速所付出的代价就是构建堆结构所需的内存，时间和空间总是一对矛盾共同体 以自定义结构作为元素的优先队列需要单独编写比较函数，可以使用lambda表达式，并用 decltype(cmp) 推导类型 需要注意的是这里的优先队列定义，第三个参数的需要的是比较函数的参数类型，而不是比较函数，区分与 std::sort 的不同 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 人在比较中奋进，同在比较中消亡，起初面临差距时会奋起直追，但是当努力过后发现距离反而越来越远时，便会麻木懈怠，曾经的努力没有用吗？我觉得不是，努力过不一定会成功，但是努力的过程已经印在了骨子里，这本身就是生活的一部分。你可以选择这条艰苦的路，同样也可以选择跳过，至于跳过时错失了什么，谁又知道呢？毕竟人生无法再来过，重新读档只发生在游戏世界中~ 2020-9-12 17:06:10]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>queue</tag>
        <tag>priority_queue</tag>
        <tag>heap</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git log根据特定条件查询日志并统计修改的代码行数]]></title>
    <url>%2Fblog%2F2020%2F09%2F05%2Fgit-log%E6%A0%B9%E6%8D%AE%E7%89%B9%E5%AE%9A%E6%9D%A1%E4%BB%B6%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97%E5%B9%B6%E7%BB%9F%E8%AE%A1%E4%BF%AE%E6%94%B9%E7%9A%84%E4%BB%A3%E7%A0%81%E8%A1%8C%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言随着年龄的增长和知识的积累，最近常常有种豁然开朗的感觉，或者对一个已经存在的事物突然有了新的认识，比如统计这个词很早就接触了，从没考虑过它是什么意思，而这篇总结的题目中用了统计一词，第一感觉应该是汇总、记录的意思，后来去查了词条定义，也确实就是类似的解释，从没有刻意去学这个词的含义，但是在每天的生活中已经潜移默化地归纳、总结出来了。 想要统计就得有数据源，而 git log 命令恰恰就能提供这个数据源，git log 本身就是一个显示日志的命令，日志记录的是代码库变化的数据，类似于描述代码库变化的 “史书”，想要描述历史就需要大量的数据支撑，想要统计修改的代码行数，只要我们从历史记录中找到需要计算的部分就可以了。 git log在统计之前我们需要先整理数据，杂乱无章的数据不是不能统计，只是计算起来更加的麻烦，所以在统计前需要先将数据规范化，所以我们需要先学习一下 git log 的相关操作。 我们以 redis 开源库为例，切换到 6.0 分支，提交记录定位到 7bf665f125a4771db095c83a7ad6ed46692cd314，以此为数据源，学习一下git log 的常用的查询方法，其实使用不同的条件查询就是整理、归类数据的过程。 git log 的用法多种多样，我们主要关心两个大类，分别是条件筛选和显示格式。 条件筛选git log 条件筛选的选项非常多，使用条件筛选的选项会影响显示的提交记录的范围，查找到想要显示的提交记录。 查询最近几条log使用 -number 参数可以查询最近几条提交提交记录： 1234567891011121314151617181920$ git log -3commit 7bf665f125a4771db095c83a7ad6ed46692cd314 (HEAD -&gt; 6.0, tag: 6.0.6, origin/6.0)Author: Oran Agra &lt;oran@redislabs.com&gt;Date: Sun Jul 19 14:00:20 2020 +0300 Redis 6.0.6.commit a5696bdf4f2687ab45f633ccb7cdc4ee9c2f957dAuthor: Oran Agra &lt;oran@redislabs.com&gt;Date: Sun Jul 19 15:33:21 2020 +0300 Run daily CI on PRs to release a branchcommit e15528bf1da1f1232fd08801ad382c915be94662Author: Itamar Haber &lt;itamar@redislabs.com&gt;Date: Thu Jul 16 21:31:36 2020 +0300 Adds SHA256SUM to redis-stable tarball upload (cherry picked from commit 5df0a64d30e7815c0a4a75a80f165fdee0bd1db6) 查询指定作者提交使用 --author 参数可以查询指定作者的提交记录： 12345678910111213Albert@DESKTOP-6746UC3 MINGW64 /d/data/maingit/redis (6.0)$ git log -2 --author='Oran Agra'commit 7bf665f125a4771db095c83a7ad6ed46692cd314 (HEAD -&gt; 6.0, tag: 6.0.6, origin/6.0)Author: Oran Agra &lt;oran@redislabs.com&gt;Date: Sun Jul 19 14:00:20 2020 +0300 Redis 6.0.6.commit a5696bdf4f2687ab45f633ccb7cdc4ee9c2f957dAuthor: Oran Agra &lt;oran@redislabs.com&gt;Date: Sun Jul 19 15:33:21 2020 +0300 Run daily CI on PRs to release a branch 查询指定时间段的日志这个可选参数比较多，比如 --since、--until、--before、--after 等等，从意思很容易分辨怎么使用： 查询2020-01-01到2020-04-01的提交记录 123456789101112$ git log -2 --after=2020-01-01 --before=2020-04-01commit 957e917a84ac9979f18145a4d0b53386f5ce4fd9 (tag: 6.0-rc3)Author: antirez &lt;antirez@gmail.com&gt;Date: Tue Mar 31 17:56:04 2020 +0200 Redis 6.0-RC3.commit ef1b1f01a84e969ea368e7fdbaf0d10615743269Author: antirez &lt;antirez@gmail.com&gt;Date: Tue Mar 31 17:41:23 2020 +0200 cast raxSize() to avoid warning with format spec. 恰好逮到了原作者的提交~ 查询1年前的提交记录 1234567891011121314151617181920$ git log -2 --until=1.year.agocommit 86aade9a024c3582665903d0cc0c5692c6677cfdMerge: 89ad0ca56 3bfcae247Author: Salvatore Sanfilippo &lt;antirez@gmail.com&gt;Date: Thu Sep 5 13:30:26 2019 +0200 Merge pull request #6364 from oranagra/fix_module_aux_when Fix to module aux data rdb format for backwards compatibility with old check-rdbcommit 3bfcae247a1c51788940bd4d2f32751ead451e42Author: Oran Agra &lt;oran@redislabs.com&gt;Date: Thu Sep 5 14:11:37 2019 +0300 Fix to module aux data rdb format for backwards compatibility with old check-rdb When implementing the code that saves and loads these aux fields we used rdb format that was added for that in redis 5.0, but then we added the 'when' field which meant that the old redis-check-rdb won't be able to skip these. this fix adds an opcode as if that 'when' is part of the module data. 查询包含指定描述内容的提交记录这里用可以使用 --grep 参数，可以过滤出包含指定内容的提交记录，这里指的是在 commit 描述中筛选符合条件的提交，比如查找提交描述中包含 client 的提交记录： 123456789101112131415161718192021222324$ git log -2 --grep='client'commit 0f75036c07db48dfcf605e090216a4447edc38fcAuthor: Wen Hui &lt;wen.hui.ware@gmail.com&gt;Date: Wed Jul 15 05:38:47 2020 -0400 correct error msg for num connections reaching maxclients in cluster mode (#7444) (cherry picked from commit d85af4d6f5fbe9cb9787b81583627cd74b47f838)commit f89f50dbd06247677b8cb3927cbb88c1b5384061Author: Oran Agra &lt;oran@redislabs.com&gt;Date: Tue Jul 14 20:21:59 2020 +0300 diskless master disconnect replicas when rdb child failed (#7518) in case the rdb child failed, crashed or terminated unexpectedly redis would have marked the replica clients with repl_put_online_on_ack and then kill them only after a minute when no ack was received. it would not stream anything to these connections, so the only effect of this bug is a delay of 1 minute in the replicas attempt to re-connect. (cherry picked from commit a176cb56a3c0235adddde33fcbaee2369a5af73e) 查找指定分支的提交记录使用 git log 默认查找的是当前分支的提交记录，如果想查询其他分支的记录直接在命令后面加上分支名字就行，比如查询 arm 分支上的提交记录： 123456789101112131415161718192021222324$ git log -2 armcommit 7329cc39818a05c168e7d1e791afb03c089f1933 (origin/arm, arm)Author: Salvatore Sanfilippo &lt;antirez@gmail.com&gt;Date: Sun Feb 19 15:07:08 2017 +0000 ARM: Avoid fast path for BITOP. GCC will produce certain unaligned multi load-store instructions that will be trapped by the Linux kernel since ARM v6 cannot handle them with unaligned addresses. Better to use the slower but safer implementation instead of generating the exception which should be anyway very slow.commit 4e9cf4cc7ed4b732fc4bb592f19ceb41d132954eAuthor: Salvatore Sanfilippo &lt;antirez@gmail.com&gt;Date: Sun Feb 19 15:02:37 2017 +0000 ARM: Use libc malloc by default. I'm not sure how much test Jemalloc gets on ARM, moreover compiling Redis with Jemalloc support in not very powerful devices, like most ARMs people will build Redis on, is extremely slow. It is possible to enable Jemalloc build anyway if needed by using "make MALLOC=jemalloc". 其实在 git 体系中，分支名、commit、标签等拥有几乎相同的含义，所以在很多场景下可以扩展互换，比如 git log 后面加上分支名就可以查询指定分支的提交记录，如果加上 commit 就会查询这个 commit 之前的提交记录，如果加上标签，就可以查询这个标签之前的提交记录，比如我们加一个 commit 试试： 123456789101112131415161718192021222324$ git log -2 7329cc39818a05c168e7d1e791afb03c089f1933commit 7329cc39818a05c168e7d1e791afb03c089f1933 (origin/arm, arm)Author: Salvatore Sanfilippo &lt;antirez@gmail.com&gt;Date: Sun Feb 19 15:07:08 2017 +0000 ARM: Avoid fast path for BITOP. GCC will produce certain unaligned multi load-store instructions that will be trapped by the Linux kernel since ARM v6 cannot handle them with unaligned addresses. Better to use the slower but safer implementation instead of generating the exception which should be anyway very slow.commit 4e9cf4cc7ed4b732fc4bb592f19ceb41d132954eAuthor: Salvatore Sanfilippo &lt;antirez@gmail.com&gt;Date: Sun Feb 19 15:02:37 2017 +0000 ARM: Use libc malloc by default. I'm not sure how much test Jemalloc gets on ARM, moreover compiling Redis with Jemalloc support in not very powerful devices, like most ARMs people will build Redis on, is extremely slow. It is possible to enable Jemalloc build anyway if needed by using "make MALLOC=jemalloc". 因为 commit id 就是之前的 arm 分支最新的记录，所以这个命令等价于 git log -2 arm 查询指定 commit 之间的提交记录如果想查询两个 commit 之前的提交记录，可以将两个 commit id 依次放在命令后面并用 .. 连接就可以了，格式为 git log commit1..commit2，需要注意的是这样查询出来的提交记录列表中不包含 commit1，其实列举出的就是 commit1 之后又做了哪些修改提交。 123456789101112$ git log e15528bf1da1f1232fd08801ad382c915be94662..7bf665f125a4771db095c83a7ad6ed46692cd314commit 7bf665f125a4771db095c83a7ad6ed46692cd314 (HEAD -&gt; 6.0, tag: 6.0.6, origin/6.0)Author: Oran Agra &lt;oran@redislabs.com&gt;Date: Sun Jul 19 14:00:20 2020 +0300 Redis 6.0.6.commit a5696bdf4f2687ab45f633ccb7cdc4ee9c2f957dAuthor: Oran Agra &lt;oran@redislabs.com&gt;Date: Sun Jul 19 15:33:21 2020 +0300 Run daily CI on PRs to release a branch 这个特性有一个应用就是在 merge 分支之前可以查询究竟会 merge 哪些记录，常见的用法比如 git log feature..dev 就是列举出 feature 分支合并到 dev 分支将要合并的提交记录有哪些。 123456$ git log 6.0..unstablecommit 324e22accf457edc996971bc97f5474349cd7c4c (unstable)Author: antirez &lt;antirez@gmail.com&gt;Date: Fri Dec 20 12:29:02 2019 +0100 Fix ip and missing mode in RM_GetClusterNodeInfo(). 查询指定文件的提交记录查询指定文件的提交记录一般直接在 git log 命令后面跟上文件名就可以，但是为了避免和分支名产生分歧，所以通常在文件名前面加上 -- 用来区分，-- 这个标识符就是用来防止混淆的，放在 -- 前面的是分支名，放在后面的是文件名，相同的作用不仅仅在 git log 命令中，在其他命令比如 git checkout 中也有相同的用法。 12345678910111213141516171819$ git log -2 -- redis.confcommit 7a536c2912be1fd9f62b26b7022a00644c88ef8bAuthor: Yossi Gottlieb &lt;yossigo@users.noreply.github.com&gt;Date: Fri Jul 10 11:33:47 2020 +0300 TLS: Session caching configuration support. (#7420) * TLS: Session caching configuration support. * TLS: Remove redundant config initialization. (cherry picked from commit 3e6f2b1a45176ac3d81b95cb6025f30d7aaa1393)commit 8312aa27d47c0befcf69eb74d0a5dc19745ffd32Author: antirez &lt;antirez@gmail.com&gt;Date: Mon Jun 22 11:21:21 2020 +0200 Clarify maxclients and cluster in conf. Remove myself too. (cherry picked from commit 59fd178014c7cca1b0c668b30ab0d991dd3030f3) 显示格式git log 除了可以筛选提交记录，还可以控制显示格式，普通不加参数，会显示作者、邮件、提交描述信息、日期等信息。 123456$ git log -1commit 7bf665f125a4771db095c83a7ad6ed46692cd314 (HEAD -&gt; 6.0, tag: 6.0.6, origin/6.0)Author: Oran Agra &lt;oran@redislabs.com&gt;Date: Sun Jul 19 14:00:20 2020 +0300 Redis 6.0.6. 通过添加参数可以控制和改变显示格式，下面来看几条常见的 显示单行信息git log 默认会显示多行信息，使用 --oneline 后每条提交记录只显示一行信息，可以在一屏幕中查看到更多的信息 1234567891011$ git log -10 --oneline7bf665f12 (HEAD -&gt; 6.0, tag: 6.0.6, origin/6.0) Redis 6.0.6.a5696bdf4 Run daily CI on PRs to release a branche15528bf1 Adds SHA256SUM to redis-stable tarball uploade28aa99af Support passing stack allocated module strings to moduleCreateArgvFromUserFormat (#7528)305143004 Send null for invalidate on flush (#7469)29b20fd52 Notify systemd on sentinel startup (#7168)5b3668121 Add registers dump support for Apple silicon (#7453)0f75036c0 correct error msg for num connections reaching maxclients in cluster mode (#7444)b1a01fda9 Fix command help for unexpected options (#7476)83f55f61a Refactor RM_KeyType() by using macro. (#7486) 显示每条记录中文件修改的具体行数和行体统计使用 --stat 参数就可以显示每条记录的中修改文件的具体行数和行数统计 1234567891011121314151617181920$ git log -2 --statcommit 7bf665f125a4771db095c83a7ad6ed46692cd314 (HEAD -&gt; 6.0, tag: 6.0.6, origin/6.0)Author: Oran Agra &lt;oran@redislabs.com&gt;Date: Sun Jul 19 14:00:20 2020 +0300 Redis 6.0.6. 00-RELEASENOTES | 245 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++ src/help.h | 4 +- src/version.h | 2 +- 3 files changed, 248 insertions(+), 3 deletions(-)commit a5696bdf4f2687ab45f633ccb7cdc4ee9c2f957dAuthor: Oran Agra &lt;oran@redislabs.com&gt;Date: Sun Jul 19 15:33:21 2020 +0300 Run daily CI on PRs to release a branch .github/workflows/daily.yml | 6 ++++-- 1 file changed, 4 insertions(+), 2 deletions(-) 显示每条提交记录中文件的增加行数和删除行数使用 --numstat 参数会把 --stat 参数中合并显示的修改行数拆分成增加行数和删除行数 123456789101112131415161718$ git log -2 --numstatcommit 7bf665f125a4771db095c83a7ad6ed46692cd314 (HEAD -&gt; 6.0, tag: 6.0.6, origin/6.0)Author: Oran Agra &lt;oran@redislabs.com&gt;Date: Sun Jul 19 14:00:20 2020 +0300 Redis 6.0.6.245 0 00-RELEASENOTES2 2 src/help.h1 1 src/version.hcommit a5696bdf4f2687ab45f633ccb7cdc4ee9c2f957dAuthor: Oran Agra &lt;oran@redislabs.com&gt;Date: Sun Jul 19 15:33:21 2020 +0300 Run daily CI on PRs to release a branch4 2 .github/workflows/daily.yml 依次罗列各提交记录中每个文件中增加的行数和删除的行数要想达到这个目的需要用到 --prety=tformat: --numstat 参数，这样的显示格式便于统计 12345$ git log -2 --pretty=tformat: --numstat245 0 00-RELEASENOTES2 2 src/help.h1 1 src/version.h4 2 .github/workflows/daily.yml 统计修改的代码行数有了前面的铺垫，想要统一修改的行数就容易了，只要配合 awk 工具就可以完成统计了 12$ $ git log -2 --pretty=tformat: --numstat | awk '&#123;adds += $1; subs += $2; diffs += $1 - $2&#125; END &#123;printf "added lines: %s removed lines: %s, diff lines: %s\n", adds, subs, diffs&#125;'added lines: 252 removed lines: 5, diff lines: 247 还可以统计两个分支相差的代码行数 12$ git log 6.0..unstable --pretty=tformat: --numstat | awk '&#123;adds += $1; subs += $2; diffs += $1 - $2&#125; END &#123;printf "added lines: %s removed lines: %s, diff lines: %s\n", adds, subs, diffs&#125;'added lines: 5 removed lines: 2, diff lines: 3 到这里可以发现前面的知识都可以用上，前面筛选的参数变了，得到的结果就变了，我们可以根据需求来调整不同的参数 总结 git log 就是一部代码库记录的“史书”，对于曾经所做的修改可以做到有史可查 git log 的选项参数可以分为筛选参数和格式参数，筛选参数可以选择记录范围，格式参数可以控制显示样式 统计就是按照一定规律来将数据进行汇总，在进行汇总前需要将数据进行整理，这样汇总的工作才会更加顺利 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 慌慌张张，匆匆忙忙，原来生活就是这样~ 2020-9-7 00:05:18]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>log</tag>
        <tag>awk</tag>
        <tag>统计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python中时间戳、时间字符串、时间结构对象之间的相互转化]]></title>
    <url>%2Fblog%2F2020%2F08%2F27%2FPython%E4%B8%AD%E6%97%B6%E9%97%B4%E6%88%B3%E3%80%81%E6%97%B6%E9%97%B4%E5%AD%97%E7%AC%A6%E4%B8%B2%E3%80%81%E6%97%B6%E9%97%B4%E7%BB%93%E6%9E%84%E5%AF%B9%E8%B1%A1%E4%B9%8B%E9%97%B4%E7%9A%84%E7%9B%B8%E4%BA%92%E8%BD%AC%E5%8C%96%2F</url>
    <content type="text"><![CDATA[前言使用 Python 写程序的时候常常要查看中间结果，需要把一些内容记录到日志中，为了不让新产生的日志覆盖之前的日志文件，所以通常使用时间字符串来作为文件名，类似于 2020827_233842.log 这种格式，就是表示程序在 2020-8-27 23:38:42 启动时产生的日志文件。 日志文件名需要一个字符串，但是这个时间字符串不能直接得到，需要将时间戳经过转化才可以，每次用到都要查一次有些浪费时间，总结到一起方便自己今后快速查找。 通过学习总结发现，操作时间和日期常用的模块有 time 和 datetime 这两个，并且 time 模块与 C 语言中的时间处理函数颇为相似，下面来一起看一下吧。 时间的表示形式显示生活中的时间表示形式多种多样，比如15分钟可以说成是1刻钟，半夜12点可以叫做子时，在程序中也有几种常用的表示形式，比如 python 中的时间戳、时间结构对象和时间字符串，分别对应 C 语言中的time_t、struct tm 和 char[]，处理函数的名字也很相近，自己可以扩展学习下，本文只列举 Python 的用法了 时间戳在Python中被实现成一个浮点数，表示从1970年1月1日00:00:00到当前时间所经历的秒数，因为是浮点数所以可以表示不足1秒的时间，而在有些语言中，比如C 语言中使用整数来表示这个值，在 python 中使用 time.time() 函数来获取时间戳： 12345678import timeval = time.time()print(val, type(val))'''输出结果1598769108.8337526 &lt;class 'float'&gt;''' 时间结构对象在 python 中使用 time.struct_time 这个类用来表示时间结构，其实是一个九元组，可以参考C语言中的 struct tm结构，表现形式相同，在 python 中这个九元组中元素依次表达的含义是：4位数年份、1-12月、1-31日、0-23小时、0-59分钟，0-59秒，0-6一周第几日，1-366一年第几日，{-1, 0, 1}夏令时标志。 通过代码我们可以尝试构造如下，不够时间使用时通常是通过函数转化，很少直接构造 time.struct_time 对象。 123456789import timeval = time.struct_time([2020, 8, 30, 14, 45, 30, 6, 243, 0])print(val, type(val))'''输出结果time.struct_time(tm_year=2020, tm_mon=8, tm_mday=30, tm_hour=14, tm_min=45, tm_sec=30, tm_wday=6, tm_yday=243, tm_isdst=0) &lt;class 'time.struct_time'&gt;''' 时间字符串时间字符串是本质上是一种普通的字符串，因为用来表示时间所以感觉上有些不同，实际使用过程时会通过转化函数来生成时间字符串，然后就可以当场普通字符串来使用了，比如记录日志时间，作为文件名等都是常见用法。 12345678import timeval = '2019-08-30 15:04:00'print(val, type(val))'''输出结果2019-08-30 15:04:00 &lt;class 'str'&gt;''' 举例说明仅仅认识了这三种类型还是不够的，还要学习经常使用的转化函数才可以，上面提到的这三种类型一般不会从时间戳到字符串或者从字符戳到时间戳，都是通过时间结构对象来转化的，所以常见的转化是时间戳和时间结构对象的转化、时间结构对象和时间字符串的转化，需要用到的函数展示如下图： 示例代码1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889import time# 生成时间戳t = time.time()print(t, type(t))'''1598775821.840567 &lt;class 'float'&gt;'''# 生成时间结构对象(本地时间)l = time.localtime()print(l, type(l))'''time.struct_time(tm_year=2020, tm_mon=8, tm_mday=30, tm_hour=16, tm_min=23, tm_sec=41, tm_wday=6, tm_yday=243, tm_isdst=0) &lt;class 'time.struct_time'&gt;'''# 时间戳 -&gt; 时间结构对象(本地时间)l = time.localtime(t)print(l, type(l))'''time.struct_time(tm_year=2020, tm_mon=8, tm_mday=30, tm_hour=16, tm_min=23, tm_sec=41, tm_wday=6, tm_yday=243, tm_isdst=0) &lt;class 'time.struct_time'&gt;'''# 生成时间结构对象(格林威治时间)g = time.gmtime()print(g, type(g))'''time.struct_time(tm_year=2020, tm_mon=8, tm_mday=30, tm_hour=8, tm_min=23, tm_sec=41, tm_wday=6, tm_yday=243, tm_isdst=0) &lt;class 'time.struct_time'&gt;'''# 时间戳 -&gt; 时间结构对象(格林威治时间)g = time.gmtime(t)print(g, type(g))'''time.struct_time(tm_year=2020, tm_mon=8, tm_mday=30, tm_hour=8, tm_min=23, tm_sec=41, tm_wday=6, tm_yday=243, tm_isdst=0) &lt;class 'time.struct_time'&gt;'''# 生成时间字符串s = time.strftime("%Y-%m-%d %X")print(s, type(s))'''2020-08-30 16:23:41 &lt;class 'str'&gt;'''# 时间结构对象 -&gt; 时间字符串s = time.strftime("%Y-%m-%d %X",time.localtime())print(s, type(s))'''2020-08-30 16:23:41 &lt;class 'str'&gt;''''================================================================='# 定义时间字符串s = '2022-02-18 09:30:00'# 时间字符串 -&gt; 时间结构对象l = time.strptime(s, '%Y-%m-%d %X')print(l, type(l))'''time.struct_time(tm_year=2022, tm_mon=2, tm_mday=18, tm_hour=9, tm_min=30, tm_sec=0, tm_wday=4, tm_yday=49, tm_isdst=-1) &lt;class 'time.struct_time'&gt;'''# 时间结构对象 -&gt; 时间戳t = time.mktime(l)print(t, type(t))'''1645147800.0 &lt;class 'float'&gt;''''================================================================='# 生成固定格式(%a %b %d %H:%M:%S %Y)时间字符串s = time.asctime(time.localtime())print(s, type(s))'''Sun Aug 30 16:23:41 2020 &lt;class 'str'&gt;'''s = time.ctime(time.time())print(s, type(s))'''Sun Aug 30 16:23:41 2020 &lt;class 'str'&gt;''' 格式化符号将时间转化成字符串表示形式的时候，需要使用格式化符号，为了查找方便整理如下： 格式 含义 %a 本地（locale）简化星期名称 %A 本地完整星期名称 %b 本地简化月份名称 %B 本地完整月份名称 %c 本地相应的日期和时间表示 %d 一个月中的第几天（01 - 31） %H 一天中的第几个小时（24小时制，00 - 23） %I 第几个小时（12小时制，01 - 12） %j 一年中的第几天（001 - 366） %m 月份（01 - 12） %M 分钟数（00 - 59） %p 本地am或者pm的相应符 %S 秒（00 - 59） %U 一年中的星期数。（00 - 53星期天是一个星期的开始。） %w 一个星期中的第几天（0 - 6，0是星期天） %W 和%U基本相同，不同的是%W以星期一为一个星期的开始。 %x 本地相应日期 %X 本地相应时间 %y 去掉世纪的年份（00 - 99） %Y 完整的年份 %Z 时区的名字（如果不存在为空字符） 总结 时间戳和时间字符串的转化，通常要经过时间结构对象作为中间结果。 时间戳也可以通过 time.ctime() 函数直接转化为时间字符串，但格式固定。 常用来表示文件名的时间字符串写法：time.strftime(&quot;%Y%m%d_%H%M%S&quot;, time.localtime()) ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 有时选择的意义确实高于努力的结果，认清这一点，学会适当的放下，会让焦躁的生活更美好一点，毕竟全部都坚持真的太累了，有时收益真的不高~ 2020-8-30 21:50:19]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>time</tag>
        <tag>datetime</tag>
        <tag>转化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GDB调试指北-启动调试或者附加到进程]]></title>
    <url>%2Fblog%2F2020%2F08%2F17%2FGDB%E8%B0%83%E8%AF%95%E6%8C%87%E5%8C%97-%E5%90%AF%E5%8A%A8%E8%B0%83%E8%AF%95%E6%88%96%E8%80%85%E9%99%84%E5%8A%A0%E5%88%B0%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言要想使用 gdb 调试程序，必须让 gdb 程序和被调试程序建立联系，这种联系可以通过程序的可执行文件、core文件或者正在运行的进程来建立，具体调试的时候使用的选项不同，涉及到参数的传递，选项的顺序，多进程启动前的设置等等，接下来可以看一些常见用法。 测试样例首先来写一段简单的但是会自动崩溃的代码，主要是为了展示core文件的调试方法，通过调试崩溃产生的core文件是一种很直接的查找问题的方法，可以帮助我们快速定位到问题的栈帧，进而找到具体的逻辑代码。 代码内容新建文件 examplepro.cpp，编写代码内容如下： 123456789101112131415161718#include &lt;iostream&gt;using namespace std;int main(int argc, char* argv[])&#123; if (argc &gt; 1) cout &lt;&lt; "argv[1] = " &lt;&lt; argv[1] &lt;&lt; endl; int a = 3, b = 4; int c = a + b; cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl; int *p = NULL; *p = c; return 0;&#125; 代码编译1g++ examplepro.cpp -o examplepro -g 运行程序123albert@home-pc:~/WorkSpace/cpp$ ./exampleproc = 7Segmentation fault (core dumped) 我们发现程序在运行之后发生了段错误，这是一种比较常见的BUG，通常由访问无效内存导致，查看程序目录下内容，多了一个叫 core 的文件。 12albert@home-pc:~/WorkSpace/cpp$ lscore examplepro examplepro.cpp 通过这一步你可能看不到这个 core 文件，需要检查两点，第一是编译的时候需要加 -g 选项，第二是使用 ulimit -c unlimited 命令设置core文件占用空间的最小限制，默认大小为0，也就是不产生 core 文件，需要改为 unlimited 才可以，如果你确定产生的 core 文件不会太大，也可以设置一个具体的数值。 使用gdb调试有了上面的程序我们就可以进行调试了，因为已经产生了 core 文件，所以先来调试一下 core 文件，看下程序崩溃的原因。 使用gdb调试core文件启动程序的语法如下，gdb 命令之后跟程序名，然后后面跟着 core 文件的名字： 1gdb examplepro core 具体调试的时候需要换成自己的崩溃的程序名，而core文件大多数是 core.进程id 的形式。 调试过程12345678910111213141516171819202122albert@home-pc:~/WorkSpace/cpp$ gdb examplepro coreGNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1Copyright (C) 2016 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-linux-gnu".Type "show configuration" for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type "help".Type "apropos word" to search for commands related to "word"...Reading symbols from examplepro...done.[New LWP 19786]Core was generated by `./examplepro'.Program terminated with signal SIGSEGV, Segmentation fault.#0 0x0000000000400932 in main (argc=1, argv=0x7ffd23cc3a18) at examplepro.cpp:1515 *p = c;(gdb) 从调试信息来看一下就定位到了问题，在代码的第15行发生了段错误，也就是我们刚刚给野指针赋值的代码。 使用gdb直接启动程序这种情况就是调试运行，相当于在 gdb 的监控下启动程序，一旦发生错误，gdb 会给出响应的提示，启动方式很简单，gdb 命令之后直接跟着程序名字就可以了。 1gdb examplepro 调试过程123456789101112131415161718192021222324albert@home-pc:~/WorkSpace/cpp$ gdb exampleproGNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1Copyright (C) 2016 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-linux-gnu".Type "show configuration" for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type "help".Type "apropos word" to search for commands related to "word"...Reading symbols from examplepro...done.(gdb) runStarting program: /home/albert/WorkSpace/cpp/exampleproc = 7Program received signal SIGSEGV, Segmentation fault.0x0000000000400932 in main (argc=1, argv=0x7fffffffdd18) at examplepro.cpp:1515 *p = c;(gdb) 这种情况下，启动之后需要输入 run 命令才可以运行程序，这时发现程序又崩溃了。 如果被调试的程序有参数的话，需要将启动的命令进行修改，写成 gdb --args examplepro testparam1，加上 --args 选项，然后将参数罗列在后面就好了，因为看这些声明很麻烦，我们利用之前学过的 -q 选项来屏蔽启动说明，测试如下： 1234567891011albert@home-pc:~/WorkSpace/cpp$ gdb -q --args examplepro NBReading symbols from examplepro...done.(gdb) runStarting program: /home/albert/WorkSpace/cpp/examplepro NBargv[1] = NBc = 7Program received signal SIGSEGV, Segmentation fault.0x0000000000400932 in main (argc=2, argv=0x7fffffffdd08) at examplepro.cpp:1515 *p = c;(gdb) 还有一种写法就是启动 gdb 之后再传参数，具体操作方法如下： 1234567891011albert@home-pc:~/WorkSpace/cpp$ gdb -q exampleproReading symbols from examplepro...done.(gdb) run NBStarting program: /home/albert/WorkSpace/cpp/examplepro NBargv[1] = NBc = 7Program received signal SIGSEGV, Segmentation fault.0x0000000000400932 in main (argc=2, argv=0x7fffffffdd08) at examplepro.cpp:1515 *p = c;(gdb) 这种情况是先启动 gdb，然后在执行 run 命令的时候传递参数。 使用gdb调试正在运行的文件这时需要获得被套是程序的进程id，可以使用 ps、top 或者 pidof 命令来获取进程id，然后通过 attch 的方式附加到进程。 比如查到需要调试的 examplepro 程序进程号是 3598，那么可以直接启动 gdb 附加到这个进程： 1gdb examplepro 3598 也可以先启动 gdb，然后使用 attach 命令附加到进程： 123albert@home-pc:~/WorkSpace/cpp$ gdb -q exampleproReading symbols from examplepro...done.(gdb) attach 3598 如果此时提示进程拒绝被附加通常是权限问题，可以使用所属账号调试，或者可以尝试 sudo 命令。 语法对比常见的调试方式就文中提到的这几种，特整理成表格方便对比和查找： 语法 解释 gdb examlepro 直接 gdb 调试启动 gdb examlepro core.3598 调试崩溃的 core 文件 gdb examlepro 3598gdb -p 3598 附加到正在运行的程序进程上 gdb attach 3598 先启动gdb，后附加到程序上 总结 gdb 不但可以调试 core 文件，还可以调试正在运行的程序，这对于难重现的 bug 来说非常有帮助 在调试正在运行的程序时可以使用 pidof 命令来直接获取被调试程序的进程号 gdb 调试附加的进程的时候要注意权限问题，如果不成功可以尝试 sudo 命令 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 兜兜转转又换了一个住所，匆匆忙忙如蝼蚁般迁徙，路程短了，可选的路却少了。回头看看，一个窝、一段事、一群人而已~ 2020-8-25 00:24:01]]></content>
      <categories>
        <category>GDB</category>
      </categories>
      <tags>
        <tag>GDB</tag>
        <tag>manual</tag>
        <tag>调试</tag>
        <tag>启动</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis源码-BFS方式浏览main函数]]></title>
    <url>%2Fblog%2F2020%2F08%2F05%2FRedis%E6%BA%90%E7%A0%81-BFS%E6%96%B9%E5%BC%8F%E6%B5%8F%E8%A7%88main%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言欠下的技术债慢慢还，继续为去年吹过的牛而努力。去年年末的时候意识到自己掌握的知识还不够深入，决定开始看一些开源项目的源码，因为当时 Redis 的兴起，所以瞄准了准备从它下手，之后确实看了一部分内容，比如跳表、网络事件库等等，后来过年就鸽了。今年开始一直熟悉新的业务，比较懒没跟进，最近间歇性踌躇满志又发作了，准备抽时间再捋顺一遍，老规矩，还是从 main() 函数下手。 对于 C/C++ 程序一定是从 main() 函数开头的，这是我们切入的一个点，至于怎么找到 main 函数，每个人有不同的方法，最暴力的方法当然就是全文搜索了，不过较为成熟的项目一般搜索出来都不止一个 main 函数，因为整个项目完整构建下来不止一个程序。 像 redis 这个项目最起码有服务器和客户端两个程序，源码中至少包含了两个 main 函数，再加上一些测试程序，main 函数在源码中会有很多。再比如 Lua 的源代码中包含和解释器和编译器，如果直接搜索至少会找到两个 main 函数。 redis 服务器程序的 main 函数在文件 src/server.c 中，之前好像是在 redis.c 文件中后来改名了，这都不重要，反正你需要从搜索出来的 main 函数中找到一个开始的地方，这个花不了多少时间。 看代码的方式标题中提到了 BFS 方式看代码，而 BFS 指的是广度优先搜索，与之相对应的是 DFS 深度优先搜索，对于不含异步调用的单线程程序来说，执行代码是以深度优先搜索的方式，遇到一个函数就调用进去，在函数中又遇到另一个函数再调用进去，当函数执行完成返回到上一层。 为什么选择 BFS 方式看代码呢？因为这样可以在短时间内更全面的了解代码结构，我们先看第一层，当第一层浏览完成之后再进入到第二层，比如我们先看 main 函数，即使 main 函数调用了很多不认识的函数也不要去管，从名字大概判断一些作用就可以了，不用纠结具体的实现内容，当 main 函数全部看完了再进入到第二层去了解它调用的那些函数。 总之使用 BFS 方式看代码就要有一种“不懂装懂”的态度，不然容易陷入细节，无法整体把握。 Redis 服务器的 main 函数redis 服务器的 main 函数代码量不是很大，总共 200 行左右，我选择了 6.0.6 这个版本 7bf665f125a4771db095c83a7ad6ed46692cd314，因为只是学习源码，没有特殊情况就不更新版本了，保证环境的统一，我先把代码贴一份在这，后面再来慢慢看。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214int main(int argc, char **argv) &#123; struct timeval tv; int j;#ifdef REDIS_TEST if (argc == 3 &amp;&amp; !strcasecmp(argv[1], "test")) &#123; if (!strcasecmp(argv[2], "ziplist")) &#123; return ziplistTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "quicklist")) &#123; quicklistTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "intset")) &#123; return intsetTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "zipmap")) &#123; return zipmapTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "sha1test")) &#123; return sha1Test(argc, argv); &#125; else if (!strcasecmp(argv[2], "util")) &#123; return utilTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "endianconv")) &#123; return endianconvTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "crc64")) &#123; return crc64Test(argc, argv); &#125; else if (!strcasecmp(argv[2], "zmalloc")) &#123; return zmalloc_test(argc, argv); &#125; return -1; /* test not found */ &#125;#endif /* We need to initialize our libraries, and the server configuration. */#ifdef INIT_SETPROCTITLE_REPLACEMENT spt_init(argc, argv);#endif setlocale(LC_COLLATE,""); tzset(); /* Populates 'timezone' global. */ zmalloc_set_oom_handler(redisOutOfMemoryHandler); srand(time(NULL)^getpid()); gettimeofday(&amp;tv,NULL); crc64_init(); uint8_t hashseed[16]; getRandomBytes(hashseed,sizeof(hashseed)); dictSetHashFunctionSeed(hashseed); server.sentinel_mode = checkForSentinelMode(argc,argv); initServerConfig(); ACLInit(); /* The ACL subsystem must be initialized ASAP because the basic networking code and client creation depends on it. */ moduleInitModulesSystem(); tlsInit(); /* Store the executable path and arguments in a safe place in order * to be able to restart the server later. */ server.executable = getAbsolutePath(argv[0]); server.exec_argv = zmalloc(sizeof(char*)*(argc+1)); server.exec_argv[argc] = NULL; for (j = 0; j &lt; argc; j++) server.exec_argv[j] = zstrdup(argv[j]); /* We need to init sentinel right now as parsing the configuration file * in sentinel mode will have the effect of populating the sentinel * data structures with master nodes to monitor. */ if (server.sentinel_mode) &#123; initSentinelConfig(); initSentinel(); &#125; /* Check if we need to start in redis-check-rdb/aof mode. We just execute * the program main. However the program is part of the Redis executable * so that we can easily execute an RDB check on loading errors. */ if (strstr(argv[0],"redis-check-rdb") != NULL) redis_check_rdb_main(argc,argv,NULL); else if (strstr(argv[0],"redis-check-aof") != NULL) redis_check_aof_main(argc,argv); if (argc &gt;= 2) &#123; j = 1; /* First option to parse in argv[] */ sds options = sdsempty(); char *configfile = NULL; /* Handle special options --help and --version */ if (strcmp(argv[1], "-v") == 0 || strcmp(argv[1], "--version") == 0) version(); if (strcmp(argv[1], "--help") == 0 || strcmp(argv[1], "-h") == 0) usage(); if (strcmp(argv[1], "--test-memory") == 0) &#123; if (argc == 3) &#123; memtest(atoi(argv[2]),50); exit(0); &#125; else &#123; fprintf(stderr,"Please specify the amount of memory to test in megabytes.\n"); fprintf(stderr,"Example: ./redis-server --test-memory 4096\n\n"); exit(1); &#125; &#125; /* First argument is the config file name? */ if (argv[j][0] != '-' || argv[j][1] != '-') &#123; configfile = argv[j]; server.configfile = getAbsolutePath(configfile); /* Replace the config file in server.exec_argv with * its absolute path. */ zfree(server.exec_argv[j]); server.exec_argv[j] = zstrdup(server.configfile); j++; &#125; /* All the other options are parsed and conceptually appended to the * configuration file. For instance --port 6380 will generate the * string "port 6380\n" to be parsed after the actual file name * is parsed, if any. */ while(j != argc) &#123; if (argv[j][0] == '-' &amp;&amp; argv[j][1] == '-') &#123; /* Option name */ if (!strcmp(argv[j], "--check-rdb")) &#123; /* Argument has no options, need to skip for parsing. */ j++; continue; &#125; if (sdslen(options)) options = sdscat(options,"\n"); options = sdscat(options,argv[j]+2); options = sdscat(options," "); &#125; else &#123; /* Option argument */ options = sdscatrepr(options,argv[j],strlen(argv[j])); options = sdscat(options," "); &#125; j++; &#125; if (server.sentinel_mode &amp;&amp; configfile &amp;&amp; *configfile == '-') &#123; serverLog(LL_WARNING, "Sentinel config from STDIN not allowed."); serverLog(LL_WARNING, "Sentinel needs config file on disk to save state. Exiting..."); exit(1); &#125; resetServerSaveParams(); loadServerConfig(configfile,options); sdsfree(options); &#125; serverLog(LL_WARNING, "oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo"); serverLog(LL_WARNING, "Redis version=%s, bits=%d, commit=%s, modified=%d, pid=%d, just started", REDIS_VERSION, (sizeof(long) == 8) ? 64 : 32, redisGitSHA1(), strtol(redisGitDirty(),NULL,10) &gt; 0, (int)getpid()); if (argc == 1) &#123; serverLog(LL_WARNING, "Warning: no config file specified, using the default config. In order to specify a config file use %s /path/to/%s.conf", argv[0], server.sentinel_mode ? "sentinel" : "redis"); &#125; else &#123; serverLog(LL_WARNING, "Configuration loaded"); &#125; server.supervised = redisIsSupervised(server.supervised_mode); int background = server.daemonize &amp;&amp; !server.supervised; if (background) daemonize(); initServer(); if (background || server.pidfile) createPidFile(); redisSetProcTitle(argv[0]); redisAsciiArt(); checkTcpBacklogSettings(); if (!server.sentinel_mode) &#123; /* Things not needed when running in Sentinel mode. */ serverLog(LL_WARNING,"Server initialized"); #ifdef __linux__ linuxMemoryWarnings(); #endif moduleLoadFromQueue(); ACLLoadUsersAtStartup(); InitServerLast(); loadDataFromDisk(); if (server.cluster_enabled) &#123; if (verifyClusterConfigWithData() == C_ERR) &#123; serverLog(LL_WARNING, "You can't have keys in a DB different than DB 0 when in " "Cluster mode. Exiting."); exit(1); &#125; &#125; if (server.ipfd_count &gt; 0 || server.tlsfd_count &gt; 0) serverLog(LL_NOTICE,"Ready to accept connections"); if (server.sofd &gt; 0) serverLog(LL_NOTICE,"The server is now ready to accept connections at %s", server.unixsocket); if (server.supervised_mode == SUPERVISED_SYSTEMD) &#123; if (!server.masterhost) &#123; redisCommunicateSystemd("STATUS=Ready to accept connections\n"); redisCommunicateSystemd("READY=1\n"); &#125; else &#123; redisCommunicateSystemd("STATUS=Waiting for MASTER &lt;-&gt; REPLICA sync\n"); &#125; &#125; &#125; else &#123; InitServerLast(); sentinelIsRunning(); if (server.supervised_mode == SUPERVISED_SYSTEMD) &#123; redisCommunicateSystemd("STATUS=Ready to accept connections\n"); redisCommunicateSystemd("READY=1\n"); &#125; &#125; /* Warning the user about suspicious maxmemory setting. */ if (server.maxmemory &gt; 0 &amp;&amp; server.maxmemory &lt; 1024*1024) &#123; serverLog(LL_WARNING,"WARNING: You specified a maxmemory value that is less than 1MB (current value is %llu bytes). Are you sure this is what you really want?", server.maxmemory); &#125; redisSetCpuAffinity(server.server_cpulist); aeMain(server.el); aeDeleteEventLoop(server.el); return 0;&#125; main 函数分段解释函数名及参数12345678int main(int argc, char **argv) &#123; struct timeval tv; int j; //... //... return 0&#125; 这就是一个标准的 main 函数，参数 argc 和 argv 对于一个命令行程序来说可以是重头戏，肯定会拿来做重度解析的，函数开头还定义了 tv 和 j 两个变量，不知道干嘛的，接着往下看吧。 启动测试程序12345678910111213141516171819202122232425#ifdef REDIS_TEST if (argc == 3 &amp;&amp; !strcasecmp(argv[1], "test")) &#123; if (!strcasecmp(argv[2], "ziplist")) &#123; return ziplistTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "quicklist")) &#123; quicklistTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "intset")) &#123; return intsetTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "zipmap")) &#123; return zipmapTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "sha1test")) &#123; return sha1Test(argc, argv); &#125; else if (!strcasecmp(argv[2], "util")) &#123; return utilTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "endianconv")) &#123; return endianconvTest(argc, argv); &#125; else if (!strcasecmp(argv[2], "crc64")) &#123; return crc64Test(argc, argv); &#125; else if (!strcasecmp(argv[2], "zmalloc")) &#123; return zmalloc_test(argc, argv); &#125; return -1; /* test not found */ &#125;#endif 当宏定义 REDIS_TEST 存在，并且参数合适的情况下启动测试程序，argv[0] 肯定是指 redis 服务器喽，那 argv[1] 的值如果是 test，而 argv[2] 的值是 ziplist，那么会调用 ziplist 的测试函数 ziplistTest，如果 argv[2] 的值是 zmalloc，那么会调用测试函数 zmalloc_test，为啥这里函数名命名规范不统一呢？挠头。 程序环境初始化12345678910 /* We need to initialize our libraries, and the server configuration. */#ifdef INIT_SETPROCTITLE_REPLACEMENT spt_init(argc, argv);#endif setlocale(LC_COLLATE,""); tzset(); /* Populates 'timezone' global. */ zmalloc_set_oom_handler(redisOutOfMemoryHandler); srand(time(NULL)^getpid()); gettimeofday(&amp;tv,NULL); crc64_init(); 当 INIT_SETPROCTITLE_REPLACEMENT 这个宏存在的时候，调用 spt_init 函数来为设置程序标题做准备 setlocale() 用来设置地点信息，这一句应该是设置成依赖操作系统的地点信息，比如中国，韩国等等 tzset() 设置时区，这里可能影响到程序运行后，调整时区是否对程序产生影响 srand(time(NULL)^getpid()); 初始化随机种子 gettimeofday(&amp;tv,NULL); 这里用到了函数开头定义的一个变量 tv，用来获取当前时间 crc64_init(); 循环冗余校验初始化，crc 神奇的存在 初始化配置信息123456789uint8_t hashseed[16];getRandomBytes(hashseed,sizeof(hashseed));dictSetHashFunctionSeed(hashseed);server.sentinel_mode = checkForSentinelMode(argc,argv);initServerConfig();ACLInit(); /* The ACL subsystem must be initialized ASAP because the basic networking code and client creation depends on it. */moduleInitModulesSystem();tlsInit(); 定一个16字节的空间用来存放哈希种子 随机获取一段16字节数据作为种子 将刚刚获取的种子数据设置到hash函数中 分析命令行参数，判断是否是哨兵模式 初始化服务器配置 ACL 初始化，不用管它具体是什么，进入下一层时自然会看到 初始化模块系统 tls 初始化，存疑，好奇的话进去看看也可以，好吧，原来是 ssl 那一套，够喝一壶的 存储参数信息123456/* Store the executable path and arguments in a safe place in order * to be able to restart the server later. */server.executable = getAbsolutePath(argv[0]);server.exec_argv = zmalloc(sizeof(char*)*(argc+1));server.exec_argv[argc] = NULL;for (j = 0; j &lt; argc; j++) server.exec_argv[j] = zstrdup(argv[j]); 这一小节比较简单，注释写的也很清楚，就是将命令行参数存储起来，方便重启 redis 服务 根据参数确定启动方式123456789101112131415/* We need to init sentinel right now as parsing the configuration file * in sentinel mode will have the effect of populating the sentinel * data structures with master nodes to monitor. */if (server.sentinel_mode) &#123; initSentinelConfig(); initSentinel();&#125;/* Check if we need to start in redis-check-rdb/aof mode. We just execute * the program main. However the program is part of the Redis executable * so that we can easily execute an RDB check on loading errors. */if (strstr(argv[0],"redis-check-rdb") != NULL) redis_check_rdb_main(argc,argv,NULL);else if (strstr(argv[0],"redis-check-aof") != NULL) redis_check_aof_main(argc,argv); 当启用哨兵模式的时候初始化额外的配置，啥是哨兵，现在还不用知道啊，从字面上来看就好了，反正知道命令行里如果指定了哨兵模式就要额外初始化一点东西。 下面这两个参数有点意思，简单扩展下，rdb 和 aof 是 redis 的两种数据落地的持久化方式，这里有意思的地方是判断了 argv[0] 这个参数，一般 argv[0] 是程序的名字，这个是固定不变的，而 redis 这里将程序名字作为参数来判断，也就是说你把可执行程序换个名字运行，它的行为就会发生变化。 处理并加载命令行参数1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465if (argc &gt;= 2) &#123; j = 1; /* First option to parse in argv[] */ sds options = sdsempty(); char *configfile = NULL; /* Handle special options --help and --version */ if (strcmp(argv[1], "-v") == 0 || strcmp(argv[1], "--version") == 0) version(); if (strcmp(argv[1], "--help") == 0 || strcmp(argv[1], "-h") == 0) usage(); if (strcmp(argv[1], "--test-memory") == 0) &#123; if (argc == 3) &#123; memtest(atoi(argv[2]),50); exit(0); &#125; else &#123; fprintf(stderr,"Please specify the amount of memory to test in megabytes.\n"); fprintf(stderr,"Example: ./redis-server --test-memory 4096\n\n"); exit(1); &#125; &#125; /* First argument is the config file name? */ if (argv[j][0] != '-' || argv[j][1] != '-') &#123; configfile = argv[j]; server.configfile = getAbsolutePath(configfile); /* Replace the config file in server.exec_argv with * its absolute path. */ zfree(server.exec_argv[j]); server.exec_argv[j] = zstrdup(server.configfile); j++; &#125; /* All the other options are parsed and conceptually appended to the * configuration file. For instance --port 6380 will generate the * string "port 6380\n" to be parsed after the actual file name * is parsed, if any. */ while(j != argc) &#123; if (argv[j][0] == '-' &amp;&amp; argv[j][1] == '-') &#123; /* Option name */ if (!strcmp(argv[j], "--check-rdb")) &#123; /* Argument has no options, need to skip for parsing. */ j++; continue; &#125; if (sdslen(options)) options = sdscat(options,"\n"); options = sdscat(options,argv[j]+2); options = sdscat(options," "); &#125; else &#123; /* Option argument */ options = sdscatrepr(options,argv[j],strlen(argv[j])); options = sdscat(options," "); &#125; j++; &#125; if (server.sentinel_mode &amp;&amp; configfile &amp;&amp; *configfile == '-') &#123; serverLog(LL_WARNING, "Sentinel config from STDIN not allowed."); serverLog(LL_WARNING, "Sentinel needs config file on disk to save state. Exiting..."); exit(1); &#125; resetServerSaveParams(); loadServerConfig(configfile,options); sdsfree(options);&#125; 这段内容很长，但是核心的内容不多，前一部分是判断特殊参数，用来显示程序使用方法，启动内存测试等等，中间部分是分析命令行参数保存到字符串中，最后几行是读取服务器配置文件，并使用字符串中的参数选项覆盖文件中的部分配置。 打印启动和警告信息1234567891011121314serverLog(LL_WARNING, "oO0OoO0OoO0Oo Redis is starting oO0OoO0OoO0Oo");serverLog(LL_WARNING, "Redis version=%s, bits=%d, commit=%s, modified=%d, pid=%d, just started", REDIS_VERSION, (sizeof(long) == 8) ? 64 : 32, redisGitSHA1(), strtol(redisGitDirty(),NULL,10) &gt; 0, (int)getpid());if (argc == 1) &#123; serverLog(LL_WARNING, "Warning: no config file specified, using the default config. In order to specify a config file use %s /path/to/%s.conf", argv[0], server.sentinel_mode ? "sentinel" : "redis");&#125; else &#123; serverLog(LL_WARNING, "Configuration loaded");&#125; 打印 redis 服务器启动信息，比如版本号，pid，警告信息等等，没有实际修改数据。 守护模式和初始化123456789server.supervised = redisIsSupervised(server.supervised_mode);int background = server.daemonize &amp;&amp; !server.supervised;if (background) daemonize();initServer();if (background || server.pidfile) createPidFile();redisSetProcTitle(argv[0]);redisAsciiArt();checkTcpBacklogSettings(); 根据守护进程配置和是否受监督来决定是否作为守护进程，什么是受监督，到现在还不知道，但是本着不懂装懂的方式看代码，可以认为我们懂了，后面自然还会有解释的地方。 接着就调用了 initServer(); 函数，这个初始化函数内容是比较长的，之前版本中很多 mian 函数中的内容都移到了这里面，初始化完成后创建 Pid 文件，设置进程名字，显示 redis 的Logo，检查一些配置，这个 backlog 参数之前面试的时候还被问到过，好奇的话可以提前了解一下。 哨兵模式判断启动并加载持久化数据1234567891011121314151617181920212223242526272829303132333435363738 if (!server.sentinel_mode) &#123; /* Things not needed when running in Sentinel mode. */ serverLog(LL_WARNING,"Server initialized");#ifdef __linux__ linuxMemoryWarnings();#endif moduleLoadFromQueue(); ACLLoadUsersAtStartup(); InitServerLast(); loadDataFromDisk(); if (server.cluster_enabled) &#123; if (verifyClusterConfigWithData() == C_ERR) &#123; serverLog(LL_WARNING, "You can't have keys in a DB different than DB 0 when in " "Cluster mode. Exiting."); exit(1); &#125; &#125; if (server.ipfd_count &gt; 0 || server.tlsfd_count &gt; 0) serverLog(LL_NOTICE,"Ready to accept connections"); if (server.sofd &gt; 0) serverLog(LL_NOTICE,"The server is now ready to accept connections at %s", server.unixsocket); if (server.supervised_mode == SUPERVISED_SYSTEMD) &#123; if (!server.masterhost) &#123; redisCommunicateSystemd("STATUS=Ready to accept connections\n"); redisCommunicateSystemd("READY=1\n"); &#125; else &#123; redisCommunicateSystemd("STATUS=Waiting for MASTER &lt;-&gt; REPLICA sync\n"); &#125; &#125;&#125; else &#123; InitServerLast(); sentinelIsRunning(); if (server.supervised_mode == SUPERVISED_SYSTEMD) &#123; redisCommunicateSystemd("STATUS=Ready to accept connections\n"); redisCommunicateSystemd("READY=1\n"); &#125;&#125; 这段代码看起来像是再做一些通知提醒，其中比较重要的几个函数是moduleLoadFromQueue()、 InitServerLast() 和 loadDataFromDisk() ，第一个函数是加载模块的，第二个函数是在模块加载完成之后才能初始化的部分内容，最后一个是从磁盘加载数据到内存，这也是 redis 支持持久化的必要保证。 打印内存警告并启动事件监听123456789/* Warning the user about suspicious maxmemory setting. */if (server.maxmemory &gt; 0 &amp;&amp; server.maxmemory &lt; 1024*1024) &#123; serverLog(LL_WARNING,"WARNING: You specified a maxmemory value that is less than 1MB (current value is %llu bytes). Are you sure this is what you really want?", server.maxmemory);&#125;redisSetCpuAffinity(server.server_cpulist);aeMain(server.el);aeDeleteEventLoop(server.el);return 0; 看到这段代码我们就来到了 main 函数结尾的部分，redisSetCpuAffinity() 是要做些和 CPU 相关的设置或配置，aeMain() 是主逻辑，对于提供服务的程序来说里面大概率是一个死循环，再满足指定的条件下才会打断退出，而 aeDeleteEventLoop() 就是循环结束时清理事件的操作，到此为止 main 函数就执行完啦。 彩蛋这个 main 函数的代码中有一个神奇的用法不知道大家有没有发现，就是下面这句话： 123serverLog(LL_WARNING, "You can't have keys in a DB different than DB 0 when in " "Cluster mode. Exiting."); 是不是看起来有些奇怪，不用管这个函数的定义是怎样的，可以告诉大家这个函数的定义类似于 printf 函数，只不过在最前面加了一个整型参数，那么调用这个函数时传了几个参数呢？3个？2个？，这个地方很神奇的会把两个字符串拼接到一起，类似于下面的写法： 12serverLog(LL_WARNING, "You can't have keys in a DB different than DB 0 when in Cluster mode. Exiting."); 这样的字符串不仅可以分成两行，实际上可以分成任意行，最后都会拼接在一起，是不是很神奇。 总结 j 这个变量在 redis 的源码中经常出现，应该是作者的行为习惯吧，有些人爱用 i，而这个作者 antirez 爱用 j。 不能一口吃个胖子，看代码也是一样，不能期望一次性把所有的内容都看懂，一段时间后自己的代码都看不懂了，跟别说别人写的了。 redis 代码中频繁使用 server 这个变量，从 main 函数分析中也能看到，这个是个全局变量，代表了整个 redis 服务器程序数据。 不懂装懂或者说不求甚解是熟悉代码整体结构的一项优秀品质，这时候只要看个大概就可以了，真到熟悉细节的时候才是需要钻研的时候。 代码风格完全统一还是比较难实现的，从一个 main 函数中也可以看到，大部分函数是驼峰命名法，还要少量的下划线命名和帕斯卡命名。 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 你微笑的模样，提醒着我不要躲藏，坚持原来的方向，哪怕最后遍体鳞伤，困难只会让坚持的人越来越强，共勉~ 2020-8-15 23:48:53]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
        <tag>源码</tag>
        <tag>C</tag>
        <tag>BFS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GDB调试指北-启动GDB并查看说明信息]]></title>
    <url>%2Fblog%2F2020%2F08%2F01%2FGDB%E8%B0%83%E8%AF%95%E6%8C%87%E5%8C%97-%E5%90%AF%E5%8A%A8GDB%E5%B9%B6%E6%9F%A5%E7%9C%8B%E8%AF%B4%E6%98%8E%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[前言学习 gdb 使用是一个漫长的过程，先了解一下 gdb 的启动方式和基础信息的查看方法，能够帮助我们更全面的认知这个工具。gdb 是一个交互式命令行程序，在使用 gdb 调试的时候不断的在命令行内输入命令，然后 gdb 程序就会给出反馈信息，这在很大程序上可以帮助我们调试程序问题。 gdb 版本查看gdb 的安装教程网络上有很多，这里就不提供安装步骤了，可以直接通过命令行，也可以从源码安装，找个教程一步步操作就行了，安装完之后使用 which 命令查看一下程序安装的位置： 12albert@home-pc:~$ which gdb/usr/bin/gdb 确认 gdb 已经安装后我们再看一下程序版本，我用的是 Ubuntu 16.04 版本中匹配的 gdb 程序，版本稍微有些低，据说 9.x 版本中对 Python 支持的非常好，调试的时候查看变量更加方便了，这些神奇的特性我们暂时还用不到，先简单了解下就好： 12345678910111213141516albert@home-pc:~$ gdb --versionGNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1Copyright (C) 2016 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-linux-gnu".Type "show configuration" for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type "help".Type "apropos word" to search for commands related to "word".albert@home-pc:~$ gdb 启动直接启动gdb 作为一个程序和其他的程序启动方式是一样的，直接敲入 gdb 命令回车就可以了： 12345678910111213141516albert@home-pc:~$ gdbGNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1Copyright (C) 2016 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-linux-gnu".Type "show configuration" for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type "help".Type "apropos word" to search for commands related to "word".(gdb) 看着是不是有些眼熟，这就是刚刚查 gdb 版本时看到的那段文字，只不过这段文字结束时不是返回到命令行，而是显现出了 (gdb) 的字样，我们暂时把它叫做 gdb 命令行，这就是我们与 gdb 程序进行交互的主要途径了。 去掉版本信息启动上面启动 gdb 时出现的这段文字很长，有时候反复调试程序时看到这段文字有点烦，想把它去掉怎么办？非常简单，在启动时加上 -q 参数就可以了。 12albert@home-pc:~$ gdb -q(gdb) 怎么样，这次上面那段文字不见了，直接就进入 gdb 命令行了吧。 gdb 信息查看其实刚刚被我们嫌弃的那段文字，里面记录了不少信息，其中还展示了 show copying、show warranty、show configuration 等多个命令，我们可以简单尝试下这些命令有什么作用。 show copying输入 show copying 命令展示的是一份比较长的版本许可证说明，我省略了中间的部分，如果想看的话可以自己输入命令试一下，GPL v3 的许可证看起来很熟悉吧。 12345678910111213141516albert@home-pc:~$ gdb -q(gdb) show copying GNU GENERAL PUBLIC LICENSE Version 3, 29 June 2007 Copyright (C) 2007 Free Software Foundation, Inc. &lt;http://fsf.org/&gt; Everyone is permitted to copy and distribute verbatim copies of this license document, but changing it is not allowed....... Later license versions may give you additional or differentpermissions. However, no additional obligations are imposed on anyauthor or copyright holder as a result of your choosing to follow alater version. show warranty命令 show warranty 输出的内容相比之前的命令就短很多了，是一份免责声明，序号从15开始，接着版本许可证的序号往下写的。 1234567891011121314151617181920212223242526272829303132(gdb) show warranty 15. Disclaimer of Warranty. THERE IS NO WARRANTY FOR THE PROGRAM, TO THE EXTENT PERMITTED BYAPPLICABLE LAW. EXCEPT WHEN OTHERWISE STATED IN WRITING THE COPYRIGHTHOLDERS AND/OR OTHER PARTIES PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTYOF ANY KIND, EITHER EXPRESSED OR IMPLIED, INCLUDING, BUT NOT LIMITED TO,THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULARPURPOSE. THE ENTIRE RISK AS TO THE QUALITY AND PERFORMANCE OF THE PROGRAMIS WITH YOU. SHOULD THE PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OFALL NECESSARY SERVICING, REPAIR OR CORRECTION. 16. Limitation of Liability. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITINGWILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MODIFIES AND/OR CONVEYSTHE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES, INCLUDING ANYGENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING OUT OF THEUSE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED TO LOSS OFDATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY YOU OR THIRDPARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER PROGRAMS),EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE POSSIBILITY OFSUCH DAMAGES. 17. Interpretation of Sections 15 and 16. If the disclaimer of warranty and limitation of liability providedabove cannot be given local legal effect according to their terms,reviewing courts shall apply local law that most closely approximatesan absolute waiver of all civil liability in connection with theProgram, unless a warranty or assumption of liability accompanies acopy of the Program in return for a fee. show configuration最后一个 show configuration 展示的 gdb 的一下配置信息，比如 --with-system-gdbinit=/etc/gdb/gdbinit 在进阶版的 gdb 调试技巧中应该经常用到，先有个印象就行。 12345678910111213141516171819(gdb) show configurationThis GDB was configured as follows: configure --host=x86_64-linux-gnu --target=x86_64-linux-gnu --with-auto-load-dir=$debugdir:$datadir/auto-load --with-auto-load-safe-path=$debugdir:$datadir/auto-load --with-expat --with-gdb-datadir=/usr/share/gdb (relocatable) --with-jit-reader-dir=/usr/lib/gdb (relocatable) --without-libunwind-ia64 --with-lzma --with-python=/usr (relocatable) --without-guile --with-separate-debug-dir=/usr/lib/debug (relocatable) --with-system-gdbinit=/etc/gdb/gdbinit --with-babeltrace("Relocatable" means the directory can be moved with the GDB installationtree, and GDB will still find it.)(gdb) apropos其实在 gdb 启动说明中还展示了 apropos 这个命令，可以用这个命令来显示与指定词语相关的命令，比如 apropos print 就是查询所有描述中带有 print 的命令，可以执行测试一下： 1234567891011121314151617(gdb) apropos printagent-printf -- Agent-printf "printf format string"alias -- Define a new command that is an alias of an existing commandbacktrace -- Print backtrace of all stack framesbt -- Print backtrace of all stack framescall -- Call a function in the programcommands -- Set commands to be executed when a breakpoint is hitcompile code -- Compilecompile print -- Evaluate EXPR by using the compiler and print resultdisable pretty-printer -- GDB command to disable the specified pretty-printer...info type-printers -- GDB command to list all registered type-printersinfo vector -- Print the status of the vector unitinspect -- Print value of expression EXPmaintenance agent-printf -- Translate an expression into remote agent bytecode for evaluation and display the bytecodesmaintenance btrace packet-history -- Print the raw branch tracing data---Type &lt;return&gt; to continue, or q &lt;return&gt; to quit--- help查询具体的命令可以使用 help 子命令，比如查看 bt 这个查看调用栈帧的命令就可以使用 help bt，输入后回车可以得到这个命令的描述信息。 123456(gdb) help btPrint backtrace of all stack frames, or innermost COUNT frames.With a negative argument, print outermost -COUNT frames.Use of the 'full' qualifier also prints the values of the local variables.Use of the 'no-filters' qualifier prohibits frame filters from executingon this backtrace. gdb工作作为一款调试利器，可以使用的命令是在是太多了，除了这些还有很多命令等着我们去发现，今天的内容仅仅作为入门必备先简单了解一下。 总结 gdb 是一个交互式的命令行调试工具，通过不断执行命令，展示调试信息帮助我们调试程序 当启动 gdb 这个工具后，命令行会变成 (gdb)的形式，等着我们输入命令开始调试使用 gdb 作为一个强大的 GNU 工具，文档比较全，如果觉的文档枯燥，也可以跟着我的总结来熟悉一下基础用法。 开源环境下软件的版权信息和免责声明写的都比较完整，其中有很多描述值得我们学习。 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 而世之奇伟、瑰怪，非常之观，常在于险远，而人之所罕至焉，故非有志者不能至也~ 2020-8-5 23:17:04]]></content>
      <categories>
        <category>GDB</category>
      </categories>
      <tags>
        <tag>GDB</tag>
        <tag>manual</tag>
        <tag>调试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小白眼中的docker究竟是个什么东西]]></title>
    <url>%2Fblog%2F2020%2F07%2F28%2F%E5%B0%8F%E7%99%BD%E7%9C%BC%E4%B8%AD%E7%9A%84docker%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%B8%AA%E4%BB%80%E4%B9%88%E4%B8%9C%E8%A5%BF%2F</url>
    <content type="text"><![CDATA[前言Docker，中文名：容器引擎，别名：小鲸鱼，生于2013年3月20日，有一个法裔美籍的母亲 Solumon Hykes，父亲是谁，不得而知。虽然只有7岁，但是在 Hello World 平行宇宙中也算进入了青壮年吧，正在飞速的发展着。 Docker 这个动物选的比较有意思，是一只蓝色的鲸鱼，作为地球上最大的动物，用它来代表容器再合适不过了。不过有谁知道为什么编程技术总是和动物挂钩啊？比如 Linux 的企鹅，Python 的大蛇，Hadoop 的大象等等，有知道的小伙伴还请告知一下。 俗话说的好，“程序不逛动物园，肯定技术有点悬”，经常看到网上有人推荐编程学习方法，先学学基础，然后再看几本儿动物书就可以了，看来这些封面上的动物已经深入人心了。 先把这些动物放到一边，来看看这个 docker 究竟是什么，之前我也不知道它是什么，甚至到了现在我也不能准确的说出它是什么，我只是以一个小白的身份来学习和使用，并且把一些弄懂的知识点总结起来，方便日后查找。 关于docker的疑问如果你之前看到 docker 时会有下面这些疑问，可以跟着文章梳理了解一下，如果你对这些问题的答案早已烂熟于胸，那么可以简单浏览下，帮我挑挑毛病，也是帮助想学习的同学们： docker 最近很火啊，它到底能用来做什么？ docker 和虚拟机好像啊，难道就是轻量虚拟机吗？它们两者还有其他的区别吗？ docker 教程里有 ubuntu 上安装 docker，还有 docker 上安装 linux，什么鬼，到底谁装谁啊？ docker 真的这么牛吗？那开发项目必须得用上它啊，显得高端大气上档次！ docker 宣称构建一次，处处运行，那它应该能跨平台吧？ 作为小白我也是带着这些疑问开始慢慢了解 docker 的，特别是那个 ubuntu 上装 docker，docker 上还能装 ubuntu，都给我整蒙圈了，通过不断学习才渐渐弄清了其中的原因。 疑问探索解答docker 是什么关于 docker 我们来看下常见的介绍： Docker 是一个开源的应用容器引擎，让开发者可以打包他们的应用以及依赖包到一个可移植的容器中，然后发布到任何流行的 Linux 机器或 Windows 机器上，也可以实现虚拟化，容器是完全使用沙箱机制，相互之间不会有任何接口。 从这一段话中我们可以得到以下几个知识点： 它是一个容器引擎 可以用来打包应用 可以发布到 linux 或者 windows 上 可以实现虚拟化 采用沙箱机制，相互隔离 结合查到的资料来了解一下 docker，首先它是一个容器引擎，引擎这个词经常出现，什么游戏引擎，物理引擎，发动机引擎等等，每种引擎其实就是负责一种核心工作的模块或事物，通过封装来简化工作流程，降低工作难度，而 docker 作为容器引擎的作用当然就是生产容器了。 它的目的就是隔离应用，在隔离空间内部署自己独特的环境，需要了解的是它并不是一项新的技术，而是利用了 Linux 核心中的 cgroups 和 namespace 等资源分脱机制来进行隔离，这种被称为容器的进程独立于宿主和其它的隔离的进程，是很早就存在的技术，只不过经过 docker 封装之后使用起来更加方便了。 再说打包应用，这也是 docker 迅速火起来的一个原因，因为环境部署是在太费时费力了，之前在服务器配置一个应用的运行环境，要安装各种软件，Java/Tomcat/MySQL等等。安装和配置这些东西非常麻烦，并且还存在各种版本，而当我们换另一台同样操作系统的服务器还要再配置一遍，有没有办法这些配置直接拷贝过来呢？其实这就是 docker 要做的事情，将应用与运行环境打包到一起，直接在 docker 中运行一个容器就好了，你所依赖的环境直接就装好了。 前面提到 docker 是利用了 linux 内核的一些特性，那么 windows 可以运行吗？如果你查询早期一点的资料会得到不可以的答案，或者说即使在 windows 上运行 docker，也是在中间加了一层 linux 虚拟机。而如今已经 2020 年了，windows 上可以直接安装 docker for windows 来启动提供 docker 服务，而 docker for mac 也使得 docker 运行在 mac 上不再困难，windows 很早就和 docker 进行了合作，最新的 win10 上启动 docker 甚至可以切换内核为 linux 或者 windows，很神奇吧。 说到这里你应该对 docker 有了一个简单的了解，其中有一点很重要，它和宿主机是共享内核的，这是解答上面很多疑惑的钥匙，至于虚拟化，隔离这些都很容易理解了，而这些概念在虚拟机上常常出现，所以很容易把它俩弄混。 容器与虚拟机自从 docker 出现，容器和虚拟机的对比就没有停过，这些对比常常从启动时间、资源占用、隔离性，操作便利性等方面来进行比较，可以用搜索引擎搜一下，大概就是下面这个样子： 特性 Docker容器 VM虚拟机 启动速速 秒级 分钟级 性能 接近原生 明显弱于原生 硬盘使用 相对较小，可以自由分配 创建时分配，易造成浪费 系统支持量 支持上千个 一般几十个 造成这种差异的原因是什么？还是前面说的 docker 和宿主机是共享内核，而虚拟机是自己创建了一整套系统，虽然隔离性更强，但是也造成了资源的浪费和效率的降低。 一直想找一个例子来形象地对比一下虚拟机和容器，我强行编一个吧，比如你是一个财富自由的人，准备回老家养养牛种种菜，包个鱼塘钓钓鱼，顺便再养一窝小白兔，但是小白兔会吃你种的蔬菜，牛偶尔也会踩到小白兔，这时怎么办，把它们隔开呗。 作为一个钱花不完的人，你准备造几个“小地球”，然后把饲养的动物和种植的植物都放到各自的“地球”中放养，每个小地球都是一个密封的环境，里面有自己的太阳、月亮、空气、河流、山川等等，这种方法当然可以，只是成本有些高，一旦建立了这个小地球，它所占有的资源就定下来了，基本上与大地球隔离，但是它还要依赖大地球，还要建立在地球上，可以类比下虚拟机。 因为建造小地球太费时费力了，所以你改了策略，这次不创建完全密闭的环境了，我直接造个篱笆就可以了，阳光、空气、河流我还是使用大地球的，只是在篱笆里我进行定制，做一些鱼塘、蔬菜大棚等等。由于建造篱笆非常省事，我可以批量生产，有需要了我可以直接拿来几个，放在地上就可以使用了，并且不同动物以及植物之间都有篱笆挡着，不会出现相互影响的问题了，这就有点像容器了。 虽然有些牵强，但是这个例子还是可以帮助我们了解容器和虚拟机的区别，实际上容器与虚拟机并不是对立的关系，有时为了防止容器无限制的占用物理机资源，还会现在物理机上运行虚拟机，然后在虚拟机里运行 docker，他们两者只是不同需求下的不同选择而已。 操作系统和容器到底谁安装谁前面说过 ubuntu 上装 docker，docker 上还能装 ubuntu 这个问题困扰了我好久，实际上 windows 可以装虚拟机，而虚拟机中有可以装 windows 这没什么好奇怪的，这里的 dokcker 指的就是 docker 引擎，或者认为是 docker 服务器。 它们确实可以相互安装，但情况是不同的，首先说 ubuntu 上装 docker，docker 说白了还是一种软件，本质上和你在电脑上装个QQ也没有多大差别，只不过这个软件有点特殊，通过它还能下载、安装别的环境，这么说它看起来有点像应用商店了，不过他虽然提供仓库，但是不仅仅是仓库，本质上它就是一种帮助你搭建环境的软件。 再来看看 docker 上装 ubuntu，还记得之前说过的一个重点吗？ docker 上安装的环境与宿主机共享内核，这就决定了他不能安装完整的系统，不管是 ubuntu、CentOS 还是 RedHat，它所安装的系统仅仅包含运行库和工具链，内核还是用宿主机的，相当于在 docker 中给内核套了一个新的壳子而已。 这下应该清楚了，ubuntu 上装 docker 就是在 ubuntu 上装了一个容器软件， docker 上装 ubuntu 就是在 docker 容器中给宿主内核套上了一个新系统的壳子，使其满足应用软件的环境，配备应用软件可使用的工具链。 这么厉害的容器项目中一定要用吗相信这种问题就是不了解容器也可以回答，肯定不是都要用啊，没有什么技术是只有优点没有缺点吧，凡是技术总有其适合的领域和场景，一味的追求最新的技术不一定符合所要开发的项目。 docker 也没有传说的那么神，它也有着这样那样的问题，比如一直津津乐道的资源伸缩机制，不像虚拟机那样创建时便规定了资源大小，即使不使用也占用着，而 docker 可以直接使用宿主资源，避免了很多浪费。但是反过来想，虚拟机规定了资源的多少，如果不够用了只影响它自己，而 docker 如果一个环境出了问题，它可以把整个物理机的资源耗完，影响机器上的所有服务。 另外，docker 建议只部署无状态的服务，它们不应该承载任何交易数据，所有数据应该保存在数据库服务器中，器随时可以停止、或者删除。当容器被删除掉，容器里的数据将会丢失，即使你要把 docker 数据放在主机来存储，它依然不能保证不丢数据，具体的细节我也在学习，有这方面经验的朋友可以发表一下见解。 docker的跨平台先来看看跨平台的概念： 跨平台概念是软件开发中一个重要的概念，即不依赖于操作系统，也不依赖硬件环境。一个操作系统下开发的应用，放到另一个操作系统下依然可以运行。 首先要弄明白你说的跨平台指的是 docker 跨平台，还是它里边的应用使用 docker 就能跨平台了，从定义来说 docker 这个容器软件应该算是跨平台的，毕竟 Linux、 Windows、 Mac 都有了 docker 的安装包，那么他里面的镜像运行之后的容器能跨平台吗？这还要看具体的应用，docker 没有让一个非跨平台软件变成跨平台软件的能力。 关于这一点你还要牢记前面说的，docker 中的环境与宿主机共享内核，你创建了一个自己编写的exe程序的镜像，拿到安装了 docker 的 ubuntu 机器上显然是无法成功运行的。 基础知识点docker的缺点docker 的卖点是让你摆脱配置环境的困扰，但真实情况是你打包镜像的机器和系统版本，最好和你要运行的目标机器和系统版本一致，另外 docker 环境最好也一样，忽然感觉它没有那么神奇了，这不还是要求版本吗？ 试想一下，你用一个高版本的 docker 服务打包，其中使用了一些新特性，然后放到低版本的 docker 服务下怎么能保证成功运行，机器配置也是一样，之前看到过一个问题 “尝试在具有 4.19 或更高内核的 Linux 系统上运行 docker official centos:6 或 centos:5 容器，当尝试启动它时，你会发现内核和程序不兼容”。 这样看来，docker 只适合在相同环境下批量复制，使得实现自动化测试和持续的集成很方便，但还是有些问题需要注意的： docker 是基于64位系统环境的，32位环境下无法使用 隔离性相比 KVM 之类的虚拟化方案还是有些欠缺 容器随着用户进程的停止而销毁，其中的日志、打点等用户数据不便收集 网络管理相对简单，主要是基于 namespace 隔离 容器的 root 和宿主机 root 等同，这使得容器容易受到攻击 … docker 的组成前面一直在说初学 docker 时的疑问，接下来看看 docker 究竟都包括哪些内容，docker 这个容器引擎实际上是一个客户端/服务器应用程序，客户端负责与守护的服务进程进行对话，而服务进程负责构建、运行和分发 docker 容器。docker 客户端和服务进程可以在同一系统上运行，也可以进行远程访问，通过网络接口使用 RESTful API 进行通信。 使用 docker 时常常要接触三个概念：镜像（Image）、容器（Container）和仓库（Repository）。简单来说镜像就是我们的想要打包的程序机加上程序运行环境，打包出来的一个文件，相当于程序安装包。当镜像运行起来我们就得到了容器，镜像与容器的关系就类似于类和对象的关系。仓库就是存放镜像的地方，与代码的仓库 Github 很像，docker 镜像也有一个常用的仓库叫 Docker Hub，方便人们直接下载镜像来运行。 运行一个镜像Hello world 常常被拿来新知识的入门和开头，今天我们用这个例子来做一下收尾吧，首先你得有 docker 环境，说人话就是你得装了 docker 软件，之前不是一直说 docker 就是一个软件吗，你想用它当然得安装了，这类教程很多，假设你已经安装完了， 我们在一台 CentOS 上操作使用一下 docker，查询下系统版本和 docker 版本： 123456789[root@remote-os ~]# lsb_release -aLSB Version: :core-4.1-amd64:core-4.1-noarchDistributor ID: CentOSDescription: CentOS Linux release 7.7.1908 (Core)Release: 7.7.1908Codename: Core[root@remote-os ~]# docker --versionDocker version 19.03.7, build 7141c199a2[root@remote-os ~]# 首先下载 hello world 镜像，使用 docker image pull hello-world 命令 123456[root@remote-os ~]# docker image pull hello-worldUsing default tag: latestlatest: Pulling from library/hello-worldDigest: sha256:49a1c8800c94df04e9658809b006fd8a686cab8028d33cfba2cc049724254202Status: Image is up to date for hello-world:latestdocker.io/library/hello-world:latest 查看本地镜，使用 docker image ls 命令，发现 hell-world 镜像已经在本地了 12345678[root@remote-os ~]# docker image lsREPOSITORY TAG IMAGE ID CREATED SIZEubuntu latest adafef2e596e 3 weeks ago 73.9MBregistry latest 708bc6af7e5e 6 months ago 25.8MBhello-world latest bf756fb1ae65 7 months ago 13.3kBwurstmeister/zookeeper latest 3f43f72cb283 18 months ago 510MBhyper/docker-registry-web latest 0db5683824d8 3 years ago 599MB[root@remote-os ~]# 下载完成之后直接使用 docker container run hello-world 命令运行就可以了，这个镜像运行打印完直接就退出了 12345678910111213141516171819202122[root@remote-os ~]# docker container run hello-worldHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the "hello-world" image from the Docker Hub. (amd64) 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://hub.docker.com/For more examples and ideas, visit: https://docs.docker.com/get-started/ 如果不想退出，运行的镜像应该是能提供某种服务的，比如前面一直说的 ubuntu，它可以在 docker 中运行起来，直接使用 docker container run -it ubuntu bash 命令就行，这里为什么我们不先下载呢？实际上如果你指定的镜像在本地没有的话会自动下载，不需要手动下载完再运行。 1234567891011[root@remote-os ~]# docker container run -it ubuntu bashroot@0577050677ac:/# cat /etc/issueUbuntu 20.04 LTS \n \lroot@0ecfed0920aa:/# lsbin boot dev etc home lib lib32 lib64 libx32 media mnt opt proc root run sbin srv sys tmp usr varroot@0ecfed0920aa:/# ll home/total 8drwxr-xr-x 2 root root 4096 Apr 15 11:09 ./drwxr-xr-x 1 root root 4096 Jul 31 16:23 ../root@0ecfed0920aa:/# 可以看到上面的操作，我们又进入了 ubuntu 系统，成功运行了镜像，现在得到了一个容器，可以通过 docker container ls 命令查看，还可以通过 docker container rm [containerID] 命令来删除容器。 总结 docker 软件可以运行在windows、linux 和 mac 上 docker 容器与宿主机共享一个系统内核，如果依赖内核版本的应用最好保证物理机系统版本一致 docker 容器与虚拟机并不是对立的，有时候会放在一起配合使用 docker 有自己的镜像仓库，可以直接下载安装，使用起来相当方便，因为网络原因，如果想快速搭建最好提前准备好镜像文件 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 海纳百川有容乃大，壁立千仞无欲则刚~ 2020-8-1 00:31:35]]></content>
      <categories>
        <category>docker</category>
      </categories>
      <tags>
        <tag>docker</tag>
        <tag>容器</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[GDB调试指北大全]]></title>
    <url>%2Fblog%2F2020%2F07%2F18%2FGDB%E8%B0%83%E8%AF%95%E6%8C%87%E5%8C%97%E5%A4%A7%E5%85%A8%2F</url>
    <content type="text"><![CDATA[前言GDB 作为程序调试利器，是一个受通用公共许可证（GPL）保护的自由软件，全称是 GNU Debugger，又常常被称为 GNU symbolic debugger 或者 GNU project debugger，能够帮助开发者调试程序，分析应用程序运行过程。目前支持调试 C、 C++、 D、 Go、 Objective-C、 Fortran、 Java、 OpenCL C、 Pascal、 assembly、 Modula-2、 Ada 等多种编程语言。 GDB能做什么GDB 是调试程序的强大武器，能够帮助开发者找出程序出现BUG的原因，但是不要指望它能自己查问题，它仅仅是一个工具，可以帮助我们查找问题原因，常常被用来做以下事情： 分析程序崩溃的原因 查找程序表现出错误行为的原因 找到一些从源码上难以发现的逻辑错误 GDB调试步骤 使用 g++ 附加 -g 参数编译程序，g++ -g mainpro.cpp -o mainpro 使用 gdb 程序来启动调试我们自己构建的程序，gdb mainpro 使用 run、break、print 等命令调试程序 使用 quit 命令退出程序 GDB调试示例 编写示例程序代码，保存到文件 mainpro.cpp 中 1234567891011#include &lt;iostream&gt;int main()&#123; int a = 110, b = 119, c; c = a + b; std::cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; std::endl; return 0;&#125; 使用 g++ 附加 -g 参数编译程序 123albert@home-pc:~$ g++ -g mainpro.cpp -o mainproalbert@home-pc:~$ lsmainpro mainpro.cpp 使用 gdb 命令来启动调试 1234567891011121314151617albert@home-pc:~$ gdb mainproGNU gdb (Ubuntu 7.11.1-0ubuntu1~16.5) 7.11.1Copyright (C) 2016 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-linux-gnu".Type "show configuration" for configuration details.For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.Find the GDB manual and other documentation resources online at:&lt;http://www.gnu.org/software/gdb/documentation/&gt;.For help, type "help".Type "apropos word" to search for commands related to "word"...Reading symbols from mainpro...done.(gdb) 使用 break 8 在第8行打断点，使用 run 命令启动程序，使用 print c 打印程序变量 12345678910(gdb) break 8Breakpoint 1 at 0x4008b7: file mainpro.cpp, line 8.(gdb) runStarting program: /home/albert/mainproBreakpoint 1, main () at mainpro.cpp:88 std::cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; std::endl;(gdb) print c$1 = 239(gdb) 使用 quit 命令退出程序 1234567(gdb) quitA debugging session is active. Inferior 1 [process 227] will be killed.Quit anyway? (y or n) yalbert@home-pc:~$ GDB启动参数与命令列表（持续更新）GDB 众多的启动参数和命令提供了强大的调试功能，每一条都可以展开得到很多知识，这些知识的学习是一个持续的过程，短时间无法消化和吸收，所以准备总结一个系列，从最简单的命令开始总结，持续更新学习下去，文章链接不定期更新。 GDB命令 备注 参考文章 gdb、gdb -q GDB启动、查看说明 [GDB调试指北-启动GDB与查看说明] gdb pro、gdb pro 123 启动调试程序、调试正在运行的程序 [GDB调试指北-使用GDB启动调试] directory new-path 查看调试源码 GDB调试指北-查找丢失源码文件 set substitute from-path to-path 查看调试源码 GDB调试指北-查找丢失源码文件 总结 GDB 调试技巧更多的是工具本身的功能，所谓“重剑无锋，大巧不工”，熟练利用这个工具才能发挥最大的威力 知识的学习时一个持续的过程，只有不断的学习和总结才能不断进步，而不要被那些花里胡哨的外表所迷惑 有些知识学着学着就通了，前几天看到 printf 这个函数，很疑惑为什么末尾要加个 f，猜想它是格式化 format 的意思 经过查证果然如此，此时距离第一次在 C 语言中学习 printf 函数已经过去了10年 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 大漠孤烟直，长河落日圆~ 2020-7-18 20:09:58]]></content>
      <categories>
        <category>GDB</category>
      </categories>
      <tags>
        <tag>GDB</tag>
        <tag>manual</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb调试解决找不到源代码的问题]]></title>
    <url>%2Fblog%2F2020%2F07%2F13%2Fgdb%E8%B0%83%E8%AF%95%E8%A7%A3%E5%86%B3%E6%89%BE%E4%B8%8D%E5%88%B0%E6%BA%90%E4%BB%A3%E7%A0%81%E7%9A%84%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[前言通过 gdb 启动程序，打好断点运行，开始调试输入 list 命令，结果发现找不到源代码，是不是很糟心，让我们来看看怎么解决这种情况。 先來说明我们要处理的情况，调试程序找不到源代码首先你得有源代码，如果编译完程序你把源代码删了，或者单独把执行程序拷贝到一个没有源代码的机器上，那么拜拜吧您嘞，这种情况不是本文能解决的。 如果你确实有源代码，正常编译源代码并且加入了 -g 选项，编译完之后没有改变源代码位置，那么调试的时候基本都会找到源代码，所以这种情况也不在我们的讨论范围之内。 分析到现在就剩下一种情况，程序编译完成之后我移动了代码的位置。实际工作中可能不会这么无聊，故意改变目录位置让调试程序找不到，但是工作中常常会出现发布机编译完代码要在开发机调试的情况，两台机器上的代码时一样的，但是源代码的位置可能放置的不同，那么在个人开发机上调试这样的程序就会找不到源代码，这也就是我们要解决的问题。 找到源代码的必要性其实在我看来找不到源代码的问题没有那么严重，编译程序里记录了文件名，行号等信息，可以在调试的时候对照着本地的源代码进行“盲调”，这种“盲调”的操作之前可没少干，因为线上环境中没有源代码，我只能一边对照着 gdb 调试输出的行号，一边对照本地的源代码进行程序分析，通过这种方法也解决了不少问题。 虽然看着源代码调试没有那么必要，但是如果可以看见那肯定是更好了，所以本文还是列举出最常见的处理方法，解决一下本来有代码，但因为目录不匹配无法正常调试的问题。 涉及到的命令下面几个命令是 gdb 命令，注意要放到和 gdb 交互命令行输入才可以，别管会不会，先混个脸熟，以后要经常用的： show dir dir 目录 set dir 目录1:目录2:目录3 dir pwd cd 目录 set substitute-path from-path to-path gdb怎样找源代码有时候很奇怪，代码明明就在那里，gdb 你睁开眼睛行不行，为什么你就是找不到呢？其实 gdb 也很苦的好不好，一直帮你查问题还要忍受着你每天的埋怨，到底是什么原因导致 gdb 对眼前的代码视而不见呢？ 其实 gdb 查找代码也要遵循一定的规则，不能每次都全盘扫描吧，那不是得给它累死。举个例子吧，我们在安装一些软件，特别是一些命令行工具的时候，总是有一步要求你把工具或软件所在目录添加到环境变量中，这个变量的名字叫做 Path。 这个 Path 其实就是电脑上众多软件所在目录的集合，当你直接使用软件的程序时，会优先从 Path 这个集合中的目录下去找，成功找到就会直接调用，否则提醒你软件不存在。 源代码目录集合而在 gdb 的调试过程中也有这样一个目录集合，我暂且称它为 SourcePathSet，后面就用这个名字了，因为还要涉及到多种查找目录，请注意区分。 gdb 在查找源码的时候首先在 SourcePathSet 中所包含的目录下找，如果找不到就会提示查找失败了，也就是这篇文章所提到的问题。 源代码文件程序在编译的过程中会记录源文件的名字和路径，这个路径可能是绝对路径，比如 /mnt/d/main.cpp，也可能是相对路径 ../main.cpp ，究竟是哪一种取决于编译时使用的参数。 我们以绝对路径为例，比如文件名为 /mnt/d/main.cpp，我们可以把它拆分成包含路径和不包含路径两种形式：/mnt/d/main.cpp 和 main.cpp，当 SourcePathSet 中包含一个路径叫 /mnt/e时， gdb 搜索的路径包括以下几种： /mnt/d/main.cpp /mnt/e/mnt/d/main.cpp /mnt/e/main.cpp 当源文件是相对路径 ../main.cpp 的时候，那么搜索的路径就变成了下面两个： /mnt/e/../main.cpp /mnt/e/main.cpp 说到这里你可能就明白了，当 gdb 找不到源文件的时候，修改 SourcePathSet 就可以了，把想让它搜索的路径添加到 SourcePathSet，如果符合它的搜索规则，那么就可以找到了。 目录集合的默认值SourcePathSet 在 gdb 启动后开始生效，默认值并不是空，而是 $cdir:$cwd，这又是什么鬼？其中的 $cdir 叫做编译目录，是代码在编译时记录到程序中的，$cwd 表示当前的调试目录，可以通过 cd 命令来修改，要注意这个 cd 修改的是 gdb 会话中的当前目录，不会影响启动 gdb 前文件系统中的目录位置。 假设 $cdir 的值是 /usr，cwd 的值是 /home/albert，我们又添加了 /mnt/e 到 SourcePathSet 中，那么此时 SourcePathSet 的值为 /mnt/e:$cdir:$cwd，如果源文件的是 /mnt/d/main.cpp，查找的目录就会出现以下几种： /mnt/d/main.cpp /mnt/e/mnt/d/main.cpp /usr/mnt/d/main.cpp /home/albert/mnt/d/main.cpp /mnt/e/main.cpp /usr/main.cpp /home/albert/main.cpp 查看各种目录先做一下准备工作，编写一段简单代码，另存文件名为 main.cpp，保存在目录 /mnt/d/cpp 下： 12345678910111213#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 1; int b = 2; int c = a + b; cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl; return 0;&#125; 切换到目录 /mnt/d下， 查看 cpp 目录下文件并使用 g++ 编译，编译完成后将文件 mian.cpp 移动到 /mnt 目录下： 123456789albert@home-pc:/mnt/d$ ls cpp/main.cppalbert@home-pc:/mnt/d$ g++ /mnt/d/cpp/main.cpp -g -o mainalbert@home-pc:/mnt/d$ ls mainmainalbert@home-pc:/mnt/d$ sudo mv cpp/main.cpp ../[sudo] password for albert:albert@home-pc:/mnt/d$ ls ../c d e f main.cpp 启动 gdb 调试程序并打好断点，输入 run 运行发现，断点被触发，但是显示出 No such file or directory.，说明没有找到源代码文件。 123456789albert@home-pc:/mnt/d$ gdb -q mainReading symbols from main...done.(gdb) b 8Breakpoint 1 at 0x4008ac: file /mnt/d/cpp/main.cpp, line 8.(gdb) runStarting program: /mnt/d/mainBreakpoint 1, main () at /mnt/d/cpp/main.cpp:88 /mnt/d/cpp/main.cpp: No such file or directory. 查看源代码文件名和编译目录直接在 gdb 命令行中输入 info source 回车就可以了 12345678(gdb) info sourceCurrent source file is /mnt/d/cpp/main.cppCompilation directory is /mnt/dSource language is c++.Producer is GNU C++ 5.4.0 20160609 -mtune=generic -march=x86-64 -g -fstack-protector-strong.Compiled with DWARF 2 debugging format.Does not include preprocessor macro info.(gdb) 通过这个命令发现，源代码文件是 /mnt/d/cpp/main.cpp，编译目录是 /mnt/d 查看源代码搜索目录在 gdb 环境下输入 show dir 命令就可以显示 SourcePathSet 这个集合中都有哪些目录，由于还没有设置过现在还是默认值 $cdir:$cwd 123(gdb) show dirSource directories searched: $cdir:$cwd(gdb) 查看当前目录查看当前目录就比较简单了，直接 pwd 就搞定了 123(gdb) pwdWorking directory /mnt/d.(gdb) 我们“如愿以偿”的让 gdb 找不到代码了，从现在的环境来看，$cdir 和 $cwd 相同都是 /mnt/d，所以此时搜索的目录只有： /mnt/d/cpp/main.cpp /mnt/d/mnt/d/cpp/main.cpp /mnt/d/main.cpp 而代码被我们移动到了/mnt/main.cpp，gdb 自然就找不到了，后面来看看具体怎么处理这种情况。 具体示例说了这么多原理的东西，如果弄明白了这些很容易找到解决问题的办法，下面写一个完整点的例子，来感受一些具体怎么修复这个问题，新建三个文件 mainpro.cpp、mymath.h、mymath.cpp，目录结构和内容如下： 1234567albert@home-pc:/mnt/d$ tree /mnt/d/mainpro//mnt/d/mainpro/|-- core| `-- mainpro.cpp`-- kit |-- mymath.cpp `-- mymath.h 123456789101112131415//mainpro.cpp#include "../kit/mymath.h"#include &lt;iostream&gt;using namespace std;int main()&#123; int a = 1, b = 2; mymath* m = new mymath(); int c = m-&gt;add(a, b); cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl; return 0;&#125; 123456//mymath.hclass mymath&#123;public: int add(int a, int b);&#125;; 12345678//mymath.cpp#include "mymath.h"int mymath::add(int a, int b)&#123; int c = a + b; return c;&#125; 在 /mnt/d/mainpro 目录下编译代码，然后将代码文件所在目录 core 和 kit 拷贝到 /mnt/e/newpro 目录下，将可执行文件拷贝到 /home/albert 目录下。 123456789101112131415albert@home-pc:/mnt/d/mainpro$ g++ /mnt/d/mainpro/core/mainpro.cpp /mnt/d/mainpro/kit/mymath.cpp -g -o mainproalbert@home-pc:/mnt/d/mainpro$ tree.|-- core| `-- mainpro.cpp|-- kit| |-- mymath.cpp| `-- mymath.h`-- mainpro2 directories, 4 filesalbert@home-pc:/mnt/d/mainpro$ mkdir /mnt/e/newproalbert@home-pc:/mnt/d/mainpro$ sudo mv core/ /mnt/e/newpro/albert@home-pc:/mnt/d/mainpro$ sudo mv kit/ /mnt/e/newpro/albert@home-pc:/mnt/d/mainpro$ mv mainpro /home/albert/ 在 /home/albert 目录下启动 gdb 开始调试，先在 main 函数打断点，查询源文件路径和编译目录等信息； 1234567891011121314151617181920212223albert@home-pc:~$ gdb -q mainproReading symbols from mainpro...done.(gdb) b mainBreakpoint 1 at 0x4008de: file /mnt/d/mainpro/core/mainpro.cpp, line 7.(gdb) runStarting program: /home/albert/mainproBreakpoint 1, main () at /mnt/d/mainpro/core/mainpro.cpp:77 /mnt/d/mainpro/core/mainpro.cpp: No such file or directory.(gdb) info sourceCurrent source file is /mnt/d/mainpro/core/mainpro.cppCompilation directory is /mnt/d/mainproSource language is c++.Producer is GNU C++ 5.4.0 20160609 -mtune=generic -march=x86-64 -g -fstack-protector-strong.Compiled with DWARF 2 debugging format.Does not include preprocessor macro info.(gdb) list2 in /mnt/d/mainpro/core/mainpro.cpp(gdb) pwdWorking directory /home/albert.(gdb) show dirSource directories searched: $cdir:$cwd(gdb) 果然找不到源代码了，从上面的调试信息来看，可以得到以下信息： 源代码文件为 /mnt/d/mainpro/core/mainpro.cpp 程序编译目录为 /mnt/d/mainpro 当前目录为 /home/albert 而源代码查找列表中只有 $cdir:$cwd，说明只包含 /mnt/d/mainpro 和 /home/albert，那么查找的目录有： /mnt/d/mainpro/core/mainpro.cpp /mnt/d/mainpro/mnt/d/mainpro/core/mainpro.cpp /home/albert/mnt/d/mainpro/core/mainpro.cpp /mnt/d/mainpro/mainpro.cpp /home/albert/mainpro.cpp 这些目录显然找不到源代码文件了，因为文件已经被我移动到 /mnt/e/newpro/ 目录下了，也就是 /mnt/e/newpro/core/mainpro.cpp，下面来尝试一些解决方法。 使用 dir 命令解决刚才说了源代码查找集合 SourcePathSet 中只有 $cdir:$cwd，我们可以自己加一个嘛，比如像下面这样： 1234567891011121314(gdb) dir /mnt/e/newpro/core/Source directories searched: /mnt/e/newpro/core:$cdir:$cwd(gdb) list2 #include &lt;iostream&gt;3 using namespace std;45 int main()6 &#123;7 int a = 1, b = 2;8 mymath* m = new mymath();910 int c = m-&gt;add(a, b);11 cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl;(gdb) 这样就可以找到了，我们接着在 add 函数上下个断点，继续执行 12345678910111213141516(gdb) b mymath::addBreakpoint 2 at 0x4009a6: file /mnt/d/mainpro/kit/mymath.cpp, line 6.(gdb) cContinuing.Breakpoint 2, mymath::add (this=0x613c20, a=1, b=2) at /mnt/d/mainpro/kit/mymath.cpp:66 /mnt/d/mainpro/kit/mymath.cpp: No such file or directory.(gdb) list1 in /mnt/d/mainpro/kit/mymath.cpp(gdb) info sourceCurrent source file is /mnt/d/mainpro/kit/mymath.cppSource language is c++.Producer is GNU C++ 5.4.0 20160609 -mtune=generic -march=x86-64 -g -fstack-protector-strong.Compiled with DWARF 2 debugging format.Does not include preprocessor macro info.(gdb) 结果发现又找不到文件 /mnt/d/mainpro/kit/mymath.cpp 了，因为和之前不是一个文件，这个文件在其他的目录下，所以还要使用 dir 命令，把新的目录加到源代码查找集合 SourcePathSet 中： 1234567891011121314(gdb) dir /mnt/e/newpro/kit/Source directories searched: /mnt/e/newpro/kit:/mnt/e/newpro/core:$cdir:$cwd(gdb) list1 #include "../kit/mymath.h"2 #include &lt;iostream&gt;3 using namespace std;45 int main()6 &#123;7 int a = 1, b = 2;8 mymath* m = new mymath();910 int c = m-&gt;add(a, b);(gdb) 这次又能成功找到了，可是如果有好多个文件要调试，难道要把所有的目录都加进去吗？其实可以有简便方法的，在启动 gdb的时候可以指定搜索的源代码路径，这些路径都会被加到到源代码查找集合 SourcePathSet 中，具体操作如下，先退出gdb，然后重新加参数启动如下： 12345albert@home-pc:~$ gdb -q mainpro `find /mnt/e/newpro/ -type d -printf '-d %p '`Reading symbols from mainpro...done.(gdb) show dirSource directories searched: /mnt/e/newpro/kit:/mnt/e/newpro/core:/mnt/e/newpro:$cdir:$cwd(gdb) 其实这条命令的本来面目是 gdb -q mainpro -d xxxxx，只不过这组合了 find 命令以后使用起来更加方便了，可以把指定目录下的子目录全都添加到参数中 使用 cd 命令解决如果是临时调试倒是用不到上面设置启动参数那么麻烦，因为变量 $cwd 也在搜索集合中，既然在编译时记录的源文件被改变了位置，那么我们调整我们的当前位置，让代码出现搜索路径中，还是上面的这个例子： 123456789101112131415161718192021222324252627albert@home-pc:~$ pwd/home/albertalbert@home-pc:~$ gdb -q mainproReading symbols from mainpro...done.(gdb) b mainBreakpoint 1 at 0x4008de: file /mnt/d/mainpro/core/mainpro.cpp, line 7.(gdb) rStarting program: /home/albert/mainproBreakpoint 1, main () at /mnt/d/mainpro/core/mainpro.cpp:77 /mnt/d/mainpro/core/mainpro.cpp: No such file or directory.(gdb) list2 in /mnt/d/mainpro/core/mainpro.cpp(gdb) cd /mnt/e/newpro/core/Working directory /mnt/e/newpro/core.(gdb) list2 #include &lt;iostream&gt;3 using namespace std;45 int main()6 &#123;7 int a = 1, b = 2;8 mymath* m = new mymath();910 int c = m-&gt;add(a, b);11 cout &lt;&lt; "c = " &lt;&lt; c &lt;&lt; endl;(gdb) 上面的操作通过 cd /mnt/e/newpro/core/ 命令直接进入了源代码目录，当然就找到了，但是这还是会有点问题，当碰到需要调试好几个文件的时候就需要使用 cd 命令跳来跳去，要想一劳永逸，请看下面这个方法。 使用 set substitute-path 命令解决我们移动源代码的时候往往会整个目录移动，或者说开发机和发布机上面的代码文件组织结构是一样，只是所在的磁盘位置是不一样的，所以如果可以设置用一个路径替换原代码文件的路径就好了， set substitute-path from-path to-path 这个命令就可以达到想要的目的，这个命令还可以简写成 set substitute from-path to-path，比如还是前面的例子，源代码从 /mnt/d/mainrpo 目录整体移动到了 /mnt/e/newpro 目录，调试时找不到源代码可以使用 set substitute /mnt/d/mainrpo /mnt/e/newpro 命令来指定替换目录，这样就可以找到源代码啦，下面来测试一下： 1234567891011121314151617181920212223242526272829303132333435363738albert@home-pc:~$ gdb -q mainproReading symbols from mainpro...done.(gdb) set substitute-path /mnt/d/mainrpo /mnt/e/newpro(gdb) b mainBreakpoint 1 at 0x4008de: file /mnt/d/mainpro/core/mainpro.cpp, line 7.(gdb) runStarting program: /home/albert/mainproBreakpoint 1, main () at /mnt/d/mainpro/core/mainpro.cpp:77 /mnt/d/mainpro/core/mainpro.cpp: No such file or directory.(gdb) cd /mnt/e/newpro/Working directory /mnt/e/newpro.(gdb) list2 /mnt/d/mainpro/core/mainpro.cpp: No such file or directory.(gdb) set substitute-path /mnt/d/mainpro /mnt/e/newpro(gdb) list 01 #include "../kit/mymath.h"2 #include &lt;iostream&gt;3 using namespace std;45 int main()6 &#123;7 int a = 1, b = 2;8 mymath* m = new mymath();910 int c = m-&gt;add(a, b);(gdb) info sourceCurrent source file is /mnt/d/mainpro/core/mainpro.cppCompilation directory is /mnt/d/mainproLocated in /mnt/e/newpro/core/mainpro.cppContains 14 lines.Source language is c++.Producer is GNU C++ 5.4.0 20160609 -mtune=generic -march=x86-64 -g -fstack-protector-strong.Compiled with DWARF 2 debugging format.Does not include preprocessor macro info.(gdb) pwdWorking directory /home/albert.(gdb) 通过调试信息 Located in /mnt/e/newpro/core/mainpro.cpp 可以看到，果然在新的位置找到了源代码。 总结 调试的时候找不到源码有多种解决方法，需要根据实际情况选择最合适的解决方案。 编译时使用绝对路径时，推荐使用 set substitute-path from-path to-path 的方式。 编译时使用相对路径时，使用 set substitute from-path to-path 或者 dir new-path 都可以。 对于临时查找一个问题，单独调试某一个文件时使用 cd 命令就可以搞定了。 直接在 gdb 环境输入 dir 命令回车确认，可以重置 dir 目录 或者 set dir 目录 命令修改过的源代码搜索目录集合。 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 当人的才华不足以撑起个人的欲望时就会感到焦虑，当面对不利的情况和事件却又无力改变时就会感到愤怒，而弱肉强食一直都是生活的本质，惟有强大才是解决这一切负面情绪的良药~ 2020-7-18 15:36:53]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>source</tag>
        <tag>linux</tag>
        <tag>gdb</tag>
        <tag>dir</tag>
        <tag>path</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell脚本中获取命令运行结果、特殊变量使用、条件判断等常用操作]]></title>
    <url>%2Fblog%2F2020%2F07%2F07%2FShell%E8%84%9A%E6%9C%AC%E4%B8%AD%E8%8E%B7%E5%8F%96%E5%91%BD%E4%BB%A4%E8%BF%90%E8%A1%8C%E7%BB%93%E6%9E%9C%E3%80%81%E6%9D%A1%E4%BB%B6%E5%88%A4%E6%96%AD%E7%AD%89%E5%B8%B8%E7%94%A8%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言最近在处理一个 Python 局部变量的作用域问题时发现有些奇怪，想起了之前常写的 Lua 脚本，于是想写个函数测试一下，结果发现短短的十几行代码出现了多个错误，这可是我写了近三年的代码啊，才放下半年就记不清了，所以知识这个东西还是要不断“温故”，今天要总结的 Shell 脚本命令也是，基本属于一看就会，一写不对的状态，所以还是要把常用的操作总结到一起，方便查找和复习。 获取命令执行结果脚本中常常要获取一些命令的执行结果，比如当前目录 pwd、当前时间 date 等等，如果在控制台时直接输入后回车就能看到结果，但是在 Shell 脚本中却不能这样做，常见的有以下两种方式。 使用反引号 `command `来执行命令反引号就是键盘上 Tab 键上方的那个按键对应的符号，常写 Markdown 的小伙伴知道这个符号就是包裹代码块的那个符号，在 Shell 脚本中被用来执行命令得到结果，举个简单的例子 1234567#!/bin/bashresult=dateecho $resultresult=`date`echo $result 将上述命令保存到文件 cmd.sh 中运行 ./cmd.sh 得到结果： 123$ ./cmd.shdateTue Jul 7 23:48:03 CST 2020 从运行结果可以看出，如果不加反引号，我们常用的这些命令会被当成普通的字符串处理。 使用括号组合 $(command) 来执行命令除了上面的反引号，使用美元符和小括号组合也可以在 Shell 脚本中运行命令，使用同样的例子测试 1234567#!/bin/bashresult=`date`echo $resultresult=$(date)echo $result 保存到文件 cmd.sh 中运行 ./cmd.sh 得到结果： 123$ ./cmd.shTue Jul 7 23:53:27 CST 2020Tue Jul 7 23:53:27 CST 2020 对比可以看出两种方式在这个命令下运行结果是一样的。 两种方式的区别虽然上述两种方式都可以在 Shell 脚本中得到命令运行的结果，但是有一点是不一样的，那就是反引号执行命令不支持嵌套，不能实现反引号中再出现反引号，而 $(command)的方式是支持嵌套的，关于这一点可以看下面这个例子。 12$ echo $(ls $(pwd))cmd.sh 分析一下这个命令 echo $(ls $(pwd))，最里面的命令是 $(pwd)先执行得到当前目录，然后执行命令 $(ls 当前目录)得到目录下的文件，再通过 echo 命令把这个结果输出，就得到了 cmd.sh 这个文件名，因为我这个目录下只有这一个文件。 系统的命令使用反引号的方式改写就不生效了。 12$ echo `ls `pwd``cmd.shpwd 我们还是仿照上面嵌套来写，但是 echo 后面的内容其实被分成了3部分，一个ls命令，一个pwd字符串、一个空命令，这样就能解释运行结果 cmd.shpwd了。 对照着结果我们就可以知道了， $(command)的方式更加强大，可以支持命令的嵌套，应用更广泛一点，而反引号的方式跟多出现在之前的脚本中。 特殊变量使用从学习语言的第一天起就记住了变量名中只能有数字、字母、下划线，并且数字不能打头（Shell中只能字母开头），但是在 Shell 脚本中有一些特殊的变量，包含各种奇奇怪怪的符号。 $0 $1 $2 …这些是运行 Shell 脚本时传递给脚本的命令行参数。命令行参数用 $n 表示，$0表示当前脚本的文件名，$1 表示第一个参数，$2 表示第二个参数，依次类推，可以类比 Windows 下的 %0、%1、%2… $$当前 Shell 脚本的进程ID。如果在命令行执行得到的是当前 bash 的进程ID，如果放到脚本中，得到的是脚本的进程ID。 $?可以获取上一个命令执行后的返回结果。 $传递给脚本的命令行参数的个数。 $*传递给脚本的命令行参数的所有参数。 $@传递给脚本的命令行参数的所有参数，与 $* 稍有不同。 测试写个脚本测试一下，新建 cmdargs.sh 文件，编写下面代码： 123456789#!/bin/bashecho \$0 is $0echo \$1 is $1echo \$2 is $2echo \$$ is $$echo \$# is $#echo \$* is $*echo \$@ is $@ 先执行 ./cmdargs.sh 脚本， 然后输出 $? 脚本的退出状态，运行结果如下: 1234567891011$ ./cmdargs.sh I love my daughter$0 is ./cmdargs.sh$1 is I$2 is love$$ is 197$# is 4$* is I love my daughter$@ is I love my daughter$ echo $?0 $* 和 $@ 的区别对照这个源码和输出结果，这些特殊变量应该可以分清楚了，其中 $* 和 $@ 都是把所有内容都列出来了，但它俩还是有点区别的，当这两个变量都被双引号包裹时，通过 for 循环会得到不同结果，写个脚本 cmdargs2.sh 试一下 12345678910111213#!/bin/bashecho "test for \"\$*\""for var in "$*"do echo "$var"doneecho "test for \"\$@\""for var in "$@"do echo "$var"done 运行结果如下, &quot;$*&quot;把所有的参数当成了一个整体，而 &quot;$@&quot; 把各个参数都拆分开了，可以通过循环依次打印出来。 12345678$ ./cmdargs2.sh I love my daughtertest for "$*"I love my daughtertest for "$@"Ilovemydaughter 条件判断说起条件判断第一反应就是 if 了，在 Shell 脚本中也有 if 语句，同样是条件判断的中坚力量，先来看看 if 语句的写法： if 语句格式1234567if [ -d $filename ]; then echo "this is a directory."elif [ -a $filename ]; then echo "the file is exist."else echo "the file is not exist."fi 直接提供一个最复杂的情况，如果不需要 elif 或者 else 分支，直接删掉就可以，但是 if、then、fi 这些都是必须的，并且中括号里面的表达式与中括号之间都要有空格，如果挨着写会报错的。 中括号 [] 的作用一度认为 if 条件语句就是这样写，中括号 [] 应该是语法的一部分，但是查询后发现这居然是一个命令，和 ls，pwd 一样是一个可以执行命令，放在 if 条件判断时基本等同于 test 命令。 1234$ which [/usr/bin/[$ which test/usr/bin/test 看着这个查询结果感觉神奇吧，此外还有一个 [[]] 双中括号的操作，这个就不是命令了，而是 Shell 的一个关键字，比 [] 要强大的多。 具体条件Shell 脚本最常见的条件就是文件判断，数字判断和字符串判断了，接下来列举一下这些判断的常见写法。 文件判断 命令 含义 -a $filename 文件存在时为真 -d $filename 文件名对应的是目录时为真 -s $filename 文件非空时为真 -r $filename 文件可读时为真 -w $filename 文件可写时为真 -x $filename 文件可执行时为真 数字判断 命令 含义 n1 -eq n2 n1等于n2时为真 n1 -ne n2 n1不等n2时为真 n1 -gt n2 n1大于n2时为真 n1 -lt n2 n1小于n2时为真 n1 -ge n2 n1大于等于n2时为真 n1 -le n2 n1小于等于n2时为真 字符串判断 命令 含义 -n str1 str1字符串不为空串时值为真 -z str1 str1字符串为空串时值为真 str1 == str2 str1与str2相等时为真 str1 != str2 str1与str2不等时为真 str1 &gt; str2 按字典序str1排在str2后面时为真 str1 &lt; str2 按字典序str1排在str2前面时为真 数字判断特殊写法 命令 含义 ((&quot;$n1&quot; == &quot;$n2&quot;)) n1等于n2时为真 ((&quot;$n1&quot; != &quot;$n2&quot;)) n1不等n2时为真 ((&quot;$n1&quot; &gt; &quot;$n2&quot;)) n1大于n2时为真 ((&quot;$n1&quot; &lt; &quot;$n2&quot;)) n1小于n2时为真 ((&quot;$n1&quot; &gt;= &quot;$n2&quot;)) n1大于等于n2时为真 ((&quot;$n1&quot; &lt;= &quot;$n2&quot;)) n1小于等于n2时为真 逻辑关系运算符 命令 含义 -a 与操作，用于[] 和 test 操作符 -o 或操作，用于[] 和 test 操作符 ！ 取反操作，用于[] 、 test 操作符 和 [[]] 关键字 &amp;&amp; 与操作，用于[[]] 关键字 \ \ 或操作，用于[[]] 关键字 这些逻辑写法千奇百怪的，写两个例子就慢慢就慢慢理解了，比如判断一个字符串不为空，并且这个字符串指定的目录还存在就可以写成 123if [ -n "$1" -a -d "$1" ]; then echo $1 directory is existfi 使用双小括号来比较数值变量，写在双小括号中的变量前面可以不加 $ 符号，还有诸多特权等着你去发现 12345num1=$1num2=$2if (( num1 &gt; num2)); then echo num1 \&gt; num2fi 总之在学习这些条件比较的时候踩了不少坑，有很多情况都没有注意到，不过慢慢也适应了这种语法，但还是免不了会出现一个小问题，这里提供一个 Shell 语法检查的在线网站 《shellcheck》，将要检查的脚本放到页面上检测，会给出详细的错误信息，当然也有命令版本，可以自己到对应的 github 页面上下载哦~ 总结 Shell 脚本中获取命令的执行结果，可以通过反引号`command`，或者小括号 $(command) 的方式得到 Shell 脚本中有一系列 $ 开头的变量，用好他们是脚本和函数传递参数的关键 Shell 脚本中的条件判断对于初学者来说很头大，有许多注意的点要记住，判断形式也多种多样 脚本中有单引号、双引号、反引号，简单来记就是单引号中原样输出，双引号中变量求值后输出，反引号中只能写需要执行的命令 脚本中还要中括号、双中括号、小括号、双小括号等，上面都提到过，可以自己练习下，具体的细节怕是要单独总结了，放到一起太多了 脚本的中的分号起到语句结束的作用，如果有换行就不需要分号了，比如 if 条件后面的 then 如果换行，那么 then 前面的分号可以省略 再记住一个坑，脚本赋值等号两端不能有空格，脚本判断等号两端必须有空格 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 有些局，选择不入便立于不败之地，选择介入，即使曾身经百战，也恐难全身而退，更不要谈什么收益了~ 2020-7-11 00:30:00]]></content>
      <categories>
        <category>shell</category>
      </categories>
      <tags>
        <tag>if</tag>
        <tag>Shell</tag>
        <tag>command</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[根证书的应用和信任基础]]></title>
    <url>%2Fblog%2F2020%2F07%2F06%2F%E6%A0%B9%E8%AF%81%E4%B9%A6%E7%9A%84%E5%BA%94%E7%94%A8%E5%92%8C%E4%BF%A1%E4%BB%BB%E5%9F%BA%E7%A1%80%2F</url>
    <content type="text"><![CDATA[前言人生在世总要相信点什么，信亲人、信朋友、信你面前的陌生人，即便这些你都不信，也要信自己吧，假如连自己都不信了，那在地球上恐怕很难生存了。 我们把钱存入银行，因为我们相信当我们需要用钱时可以通过银行卡把钱取出来；我们拿着车票准时来到候车大厅，因为我们相信除非特殊情况，我们买的那趟车绝不会提前丢下我们而去；遇到纠纷我们会选择打官司，因为我们相信法官最后会给我们公正的判决结果。 生活中我们信任自己的经验，信任自己的亲人朋友，并依赖这些信任来做许多事情，这些信任是我们正常生活学习的前提，缺了这些我们将寸步难行。而在网络中我们同样需要信任，这些信任是筑造网络社会的基石。 有些信任是有条件的，比如银行贷款时不能通过空口白话就借来白花花的银子，而抵押物是贷款银行为了相信你附加的筹码；有些信任是无条件的，比如前面一篇总结 《认证、HTTPS、证书的基本含义》中提到的根证书，我们必须无条件信任，否则我们将置身于网络猜疑的海洋之中，无法正常利用网络带给我们的便利。 信任链我们常听说 HTTPS 更加安全，它是通过非对称加密技术，让我们可以在不确定的网络环境中可以确认对方的身份，安全传输密钥，但这一切都是有前提的，你得相信你的操作环境是安全的，你没有被人监控，你的电脑没有被人控制，你的数据没有被人篡改，抛开环境谈安全都是耍流氓~ 好了，我们可以回顾一下，要想验证一个网站的身份，我们需要得到网站的公钥，如果可以解开网站拿私钥加密的消息，我们就证明了网站的身份，而网站的公钥不能由网站直接发给我们，需要找权威机构给它证明，相当于找了个担保人。 权威机构会用自己的私钥把网站的信息和公钥合在一起生成证书，当我们访问网站时首先得到这个证书，然后用权威机构的公钥来解开证书内容，得到网站的信息和网站的公钥，然后进行信息比对和公钥解密来认证身份，这时我们需要思考，权威机构的公钥从哪里来？ 权威机构可以找更加权威的机构按照相同的方式给它做证书，这样一环一环的就走下去，形成了信任链，然后就无穷无尽了，一个权威机构给另一个权威机构证明，我可以玩到天荒地老，到底什么时候是个头啊，其实我们可以人为的确定一个，那就是根证书，他不需要找别的人给它证明，如果一个网站证书最终信任链顶端是有效的根证书，那么网站身份被确认。 根证书接下来看看根证书在哪呢？它内置在我们的浏览器（Firefox）和操作系统中，我们需要无条件的信任，从理论上讲没办法判断根证书的真假，它是自证清白的。这里需要注意，根证书不止有一个，它可以有很多个，“根”只是说明信任链到此为止，整条信任链上的节点都是“可信”的。所以说还是不要随意安装根证书，因为有了它就可以在你的电脑为所欲为。 说到这里有些人会想，根证书内置在操作系统和浏览器（Firefox）中，如果我下载一个被恶意修改的浏览器岂不是危险了，这种担心是有必要的，所以请尽量在正规网站下载，可是怎么证明哪些网站是正规网站呢？可以使用系统自带的根证书判断。 如果我的系统是盗版系统，根证书被人改过，那不是更危险了，事实确实如此，算了吧，还是暂时不相信网络了，我去买个系统光盘吧（不知道现在还有没有人用光盘装系统），可是卖你光盘的人能保证光盘的内容不被篡改吗？你说那不能，因为他是微软高级经理的小舅子，应该不能卖盗版碟吧。 即使光盘不是盗版的，但是制作光盘的内容有没有人动过手脚呢？这些我们还是无法确认，我们能做的只是尽可能的在正规渠道购买正版系统，这种情况遇到证书被篡改的情况很小，然后就无条件相信这个系统了，这就是我文章开头说的，我么总要信点什么，试想如果盖茨在 Windows 操作系统的证书中留有后门，你又能做些什么呢，所以还是不要纠结了，既然用就在正常使用的前提下信任它。 应用及分析说是应用，实际上我只是想吐槽而已，在吐槽之前我们应该了解，证书可以跟各大证书机构（也就是各种CA）来买，也可以自己生成，可能有人会想了，自己生成挺好啊，不用花钱谁还买啊？可是刚刚说过了，跟CA买的证书都是操作系统内置证书认证过的，自己生成的证书操作系统和浏览器可不认，那怎么办呢？ 干脆自己安装个根证书，自己给自己认证得了，用户岂是你想让安装就安装的，别说，还真是这样，只要你说的情况很危急，必须安装，那么大多数的小白用户是会自动安装的，这时你想到了谁？ 不知道大家想到了谁，反正我是想到了建行网银证书和令人“可歌可气”的12306，接下来简单扒一扒他们两个的故事… 建行网银证书最先接触的证书就是建行网银证书，我的第一代网银盾用了将近10年，去年才刚刚升级成2代，可以说真的是太稳定了，不知道做网银的产品经理是谁，你简直就是程序员的福音，在2020年的今天打开建行的官网，首页倒是好看了许多，但是有些内容，比如证书安装、U盾介绍的页面还是原来丑丑的样子。 之前办理U盾时还花钱，根本都不懂啊，使用U盾必须装证书啊，不装就不安全啊，现在回想起来，和我说这话的人可能根本就不懂什么是安全，什么是不安全，反正装就是了，每次付款都要启动建行验证程序，这也是我手动安装过的次数最多的证书，是它开启了我网上购物的里程。 已经2020年了，打开建行的官网依旧提示我正在使用不安全的连接，使用网银依旧让我自己安装证书，可能作为一个大银行，官方网站迟迟不启用 HTTPS，使用网银盾坚持要用户自己安装证书，应该不仅仅是证书价格的问题，可能还有什么其他的原因。 神奇的12306毕业后直接在12306买票的次数就少了，现在一般使用 APP 来解决，前一阵发现12306居然不要求自己安装证书了，仔细一查原来从2017年开始，12306官网就购买了 DigiCert Inc 认证的证书，确实是一个进步的boy，终于舍得花点钱买证书了，作为一个巨大型的网站，它方便了人们购票的方式，是值得歌颂和称赞的，但是每次购票前还要安装烦人的证书，确实挺令人生气的。 原来“根证书”3个红字显示在页面正中间，确实起到了提醒的作用，挺扎眼的，不过那已经一去不复返了，我再放个图，大家一起回顾一下。 ESET SSL Filter CA最后放一个例子，让你感受下根证书的威力，ESET是总部位于斯洛伐克布拉迪斯拉发的一家世界知名的电脑安全软件公司，主要做杀毒软件，前不久复习 HTTPS 知识的时候发现，我访问各大网站的证书全都变成了 ESET SSL Filter CA，这是什么鬼，难道 ESET SSL Filter CA 是个特别大的证书机构？ 当时还没有意识到是杀毒软件的证书，以为大家都是买的这家证书，后来发现不太对，百度、谷歌、GitHub、Stack Overflow，怎么都是一样的证书，继续深究才发现被“窃听”了。 我们知道使用 HTTPS 通信因为使用了非对称加密，没有私钥是无法窃听加密内容的，但是这款杀毒软件做到了，它有一个HTTPS 内容过滤的功能，做了我的电脑和各大网站的中间人，按理说 HTTPS 是可以检测出中间人的，但是这款软件在电脑中安装了根证书，所有浏览器认为它是合法的，理论上可以窃听你所有内容，甚至为所欲为。 总结 信任不仅是人类社会的基石，在网络世界同样重要 证书之间的层层信任构成了信任链，而根证书是不需要被其他人证明的 不要随意安装来历不明的根证书，那样可能会使的电脑更容易遭受到攻击 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 若衣食无忧，谁甘愿拼搏！努力鞭策自己无非是为了挣得可以选择生活的权利~ 2020-7-5 23:44:41]]></content>
      <categories>
        <category>加密与认证</category>
      </categories>
      <tags>
        <tag>认证</tag>
        <tag>非对称加密</tag>
        <tag>HTTPS</tag>
        <tag>根证书</tag>
        <tag>中间人</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[码龄10年工作6年的搬砖小哥，最常访问的学习网站都在这里了]]></title>
    <url>%2Fblog%2F2020%2F06%2F18%2F%E7%A0%81%E9%BE%8410%E5%B9%B4%E5%B7%A5%E4%BD%9C6%E5%B9%B4%E7%9A%84%E6%90%AC%E7%A0%96%E5%B0%8F%E5%93%A5%EF%BC%8C%E6%9C%80%E5%B8%B8%E8%AE%BF%E9%97%AE%E7%9A%84%E5%AD%A6%E4%B9%A0%E7%BD%91%E7%AB%99%E9%83%BD%E5%9C%A8%E8%BF%99%E9%87%8C%E4%BA%86%2F</url>
    <content type="text"><![CDATA[前言这完全是一篇水文，主要看别人分享的文章很有收藏价值，所以也想试着总结一下这种类型的文章，不过之前确实用过一些比较好的网站，有些网站是查找问题时找到的，但是解决完问题就找不到了很可惜，所以我养成了收藏网址的习惯，感觉有用就会分门别类的添加到书签中，再次遇到之前解决过的问题就先在书签里搜一下，有时候会加快解决问题的进度，下面这幅图是我浏览器书签中的一部分。 网络技术飞速发展到今天，越来越多的功能被搬到了“云”上，导致原来需要在本地安装的多种开发环境完全不需要搭建了，如果是临时使用完全可以在浏览器中实现，比如对于程序猿来说不可或缺的编程开发环境，已经出现很多在线编译和运行的网站，再比如原来被称作 PS大神 的设计者们必须要在电脑上安装 Photoshop 这个庞然大物，可是现在你可以发现很多在线 PS 的软件，处理简单功能分分钟搞定，这是我截取的网页上 在线PS软件 的一部分，足以以假乱真。 好了，开始进入正题了，作为一个天天写代码的搬砖小伙，每天都在敲敲敲，不是在敲代码就是在敲代码的路上，还有一种可能就是在学习如何敲代码，那么这样的榆木脑袋每天都会访问哪些学习网站呢？接下来我把最常访问的一些网站列举一下，有可能后续会更新，但我要是犯懒就算了。 网站列表接下来会分成几个大类来列举一个我最常用的一些网站，每个人的喜好不同，但是仔细看看，或许有些你会感兴趣哦！ 一、文档项目如果写一个功能有现成的轮子给我用就好了，其实网络上有很多现成的轮子，我们要善于利用别人的成果转换为自己进步的阶梯。 1、cppreference &gt;&gt; https://en.cppreference.com/w/ 首推这个网站其实是有点偏心的，因为每天都在写C++，所以还是首先就想到了这个网站，这个网站中可以查到已经发布的各个C++标准的库函数，特性、头文件等等，对于不确定的函数返回值、新标准的特性、函数的常见用法都可以在这个网站找到，这个网站还有中文版的，学习C++的小伙伴可以常来逛逛。 2、 GitHub &gt;&gt; https://github.com/ 被广大程序员调侃成“全球最大的同性交友网站”怎么能不上榜，GitHub 这个网站就算你不常用但也会常听到吧，上面充满了全世界精英团队编写的轮子，有趣的是这样一个最支持开源的网站居然被微软的这个最大的闭源厂商受够了，不过现在还是发展的越来越好了。你可以在上面阅读一些开源代码，看看那些明星产品究竟是怎样实现的，真正为我所用。 二、数据仓库程序发展离不开数据存储，数据是支撑程序发展的基石，现在的数据库已经不是当初的关系数据满天下了，各种各样的数据库类型被发明了出来，列数据库、文档数据库、键值数据库等等，真的是太多了。 1、 Redis &gt;&gt; https://redis.io/commands 非关系型数据库中最火的一个了吧，在认真学习之前一度认为它是一个新产品，后来才知道 Redis 其实在 2009 年就已经诞生了，作为一款键值型的内存数据库，现在被广泛引用于各个领域，而 Redis 的官方文档是需要不断去翻阅的，最近发布了 Redis 6.0，引入了网络多线程，以后的面试题可能要留神了。 2、 MySQL &gt;&gt; https://dev.mysql.com/doc/refman/8.0/en/ 虽然 NoSQL 数据库在各个领域兴起，但是现在还是关系数据库占据着主导地位，MySQL 就是关系数据库中的明星产品了，自从被 ORACLE 收购以后也在不断发展，最近版本从5.7一跃直接到8.0，据说MySQL 8 要比 MySQL 5.7 快 2 倍，还带来了大量的改进和更快的性能！感兴趣的可以查阅一下 MySQL 的文档，它的文档格式特别棒，看着就让人赏心悦目。 3、 墨天轮 &gt;&gt; https://www.modb.pro/dbRank 墨天轮上聚集了很多数据库爱好者，是一个新兴的数据库技术交流平台，一直渴望成为一个专业的技术社区，高效便捷、开放互助、乐于分享，能够承载我们数据人的学习和成长，促进整个行业的发展和创新，在这个网站上我们可以看到各大数据库排行，了解数据库相关的最新发展和方向。 三、工具集合文章开头也提到了，如今很多工具都搬到了线上，这样既节省了电脑空间，也免去了安装和配置工具的麻烦，只要不是IDE的重度依赖者，使用在线工具还是很方便的。 1、 在线工具 &gt;&gt; https://tool.lu/ 这个网站提供了众多的在线工具，每次一用到时间戳转换或者URL编码等操作，我肯定会第一时间打开这个页面，因为本地调 API 太麻烦了，有时还需要搭建环境，在网站上找到对应的工具直接操作就可以了，还带有实时刷新的功能，完全没必要自己在本地写代码。 2、AlbertWorld &gt;&gt; http://www.008ct.top 这个网站收录了很多有用的网址，不仅仅是工具，文档、教程、数据、资源包括方方面面，其中包括很多讲解原理的知识和有用的素材，很像一个小小的杂货铺，偶尔上新哦！ 四、疑难解答解决问题是程序员每天都要面临的功课，而程序员要解决的问题往往是没见过的，如果一个程序猿天天值只处理那么几个相同的问题，那么他已经走上了被淘汰的道路，查找问题原因，给出解决方案，祝贺你，你今天又进步了。 1、 CSDN &gt;&gt; https://www.csdn.net/ 用了这么久的 CSDN 一直不知道全称是什么？前几天才查了一下全称是 Chinese Software Developer Network，立意很深远的样子，不过确实是一个不错的网站，从去年开始大面积调整，原来的广告真是惨不忍睹，改版后现在好多了，工作中很多解决方案都出自这个网站，之前在论坛里没少逛，解答问题的同时，自己的知识也得到了巩固。 2、 StackOverflow &gt;&gt; https://stackoverflow.com/ 一个和 GitHub 比肩的网站，一个专门解决程序猿问题的网站，你要坚信，作为一个普通的程序搬砖工，你遇到的问题别人也遇到过，所以遇到问题来这个网站查一查，有时问题瞬间就被解决了，特别是一些专业的工具仅仅报了一个错误代码，通过搜索引擎很难定位具体问题，但是在这个网站上的前辈已经为你趟好路了。 五、进阶刷题程序猿就是一个活到老学到老的职业（如果35岁被淘汰就不用学了），必须时刻保证自己的学习状态，更新自己的知识储备，刷题成为了一项锻炼脑力的活动，因为很多公司特别是大公司都会要求算法达到一定的水平，所以没事多刷刷题，不要让自己的大脑锈住了。 1、力扣 &gt;&gt; https://leetcode-cn.com/problemset/all/ 这个网站貌似有很多名字，现在显示的是力扣，之前是在全球服注册的，后来莫名其妙的有注册了一次，变成了家门口的版本，这上面有很多算法题，一段时间没看居然还加上了面试题，不过它搞的那个竞赛挺有意思的，作为长期的两题选手，看着高手们10分钟做完4题，犹如神仙打架一般。 2、 POJ &gt;&gt; http://poj.org/ 这个 Online Judge 有些历史了，不过一直保持着更新，ACM 竞赛时也尝试在这里刷过题，和 LeetCode 比起来这里的题似乎更难一些，如果想挑战更高难度，不妨来这里试一下。 六、教程案例当我们想学习一门新技术的时候，很渴望得到一份简单明了的教程，实际上很多技术的官方网站文档都非常完整，但是对于初学者来说理解起来会有些难度，这时候可以看一些边学边做的教程，在不断尝试中学习知识。 1、廖雪峰官网 &gt;&gt; https://www.liaoxuefeng.com/wiki/1016959663602400 廖雪峰此乃神人也，看看我截取的这篇教程的访问量你就清楚了，前两年我看到这篇文章的时候访问量才几亿，跟着教程完整的学了一遍，现在访问量已经400多亿了，受欢迎程序难以想象，廖大神写得教程浅显易懂，非常适合初学者，从头来一步步的就学会了，想当初我跟着他学爬虫把他的文章都爬了，哈哈~2、 菜鸟教程 &gt;&gt; https://www.runoob.com/ 同样是一个接地气的教程网站，谁刚开始学的时候不是一只菜鸟呢，这个网站教程很多，只要你想学总能找到你喜欢的那款，并且在讲解时会有例子和函数参数说明，非常适合初学者。 总结 总有小伙伴调侃说：收藏从未停止，学习从未开始，其实收藏是一个好苗头，只有想学才有可能去学 如果仔细看了这些网站，你会发现有些网站的设计让人真的很舒服，临时补充一个 https://git-scm.com/ 真正应了那句话，比你优秀的人比你还努力，你的产品都那么强了，网站居然还那么好看，还让不让人活了~ ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 我们没有生活在和平的年代，只是生活在了和平的国度，想开点，珍惜眼前的一切，灾难都会过去，我们还有一双手去争夺属于自己的未来。 2020-6-20 00:16:49]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>收集</tag>
        <tag>网站</tag>
        <tag>working</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++中的std::lower_bound()和std::upper_bound()函数]]></title>
    <url>%2Fblog%2F2020%2F06%2F15%2FC-%E4%B8%AD%E7%9A%84std-lower-bound-%E5%92%8Cstd-upper-bound-%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言问题是躲不掉的，该来的总会来，这不是代码中又遇到了 std::upper_bound() 函数，再来学习一遍好了，在我的印象中每次看到这 lower_bound 和 upper_bound 两个函数都有些别扭，凡是见到他们必须查一遍，因为我记得它们两个函数的作用不对称，这一点记得很清楚，但是它们两个函数查找的细节却记不住，这次总结一下，强化记忆，下次回忆起来应该会快一点。 函数定义今天看到这两个函数时挠挠头又打开了搜索引擎，看到文章里写到 std::lower_bound() 是返回大于等于 value 值的位置，而 std::upper_bound() 是返回第一个大于 value 值的位置，第一反应真是瞎写，怎么俩都是大于，肯定应该是一个大于一个小于啊，这样才“合理”嘛！ 但是当看到多个文章中采用相同的说法时，刚刚还“坚定”的想法开始动摇，然后开始查C++标准文档，一遍遍读着那有些拗口的文字: std::lower_bound returns an iterator pointing to the first element in the range [first, last) that is not less than (i.e. greater or equal to) value, or last if no such element is found. std::upper_bound returns an iterator pointing to the first element in the range [first, last) that is greater than value, or last if no such element is found. 这些标准文档上的文字印证了刚刚查询到的结果，两个函数返回的结果都是迭代器，std::lower_bound() 是在区间内找到第一个大于等于 value 的值的位置并返回，如果没找到就返回 end() 位置。而 std::upper_bound() 是找到第一个大于 value 值的位置并返回，如果找不到同样返回 end() 位置。 两个函数都提到了大于操作，而没有涉及到小于操作，这就是我前面提到的不对称，也是我感觉不合理的地方，但是当尝试使用了几次这两个函数之后，我发现这两个函数的设计的恰到好处，这样的设计很方便我们来做一些具体的操作。 实际例子首先说明这两个函数内部使用了二分查找，所以必须用在有序的区间上，满足有序的结构中有两个常见的面孔：std::map 和 std::set，他们本身就是有序的，所以提供了 std::map::lower_bound() 和 std::set::lower_bound() 这种类似的成员函数，但是原理都是一样的，我们可以弄明白一个，另外类似的函数就都清楚了。 自己设计如果你看了这两个函数的具体含义也和我一样不太理解为什么这样设计，可以思考一下接下来这个需求，找出数组内所有值为2和3的元素，图例如下： 对于一个有序数组，我们在实现 lower_bound() 函数和 upper_bound() 函数时可以让它返回指定的位置来确定取值区间，第①种情况就是标准函数库的实现方式，而第②种和第③种就是我第一印象中感觉应该对称的样子，这样看起来也没什么问题，下面具体来分析下后两种设计有哪些不好的地方。 具体分析假如我们采用第②种实现方式，那么实现打印元素2和3的代码要写成下面这样： 12345678910111213141516171819#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;int main()&#123; std::vector&lt;int&gt; v&#123;1,1,2,2,3,3,3,5,7,8&#125;; std::vector&lt;int&gt;::const_iterator itorLower = std::lower_bound(v.begin(), v.end(), 2); std::vector&lt;int&gt;::const_iterator itorUpper = std::upper_bound(v.begin(), v.end(), 3); while(true) &#123; std::cout &lt;&lt; *itorLower &lt;&lt; std::endl; if (itorLower == itorUpper) break; ++itorLower; &#125; return 0;&#125; 代码看起来还可以，打印完元素后判断到达了结尾直接跳出循环，但是如果要是数组中不包含元素2和3呢，那么也会打印出一个元素，还有可能导致程序崩溃。 如果我们采用第③种实现方式，那么实现打印元素2和3的代码要写成下面这样： 12345678910111213141516#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;int main()&#123; std::vector&lt;int&gt; v&#123;1,1,2,2,3,3,3,5,7,8&#125;; std::vector&lt;int&gt;::const_iterator itorLower = std::lower_bound(v.begin(), v.end(), 2); std::vector&lt;int&gt;::const_iterator itorUpper = std::upper_bound(v.begin(), v.end(), 3); for(++itorLower; itorLower != itorUpper; ++itorLower) &#123; std::cout &lt;&lt; *itorLower &lt;&lt; std::endl; &#125; return 0;&#125; 这代码看起来简洁了很多，但是在循环开始前需要先调用 ++itorLower，因为第一个元素并不是需要找到的元素，所以要先跳过它，这样看来确实多做了一步操作，一开始就让 itorLow 指向第一个2就好了呀。 最终版本当你尝试几种实现方式就会发现，还是标准库提供的这种方式使用起来更加方便，虽然采取的不是对称的方式，但是统一了存在查找元素和不存在查找元素的的情况，写出的代码也比较简洁，没有多余的步骤，代码如下： 123456789101112131415#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;using namespace std;int main()&#123; std::vector&lt;int&gt; v&#123;1,1,2,2,3,3,3,5,7,8&#125;; auto itorUpper = std::upper_bound(v.begin(), v.end(), 3); for(auto itorLower = std::lower_bound(v.begin(), v.end(), 2); itorLower != itorUpper; ++itorLower) &#123; std::cout &lt;&lt; *itorLower &lt;&lt; std::endl; &#125; return 0;&#125; 总结 有些函数的实现方式和我们想象的并不一样，但是我们可以通过熟练使用来了解它为什么这样设计 对称结构虽然是很美的，但是非对称的结构在编程中常常出现，同样有其美丽所在 遇到类似的问题可以动笔画一画，列举出各种情况会有利于你做出正确的判断 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 有时会很焦虑，看到优秀的人比你还努力时总让人感到急迫，但是一味的忧患是无意义的，脚下迈出的每一步才是真真正正的前进，不要去忧虑可能根本就不会发生的事情，那样你会轻松许多 2020-6-26 23:21:40]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>lower_bound</tag>
        <tag>upper_bound</tag>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认证、HTTPS、证书的基本含义]]></title>
    <url>%2Fblog%2F2020%2F06%2F14%2F%E8%AE%A4%E8%AF%81%E3%80%81HTTPS%E3%80%81%E8%AF%81%E4%B9%A6%E7%9A%84%E5%9F%BA%E6%9C%AC%E5%90%AB%E4%B9%89%2F</url>
    <content type="text"><![CDATA[前言通过前面的总结 《对称加密、非对称加密、公钥、私钥究竟是个啥？》，我们基本了解了对称加密和非对称加密的概念和特点，考虑到效率和安全性，一般可以使用非对称加密来传递对称加密所需密钥，之后就采取对称加密通信了，这样可以大大提高数据发送的的效率。 其实密码技术除了应用在加密领域外还有很多其他的用途，比如验证数据的完整性、用来做认证、提供一些不可否认的证据等，这些应用也常常出现在我们的日常生活中，比如很多官方网站在提供软件下载链接的同时，还附带一个验证的字符串，实际上很多就是md5码或者hash码，这些就是供下载的人来验证完整性的，防止被其他人篡改。 我们下载完软件之后，使用工具来将软件转化成一串字符，听起来很神奇，实际上就是计算一下软件的md5码或hash码，然后和网站上的标注的信息进行对比，如果一致那么软件就是完整的。我曾经就遇到过一次，当时做的游戏发包，同事给我发了测试包，安装之后无法正常使用，检查包的大小与发送端的一样，后来使用检测工具计算发现md5是不同的，原因可能是发送包的时候电脑卡死过，导致最后发来数据包与原始数据产生了差异。 但是你有没有想过，这个软件虽然是完整的，通过md5计算发现也没有被其他人篡改，那么怎么证明你下载的网站真的是官网呢？万一官网也是伪造的呢？如果有人伪造了官网，又将上面的软件进行修改重新计算md5然后上传到自己伪造的界面上，你要怎么来识别呢？ 可能有的人会想到看网址啊，taobao.com 就一定是淘宝的网站吗？这个域名是可以伪造的，所以要验证网站上东西是真的，那么首先要验证你看到的网站是真的，这就涉及到了认证身份，接下来可以简单了解下什么是认证。 认证其实密钥不仅仅可以用来加密，还可以用来认证的，那么什么是认证？认证是一种信用保证形式，表示对一种事物或一个人的信任和认可，比如常见的毕业证书、结婚证书都是对人一段经历或一种关系的证明和认可。最简单的网站登录是基于密码的验证，这实际上就是利用对称加密的认证。 网站保存了你的用户信息和密码，下次再登录的时候输入密码后，网站会用你输入的密码和之前保存的密码进行对比，如果密码相同则认证成功，成功的证明了“你”就是“你”，而非对称加密同样可以用来做认证。 在非对称加密的实现中，私钥是只有自己保存的，而私钥加密的内容可以使用公钥解开，如果一份加密数据可以用 Jerry的公钥解开，那么我们就可以认为这份数据是 Jerry 发出的，因为只有 Jerry 自己有私钥，所以可以通过这种方式来进行认证。 而在网络上想要认证一个网站的身份，确认它不是钓鱼网站，第一个映入脑海中的就是 https，一般提到 https 都会说它是加密的、安全的，是 http 的升级版，但是 https 的安全不仅仅体现在加密上，还有它的认证功能，可以使你免受钓鱼网站的侵害。 HTTPS简单了解下 HTTPS，一般来说网络模型常说的有OSI七层模型和五层模型，HTTPS 的诞生并没有增加模型的层数，HTTP 是建立在 TCP基础上的应用层协议，而 HTTPS 是在 TCP 和 HTTP 之间的会话层中加了一些特殊操作，使原来明文传输的内容，在会话层这一步进行加密，并且可以对数据来源进行认证。 提到 HTTPS 就不得不说 SSL 和 TSL， SSL 是应用在 HTTP上的一个协议加密层，最初是由网络大佬网景公司（Netscape）研发，后来升级为 TSL，简单的理解就是 HTTP + SSL/TSL = HTTPS。 随着网络安全逐渐得到大家的认识，一些主流网站基本都都将访问方式改成了 https，支持 https 的网站在浏览器的地址栏中通常有一把小锁，点开会提醒你访问的是安全的连接，如果你访问的连接疑似被人篡改或者仿冒，那么这把小锁会被斜线划掉，提醒你网站危险请谨慎访问。 那么 https 是怎么判断出来哪些网站是安全的，哪些网站是仿冒的呢？毕竟有些网址都很像甚至可以做成一模一样的，这就用到了非对称加密的认证功能，当我用 A 的公钥可以解密一段消息，那么就可以证明消息是 A 发来的，https 的认证功能正是利用了这个特点。 当访问一个网站的时候，网站先给我发一个用它的私钥加密的数据，然后我用它的公钥来解密，如果解密成功就说明我访问的网站是正常的，可以继续访问，如果解密失败则很有可能是虚假或者仿冒的网站，应该仔细辨别一下了。 这里会有一个问题，我怎么才能得到网站的公钥呢？之前说过密钥配送问题，直接由网站发给我肯定不行，中间可能被篡改，也有可能一个虚假网站把它自己的公钥发给我了，我用假的公钥验证对应的假的私钥也是成功的，这样就起不到认证的效果了，必须给他找个证明人才行，这就要用到我们下面要说的证书了。 证书证书是用来证明一件事情或东西的，刚才说网站的公钥不能它自己来发，这样不能证明它的身份，我们可以找一个权威的机构给它认证一下，我每次从权威机构获得网站的证书，从这个证书中取得公钥，如果用这个公钥可以解开网站私钥加密的内容，那么就可以认证它的身份了。 这里提到的证书就是网站所有者找权威机构申请的，权威机构把网站信息、有效时期、对应的公钥、序列号消息等数据存储到证书中，当我们需要能某个网站的公钥时，去证书中取就可以了，这里的证书有点像营业执照了，由权威机构发布，用来证明你的身份。 但是权威机构的证书怎么发给我呢？我们有理由认为网络是不安全的，那证书如果直接通过网络发给我同样是不安全的，还有一个问题就是网站虽然找了一个权威机构，但是我认为它不够权威怎么办？这时这个权威机构可以找一个更权威的机构证明自己，让更权威的机构给自己颁发一个证书，这样就形成了证书链。 就像现实生活中我要找个人来干活，因为工期比较紧所以找的人要求踏实，必须能老老实实把活干完，不能半路撂挑子，张三过来应聘，正在我犹豫时，走过来一个叫李四的人说张三没问题，但是我还是不能确定，因为李四我也不熟悉，然后李四居然把我爸叫来了，我爸和我说李四这个人特别诚实，从来不说谎，这时一条证书链就形成了，李四为张三证明，我爸为李四证明，那谁来证明我爸说的是真的呢？不需要的，我无条件相信他。 这在计算机的证书链中就是根证书，根证书不需要别人来证明，你只能无条件相信它，它是整个信息链的源头，通常内置在操作系统或者浏览器中，关于根证书还要一些好玩的故事和一些变态的应用，下次再说吧，准备睡觉了~ 总结 密码技术除了应用在加密领域，还可以用来验证数据的完整性、用来做认证、提供一些不可否认的证据 HTTPS 不仅可以用来加密通信内容，还可以用来验证网站的真实性 正规的支持 HTTPS的网站在访问时会地址栏会有一把安全的小锁头，但是有些不出现小锁头的网站并不一定都是非法的 HTTP 网站是没有小锁头的，因为有些数据不需要加密，毕竟绝大多数的 HTTPS 证书是要钱的，有很多网站由于经费问题还未投身于 HTTPS 的怀抱 根证书通常内置的操作系统或者浏览器中，是证书链的源头，你必须无条件的信任他。 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 当我们拼劲全力到达自己的终点时，可能会看到同行的人正在你的终点线前伸伸懒腰准备出发，然后一骑绝尘消失在你震惊的目光中，但是这不是我们放弃努力的理由，因为如果你不努力，你甚至连他们的背影也看不到~ 2020-6-14 23:20:21]]></content>
      <categories>
        <category>加密与认证</category>
      </categories>
      <tags>
        <tag>加密</tag>
        <tag>认证</tag>
        <tag>非对称加密</tag>
        <tag>HTTPS</tag>
        <tag>证书</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[对称加密、非对称加密、公钥、私钥究竟是个啥？]]></title>
    <url>%2Fblog%2F2020%2F06%2F07%2F%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E3%80%81%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E3%80%81%E5%85%AC%E9%92%A5%E3%80%81%E7%A7%81%E9%92%A5%E7%A9%B6%E7%AB%9F%E6%98%AF%E4%B8%AA%E5%95%A5%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[前言进入正题之前先唠叨几句，不久前听到一个名词叫——费曼学习法，核心思想就是用通俗的话语把复杂道理或技术讲清楚，如果你已经明白了这个方法的含义，那么我好像离成功又进了一步。其实这个方法一直在尝试使用，但是没想到它居然有个“洋气”的名字。 由于之前学习时接触了加密、验证、HTTPS、证书等知识，感觉挺有意思的，最近也用到了一些这方面的内容，所以决定把这些概念重新梳理一下，免得一段时间不复习又还给书本了。本打算写一篇总结把这些概念整理到一起，但是初步想了一下很难实现，涉及到的概念实在太多了，所有还是决定分成几次来写吧。 分开写就比较随便了，写到哪完全看心情，不过我还是力图用最简单的描述来讲清楚问题，抛开具体的实现细节（其实我也不懂），梳理流程和概念性的知识，想了解具体的实现细节还是找专业的书籍去补充吧，我曾经看了一遍《图解密码技术》，过了这么久整本书我就记得两个词——异或、求余，再比如使用公钥和私钥来完成非对称加密，就是利用了两个大质数 (p,q) 乘积 (n) 难以逆向求解，这些太细节的东西很难展开一点点讲清楚。 最理想的状态是把学习知识当成是看故事书，阅读完一个个情节就吸收的差不多了，而不是把这些知识当成武功秘籍，然后一点点参悟，最后觉得枯燥而放弃，所以为了知识解惑，也算是将学习成果做个笔记，我们开始从最基础的知识学起。 对称加密对称加密一般指：加密和解密使用的是同一个密钥的加密方式。就像防盗门的钥匙一样，可以用钥匙把门锁上，也可以用这同一把钥匙再把门打开。 对称加密示例至于密钥怎么使用要看具体的加密算法了，可以举一个简单的例子，比如有下面这样一句话： I like cat 我想把它发给一个好朋友，但是又不想被别人看到，万一有其他人一眼看到，那我的喜好就暴露了（那有怎样呢？），这时我们可以把这句话改的稍微隐晦一点，我可以和好友约定一个密码，假设是 1，然后我把原来这句话的每个非空白字母都替换一下，按字母表顺序使用后一个字母替换前一个字母，比如用字母 b 替换字母 a，那么这句话就变成了： J mjlf dbu 这时就不怕被别人一眼看穿消息内容了，没有意义的字符串是比较难记的，但是当我的好友收到这句话时，使用我们约定的密码 1 就知道字母顺序变换了1位，所以他再将将字母反向替换回来就能够将文字还原。 这个例子很简单，但可以说明对称加密的关键，就是加密解密使用同一个密钥，例子中的 1 就是这个密钥，它可以让解密者知道，还原信息时需要反向移动1位即可，消息发送流程如下： 1234graph LRA[I like cat] -- 用1加密 --&gt; B((J mjlf dbu))B((J mjlf dbu))-- 发送给好友 --&gt; C((J mjlf dbu))C((J mjlf dbu))-- 用1解密 --&gt; D[I like cat] 对称加密的问题刚才的例子已经说了对称加密的流程，但是有一个问题需要解决，这个密码 1 我要怎么告诉我的好友呢？直接发消息被别人看到怎么办，打电话也有可能被别人窃听啊！ 密钥配送这就涉及到了一个密钥配送的问题，如果想让对方解密就需要把密码发过去，但是密钥有可能被其他人窃取，这样秘密就不再是秘密了，可能你会想即使密码被别人窃取了也不要紧，因为他根本不知道怎么用。 请不要做这种假设，简单的情况没有密码都能破解，更何况在密码和数据都被窃取的情况下呢，另外在密码领域我们建议使用完全公开的密码算法，这样的算法经过时间的检验才能被用于加密，千万不要独创一套自认为很安全的加密算法，单靠隐藏算法的细节来达到加密的目的是很危险的。 发送密钥可能被窃取，不发送密钥对方无法解密，这个加密的密钥配送问题是使用对称加密必须要解决的，而下面要说的这种非对称就不同了，可以将一把密钥直接发送给对方，即使被窃取也没有关系。 非对称加密看这个名字就知道它有点“针对”那个叫做对称加密的小伙伴，从定义上来说对称加密指的是加密和解密使用相同的密钥（为啥不叫同钥加密咧），而非对称加密指的是加密和解密过程使用不同的密钥来进行。 乍一听好像有点不可思议啊，怎么滴，难道还能两把不同的钥匙开一把锁？确实可以！这有点像中学物理里面的两个开关控制一个灯泡。在一个漆黑的楼梯两端，分别有一个开关，控制着楼梯上方的一个灯泡，上楼前先打开楼梯下面的开关，然后上楼后关掉楼梯上面的开关，而下楼时进行相反的操作，先打开楼梯上面的开关，然后下楼后默认楼梯下面的开关，找了张电路图，感兴趣可以再分析一下。 不过非对称加密和这种双掷开关不完全相同，使用开关时可以在同一端打开或关闭，但是非对称加密时，只能在一端加密，然后在另一端解密，同一端是不能同时加密和解密的。 公钥与私钥具体地，非对称加密指的是根据特殊规则生成两把密钥 A 和 B，分别叫做公钥和私钥。私钥自己保留，公钥则分发给自己的小伙伴用来用来和自己通信，理论上生成的两把密钥选择哪一把作为私钥都可以，但是出于效率和安全等方面的要求，公钥和私钥再生成时会给出特殊的条件，所以在实际使用过程中，两者通常是不会互换的。 非对称加密的示例使用公钥和私钥怎样完成非对称加密呢？下面来看一个具体的场景，比如有 Tom 、Jerry 、Spike 三个小伙伴，有一天 Jerry 想给 Tom 发点小秘密，又不想让 Spike 发现，首先他想到的是对称加密，先和 Tom 约定一个密码，再给 Tom 发送加密消息，但是想到前几天，自己和 Tom 的消息被 Spike 破解了，因为两个人发送密钥和加密消息的过程都被窃听了，如果这次的消息再被窃听到怎么办？ 后来Jerry想起Tom曾经自己生成了一对公钥和私钥，然后把公钥发给了自己和 Spike，那这样就可以使用非对称加密了，Jerry 使用 Tom 给的公钥把要发送的小秘密进行加密，然后发送给了 Tom。这时 Spike 果然在窃听，但是窃听到的消息使用了 Tom 的公钥进行了加密，只有 Tom 拥有解开这条消息的私钥，而 Spike 虽然拥有 Tom 的公钥也是解不开的。 1234graph LRA[I like cat] -- Jerry用Tom公钥加密 --&gt; B((密文))B((密文))-- 发送给Tom --&gt; C((密文))C((密文))-- Tom用自己的私钥解密 --&gt; D[I like cat] 怎么判断解开上面的描述中出现了“解开”一词，这两个字在我刚开始学习加密这些知识的时候困扰了我好久，查了好多讲解也没弄明白，什么叫能解开，什么叫解不开。它不像现实生活中的事物那么形象，比如把电视打开，那么电视就出现图像了，把锁解开门就能打开了。在数据加密的过程中，数据本质上是一堆二进制数据，加密之后还是一堆二进制数据，解密时使用密钥进行特定的运算就会得到解密后的二进制数据，怎么判定这些“解开”的数据是否是原数据呢？ 后来在不断的学习过程中，接触了一些开源的非对称加密算法实现，比如常用的 RSA，基础的函数包括公钥加密、私钥解密、私钥加密、公钥解密等，当你在解密时将密文和密钥传入解密函数进行特定的运算，计算过程和计算结果必须满足特定的条件，这些条件是算法保证的，如果有条件不满足那么解密失败，这就是上面所提到的解不开。 非对称加密的问题之前提到对称加密时，密钥配送问题是一个难题，因为网络上发送密钥很容易被截获，无法保证密钥不被窃取。很多情况下又不能面对面的传递密钥，而非对称加密的出现解决了这个问题，因为公钥是可以被任何人知道的，所以网络上发送公钥就不怕被窃取，但是如果例子中，Jerry 收到的 Tom 的公钥实际上在途中被 Spike 替换了怎么办？ 这就又引入了一个问题——中间人攻击，形象的来表述就是有第三方 Spike 侵入了原本两个人 Tom 和 Jerry 的通信中，Spike 对 Tom 时把自己伪装成 Jerry，和 Jerry 沟通时又将自己伪装成 Tom，这样原本两个人的沟通信息全都被第三方窃取了，这个问题的根本就是获取公钥不可信，不过证书中心可以解决这个问题，后面我们再继续深入了解，这里就不展开了。 对称加密和非对称加密对比 加密类型 常见算法 加密处理速度 遇到的问题 解决办法 对称加密 DES、AES 快 密钥配送问题 面对面交换或者使用非对称加密传送秘密 非对称加密 RSA、DSA 慢 中间人攻击问题 通过证书中心来解决中间人攻击 总结 虽然想写的尽可能的通俗易懂，但还是不免会引入一些令人犯困的概念，一开始记住就好，后面理解了不会觉得枯燥 还在不断尝试表达方式，总结中融入了一些我当时学习时的想法和疑惑，我遇到的这些问题应该很多人也遇到过 使用对称加密方法，速度快，效率高，但是会面临密钥配送的问题 非对称加密虽然很巧妙的，但是效率较低，所以一般的用法是使用非对称加密来传送简短的对称加密密钥，然后再使用对称加密的方式传送数据 为了更好的加密你的数据，应使用公开的加密算法，他们都是经过时间考验的，单靠隐藏加密细节来加密时很危险的 ==&gt;&gt; 反爬链接，请勿点击，原地爆炸，概不负责！&lt;&lt;== 见过了外面的大千世界，便不再甘心留在原地，而这种不甘心恰恰就是动力~]]></content>
      <categories>
        <category>加密与认证</category>
      </categories>
      <tags>
        <tag>加密</tag>
        <tag>认证</tag>
        <tag>非对称加密</tag>
        <tag>公钥</tag>
        <tag>私钥</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git在回退版本时HEAD\~和HEAD^的作用和区别]]></title>
    <url>%2Fblog%2F2020%2F05%2F30%2Fgit%E5%9C%A8%E5%9B%9E%E9%80%80%E7%89%88%E6%9C%AC%E6%97%B6HEAD%E2%80%A6-%E5%92%8CHEAD-%E7%9A%84%E4%BD%9C%E7%94%A8%E5%92%8C%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言今天总结一个小知识点，虽然不难，但是对新手有很强的迷惑性，了解一下也挺好。我们在使用 Git 回退到版本的时候，可能见过这种写法 git reset --hard HEAD~，有时候也会遇到这种写法 git reset --hard HEAD^，这两个语句都是将代码库还原到上一个版本，但是只差了一个符号，他们究竟有什么区别呢？这里先给出结论：HEAD~ 和 HEAD^ 含义不同，功能一样！ HEADHEAD 这个词在 git 使用过程中经常出现，作用很像是数据结构中指向二叉树根节点root的指针。有个 root 指针我们就可以对二叉树进行任意操作，它是二叉树的根基。而 git 中的 HEAD 概念也类似一个指针，它指向是当前分支的“头”，通过这个头节点可以追寻到当前分支之前的所有提交记录。 git 的提交记录之间的关系很像一棵树，或者说是一张图，通过当前的提交记录指向上一次提交记录串联起来，形成一个头结构，而在 git 中我们常常说的切换分支，只不过是 git 客户端帮你把要操作的那条路径的头节点，存储到了 HEAD 文件中。 HEAD 在 git 版本控制中代表头节点，也就是分支的最后一次提交，同时也是一个文件，通常在版本库中 repository/.git/HEAD，其中保存的一般是 ref: refs/heads/master 这种分支的名字，而本质上就是指向一次提交的 hash 值，一般长成这个样子 ce11d9be5cc7007995b607fb12285a43cd03154b。 HEAD~ 和 HEAD^在 HEAD 后面加 ^ 或者 ~ 其实就是以 HEAD 为基准，来表示之前的版本，因为 HEAD 被认为是当前分支的最新版本，那么 HEAD~ 和 HEAD^ 都是指次新版本，也就是倒数第二个版本，HEAD~~ 和 HEAD^^ 都是指次次新版本，也就是倒数第三个版本，以此类推。 这个说法在之前的总结 《git checkout/git reset/git revert/git restore常用回退操作》 中提到过，但是并未展开说，今天就来测试一下。 HEAD 后面 ~ 和 ^ 的区别其实 HEAD~ 和 HEAD^ 的作用是相同的，这两者的区别出现在重复使用或者加数字的情况，下面来分情况说明一下。 HEAD~ 和 HEAD^后面都加1加上参数1之后变成了 HEAD~1 和 HEAD^1，其实这就是他们本来的面貌，在参数为 1 的情况下可以省略，HEAD~1 表示回退一步，参数1表示后退的步数，默认推到第一个父提交上，而HEAD^1表示后退一步，直接后退到第n个父提交上，数字1表示是第一个父提交。 这里引入一个父提交的概念，也就是在最新提交之前的最近的提交我称它为父提交，但是父提交会有两个吗？实际上会的，直接的父提交可能会有很多，分支合并是产生父提交的一种常见原因，两个分支合并到一起时，这两个分支的原 HEAD 都会成为合并后最新提交的父提交。 理解了这个概念，我们发现虽然数字是一样的，但是含义却不相同，HEAD~1 中指的是后退的步数，HEAD^1指的是退到第几个父提交上。 HEAD~ 和 HEAD^后面都加0这是一种比较特殊的情况， 加上参数0之后变成了 HEAD~0 和 HEAD^0，其实他们指向的节点没有改变，还是代表了 HEAD，只要了解这种情况就行了，我还没有见过谁这样写过。 HEAD~ 和 HEAD^后面都加大于1的数字这时就会发现两者的不同了，比如我们把数字都定为2，那么 HEAD~2 代表后退两步，每一步都后退到第一个父提交上，而 HEAD^2 代表后退一步，这一步退到第二个父提交上，如果没有第二个父提交就会报出以下错误： fatal: ambiguous argument ‘HEAD^2’: unknown revision or path not in the working tree.Use ‘–’ to separate paths from revisions, like this:‘git […] – […]’ 具体示例上面说了几种加数字的情况，如果是第一次接触可能还是不太明白，没关系，我可以实际操作一下，看个具体的例子就明白了。 准备工作下面是一个测试代码库的分支结构，一共有 dev1、dev2、dev3、dev4 四个分支，最终合并到 dev1 分支，提交记录如下： 123456789101112131415161718192021albert@home-pc MINGW64 /d/gitstart (dev1)$ git alllog* ce11d9b (HEAD -&gt; dev1) Merge branch 'dev3' into dev1|\| * e330eac (dev3) update at dev3 - 3| * 7ab3c98 Merge branch 'dev4' into dev3| |\| | * c8795e8 (dev4) update at dev4 - 2| | * 155d3db update at dev4 - 1| * | ccdf16a update at dev3 - 2| * | 9f08bb0 update at dev3 - 1| |/* | f82b57b update at dev1 - 3* | dcdcb87 Merge branch 'dev2' into dev1|\ \| * | 32d6213 (dev2) update at dev2 - 2| * | ca4db4a update at dev2 - 1| |/| * d8d80b7 update readme at dev2* | 034ccb6 update readme at dev1 - 2* | d58fedc update readme at dev1 - 1 也许有颜色标记会看得更清楚一些，所以截个图放在这： 刚看这种图的时候要注意一点，记录列表中的先后关系不代表提交时间的先后，如果习惯于看SVN的记录以后，很容易在看日志信息时加上时间因素，但是这个时间因素在 git 查看记录时变得不再明显，比如上面记录中的 e330eac 在图形上要比 f82b57b 更接近 HEAD 提交 ce11d9b，但是因为处在不同的分支上，在合并之前他俩的修改时间还真不一定是哪个更早一些。 树形记录在 git 的提交记录图上，我们可以确定当前提交的父提交（所依赖的提交）是哪一个或者哪几个，但是不能确定任意两个提交的时间先后，为了能更清楚的看清分支提交的依赖关系，还是看下面这个树形图更方便一些。 1234567891011121314151617181920graph TB ce11d9b--&gt;f82b57b; f82b57b--&gt;dcdcb87; dcdcb87--&gt;034ccb6; 034ccb6--&gt;d58fedc; d58fedc--&gt;dev1; dcdcb87--&gt;32d6213; 32d6213--&gt;ca4db4a; ca4db4a--&gt;dev2; ce11d9b--&gt;e330eac; e330eac--&gt;7ab3c98; 7ab3c98--&gt;ccdf16a; ccdf16a--&gt;9f08bb0; 9f08bb0--&gt;dev3; 7ab3c98--&gt;c8795e8; c8795e8--&gt;155d3db; 155d3db--&gt;dev4; 查看命令在验证 HEAD~ 和 HEAD^ 之前我们先学习一个命令 git rev-parse HEAD 这个命令可以显示出 HEAD 对应的提交的 hash 值，加上 --short 参数就可以显示出长度为7位的短 hash，用起来比较方便，测试如下： 1234567albert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse HEADce11d9be5cc7007995b607fb12285a43cd03154balbert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEADce11d9b 开始测试下面可以用 git rev-parse --short 命令来测试 HEAD 后面跟不同参数时对应的提交是哪一个了，测试如下： HEAD~、HEAD^、HEAD~1、HEAD^1123456789101112131415albert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEAD~f82b57balbert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEAD^f82b57balbert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEAD~1f82b57balbert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEAD^1f82b57b 测试后发现，这四种写法结果是一样的，都是指向 HEAD 的第一个父提交，这和我们前面说的观点一致。 HEAD~~、HEAD^^、HEAD~2、HEAD^2123456789101112131415albert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEAD~~dcdcb87albert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEAD^^dcdcb87albert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEAD~2dcdcb87albert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEAD^2e330eac 这次我们发现，前三个表示方法是一样的，指向同一个提交记录，但是最后一个与他们不同，这时根据前面提到定义来看就行了，HEAD~~ 实际上是 HEAD~1~1的简写，而~ 后的数字就是指的后退的步数，所以 HEAD~~ 等价于 HEAD~2，属于一种合并计算。 HEAD^^ 是 HEAD^1^1 的简写，而 ^ 后面的数字表示后退一步到第几个父提交上，因为数字是1，所以 HEAD^^ 表示退一步到第一个父提交上，在退一步到第一个父提交上，这时与 HEAD~~ 的作用是相同的。 HEAD^2 就有些不同了，它表示后退一步到第二个父提交上，所以对照树形图是第二排的第二个节点。 ~ 和 ^ 混合使用看了上面的例子对于 ~ 和 ^ 的使用应该有些明白了，它俩其实可以组合使用的，比如想退到第5排、第2个节点上，也就是 ca4db4a 上，简单来看需要第一步到第一个父提交上，在退一步到第一个父提交上，然后退一步到第二个父提交上，最后退一步到第一个父提交上。 那么我们根据需求可以写成 HEAD^1^1^2^1，测试一下看看 hash 是否正确： 123albert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEAD^1^1^2^1ca4db4a 测试发现没有问题，其实还可以合并啊，我们知道1是可以省略的，所以可以简写成 HEAD^^^2^，另外多个 ^ 还可以写成 ~n 的形式，所以这个节点还可以表示成 HEAD~2^2^的样子，测试如下，结果是一样的。 1234567albert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEAD^^^2^ca4db4aalbert@home-pc MINGW64 /d/gitstart (dev1)$ git rev-parse --short HEAD~2^2^ca4db4a 关于 git reset 的一点思考刚学习 git reset 的命令时一直认为是一个回退命令，其实学习一段时间之后发现，这个命令其实很符合它的名字，就是一个重置(reset)命令，通过 git reset 命令可以修改 HEAD 指向不同的提交，这个提交甚至都不必是当前分支上的某次提交，测试后发现，只要是版本库中合法提交都可以使用这个命令进行设置，相应的版本库的内容也会发生对应的变化，从这一点来看，它真的太强大了，它可以使你正在开发的 dev 分支瞬间变成 master 分支。 总结 HEAD~ 后面加数字表示后退的步数，每次后退都默认退到第一个父提交上，HEAD~2 表示连退两步。 HEAD^ 后面加数字表示只退一步，但是这一步后退到数字表示的父提交上，HEAD^2 表示退一步到第二个父提交上。 git 在查看多分支提交记录时，日志的先后顺序不代表提交时间的先后顺序。 git reset 命令是一个重置 HEAD 的命令，可以指挥版本库指向任何一个合法提交。 俗话说：人不犯我，我不犯人；可俗话又说：先下手为强，后下手遭殃！俗话说：宁为玉碎，不为瓦全；可俗话又说：留得青山在，不怕没柴烧！…其实只要你变成了那个成功的“俗话”，你说的就是金科玉律，警世哲理！ 2020-5-31 14:51:49]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>reset</tag>
        <tag>版本控制</tag>
        <tag>Git</tag>
        <tag>HEAD</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置Beyond Compare 4作为git mergetool来解决git merge命令导致的文件冲突]]></title>
    <url>%2Fblog%2F2020%2F05%2F21%2F%E9%85%8D%E7%BD%AEBeyond-Compare-4%E4%BD%9C%E4%B8%BAgit-mergetool%E6%9D%A5%E8%A7%A3%E5%86%B3git-merge%E5%91%BD%E4%BB%A4%E5%AF%BC%E8%87%B4%E7%9A%84%E6%96%87%E4%BB%B6%E5%86%B2%E7%AA%81%2F</url>
    <content type="text"><![CDATA[前言使用 git merge 命令合并代码的时候可能会产生文件冲突，产生这种冲突的根本原因是文件的同一处同时被多次修改，这种同时修改常体现的不同分支上，当多个分支修改了同一处代码，再合并代码的时候就会产生冲突，因为 git 程序也不知道我们想要保留哪一份修改，这时就需要我们手动修改产生冲突的文件。 当冲突内容很少的时候我们可以打开文本编辑器，找到 &gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;、=========== 和 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 这三行字符包裹的内容就是需要解决冲突的部分，但是当冲突内容特别多时我们还是习惯于通过可视化的工具来处理，Beyond Compare 就是这样一款工具，可以用来比较不同的文本文件、表格文件，还可以比较文件夹内容，之前用着比较习惯，所以在处理 git 冲突的时候也想使用这个工具来做，通过查找技术文档发现了下面的方法。 解决方案鉴于大家都比较急，查找问题时想要直接找到答案，所以我这里直接说明配置步骤，送给不求甚解的小伙伴，也方便今后我可以直接找到，不过配置之前还是要先看一下前提。 前提 在 Windows 上安装了 git 客户端，可以执行 git 命令（废话！没装 git 怎么产生冲突的） 安装了 Beyond Compare 4 这个软件，下载链接很多，自己找一个吧，实在找不到，那就放弃吧（找我要） 配置首先找到 Beyond Compare 的安装路径，比如我的软件安装路径是 D:\mybc4\BComp.exe，然后在 git 命令行客户端中执行下面命令： 1234git config --global merge.tool bc4git config --global mergetool.bc4.cmd "\"D:\\mybc4\\BComp.exe\" \"\$LOCAL\" \"\$REMOTE\" \"\$BASE\" \"\$MERGED\""git config --global mergetool.bc4.trustExitCode truegit config --global mergetool.keepBackup false 至此，git mergetool 就配置完了，当下次冲突的时候，直接使用 git mergetool 命令就可以调用 Beyond Compare 解决冲突文件了，但是你不好奇，这些设置命令都是什么意思吗？为什么执行完这些命令就能调用 Beyond Compare 4 这个软件了，如果你感兴趣可以接下往下看一看。 Beyond Compare这是一款强大的比较工具，前面提到它可以比较文本、比较表格、比较文件夹，但是它的能力不仅限于此，它甚至可以比较MP3、比较图片、比较注册表，我们的目的是调用它的比较功能，但是前提是这款软件允许你调用，如果它不给你提供接口，你就是想调用也得绕上八百个圈才可以。 这一点我们可以查询文档确定，文档是安装软件时自带的，名字为 BCompare.chm，如果找不到，安利你一个叫做 Everything 的软件，装上它以后，电脑中的一切东西都能搜索找到。 这个文档应该很容易找到的，与软件的可执行文件在同一目录，其实我们使用的比较工具应该是 BCompare.exe，但是为什么在配置 git mergetool 的是后用的是 BComp.exe 呢？这一点文档中有写： BCompare.exe: This is the main application. Only one copy will run at a time, regardless of how many windows you have open. If you launch a second copy it will tell the existing copy to start a comparison and exit immediately.BComp.exe: This is a Win32 GUI program. If launched from a version control system, it should work just fine. If launched from a console window, the console (or batch file) will not wait for it. 文档是英文的，但是比较容易理解，总的来说 BCompare.exe 是主程序，BComp.exe 用在版本控制工具中更加优秀，至于文档中提到的主程序只能启动一个副本的说明，我试了一下并不是这样的，但是这不是重点，根据文档建议，我们应该调用 BComp.exe 程序。 关于调用参数，文档中对于每种形式的比较也给出了说明，我们这里只列举两个文件和四个文件这两种参数，两个文件作为参数时常用来对比，我直接使用主程序对比文件就是这种形式，参数格式为 BCompare.exe &quot;C:\Left File.ext&quot; &quot;C:\Right File.ext&quot;，但是使用时我常把文件直接拖拽到软件上进行比较。四个文件作为参数时常用来处理文件冲突，参数类型为 BCompare.exe C:\Left.ext C:\Right.ext C:\Center.ext C:\Output.ext，参数中文件的名字表明处理时的位置和作用，看下面这个图就明白了。 从红框圈定的位置就可以发现和文件的对应关系了，最下面是最终的输出文件，也是我们可以手动修改的文件。 文件冲突及处理产生冲突先看一下 git 仓库的原始情况 12345678910111213141516albert@home-pc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.nothing to commit, working tree cleanalbert@home-pc MINGW64 /d/gitstart (dev)$ lsREADME.mdalbert@home-pc MINGW64 /d/gitstart (dev)$ cat README.mdlearn git branch commandm2test checkout 在此基础上新建两个分支 dev1 和 dev2 12345678910111213albert@home-pc MINGW64 /d/gitstart (dev)$ git checkout -b dev1Switched to a new branch 'dev1'albert@home-pc MINGW64 /d/gitstart (dev1)$ git checkout -b dev2Switched to a new branch 'dev2'albert@home-pc MINGW64 /d/gitstart (dev2)$ git branch | grep dev dev dev1* dev2 在 dev2 分支上修改 README.md 文件后提交 12345678910111213141516171819albert@home-pc MINGW64 /d/gitstart (dev2)$ echo "this is dev2 test"&gt;&gt;README.mdalbert@home-pc MINGW64 /d/gitstart (dev2)$ git add README.mdwarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directoryalbert@home-pc MINGW64 /d/gitstart (dev2)$ git commit -m"update readme at dev2"[dev2 d8d80b7] update readme at dev2 1 file changed, 1 insertion(+)albert@home-pc MINGW64 /d/gitstart (dev2)$ cat README.mdlearn git branch commandm2test checkoutthis is dev2 test 切换回 dev1 分支修改 README.md 文件后提交 1234567891011121314151617181920212223albert@home-pc MINGW64 /d/gitstart (dev2)$ git checkout dev1Switched to branch 'dev1'albert@home-pc MINGW64 /d/gitstart (dev1)$ echo "this is dev1 test"&gt;&gt;README.mdalbert@home-pc MINGW64 /d/gitstart (dev1)$ git add README.mdwarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directorygit com -albert@home-pc MINGW64 /d/gitstart (dev1)$ git commit -m"update readme at dev1"[dev1 3136341] update readme at dev1 1 file changed, 1 insertion(+)albert@home-pc MINGW64 /d/gitstart (dev1)$ cat README.mdlearn git branch commandm2test checkoutthis is dev1 test 这时在 dev1 分支上合并 dev2 分支上的修改就会产生冲突 1234567891011121314151617181920albert@home-pc MINGW64 /d/gitstart (dev1)$ git merge dev2Auto-merging README.mdCONFLICT (content): Merge conflict in README.mdAutomatic merge failed; fix conflicts and then commit the result.albert@home-pc MINGW64 /d/gitstart (dev1|MERGING)$ cat README.mdlearn git branch commandm2test checkout&lt;&lt;&lt;&lt;&lt;&lt;&lt; HEADthis is dev1 test=======this is dev2 test&gt;&gt;&gt;&gt;&gt;&gt;&gt; dev2albert@home-pc MINGW64 /d/gitstart (dev1|MERGING)$ lsREADME.md 冲突产生了，文档中同一位置被两个分支修改后合并导致的，内容里出现了 &lt;&lt;&lt;、===、&gt;&gt;&gt;，包裹的内容被分成了两部分，上面一部分是当前分支修改的，下面一部分是从 dev2 分支合并过来的，还要注意虽然产生了产生了冲突，但是目录中并没有产生其他多余的文件。 解决冲突这样的冲突比较简单，我们只要使用文本工具删除不想要的内容，保存后 git add README.md，然后再 git commit 就完成了冲突的解决，但是因为配置了 git mergetool，我们可以用它来解决冲突，直接在命令行敲命令 git mergetool 就可以: 12345678albert@home-pc MINGW64 /d/gitstart (dev1|MERGING)$ git mergetoolMerging:README.mdNormal merge conflict for 'README.md': &#123;local&#125;: modified file &#123;remote&#125;: modified file 这时光标不会退出，一闪一闪并且打开 BComp.exe 工具，截图如下： 这时如果你打开 git 库所在目录会发现除了 README.md 还多了下面4个文件： 12345README.mdREADME_BACKUP_584.mdREADME_BASE_584.mdREADME_LOCAL_584.mdREADME_REMOTE_584.md 按照自己的实际情况修改最下面的文件，然后点击箭头所指的保存按钮，关闭 Beyond Compare，查询一下仓库状态 123456789101112albert@home-pc MINGW64 /d/gitstart (dev1|MERGING)$ git statusOn branch dev1All conflicts fixed but you are still merging. (use "git commit" to conclude merge)Changes to be committed: modified: README.mdalbert@home-pc MINGW64 /d/gitstart (dev1|MERGING)$ lsREADME.md 不但冲突文件没有了，还给我们自动执行 git add README.md 命令，我们只需要执行 git commit 就解决完了冲突。 123456789101112albert@home-pc MINGW64 /d/gitstart (dev1|MERGING)$ git commit[dev1 b348ae6] Merge branch 'dev2' into dev1albert@home-pc MINGW64 /d/gitstart (dev1)$ git adog* b348ae6 (HEAD -&gt; dev1) Merge branch 'dev2' into dev1|\| * d8d80b7 (dev2) update readme at dev2* | 3136341 update readme at dev1|/* 5f4181e (origin/dev, dev) add comments 工具配置的参数含义回过头来再看看 git mergetool 的4句配置到底有什么用 1234git config --global merge.tool bc4git config --global mergetool.bc4.cmd "\"D:\\mybc4\\BComp.exe\" \"\$LOCAL\" \"\$REMOTE\" \"\$BASE\" \"\$MERGED\""git config --global mergetool.bc4.trustExitCode truegit config --global mergetool.keepBackup false git config首先你需要知道 git config 的作用，就是用来配置 git 的，加上了 --global 表示调整全局 git 配置，不加的话就是调整当前库的 git 配置。windows上的全局配置一般在 C:\Users\用户名\.gitconfig，如果你之前用过 git，一般会执行过 git config --global user.name xxx 对吧，这些命令都是来调整 git 配置的，打开这个 .gitconfig 你会看到 123456789101112131415[user] name = albert email = albert@163.com[core] autocrlf = true[alias] st = status adog = &quot;log --all --decorate --oneline --graph&quot;[merge] tool = bc4[mergetool &quot;bc4&quot;] cmd = \&quot;D:\\mybc4\\BComp.exe\&quot; \&quot;$LOCAL\&quot; \&quot;$REMOTE\&quot; \&quot;$BASE\&quot; \&quot;$MERGED\&quot; trustExitCode = true[mergetool] keepBackup = false 看看最后几行就是我们添加的4项配置，只不过到文件中变成了键值对的形式，经过测试后发现，这些属性最少两级，比如 user.name 、core.autocrlf，最多三级比如 mergetool.bc4.cmd、 mergetool.bc4.trustExitCode，如果级数再多会怎么办，你可以试试 git config --global a.b.c.d.e test，它最终也会被拆成三级如下 12[a &quot;b.c.d&quot;] e = test git mergetool这个需要查一下官方文档了，git mergetool --help 就能打开git官方文档，文档写得真不错，排版格式看着就很舒服。 文档提到添加 --tool-help 选项可以列举可以的合并工具，展示如下 12345678910111213141516171819202122232425262728293031323334353637albert@home-pc MINGW64 /d/gitstart (dev1)$ git mergetool --tool-help'git mergetool --tool=&lt;tool&gt;' may be set to one of the following: vimdiff vimdiff2 vimdiff3 user-defined: bc4.cmd "D:\Program Files\Beyond Compare 4\BComp.exe" "$LOCAL" "$REMOTE" "$BASE" "$MERGED"The following tools are valid, but not currently available: araxis bc bc3 codecompare deltawalker diffmerge diffuse ecmerge emerge examdiff guiffy gvimdiff gvimdiff2 gvimdiff3 kdiff3 meld opendiff p4merge smerge tkdiff tortoisemerge winmerge xxdiffSome of the tools listed above only work in a windowedenvironment. If run in a terminal-only session, they will fail. 这一查才发现，原来 git mergetool 支持的工具有这么多，不过下面这些我都没安装，用一下上面列举的3个，试试 git mergetool --tool=vimdiff，果然打开了一个界面 幸亏不如 Beyond Compare 好用，不然我不是白配置了，不过这些工具确实方便，都不需要配置，只要安装了参数中指定一下就可以用了，比如这个 bc3，我猜它是 Beyond Compare 3，只不过我安装的是 Beyond Compare 4 这个版本。 这些内置工具使用的前提是已经安装了，并且安装软件的目录放在了环境变量 Path 中，如果没有放在这个变量中需要通过 mergetool.&lt;tool&gt;.path 参数来配置，比如我把 Beyond Compare 3 安装在了 D 盘根目录，就可以设置 git config --global mergetool.bc3.path &quot;D:\\&quot;。 我们在可用工具中没有找到 Beyond Compare 4 为什么我们可以用呢？因为 git mergetool 命令还支持自定义合并解决冲突的工具，只要指定 mergetool.&lt;tool&gt;.cmd 就可以调用了，就像 git mergetool --tool-help 查询结果中提到的 user-defined: bc4.cmd &quot;D:\Program Files\Beyond Compare 4\BComp.exe&quot; &quot;$LOCAL&quot; &quot;$REMOTE&quot; &quot;$BASE&quot; &quot;$MERGED&quot;，git mergetool 把 bc4 作为了一个等同于内置合并工具的软件。 再来看看这4句配置的含义： 1234git config --global merge.tool bc4git config --global mergetool.bc4.cmd "\"D:\\mybc4\\BComp.exe\" \"\$LOCAL\" \"\$REMOTE\" \"\$BASE\" \"\$MERGED\""git config --global mergetool.bc4.trustExitCode truegit config --global mergetool.keepBackup false 第一句 git config --global merge.tool bc4 是说把 git mergetool 的默认工具配置成 bc4，如果不指定默认工具在使用时就需要写成 git mergetool --tool=bc4 或者 git mergetool -t bc4 了，可是 bc4 是我们自己起的名字，根本就没有这个名字啊，接着往下看。 第二句 git config --global mergetool.bc4.cmd &quot;\&quot;D:\\mybc4\\BComp.exe\&quot; \&quot;\$LOCAL\&quot; \&quot;\$REMOTE\&quot; \&quot;\$BASE\&quot; \&quot;\$MERGED\&quot;&quot; 指定了工具 bc4 的调用路径和参数，后面的这4个参数都是 git mergetool 命令提供的，依次代表本地修改，被合并分支修改，两端未修改前版本文件，最终合并导出的文本文件。 第三句 git config --global mergetool.bc4.trustExitCode true， 设置为 true 表示信任软件的返回码，并依据返回码确定合并是否成功，如果设置成 false 就会在合并完成后问你是否解决完冲突，设置成 true 会方便很多。 第四句 git config --global mergetool.keepBackup false， 是指定在合并完成后删除备份文件 *.orig，这个文件会在调用 git mergetool 是产生 *.orig 备份文件，成功合并后自动删除就可以了。 思考至此终于弄明白这个 git mergetool 是怎么工作的了，但是想这样一个问题，这个 &lt;tool&gt;.cmd 一定得调用冲突解决工具吗？如果你从头看到这里应该会明白，这里只是给用户提供了一个调用自定义工具的方式，至于你调用什么它是不关心的，你完全可以在 git mergetool 的时候让电脑关机，这些都是可以的，在你明白了原理以后，一切都变得简单了。 总结 Beyond Compare 是一款强大的比较工具，合理的使用可以有效的提升工作效率 git mergetool 内置了很多可以使用的合并工具，并且支持调用自定义的合并工具 git 的官方文档写得真的挺详细，有时间可以多看一看，你会发现很多有意思的功能 急于解决问题时可以不求甚解，解决问题后最好可以明白其中的缘由，这其实就是一种进步 尽管科技很发达，但有些人一旦分开可能真的就是一生不见了]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>工具</tag>
        <tag>mergetool</tag>
        <tag>文件冲突</tag>
        <tag>bc4</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用c++filt命令还原C++编译后的函数名]]></title>
    <url>%2Fblog%2F2020%2F05%2F16%2F%E4%BD%BF%E7%94%A8c-filt%E5%91%BD%E4%BB%A4%E8%BF%98%E5%8E%9FC-%E7%BC%96%E8%AF%91%E5%90%8E%E7%9A%84%E5%87%BD%E6%95%B0%E5%90%8D%2F</url>
    <content type="text"><![CDATA[前言这个命令功能单一，但是非常强大，可以用来还原C++编译后的函数名，为什么C++的函数名需要单独的命令来还原，因为他们看起来都是这样 _ZNK4Json5ValueixEPKc、这样 _Z41__static_initialization_and_destruction_0ii 或者这样的 _ZN6apsara5pangu15ScopedChunkInfoINS0_12RafChunkInfoEED1Ev，仅通过这一串字母很难知道原函数的名字是什么，参数类型就更难分析了，实际上C++在编译函数时有一套命名函数的规则，每种参数使用什么字母表示都是有约定的，但是通过学习这些约定来还原函数太麻烦了，还好有人编写了 c++filt 命令可以让我们直接得到编译前的函数名，真好…… C++编译后的函数名C++ 编译后的函数名字非常古怪，相比而言 C 语言编译后的函数看起来就正常许多了，extern &quot;C&quot;、函数重载、name mangling 这些知识点都与 C++ 这个奇怪的函数名有些关系，extern &quot;C&quot; 的作用简而言之就是告诉编译器和链接器被“我”修饰的变量和函数需要按照 C 语言方式进行编译和链接，这样做是由于 C++ 支持函数重载，而 C 语言不支持，结果导致函数被 C++ 编译后在符号库中的名字和被 C语言编译后的名字是不一样的，程序编译和连接就会出现问题，此类问题一般出现在 C++ 代码调用 C 语言写的库函数的时候。 而 name mangling 就是实现 C++ 函数重载的一种技术或者叫做方式，要求同名的 C++ 函数参数个数不同或参数类型不同，如果只有返回值类型不同，那么两个函数被认为是相同的函数，无法成功通过编译。接下来我们就来看几个例子，看看 C++ 编译后的函数名有什么变化。 C++和C语言编译后的函数名对比我们来写一段相同的代码，分别使用 gcc 和 g++ 进行编译，从代码到可执行文件需要经历“预处理、编译、汇编、链接”4个步骤，接下来为了看到编译后函数名的不同，我们只进行前两步，生成汇编代码，再来比较不同。 gcc编译simple.c文件123456789101112131415// simple.cint myadd(int a, int b)&#123; return a + b;&#125;int main()&#123; int a = 110; int b = 119; int c = myadd(a, b); return 0;&#125; gcc simple.c -S 生成汇编代码文件simple.s内容 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051 .file "simple.c" .text .globl myadd .type myadd, @functionmyadd:.LFB0: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 movl %edi, -4(%rbp) movl %esi, -8(%rbp) movl -4(%rbp), %edx movl -8(%rbp), %eax addl %edx, %eax popq %rbp .cfi_def_cfa 7, 8 ret .cfi_endproc.LFE0: .size myadd, .-myadd .globl main .type main, @functionmain:.LFB1: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 subq $16, %rsp movl $110, -12(%rbp) movl $119, -8(%rbp) movl -8(%rbp), %edx movl -12(%rbp), %eax movl %edx, %esi movl %eax, %edi call myadd movl %eax, -4(%rbp) movl $0, %eax leave .cfi_def_cfa 7, 8 ret .cfi_endproc.LFE1: .size main, .-main .ident "GCC: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609" .section .note.GNU-stack,"",@progbits g++编译simple.cpp文件123456789101112131415// simple.cppint myadd(int a, int b)&#123; return a + b;&#125;int main()&#123; int a = 110; int b = 119; int c = myadd(a, b); return 0;&#125; g++ simple.cpp -S 生成汇编代码文件simple.s内容 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455 .file "simple.cpp" .text .globl _Z5myaddii .type _Z5myaddii, @function_Z5myaddii:.LFB0: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 movl %edi, -20(%rbp) movl %esi, -24(%rbp) movl $0, -4(%rbp) movl -20(%rbp), %edx movl -24(%rbp), %eax addl %edx, %eax movl %eax, -4(%rbp) movl -4(%rbp), %eax popq %rbp .cfi_def_cfa 7, 8 ret .cfi_endproc.LFE0: .size _Z5myaddii, .-_Z5myaddii .globl main .type main, @functionmain:.LFB1: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 subq $16, %rsp movl $110, -12(%rbp) movl $119, -8(%rbp) movl $0, -4(%rbp) movl -8(%rbp), %edx movl -12(%rbp), %eax movl %edx, %esi movl %eax, %edi call _Z5myaddii movl %eax, -4(%rbp) movl $0, %eax leave .cfi_def_cfa 7, 8 ret .cfi_endproc.LFE1: .size main, .-main .ident "GCC: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609" .section .note.GNU-stack,"",@progbits 虽然只有几行代码，可是生成汇编文件之后变成了50多行，我们只需要关注 myadd() 这个函数编译之后变成了什么就可以了，汇编代码虽然不好读，但是查找一个函数名应该没问题的，对照着上面的代码我们发现，myadd() 这个函数通过 gcc 编译之后的函数名还是 myadd，而通过 g++ 编译之后的函数名变成了 _Z5myaddii，可以明显感觉到最后的两个字母 i 代表的是参数 int，使用 c++filt 命令还原如下： 12$ c++filt _Z5myaddiimyadd(int, int) C++函数重载编译后的函数名对比我们还是在刚才的代码的基础上增加一个参数类型不同的 myadd 函数，修改后的代码如下： 1234567891011121314151617int myadd(int a, int b)&#123; return a + b;&#125;float myadd(float a, float b)&#123; return a + b;&#125;int main()&#123; int c = myadd(110, 119); float d = myadd(52.0f, 13.14f); return 0;&#125; g++ simple.cpp -S 生成汇编代码文件simple.s内容为： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879 .file "simple.cpp" .text .globl _Z5myaddii .type _Z5myaddii, @function_Z5myaddii:.LFB0: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 movl %edi, -4(%rbp) movl %esi, -8(%rbp) movl -4(%rbp), %edx movl -8(%rbp), %eax addl %edx, %eax popq %rbp .cfi_def_cfa 7, 8 ret .cfi_endproc.LFE0: .size _Z5myaddii, .-_Z5myaddii .globl _Z5myaddff .type _Z5myaddff, @function_Z5myaddff:.LFB1: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 movss %xmm0, -4(%rbp) movss %xmm1, -8(%rbp) movss -4(%rbp), %xmm0 addss -8(%rbp), %xmm0 popq %rbp .cfi_def_cfa 7, 8 ret .cfi_endproc.LFE1: .size _Z5myaddff, .-_Z5myaddff .globl main .type main, @functionmain:.LFB2: .cfi_startproc pushq %rbp .cfi_def_cfa_offset 16 .cfi_offset 6, -16 movq %rsp, %rbp .cfi_def_cfa_register 6 subq $16, %rsp movl $119, %esi movl $110, %edi call _Z5myaddii movl %eax, -8(%rbp) movss .LC0(%rip), %xmm1 movss .LC1(%rip), %xmm0 call _Z5myaddff movd %xmm0, %eax movl %eax, -4(%rbp) movl $0, %eax leave .cfi_def_cfa 7, 8 ret .cfi_endproc.LFE2: .size main, .-main .section .rodata .align 4.LC0: .long 1095908721 .align 4.LC1: .long 1112539136 .ident "GCC: (Ubuntu 5.4.0-6ubuntu1~16.04.12) 5.4.0 20160609" .section .note.GNU-stack,"",@progbits 这次一共3个函数，生成的汇编代码更长，但是我们一眼就能看见汇编代码中包含 _Z5myaddii 和 _Z5myaddff 两个函数，这就是函数重载的产物，两个参数类型不同的同名函数编译之后生成了不同的名字，_Z5myaddff 函数末尾的两个 f 应该指的就是参数类型 float。 使用c++filt定位问题示例c++filt的作用就是还原函数名字，它可以帮我们查找动态链接库中缺少的函数，还原崩溃堆栈中一大串的函数名字母等等，下面来看一个崩溃堆栈的例子，代码内容尽量简写，只为了说明问题，现实情况可能要复杂的多。 首先定义一个打印函数堆栈的函数，参考之前的总结《linux环境下C++代码打印函数堆栈调用情况》，代码如下： 123456789101112131415161718192021222324252627282930#include &lt;execinfo.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;signal.h&gt;#include &lt;iostream&gt;void show_stack(int nSignal)&#123; static const int MAX_STACK_FRAMES = 12; void *pStack[MAX_STACK_FRAMES]; static char szStackInfo[1024 * MAX_STACK_FRAMES]; char ** pStackList = NULL; int frames = backtrace(pStack, MAX_STACK_FRAMES); pStackList = backtrace_symbols(pStack, frames); if (NULL == pStackList) return; strcpy(szStackInfo, "stack traceback:\n"); for (int i = 0; i &lt; frames; ++i) &#123; if (NULL == pStackList[i]) break; strncat(szStackInfo, pStackList[i], 1024); strcat(szStackInfo, "\n"); &#125; std::cout &lt;&lt; szStackInfo; // 输出到控制台，也可以打印到日志文件中&#125; 再写一段隐藏着崩溃问题的代码： 12345678910111213141516171819202122232425262728293031323334353637383940#include &lt;string&gt;class CTest&#123;public: const std::string&amp; get_string() &#123;return s;&#125; void set_string(const std::string&amp; str) &#123;s = str;&#125;private: std::string s;&#125;;void foo(float z)&#123; int *p = nullptr; *p = 110; std::cout &lt;&lt; z;&#125;void test(std::string str)&#123; CTest* pTest = new CTest(); pTest-&gt;set_string("20200517"); const std::string&amp; s = pTest-&gt;get_string(); delete pTest; std::cout &lt;&lt; str &lt;&lt; std::endl; if (s == "20200517") foo(13.14);&#125;void func(int a, int b)&#123; std::string s = std::to_string(a) + std::to_string(b); test(s);&#125;int main()&#123; signal(SIGSEGV, show_stack); func(250, 520); return 0;&#125; 编译运行，果然崩溃了： 12345678910111213$ g++ simple.cpp --std=c++11$ ./a.outstack traceback:./a.out() [0x401aff]/lib/x86_64-linux-gnu/libc.so.6(+0x354b0) [0x7fd5f98b54b0]/lib/x86_64-linux-gnu/libc.so.6(+0x16eff6) [0x7fd5f99eeff6]/usr/lib/x86_64-linux-gnu/libstdc++.so.6(_ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE7compareEPKc+0x3a) [0x7fd5f9f9145a]./a.out() [0x4022b6]./a.out() [0x401d30]./a.out() [0x401e27]./a.out() [0x401ed8]/lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf0) [0x7fd5f98a0830]./a.out() [0x4019f9] 这时崩溃的堆栈中发现了一个特别长的函数 _ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE7compareEPKc，使用 c++filt 命令来还原函数： 12$ c++filt _ZNKSt7__cxx1112basic_stringIcSt11char_traitsIcESaIcEE7compareEPKcstd::__cxx11::basic_string&lt;char, std::char_traits&lt;char&gt;, std::allocator&lt;char&gt; &gt;::compare(char const*) const 从函数名来看是一个与字符串相关的 compare 函数，查看代码发现是 s == &quot;20200517&quot; 这一句的问题，所以说能确切的知道函数名对我们查找问题来说还是挺有帮助的。 总结 c++filt 命令可以还原 C++ 为实现函数重载采用 name mangling 搞出来的奇奇怪怪的函数名 注册信号回调函数方式：signal(SIGSEGV, show_stack);，SIGSEGV代表无效的内存引用 注意 C 语言和 C++ 在编译后函数命名方式的不同，C 语言不支持严格意义的重载，C++支持 阳光、空气、水，这些真的是好东西，当你真的快要失去它们才意识的到的话就有些晚了…]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>linux</tag>
        <tag>工具</tag>
        <tag>c++filt</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[汇编指令入门级整理]]></title>
    <url>%2Fblog%2F2020%2F05%2F09%2F%E6%B1%87%E7%BC%96%E6%8C%87%E4%BB%A4%E5%85%A5%E9%97%A8%E7%BA%A7%E6%95%B4%E7%90%86%2F</url>
    <content type="text"><![CDATA[前言我们大都是被高级语言惯坏了的一代，源源不断的新特性正在逐步添加到各类高级语言之中，汇编作为最接近机器指令的低级语言，已经很少被直接拿来写程序了，不过我还真的遇到了一个，那是之前的一个同事，因为在写代码时遇到了成员函数权限及可见性的问题，导致他无法正确调用想执行的函数，结果他就开始在 C++ 代码里嵌入汇编了，绕过了种种限制终于如愿以偿，但是读代码的我们傻眼了… 因为项目是跨平台的，代码推送的 Linux 上编译的时候他才发现，汇编代码的语法在 Linux 和 Windows 上居然是不一样的，结果他又用一个判断平台的宏定义“完美”的解决了，最终这些代码肯定是重写了啊，因为可读性太差了，最近在学习左值、右值、左引用和右引用的时候，总是有人用程序编译生成的中间汇编代码来解释问题，看得我迷迷糊糊，所以决定熟悉一下简单的汇编指令，边学习边记录，方便今后忘记了可以直接拿来复习。 什么是汇编语言汇编语言是最接近机器语言的编程语言，引用百科中的一段话解释为： 汇编语言（assembly language）是一种用于电子计算机、微处理器、微控制器或其他可编程器件的低级语言，亦称为符号语言。在汇编语言中，用助记符代替机器指令的操作码，用地址符号或标号代替指令或操作数的地址。汇编语言又被称为第二代计算机语言。 汇编语言产生的原因对于绝大多数人来说，二进制程序是不可读的，当然有能人可以读，比如第一代程序员，但这类人快灭绝了，直接看二进制不容易看出来究竟做了什么事情，比如最简单的加法指令二进制表示为 00000011，如果它混在一大串01字符串中就很难把它找出来，所以汇编语言主要就是为了解决二进制编码的可读性问题。 汇编与二进制的关系换句话来说，汇编语言就是把给机器看的二进制编码翻译成人话，汇编指令是机器指令的助记符，与机器指令是一一对应的关系，是一种便于阅读和记忆的书写格式。有效地解决了机器指令编写程序难度大的问题，并且使用编译器，可以很方便的把汇编程序转译成机器指令程序，比如之前提到的 00000011 加法指令，对应的汇编指令是 ADD，在调用汇编器时就会把 ADD 翻译成 00000011。 寄存器说到汇编指令不得不提到寄存器，寄存器本身是用来存数据的，因为 CPU 本身只负责逻辑运算，数据需要单独储存在其他的地方，但是对于不熟悉寄存器的人来说会有疑惑，数据不是存在硬盘上吗？或者说数据不是存在内存中吗？这些想法都没错，那么寄存器是用来做什么的呢？ 寄存器作用其实硬盘、内存都是用来存储数据的，但是 CPU 的运算速度远高于内存的读写速度，更不用说从硬盘上取数据了，所以为了避免被拖慢速度影响效率，CPU 都自带一级缓存和二级缓存，一些 CPU 甚至增加了三级缓存，从这些缓存中读写数据要比内存快很多，但是还是无法使用飞速运转的 CPU，所以才会有寄存器的存在。 寄存器不是后来增加的，在最初的计算中就已经设计出来，相比而言，多级缓存出现的更晚一些，通常那些最频繁读写的数据都会被放在寄存器里面，CPU 优先读写寄存器，再通过寄存器、缓存跟内存来交换数据，达到缓冲的目的，因为可以通过名称访问寄存器，这样访问速度是最快的，因此也被称为零级缓存。 存取速度比较通过上面的叙述我们可以知道存取速度从高到低分别是: 寄存器 &gt; 1级缓存 &gt; 2级缓存 &gt; 3级缓存 &gt; 内存 &gt; 硬盘，关于它们的存取速度，举个例子很容易就能明白了，比如我们做菜（CPU工作）时，取手中（寄存器）正拿着的肉和蔬菜肯定是最快的，如果没有就需要把案板上（1级缓存）处理好的菜拿过来，如果案板上没有就在更远一点的洗菜池（2级缓存）中找一找，还没找到的话就要到冰箱（3级缓存）中看一看了，这时发现家里真没有，那去楼下的菜店（内存）去买点吧，转了一圈发现没有想要的，最后还是开车去农贸市场（硬盘）买吧。 通过上面这个例子应该能明白它们的速度关系了，既然缓存这么快，为什么不用缓存代替内存，或者将2、3级缓存都换成1级缓存呢？这里边有一个成本问题，速度越快对应着价格越高，如果你买过机械硬盘和固态硬盘应该很容易就理解了。 寄存器分类常用的 x86 CPU 寄存器有8个：EAX 、EBX、ECX、EDX、EDI、ESI、EBP、ESP，据说现在寄存器总数已经超过100个了，等我找到相关资料再来补充，上面这几个寄存器是最常用的，这些名字也常常出现在汇编的代码中。 我们常说的32位、64位 CPU 是指数据总线的宽度或根数，而寄存器是暂存数据和中间结果的单元，因此寄存器的位数也就是处理数据的长度与数据总线的根数是相同的，所以32位 CPU 对应的寄存器也应该是32位的。 常用寄存器用途上面提到大8个寄存器都有其特定的用途，我们以32位 CPU 为例简单说明下这些寄存器的作用，整理如下表： 寄存器 含义 用途 包含寄存器 EAX 累加(Accumulator)寄存器 常用于乘、除法和函数返回值 AX(AH、AL) EBX 基址(Base)寄存器 常做内存数据的指针, 或者说常以它为基址来访问内存. BX(BH、BL) ECX 计数器(Counter)寄存器 常做字符串和循环操作中的计数器 CX(CH、CL) EDX 数据(Data)寄存器 常用于乘、除法和 I/O 指针 DX(DH、DL) ESI 来源索引(Source Index)寄存器 常做内存数据指针和源字符串指针 SI EDI 目的索引(Destination Index)寄存器 常做内存数据指针和目的字符串指针 DI ESP 堆栈指针(Stack Point)寄存器 只做堆栈的栈顶指针; 不能用于算术运算与数据传送 SP EBP 基址指针(Base Point)寄存器 只做堆栈指针, 可以访问堆栈内任意地址, 经常用于中转 ESP 中的数据, 也常以它为基址来访问堆栈; 不能用于算术运算与数据传送 BP 寄存器EAX、AX、AH、AL的关系在上面的图标中每个常用寄存器后面还有其他的名字，它们是同一个寄存器不同用法下的不同名字，比如在32位 CPU 上，EAX是32位的寄存器，而AX是EAX的低16位，AH是AX的高8位，而AL是AX的低8位，它们的对照关系如下: 1234500000000 00000000 00000000 00000000|===============EAX===============|---4个字节 |======AX=======|---2个字节 |==AH===|-----------1个字节 |===AL==|---1个字节 汇编语言指令终于说到汇编常用指令了，因为 linux 和 windows 下的汇编语法是有些不同的，所以下面我们先通过 windows 下的汇编指令来简单学习一下，后续再来比较两者的不同。 数据传送指令 指令 名称 示例 备注 MOV 传送指令 MOV dest, src 将数据从src移动到dest PUSH 进栈指令 PUSH src 把源操作数src压入堆栈 POP 出栈指令 POP desc 从栈顶弹出字数据到dest 算术运算指令 指令 名称 示例 备注 ADD 加法指令 ADD dest, src 在dest基础上加src SUB 减法指令 SUB dest, src 在dest基础上减src INC 加1指令 INC dest 在dest基础上加1 DEC 减1指令 DEC dest 在dest基础上减1 逻辑运算指令 指令 名称 示例 备注 NOT 取反运算指令 NOT dest 把操作数dest按位取反 AND 与运算指令 AND dest, src 把dest和src进行与运算之后送回dest OR 或运算指令 OR dest, src 把dest和src进行或运算之后送回dest XOR 异或运算 XOR dest, src 把dest和src进行异或运算之后送回dest 循环控制指令 指令 名称 示例 备注 LOOP 计数循环指令 LOOP label 使ECX的值减1，当ECX的值不为0的时候跳转至label，否则执行LOOP之后的语句 转移指令 指令 名称 示例 备注 JMP 无条件转移指令 JMP lable 无条件地转移到标号为label的位置 CALL 过程调用指令 CALL labal 直接调用label JE 条件转移指令 JE lable zf =1 时跳转到标号为label的位置 JNE 条件转移指令 JNE lable zf=0 时跳转到标号为label的位置 linux 和 windows 下汇编的区别前面说到 linux 和 windows 下的汇编语法是不同的，其实两种语法的不同和系统不同没有绝对的关系，一般在 linux 上会使用 gcc/g++ 编译器，而在 windows 上会使用微软的 cl 也就是 MSBUILD，所以产生不同的代码是因为编译器不同，gcc 下采用的是AT&amp;T的汇编语法格式，MSBUILD 采用的是Intel汇编语法格式。 差异 Intel AT&amp;T 引用寄存器名字 eax %eax 赋值操作数顺序 mov dest, src movl src, dest 寄存器、立即数指令前缀 mov ebx, 0xd00d movl $0xd00d, %ebx 寄存器间接寻址 [eax] (%eax) 数据类型大小 操作码后加后缀字母，“l” 32位，“w” 16位，“b” 8位（mov dx, word ptr [eax]） 操作数前面加dword ptr， word ptr，byte ptr的格式 （movb %bl %al） 总结 汇编指令是机器指令的助记符，与机器指令是一一对应的 AT&amp;T的汇编语法格式和Intel汇编语法格式的是不同的 常用寄存器：EAX 、EBX、ECX、EDX、EDI、ESI、EBP、ESP 存取速度从高到低分别是: 寄存器 &gt; 1级缓存 &gt; 2级缓存 &gt; 3级缓存 &gt; 内存 &gt; 硬盘 常用的汇编指令：mov、je、jmp、call、add、sub、inc、dec、and、or 如今的每分每秒都是人生，不要总想着将自然发生的事情拖到预定的时刻才进行~]]></content>
      <categories>
        <category>ASM</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>汇编</tag>
        <tag>linux</tag>
        <tag>windows</tag>
        <tag>asm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11在左值引用的基础上增加右值引用]]></title>
    <url>%2Fblog%2F2020%2F05%2F05%2FC-11%E5%9C%A8%E5%B7%A6%E5%80%BC%E5%BC%95%E7%94%A8%E7%9A%84%E5%9F%BA%E7%A1%80%E4%B8%8A%E5%A2%9E%E5%8A%A0%E5%8F%B3%E5%80%BC%E5%BC%95%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言右值引用这个词是最开始是学习 easylogging++ 这个日志开源项目的时候遇到的，当时遇到 &amp;&amp; 这样的写法先是一愣，还有这种写法？难道是引用的地址？结果查询资料才明白这叫做右值引用。 右值引用的出现其实右值引用是在 C++11 时增加的新内容，在此之前，引用是没有左值和右值之分的，只存在一种引用，也就是后来 C++11 标准中的左值引用，而右值引用的提出主要是为了解决之前左值引用出现的一些尴尬的问题。 左值和右值说到右值引用需要先了解下左值和右值，这也是我自己学习的过程，之前在 《简单聊聊C/C++中的左值和右值》 这篇笔记中总结过，可以简单理解左值就是放在 = 左边，可以取到地址，可以被赋值的表达式，而右值通常是放在 = 右侧，不能取地址，只能被当成一个“值”的表达式。 右值引用的作用右值引用的出现并不是为了取代左值引用，也不是和左值引用形成对立，而是充分利用右值内容来减少对象构造和析构操作，以达到提高程序代码效率的目的。 也就是说增加右值引用这个特性是为了提高效率，之前的总结中也提到过，在 C++11 中还引入了 std::move() 函数，并用这个函数改写了 std::remove_if() 函数，这就是提高效率的例子。 使用 std::move() 函数意味着放弃所有权，对于一个左值，如果我们明确放弃对其资源的所有权，则可以通过 std::move() 来将其转为右值引用，放弃所有权的这个操作不一定都是方便的，比如 std::auto_ptr 这个第一代的智能指针，就是因为转移了所有权，使用起来不太方便，才在最新标准中被废弃的。但如果你明确要转移所有权，并且合理使用，有时可以有效的提高程序效率。 引用类型的对比在学习使用右值引用之前先复习一下左值引用，对比学习更有利于我们的记忆。 左值引用1234int i = 22;int&amp; j = i;j = 11; 上面这几行代码就是最常见左值引用的例子，变量 j 引用了变量 i 的存储位置，修改变量 j 就修改了变量 i 的值，但是如果引用一个值会怎么样呢？比如下面这行代码： 1int&amp; j = 22; 编译这行代码会得到一个编译错误： error: invalid initialization of non-const reference of type ‘int&amp;’ from an rvalue of type ‘int’ int&amp; j = 22; 像上面这种问题，可以使用常量引用来解决。 常量引用针对上面的编译错误，改成常量引用就可以通过编译了，就像这样： 1const int&amp; j = 22; 使用常量引用来引用数字常量22，可以编译通过是因为内存上产生了临时变量保存了22这个数据，这个临时变量是可以进行取地址操作的，因此变量 j 引用的其实是这个临时变量，相当于下面的这两句： 12const int temp = 22;const int &amp;j = temp; 看到这里我们发现常量引用可以解决引用常量的问题，那么为什么非得新增一个右值引用呢？那是因为使用常引用后，我们只能通过引用来读取数据，无法去修改数据，这在很多情况下是很不方便的。 右值引用常量引用可以使用右值引用来改写，改写之后可以正常编译，并且还可以进行修改： 1int&amp;&amp; j = 22; 这句代码有两个需要注意的点，第一是右值引用是 C++11 中才增加的，所以需要增加 --std=c++11 这个编译选项才能正常编译，第二是右值引用的两个地址符需要连着写成 &amp;&amp;, 如果中间有空格写成 &amp; &amp; 会被认为是引用的引用而导致编译错误，这是不符合语法的。 右值引用的示例前面对引用类型进行了对比，但是还没有发现右值引用的好处，接下来用一个例子来展示一下增加右值引用之前的写法，和使用右值引用的写法，通过对比来了解一下右值引用究竟有什么好处。 我们来实现一个自定义缓冲区，先使用最常见的方法来实现拷贝构造函数和拷贝赋值函数，简单实现如下，功能不太完整，但是可以说明右值引用的作用： 常量引用实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273#include &lt;iostream&gt;#include &lt;cstring&gt;using namespace std;class CBuffer&#123;public: // 构造函数 CBuffer(int size = 1024): m_size(size) &#123; cout &lt;&lt; "CBuffer(int)" &lt;&lt; endl; m_buffer = new char[size]; &#125; // 析构函数 ~CBuffer() &#123; cout &lt;&lt; "~CBuffer()" &lt;&lt; endl; delete[] m_buffer; m_buffer = nullptr; m_size = 0; &#125; // 拷贝构造 CBuffer(const CBuffer &amp;origin): m_size(origin.m_size) &#123; cout &lt;&lt; "CBuffer(const CBuffer&amp;)" &lt;&lt; endl; m_buffer = new char[origin.m_size]; memcpy(m_buffer, origin.m_buffer, m_size); &#125; // 赋值重载 CBuffer&amp; operator=(const CBuffer &amp;origin) &#123; cout &lt;&lt; "operator=(const CBuffer&amp;)" &lt;&lt; endl; if (this == &amp;origin) return *this; delete[] m_buffer; m_size = origin.m_size; m_buffer = new char[origin.m_size]; memcpy(m_buffer, origin.m_buffer, m_size); return *this; &#125; int get_size() &#123; return m_size; &#125; static CBuffer gen_buffer(const int size) &#123; CBuffer temp_buffer(size); return temp_buffer; &#125;private: char *m_buffer; int m_size;&#125;;int main()&#123; CBuffer b1; CBuffer b2(b1); cout &lt;&lt; "b1.size = " &lt;&lt; b1.get_size() &lt;&lt; endl; cout &lt;&lt; "b2.size = " &lt;&lt; b2.get_size() &lt;&lt; endl; b2 = CBuffer::gen_buffer(100); return 0;&#125; 运行结果是： CBuffer(int)CBuffer(const CBuffer&amp;)b1.size = 1024b2.size = 1024CBuffer(int)operator=(const CBuffer&amp;)~CBuffer()~CBuffer()~CBuffer() 这个例子不具有实用性，只为了说明问题，CBuffer 这个类定义为了拷贝构造函数并且重载了 = 运算符，两个函数参数均使用常量引用的类型，这就是一般的写法。 但是这样实现有一个问题，因为参数是常量引用，所以没办法修改原对象的值，我们看到拷贝构造和赋值重载两个函数中都有申请空间和拷贝的操作，这种操作在操作内存较大的对象是比较耗时，所以应该尽量避免，我们想到可以使用新对象的指针指向旧对象指针来解决，这样就不用拷贝了，可是这样修改会导致两个对象指向同一块内存，这个问题需要解决。 改为左值引用实现报错如果两个对象指向同一块内存，那么对象在析构的时候就会将一块内存释放两次导致奔溃，这时考虑在拷贝构造或者赋值重载时，将原来对象的指针设置成空就可以了，但是参数是常量没有办法修改啊，那我们将 const 关键字去掉试试，将两个函数改成这样： 1234567891011121314151617181920212223// 拷贝构造CBuffer(CBuffer &amp;origin): m_size(origin.m_size)&#123; cout &lt;&lt; "CBuffer(CBuffer&amp;)" &lt;&lt; endl; m_buffer = origin.m_buffer; origin.m_buffer = nullptr; origin.m_size = 0;&#125;// 赋值重载CBuffer&amp; operator=(CBuffer &amp;origin)&#123; cout &lt;&lt; "operator=(CBuffer&amp;)" &lt;&lt; endl; if (this == &amp;origin) return *this; m_buffer = origin.m_buffer; origin.m_buffer = nullptr; origin.m_size = 0; return *this;&#125; 看起来没有什么问题，但是编译的时候会报错： error: invalid initialization of non-const reference of type ‘CBuffer&amp;’ from an rvalue of type ‘CBuffer’ b2 = CBuffer::gen_buffer(100); ^note: initializing argument 1 of ‘CBuffer&amp; CBuffer::operator=(CBuffer&amp;)’ CBuffer&amp; operator=(CBuffer &amp;origin) 这个错误是什么意思呢？其实说的就是在调用 CBuffer::gen_buffer(100); 函数时，会产生一个临时对象，这个临时对象在赋值给 b2 是会调用CBuffer&amp; operator=(CBuffer &amp;origin) 函数，但是这个函数的参数是一个左值引用类型，而临时对象是一个右值，无法绑定到左值引用上，所以报错了。 还有拷贝构造函数也是有相同的问题，当写出类似 b2 = CBuffer(CBuffer(1000)) 类型会产生临时对象的语句时，同样会因为左值引用不能绑定到右值上而报错，这时候就要请出右值引用了。 改为右值引用实现对于赋值重载函数，我们使用右值引用将其改写为: 12345678910111213// 赋值重载CBuffer&amp; operator=(CBuffer &amp;&amp;origin)&#123; cout &lt;&lt; "operator=(CBuffer&amp;&amp;)" &lt;&lt; endl; if (this == &amp;origin) return *this; m_buffer = origin.m_buffer; origin.m_buffer = nullptr; origin.m_size = 0; return *this;&#125; 这时可以正常通过编译，并且只是修改了指针的指向，并没有申请和拷贝另外一份内存。 std::move() 函数如果我们将拷贝构造函数的参数也改成右值引用的形式： 123456789// 拷贝构造CBuffer(CBuffer &amp;&amp;origin): m_size(origin.m_size)&#123; cout &lt;&lt; "CBuffer(CBuffer&amp;)" &lt;&lt; endl; m_buffer = origin.m_buffer; origin.m_buffer = nullptr; origin.m_size = 0;&#125; 编译时就会发现编译错误： error: use of deleted function ‘constexpr CBuffer::CBuffer(const CBuffer&amp;)’ CBuffer b2(b1); ^note: ‘constexpr CBuffer::CBuffer(const CBuffer&amp;)’ is implicitly declared as deleted because ‘CBuffer’ declares a move constructor or move assignment operator class CBuffer 其本质问题就是主函数中 CBuffer b2(b1); 这一句引起的，因为变量 b1 是一个左值，但是拷贝构造函数接受的是右值引用，所以类型不匹配导致了编译错误，这时可以使用 std::move() 函数改成这条语句为 CBuffer b2(std::move(b1)); 就可以正常编译运行了，运行结果为： CBuffer(int)CBuffer(CBuffer&amp;)b1.size = 0b2.size = 1024CBuffer(int)operator=(CBuffer&amp;&amp;)~CBuffer()~CBuffer()~CBuffer() 查看运行结果会发现 b1.size = 0，因为 b1 调用了 std::move() 函数，转移了资源的所有权，内部已经被“掏空”了，所以在明确所有权转移之后，不要再直接使用变量 b1 了。 万能引用听到这个名字就感觉很厉害，什么是万能引用，其实就是可以同时接受左值和右值的引用类型，但是这种完能引用只能发生在推导的情况下，下面给出了一个例子： 12345678910111213141516#include &lt;iostream&gt;using namespace std;template&lt;typename T&gt;void func(T&amp;&amp; val)&#123; cout &lt;&lt; val &lt;&lt; endl;&#125;int main()&#123; int year = 2020; func(year); func(2020); return 0;&#125; 这段代码中 T&amp;&amp; val 就是万能引用，因为是在模板中，类型需要推导，如果是在普通函数中 T&amp;&amp; val 这个形式就是右值引用。 左值引用和右值引用判定的函数文中多次提到左值和右值，可能刚学习这块内容的小伙伴会有些懵，其实 C++ 中提供了判定左值引用和右值引用的函数，头文件为 &lt;type_traits&gt;，函数名为 is_reference、 is_rvalue_reference、 is_lvalue_reference，看名字就可以知道他们的用途，看下面的例子就更清楚了。 12345678910111213141516171819202122232425#include &lt;iostream&gt;#include &lt;type_traits&gt;using namespace std;int main()&#123; int i = 22; int&amp; j = i; int&amp;&amp; k = 11; cout &lt;&lt; "i is_reference: " &lt;&lt; is_reference&lt;decltype(i)&gt;::value &lt;&lt; endl; cout &lt;&lt; "i is_lvalue_reference: " &lt;&lt; is_lvalue_reference&lt;decltype(i)&gt;::value &lt;&lt; endl; cout &lt;&lt; "i is_rvalue_reference: " &lt;&lt; is_rvalue_reference&lt;decltype(i)&gt;::value &lt;&lt; endl; cout &lt;&lt; "j is_reference: " &lt;&lt; is_reference&lt;decltype(j)&gt;::value &lt;&lt; endl; cout &lt;&lt; "j is_lvalue_reference: " &lt;&lt; is_lvalue_reference&lt;decltype(j)&gt;::value &lt;&lt; endl; cout &lt;&lt; "j is_rvalue_reference: " &lt;&lt; is_rvalue_reference&lt;decltype(j)&gt;::value &lt;&lt; endl; cout &lt;&lt; "k is_reference: " &lt;&lt; is_reference&lt;decltype(k)&gt;::value &lt;&lt; endl; cout &lt;&lt; "k is_lvalue_reference: " &lt;&lt; is_lvalue_reference&lt;decltype(k)&gt;::value &lt;&lt; endl; cout &lt;&lt; "k is_rvalue_reference: " &lt;&lt; is_rvalue_reference&lt;decltype(k)&gt;::value &lt;&lt; endl; return 0;&#125; 运行结果如下，满足返回1，否则返回0： i is_reference: 0i is_lvalue_reference: 0i is_rvalue_reference: 0j is_reference: 1j is_lvalue_reference: 1j is_rvalue_reference: 0k is_reference: 1k is_lvalue_reference: 0k is_rvalue_reference: 1 总结 右值引用的写法为 T&amp;&amp; val，两个地址符要挨在一起，在模板中被称为万能引用 注意左值引用和右值引用的使用区别，其实本质都是为了减少无效的拷贝 std::move() 函数会转移对象的所有权，转移操作之后将左值转为右值引用，原对象不可再直接使用 可以使用 is_reference、 is_rvalue_reference、 is_lvalue_reference 来判断引用类型 陪伴是最长情的告白，等待是最极致的思念五一离家返工了，心里有些不是滋味，为了家出来奋斗却将“家”抛在了身后，珍惜眼前人吧~]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>左值</tag>
        <tag>右值</tag>
        <tag>左值引用</tag>
        <tag>右值引用</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简单聊聊C/C++中的左值和右值]]></title>
    <url>%2Fblog%2F2020%2F04%2F24%2F%E7%AE%80%E5%8D%95%E8%81%8A%E8%81%8AC-C-%E4%B8%AD%E7%9A%84%E5%B7%A6%E5%80%BC%E5%92%8C%E5%8F%B3%E5%80%BC%2F</url>
    <content type="text"><![CDATA[前言为什么标题要写成简单聊聊，而不是写成什么“C++中左值与右值详解”或者现在很流行的“惊了！看了这一篇左值与右值讲解，他吊打了面试官”，其实带有详解这个词是需要勇气的，最起码要融会贯通之后才敢这么说吧，本来是学习右值引用的，结果涉及到了左值和右值，然后去了解他们历史发现也是有些混乱，操作中又经常涉及到运算符优先级，真是越学越乱了。 问题索性也把右值引用放一边，从头来看看这个左值和右值，其实我跟这两个词一点都不熟，最多就是在编译报错的提示框中看到他们，当然有时候也会看到他们的英文名字 lvalue 和 rvalue，这时候一般就是编译器开始抱怨了，说我写了什么它不能理解的东西，其实嘛，我自己都没完全理解，从现在开始边学边总结了，先展示一个常见报错： 1error: lvalue required as increment operand 这是什么意思，这么绕嘴，左值需要作为增长操作数，请说人话：自增操作需要一个可以赋值的变量作为操作数，需要变量就直说嘛，为什么要左值、右值的把人都绕蒙了。 历史渊源这个世界一直是在变化的，可能之前你一直引以为豪的经验大楼，转眼之间就会倾塌。关于左值和右值的历史，普遍的观点是最初来源于 C 语言，后来被引入到了 C++，但是关于左值和右值的含义和实现却在一直改变和完善，对于它的历史讲解发现一篇总结的比较好的文章 《C/C++ 左值和右值, L-value和R-value》。 这是2012年的一篇文章，文中给出了历史说明依据，最后还举了一些例子来说明 C 和 C++ 关于左值实现的不同，但是实际操作后你会发现，时间的车轮早已向前行进了一大截，文中提到的那些不同，在最新的 gcc 和 g++ 编译器上早已变得相同，文中提到的反例现在看来几乎没有意义了。 简单梳理下，左值的定义最早出现在 《The C Programming Language 》一书中，指的是引用一个对象，放在赋值表达式 = 左边的值。 后来在新的 C 语言标准中提到左值是赋值表达式 = 左边的值或者需要被改变的值，而等号的右边的值被称为右值。左值更好的表达为可以定位的值，而右值是一种表达数据的值，基于这个表述 L-value 可以理解为 locator value，代表可寻址，而 R-value 可以理解为 read value，代表可读取。 不过以上的新解，完全是人们为了理解左值、右值赋予的新含义，从历史发展来看，一开始左值和右值完全就是通过等号的左边和右边来命名的，只不过随着标准的完善和语言的发展、更替，虽然两个名字保留了下来，但是它们的含义却在逐步发生改变，与最初诞生时的 = 左右两边的值这个含义相比，已经相差很多了。 认识左值和右值关于左值右值有几条规则和特点，先列举在这里，后面可以跟随例子慢慢体会： 左值和右值都是指的表达式，比如 int a = 1 中的 a 是左值，++a 是左值, func() 也可能是左值，而 a+1 是右值， 110 也是一个右值。 左值可以放在 = 的左边，右值只能放在 = 的右边，这其中隐含的意思就是左值也能放在 = 的右边，但是右值不能放在 = 的左边。 左值可以取地址，代表着内存中某个位置，可以存储数据，右值仅仅是一个值，不能取地址，或者它看起来是一个变量，但它是临时的无法取地址，例如一个函数的非引用的值返回。 以上规则从定义来看一点也不严谨，比如一个常量定义是可以赋值，后面就不行了，它也可以取地址，但是不能赋值的它到底是左值还是右值，这点其实不用纠结，心里知道这个情况就可以了。 再比如一个普通变量，它原本是一个左值，当用它给其他变量赋值的时候，它又化身为一个右值，这时它也可以取地址，好像与上面的说法相违背了，但是仔细想想真的是这样吗？它只是临时化身为右值，其实是一个左值，所以才可以取地址的。 其实你如果不做学术研究、不斤斤计较，那么完全可以把能够赋值的表达式作为左值，然后把左值以外的表达式看成右值，如果你不熟悉解左值和右值可能根本不会影响你平时的工作和学习，但是了解它有助于我们深入理解一些内置运算符和程序执行过程，以及在出现编译错误的时候及时定位问题。 具体的示例最简单的赋值语句1int age = 18; 这个赋值语句很简单，= 作为分界线，左边的 age 是左值，可以被赋值，可以取地址，它其实就是一个表达式，代表一个可以存储整数的内存地址；右边的 18 也是一个表达式，明显只能作为右值，不能取地址。 118 = age; 这个语句在编译时会提示下面的错误： 1error: lvalue required as left operand of assignment 错误提示显示：赋值语句的左边需要一个左值，显然 18 不能作为左值，它不代表任何内存地址，不能被改变。 如果程序中的表达式都这么简单就不需要纠结了，接着我们往下看一些复杂点的例子。 自增自减运算1++age++; 第一眼看到这个表达式，你感觉它会怎样运算，编译一下，你会发现编译失败了，错误如下： error: lvalue required as increment operand 加个括号试试： 1++(age++) 编译之后会出现相同的错误： error: lvalue required as increment operand 再换一种加括号的方式再编译一次： 1(++age)++ 这次成功编译了，并且输出值之后发现 age 变量增加了两次。 先不考虑左值右值的问题，我们可以从这个例子中发现自增运算的优先级，后置自增 age++ 的优先级要高于前置自增 ++age 的优先级。 现在回过头来看看之前的编译错误，为什么我们加括号改变运算顺序之后就可以正常执行了呢？这其实和自增运算的实现有关。 前置自增前置自增的一般实现，是直接修改原对象，在原对象上实现自增，然后将原对象以引用方式返回： 12345UPInt&amp; UPInt::operator++()&#123; *this += 1; // 原对象自增 return *this; // 返回原对象&#125; 这里一直操作的是原对象，返回的也是原对象的引用，所以前置自增表达式的结果是左值，它引用的是原对象之前所占用的内存。 后置自增后置自增的一般实现，是先将原对象的数据存储到临时变量中，接着在原对象上实现自增，然后将临时变量以只读的方式返回： 123456const UPInt UPInt::operator++(int)&#123; UPInt oldValue = *this; // 将原对象赋值给临时变量 ++(*this); // 原对象自增 return oldValue; // 返回临时变量&#125; 这里返回的是临时变量，在函数返回后就被销毁了，无法对其取地址，所以后置自增表达式的结果是右值，不能对其进行赋值。 所以表达式 ++age++; 先进行后置自增，然后再进行前置自增就报出编译错误了，因为不能修改右值，也不能对右值进行自增操作。 自增表达式赋值前面说到前置自增表达式是一个左值，那能不能对其赋值呢？当然可以！试试下面的语句： 1++age = 20; 这条语句是可以正常通过编译的，并且执行之后 age 变量的值为 20。 函数表达式函数可以作为左值吗？带着这个疑问我们看一下这个赋值语句： 1func() = 6; 可能有些同学会有疑问，这是正常的语句吗？其实它是可以正常的，只要 func() 是一个左值就可以，怎么才能让他成为一个左值呢，想想刚才的前置自增运算可能会给你启发，要想让他成为左值，它必须代表一个内存地址，写成下面这样就可以了。 1234567891011int g;int&amp; func()&#123; return g;&#125;int main()&#123; func() = 100;&#125; 函数 func() 返回的是全局变量 g 的引用，变量 g 是一个可取地址的左值，所以 func() 表达式也是一个左值，对其赋值后就改变了全局变量 g 的值。 那么我们注意到这里 func() 函数返回的是全局变量的引用，如果是局部变量会怎么样呢？ 12345678910int&amp; func()&#123; int i = 101; return i;&#125;int main()&#123; func() = 100;&#125; 上面的代码编译没有错误，但是会产生一个警告，提示返回了局部变量的引用: 1warning: reference to local variable ‘i’ returned [-Wreturn-local-addr] 运行之后可就惨了，直接显示段错误： 1Segmentation fault (core dumped) 改为局部变量之后，func() 函数虽然返回了一个值，但是这个值是一个临时值，函数返回之后该值被销毁，对应的内存空间也不属于它了，所以在最后赋值的时候才会出现段错误，就和我们访问非法内存是产生的错误时一样的。 总结 可以被赋值的表达式是左值，左值可以取地址。 右值应该是一个表示值的表达式，不是左值的表达式都可以看成是右值 后置自增操作符的优先级要高于前置自增操作符，它们是按照从右向左结合的 关于左值和右值的知识点还有很多，后续想到了再补充，我也是边学边总结，如果有错误也欢迎小伙伴们及时指出，我会及时改正的 时刻静下来想想当初为什么出发，不要在现实的汪洋中偏离航向]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>左值</tag>
        <tag>右值</tag>
        <tag>lvalue</tag>
        <tag>rvalue</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[.bat批处理（九）：替换带有等号=的字符串的子串]]></title>
    <url>%2Fblog%2F2020%2F04%2F18%2Fbat%E6%89%B9%E5%A4%84%E7%90%86%EF%BC%88%E4%B9%9D%EF%BC%89%EF%BC%9A%E6%9B%BF%E6%8D%A2%E5%B8%A6%E6%9C%89%E7%AD%89%E5%8F%B7-%E7%9A%84%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9A%84%E5%AD%90%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[前言今天写这篇记录要解决的问题来源于最近一名读者的提问，之前写过一篇名为《.bat批处理（六）：替换字符串中匹配的子串》的总结文章，结果有读者在评论区提问说，如果想要替换的子串中包含等号 =，那么就无法替换了，问有没有什么办法可以解决。遇到这个问题的第一感觉应该挺好处理的吧，如果批处理程序在替换操作中认为等号 = 比较特殊，那就加个转义字符应该就可以了，但事实却证明这种想法有些天真了。 在尝试多次失败之后，我意识到事情远没有想象的那么简单，开始在网上寻找解决方案，结果有些让人意外，绝大多数人都说这是 SET 命令的执行规则决定的，无法实现这种需求。当要替换的子串中包含 = 时，第一个 = 就会被认为是替换语法中的 =，进而导致无法得到正确的结果，即使是使用转义字符都无法完成正确替换，加入的转义字符会影响匹配，导致替换失败。还有一些人建议用其他工具来完整这种需求，比如记事本的替换功能 O(∩_∩)O。 遇到的问题看了上面的叙述，可能有些小伙伴对我所说的问题还没有太直观的认识，接下来我们举个例子来说一下这个问题究竟是怎样产生的。 0x00 带有 = 的字符串首先需要被替换的字符串中要包含等号，我们来定义一个这样的变量： 1set STR=abcdo=ocar12a=ajdjko=ot 变量的名字是 STR，变量的值是 abcdo=ocar12a=ajdjko=ot，其中包含了三个 =。 0x01 带有 = 的想要被替换的子串确定一下我们想要替换的子串 o=o，假如我们想把它替换成字母 A，按照一般的替换规则X:Y=Z，在 X 串中寻找到 Y 串之后把它替换成 Z 串，实现的代码如下： 1234567@echo offset STR=abcdo=ocar12a=ajdjko=otset RESULT=%STR:o=o=A%echo %RESULT%pause &gt; nul 运行之后的结果是： abcdo=A=o=Acar12a=ajdjko=A=o=At 和我们想法不一样，我们本来想把 o=o 替换成 A，但是从结果来看应该是把 o 替换成了 o=A，原因就是我们选择的被替换中的子串 o=o 包含一个 =，而这个 = 被当成了替换语法 X:Y=Z 中的 =，所以就不对了。 0x02 尝试用转义字符来处理很多语言中都有转义字符，比如 Markdown 语法中的反斜杠 \，在 Markdown 语法中被星号 * 包裹的文字是倾斜的，但是如果想正常的输出一个 * 怎么办呢？就需要在 * 前面加一个反斜杠 \，变成 \*，这样 * 原本的倾斜文字的作用就被转义了，变成了一个普通的输出字符。 在批处理中也有转义字符的概念，它就是 ^，我们知道在批处理中 &gt;、| 等符号都是有特殊用处的，所以不能简单的输出，比如 echo &gt; 是无法输出一个大于号的，要写成 echo ^&gt; 才能正常输出一个 &gt; 符号。 我们就利用这个转义字符来告诉替换命令，被替换的子串中的 = 是一个普通字符，不能作为替换规则的一部分，所以被替换的子串写成了 o^=o，我们实现下面的代码，看看能不能达到目的： 1234567@echo offset STR=abcdo=ocar12a=ajdjko=otset RESULT=%STR:o^=o=A%echo %RESULT%pause &gt; nul 运行之后结果如下： abcdo=ocar12a=ajdjko=ot 与替换前对比发现没有任何变化，看来转义字符的想法没能帮助我们解决问题，还是想想其他的办法吧。 稳扎稳打的解决方案既然 = 这么特殊，我们就先想办法干掉等号，直接替换的方式不好使，我们可以一个字符一个字符的判断啊，虽然麻烦一点，但是解决问题才是最重要的。 既然要一个个的字符去判断，就需要遍历原字符串，最简单的可以使用字符串分割啊，语法为 原串:~偏移,长度 就可以了，如果不太清楚可以参考一下 《.bat批处理（三）：变量声明、设置、拼接、截取》，截取第一个字符的语法是 原串:~0,1， 截取第二个字符的语法是 原串:~1,1，以此类推。 具体的思路就是我们先判断第一个字符，如果是 = 就进行替换，如果不是 = 就放到结果字符串里，然后继续判断第二个字符进行操作，最后所有的字符处理一遍就完成了替换。 需要使用 goto 语句来写一个循环，代码逻辑比较简单，就是遍历所有字符，是 = 就替换，不是 = 就保留，假设我们先把 = 替换成 #，实现的代码如下： 123456789101112131415161718@echo offset STR=abcdo=ocar12a=ajdjko=otset CURSTR=%STR%set RESULT=:nextif "%CURSTR%" equ "" goto endset a=%CURSTR:~0,1%if "%a%" equ "=" (set RESULT=%RESULT%#) else (set RESULT=%RESULT%%a%)set CURSTR=%CURSTR:~1%goto next:endecho source string is %STR%echo result string is %RESULT%pause &gt; nul :next 是循环的入口，每次截取第一个字符，判断是 = 就在结果中拼接 # 字符，相当于完成了替换，如果字符不是 = ，就将字符直接拼接到结果中，操作之后将原串的第一个字符删除形成新的原串，然后再判断第一个字符，以此类推，直到原串为空，运行结果如下： source string is abcdo=ocar12a=ajdjko=otresult string is abcdo#ocar12a#ajdjko#ot 最终方案事情到了这里好像还没完，在实际操作中有些情况不是替换一个 =，往往是替换的内容中包含 =，上面将 = 替换成 # 不具有通用型，如果是一开始的请求，将 o=o替换成 A 就不能这样写了，就应该是每次判断3个字符了，写起来有些麻烦，批处理中没有获得字符串长度的函数，需要自己实现一个，如果是100个字符的被替换串，那代码就很难写了。 既然 = 都能被我们替换掉，肯定有办法实现上面我们这种将 o=o替换成 A 的要求，下面我们就列举一种通用的处理方法。 0x00 首先将 = 替换成一个原串中不可能出现的字符或者序列这步替换可能最后需要还原的，所以要求我们替换成的目标序列不能在原串中出现，比如我们上面把 = 替换成了 #， 如果原串中有 # 就会弄混了，不能确定是原来字符串中就存在的 #，还是由 = 变成的 #。 这个序列我们可以定义的变态一点，比如把 = 替换成 ###i#am#happy###，我们把它记作 α。 0x01 用这个不能出现序列替换我们之前要查找替换子串中的 =我们之前要查找替换的子串是 o=o，那么替换之后形成 o###i#am#happy###o，我们把它记作 β。 0x02 将第1步结束获得的替换结果作为原串，将其中的 β 替换成 A其实就是把第1步替换完结果作为原串，把其中的 o###i#am#happy###o 也就是原来的 o=o 替换成 A。 0x03 将第3步结果的子串作为原串，将其中的 α 替换为 =这一步就是处理那些虽然是 =，但是这个 = 不是我要替换的结果子串中的，所以要还原 代码实现步骤梳理清楚了，下面来写代码，按照步骤一步步写就可以了： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@echo offrem 第一步set CORESTR=###i#am#happy###set STR=abcdo=ocar12a=ajdjko=otset CURSTR=%STR%set RESULT1=:next1if "%CURSTR%" equ "" goto end1set a=%CURSTR:~0,1%if "%a%" equ "=" (set RESULT1=%RESULT1%%CORESTR%) else (set RESULT1=%RESULT1%%a%)set CURSTR=%CURSTR:~1%goto next1:end1echo source1 string is %STR%echo result1 string is %RESULT1%pause &gt; nulrem 第 2 步set CORESTR=###i#am#happy###set STR=o=oset CURSTR=%STR%set RESULT2=:next2if "%CURSTR%" equ "" goto end2set a=%CURSTR:~0,1%if "%a%" equ "=" (set RESULT2=%RESULT2%%CORESTR%) else (set RESULT2=%RESULT2%%a%)set CURSTR=%CURSTR:~1%goto next2:end2echo source2 string is %STR%echo result2 string is %RESULT2%pause &gt; nulrem 第3步，需要开启延迟变量setlocal ENABLEDELAYEDEXPANSIONset RESULT3=!RESULT1:%RESULT2%=A!echo result3 string is %RESULT3%pause &gt; nulrem 第4步set RESULT4=!RESULT3:%CORESTR%==!echo finally result is %RESULT4% 运行之后的结果为： source1 string is abcdo=ocar12a=ajdjko=otresult1 string is abcdo###i#am#happy###ocar12a###i#am#happy###ajdjko###i#am#happy###otsource2 string is o=oresult2 string is o###i#am#happy###oresult3 string is abcdAcar12a###i#am#happy###ajdjkAtfinally result is abcdAcar12a=ajdjkAt 这次终于替换成功了，o=o 被成功替换成了字母 A，代码中用到了延迟变量，主要是为了实现被替换字符串是变量的情况，不清楚延迟变量的用法可以简单查询一下，至此文章开头提出的问题我们就成功解决了，虽然路途有些坎坷。 总结 批处理程序中的 = 比较特殊，使用常规的 X:Y=Z 的语法不能替换包含 = 的子串 遇到上述情况可以将字符串切割，采用逐个字符比较的方式，将 = 替换成其他字符再进行后续操作 有时候也不必非得使用批处理来替换包含 = 的字符串，随便一个文本工具，比如记事本都可以文本进行替换 如果非得用命令解决，也可以使用从 linux 的 sed 命令移植到 windows 的 sed.exe 程序来很方便的进行替换 使用 sed 命令的语法是 echo abcdo=ocar12a=ajdjko=ot | sed -e &quot;s/o=o/A/g&quot;，一步就可以完成了文章开头的需求了 如果你暂时没有 sed.exe 程序，可以点击这个链接 sed.exe程序 下载，若不是在同一目录使用，记得将命令目录添加到环境变量中 时间慢慢地磨去了年少轻狂，也渐渐地沉淀了冷暖自知。]]></content>
      <categories>
        <category>bat</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++11中的时间库std::chrono（引发关于时间的思考）]]></title>
    <url>%2Fblog%2F2020%2F04%2F08%2FC-11%E4%B8%AD%E7%9A%84%E6%97%B6%E9%97%B4%E5%BA%93std-chrono%2F</url>
    <content type="text"><![CDATA[时间都去哪了？还没好好感受年轻就… 前言时间是宝贵的，我们无时无刻不在和时间打交道，这个任务明天下班前截止，你点的外卖还有5分钟才能送到，那个程序已经运行了整整48个小时，既然时间和我们联系这么紧密，我们总要定义一些术语来描述它，像前面说到的明天下班前、5分钟、48个小时都是对时间的描述，程序代码构建的程序世界也需要定义一些术语来描述时间。 今天要总结学习的是 std::chrono 库，它是 C++11 标准时从 boost 库中引入的，其实在 C++ 中还有一种 C 语言风格的时间管理体系，像我们常见的函数 time()、clock()、localtime()、mktime() 和常见的类型 tm、time_t、clock_t 都是 C 语言风格的时间管理体系。 std::chrono 这个库之前接触的不多，C++20 标准都出了，C++11 引入的这个库还没怎么用过，整天和 time()、 localtime()、 tm 打交道，最近工作中换了项目，代码中出现了 std::chrono 的使用，是时候好好学习总结一下了。 chrono 的概况 头文件 #include &lt;chrono&gt; 命名空间 std::chrono 这个库从 C++11 引入标准之后，每个版本都有所修改，不过核心内容变化不是太大，他定义了三种主要类型，分别是 durations、clocks 和 time points，以及围绕这些类型的一些工具函数和衍生的定义。 chrono 的核心内容duration这个模板类用来表示时间间隔，我们知道时间的基本单位是秒，这个类的对象所表示的时间间隔也是以秒为单位的，它的定义如下： 12template&lt;class Rep, class Period = std::ratio&lt;1&gt;&gt;class duration; Rep 表示一种数值类型，用来描述周期 Period 的数值类型，比如可以是 int、float 等，而 Period 的类型是 std::ratio，同样是一个模板类，实际表示的是一个有理数，像100、0、1/1000（千分之一）等等。 在 std 这个命名空间下有很多已经定义好的有理数，可以举几个常见的头文件 &lt;ratio&gt; 中的例子: 12345678nano std::ratio&lt;1, 1000000000&gt; // 十亿分之一micro std::ratio&lt;1, 1000000&gt; // 百万分之一milli std::ratio&lt;1, 1000&gt; // 千分之一centi std::ratio&lt;1, 100&gt; // 百分之一deci std::ratio&lt;1, 10&gt; // 十分之一deca std::ratio&lt;10, 1&gt; // 十hecto std::ratio&lt;100, 1&gt; // 百kilo std::ratio&lt;1000, 1&gt; // 千 比如我们想定义一个整数类型的100秒的时间间隔类型可以使用： 1typedef std::chrono::duration&lt;int, std::ratio&lt;100,1&gt;&gt; my_duration_type; 当然也可以简写成： 1typedef std::chrono::duration&lt;int, std::hecto&gt; my_duration_type; 如果我们想定义一个整数类型1分钟的时间间隔类型可以写成： 1typedef std::chrono::duration&lt;int, std::ratio&lt;60,1&gt;&gt; my_minute_type; 因为这种时、分、秒的时间表示在代码逻辑中很常用，所有在 std::chrono 命名空间下已经定义好了一些时间间隔类型: 123456std::chrono::nanoseconds duration&lt;/*signed integer type of at least 64 bits*/, std::nano&gt;std::chrono::microseconds duration&lt;/*signed integer type of at least 55 bits*/, std::micro&gt;std::chrono::milliseconds duration&lt;/*signed integer type of at least 45 bits*/, std::milli&gt;std::chrono::seconds duration&lt;/*signed integer type of at least 35 bits*/&gt;std::chrono::minutes duration&lt;/*signed integer type of at least 29 bits*/, std::ratio&lt;60&gt;&gt;std::chrono::hours duration&lt;/*signed integer type of at least 23 bits*/, std::ratio&lt;3600&gt;&gt; 另外还有一个很重要的成员函数 count()，用来获得指定的时间间隔对象中包含多少个时间周期，接下来可以写个例子理解一下，我们用 duration 这个模板类来表示一下5分钟和12小时，看看他应该怎么使用，对于5分钟你可以看成是 5 个 1 分钟或者 1 个 5 分钟，或者更变态你可以看成 2.5 个 2 分钟，而 12 小时一般会看成是 12个 1 小时，你当成 0.5 个 1 天也是可以的： 123456789101112131415161718192021222324#include &lt;chrono&gt;#include &lt;iostream&gt;int main()&#123; // 以下为5分钟表达 std::chrono::minutes minute1&#123;5&#125;; // 5个1分钟 std::chrono::duration&lt;int, std::ratio&lt;5*60, 1&gt;&gt; minute2&#123;1&#125;; // 1个5分钟 std::chrono::duration&lt;double, std::ratio&lt;2*60, 1&gt;&gt; minute3&#123;2.5&#125;; // 2.5个2分钟 std::cout &lt;&lt; "minutes1 duration has " &lt;&lt; minute1.count() &lt;&lt; " ticks\n" &lt;&lt; "minutes2 duration has " &lt;&lt; minute2.count() &lt;&lt; " ticks\n" &lt;&lt; "minutes3 duration has " &lt;&lt; minute3.count() &lt;&lt; " ticks\n"; // 一下为12小时表达 std::chrono::hours hours1&#123;12&#125;; // 12个1小时 std::chrono::duration&lt;double, std::ratio&lt;60*60*24, 1&gt;&gt; hours2&#123;0.5&#125;; // 0.5个1天 std::cout &lt;&lt; "hours1 duration has " &lt;&lt; hours1.count() &lt;&lt; " ticks\n" &lt;&lt; "hours2 duration has " &lt;&lt; hours2.count() &lt;&lt; " ticks\n"; // 使用 std::chrono::duration_cast&lt;T&gt; 将分钟间隔转化成标准秒间隔 std::cout &lt;&lt; "minutes1 duration has " &lt;&lt; std::chrono::duration_cast&lt;std::chrono::seconds&gt;(minute1).count() &lt;&lt; " seconds\n";&#125; 上述代码中还使用了 std::chrono::duration_cast&lt;T&gt;() 函数，用于各种时间间隔的换算，运行结果如下： 123456minutes1 duration has 5 ticksminutes2 duration has 1 ticksminutes3 duration has 2.5 tickshours1 duration has 12 tickshours2 duration has 0.5 ticksminutes1 duration has 300 seconds clock从名字可以看出这个类叫做时钟，时钟是用来看时间和计时的，常用的两个类是 system_clock 和 steady_clock，在 C++20 标准中又加入了多种内容，现在我们先来看看这两个常用类。 从这一部分开始类的定义让人有些迷糊，其实 clock 引用了 std::chrono::duration 和后面要说的 std::chrono::time_point， 而 std::chrono::time_point 又引用了 std::chrono::duration 和现在要讲的 std::chrono::system_clock、 std::chrono::steady_clock，如果只看定义很容易被绕晕，所以还是先做个练习实验一下。 system_clock这个类被称为系统内时钟，当修改系统时钟时可能会改变其单调递增的性质，静态成员函数有 now()、to_time_t()、from_time_t() 三个，关于它的单调性被修改举个例子，一般认为时间一直是递增的，但是当你现在调用一次函数 now()，然后把时间往过去调1天，然后再调用 now() 函数，就会发现新得到的时间“变小”了。 也因为这样它会受到 NTP（Network Time Protocol，网络时间协议）的影响，但是不会受时区和夏令时的影响（其实很多国家早就废除夏令时了）。 下面写个例子练习一下，例子中使用了 now()、to_time_t()、from_time_t() 三个函数，不清楚的时候可以对照一下： 12345678910111213141516171819202122232425262728293031#include &lt;chrono&gt;#include &lt;iostream&gt;int main()&#123; std::chrono::duration&lt;int, std::ratio&lt;60*60*24&gt; &gt; one_day(1); // 根据时钟得到现在时间 std::chrono::system_clock::time_point today = std::chrono::system_clock::now(); std::time_t time_t_today = std::chrono::system_clock::to_time_t(today); std::cout &lt;&lt; "now time stamp is " &lt;&lt; time_t_today &lt;&lt; std::endl; std::cout &lt;&lt; "now time is " &lt;&lt; ctime(&amp;time_t_today) &lt;&lt; std::endl; // 看看明天的时间 std::chrono::system_clock::time_point tomorrow = today + one_day; std::time_t time_t_tomorrow = std::chrono::system_clock::to_time_t(tomorrow); std::cout &lt;&lt; "tomorrow time stamp is " &lt;&lt; time_t_tomorrow &lt;&lt; std::endl; std::cout &lt;&lt; "tomorrow time is " &lt;&lt; ctime(&amp;time_t_tomorrow) &lt;&lt; std::endl; // 计算下个小时时间 std::chrono::system_clock::time_point next_hour = today + std::chrono::hours(1); std::time_t time_t_next_hour = std::chrono::system_clock::to_time_t(next_hour); std::chrono::system_clock::time_point next_hour2 = std::chrono::system_clock::from_time_t(time_t_next_hour); std::time_t time_t_next_hour2 = std::chrono::system_clock::to_time_t(next_hour2); std::cout &lt;&lt; "tomorrow time stamp is " &lt;&lt; time_t_next_hour2 &lt;&lt; std::endl; std::cout &lt;&lt; "tomorrow time is " &lt;&lt; ctime(&amp;time_t_next_hour2) &lt;&lt; std::endl; return 0;&#125; 运行结果如下： 12345678now time stamp is 1586662332now time is Sun Apr 12 11:32:12 2020tomorrow time stamp is 1586748732tomorrow time is Mon Apr 13 11:32:12 2020tomorrow time stamp is 1586665932tomorrow time is Sun Apr 12 12:32:12 2020 steady_clock这是一个单调时钟，一旦启动之后就与系统时间没有关系了，完全根据物理是时间向前移动，成员函数只有一个 now()，通常可以用来计时，使用方法与 system_clock 相比简单许多，下面写个小例子。 123456789101112131415161718#include &lt;chrono&gt;#include &lt;iostream&gt;int main()&#123; // 先记录程序运行时间 std::chrono::steady_clock::time_point start = std::chrono::steady_clock::now(); volatile int nDstVal, nSrcVal; for (int i = 0; i &lt; 1000000000; ++i) nDstVal = nSrcVal; // 做差值计算耗时 std::chrono::duration&lt;double&gt; duration_cost = std::chrono::duration_cast&lt; std::chrono::duration&lt;double&gt; &gt;(std::chrono::steady_clock::now() - start); std::cout &lt;&lt; "total cost " &lt;&lt; duration_cost.count() &lt;&lt; " seconds." &lt;&lt; std::endl; return 0;&#125; 运行结果如下：1total cost 1.9424 seconds. time point这个类与 duration 类似，同样是模板类，表示具体的时间点，比如今天 18:00 开饭，明天上午 10:00 发版本，今年 5 月 1 日可能因为疫情不让出去玩了，像这些具体的时间点可以使用 std::chrono::time_point 来表达，它的定义如下： 12template&lt;class Clock, class Duration = typename Clock::duration&gt;class time_point; 首先这个类是在 std::chrono 这个命名空间下，但是你会经常看到以下这种写法： 12std::chrono::system_clock::time_point today = std::chrono::system_clock::now();std::chrono::steady_clock::time_point start = std::chrono::steady_clock::now(); 好像 time_point 又在 std::chrono::system_clock 和 std::chrono::steady_clock 范围内，实际上这两个范围内的 time_point 引用的是 std::chrono::time point，看看 std::chrono::system_clock 的定义能明白一些。 123456789101112class system_clock &#123;public: using rep = /*see description*/ ; using period = ratio&lt;/*unspecified*/, /*unspecified*/ &gt;; using duration = chrono::duration&lt;rep, period&gt;; using time_point = chrono::time_point&lt;system_clock&gt;; static constexpr bool is_steady = /*unspecified*/ ; static time_point now() noexcept; // Map to C API static time_t to_time_t (const time_point&amp; t) noexcept; static time_point from_time_t(time_t t) noexcept;&#125;; 对照上面的定义可以知道，std::chrono::system_clock::time_point 实际上 std::chrono::time_point&lt;system_clock&gt;，这几个时间类的定义相互引用，看到这一部分的时候一定不要烦躁，一步步推导分析其中的关系。 time_point 这个类有一个成员函数 time_since_epoch() 用来获得 1970-01-01 00:00:00 到 time_point 时间经过的 duration, 返回的 duration 的单位取决于 timepoint 定义时的 duraion 的单位，不过你也可以得到 duration 之后使用 std::chrono::duration_cast&lt;T&gt;() 函数来转化。 12345678910111213141516171819202122232425262728293031#include &lt;chrono&gt;#include &lt;iostream&gt;int main()&#123; // 获得epoch 和 now 的时间点 std::chrono::time_point&lt;std::chrono::system_clock&gt; epoch = std::chrono::time_point&lt;std::chrono::system_clock&gt;&#123;&#125;; std::chrono::time_point&lt;std::chrono::system_clock&gt; now = std::chrono::system_clock::now(); // 显示时间点对应的日期和时间 time_t epoch_time = std::chrono::system_clock::to_time_t(epoch); std::cout &lt;&lt; "epoch: " &lt;&lt; std::ctime(&amp;epoch_time); time_t today_time = std::chrono::system_clock::to_time_t(now); std::cout &lt;&lt; "today: " &lt;&lt; std::ctime(&amp;today_time); // 显示duration的值 std::cout &lt;&lt; "seconds since epoch: " &lt;&lt; std::chrono::duration_cast&lt;std::chrono::seconds&gt;(epoch.time_since_epoch()).count() &lt;&lt; std::endl; std::cout &lt;&lt; "today, ticks since epoch: " &lt;&lt; now.time_since_epoch().count() &lt;&lt; std::endl; std::cout &lt;&lt; "today, hours since epoch: " &lt;&lt; std::chrono::duration_cast&lt;std::chrono::hours&gt;(now.time_since_epoch()).count() &lt;&lt; std::endl; return 0;&#125; 运行结果如下： 12345epoch: Thu Jan 1 08:00:00 1970today: Sun Apr 12 12:30:04 2020seconds since epoch: 0today, ticks since epoch: 1586665804624992500today, hours since epoch: 440740 从运行结果来看，epoch 的时间点是 Thu Jan 1 08:00:00 1970，为什么不是 1970-01-01 00:00:00 呢？那是因为我们在东8区，格林威治时间为1970-01-01 00:00:00 的时候，我们的时间就是 Thu Jan 1 08:00:00 1970，这样看来 std::ctime() 这个函数考虑了时区的影响，相同的代码如果在韩国同时运行得到的可能就是 epoch: Thu Jan 1 09:00:00 1970。 关于时间的思考思考一个问题，时间是不是一种不变的量，或者换一种说法，它是不是一种均匀的量。如果了解过《三体》中的部分章节，你就会发现时间总在被任意改变着。但是在现实生活中好像时间就是一个标准，我们认为它是一成不变的，总是感觉今天的1天和昨天的24小时在时间上是等同的，今年的这一年和去年的365天是等同的，但其实你了解一下闰年、闰秒、夏令时就会发现，前面提到的这些未必等同。 日常生活中对时间的描述只是为了理解和阐明一些事物，我们把太阳升到头顶叫做中午，把地球自转一圈叫做一天24小时，把地球围绕太阳公转一圈叫做1年365天，但是地球自转不是那么均匀的，也就是说每转一圈占用的绝对时间是不一样的，我们现在使用的时钟通常是滴答滴答一秒秒的走着，如果地球自转一圈的时间不是完全相同的，那么建立在这个滴答上的一切时间都是不准确的。 什么是建立在滴答滴答上的时间，我们以滴答一次作为1秒来计算，那么1分钟是60秒，也就是滴答60次，1小时是60分钟，滴答3600次，一天是24小时，滴答86400次，滴答的次数是均匀的，但是自转和公转是不均匀的，那么两个时间就对不上了，所以出现了闰秒、闰年等方法来调整时间，使得我们用来描述生活的时间和周围的环境现象可以一致，不然大约几千年以后就会出现中午12点天上出现月亮的奇观，那时的人们在史书中会发现我们这个时代中午12点挂在天上的是太阳，简直太玄幻。 有没有一种计时可以描述这种不均匀的自转呢？其实我们伟大的古人早已经发明出来了，你一定听说过日晷这种计时工具，它是观测日影记时的仪器，主要是根据日影的在日晷面上的位置，以指定当时的时辰或刻数，是我国古代较为普遍使用的计时仪器。为什么它没有时间不一致的问题？因为它本身就是不均匀的，它是根据自然现象来规定生活中每天的时间的，其实对照现在来说就是每个时辰的滴答数实际上是不一样的。 日晷这种不均匀的计时其实是为了适应天文现象，方便人们的生产生活，所以说现在地球自转一圈是一天，但不一定是86400秒，地球公转一圈是一年，但不一定是365天，后来人们使用电子设备计时，按道理来说应该非常准确，但是因为地球自转、公转的速率都不稳定，这种差距渐渐地会给生活带来困扰，于是又发明了一个折中的协调世界时，会在适当的时候闰秒、闰天，以弥补这种差距。假如你买了一个绝对精准的不联网的电子计时器，但是几年之后你就会发现你的计时器肯定和大家使用的标准时间不一致了。 其实还有一种基于特定铯原子的振荡周期来确定的国际原子时，主要是在时间精度要求较高的航天、通讯、电子等领域，为了保持系统的连续性而使用的，在日常生活中基本不会使用，但是这个时间是相对恒定的，不会去计较天文现象，每一秒都“准确”的流逝着。 时间函数思考现在回过头来再来看这些时间函数，是不是感觉有点不一样了，比如 time(NULL) 这个函数，它返回的是从 1970-01-01 00:00:00 到现在时间的秒数，回忆一下上面关于时间的思考，这个秒数真的是准确的吗？其实你如果理解了上面的内容就能得出结论，它肯定和国际原子时是有出入的。 再考虑下闰秒的影响，假如你实现了一个函数，第一次执行是在0点执行，执行之后你设置了一个86400秒的倒计时，也就是1天的时间，到第二天0点的时候正好又执行，你又设置了一个86400秒的倒计时，但今天正好是闰秒的日子，也就是今天会比昨天多1秒，那么今天的时间到23:59:59的时候就经过了86400秒，也就是说在23:59:59的时候就会执行你写的函数，如果碰到秒杀就尴尬了… 一般的程序开发不用太考虑闰秒的影响，但是如果这一秒的误差出现的宇宙飞船的飞行中，可能会导致几十公里的误差，所以程序员们一定要理解闰秒的可能带来的问题，评估自己所写的代码需不需要处理这种情况。曾经的一次闰秒直接导致了芬兰航空系统的瘫痪，所以一些大型项目还是会提前很长时间就把即将到来的闰秒处理写入到自己的系统中，以应对它带来的危险。 当你认为时间不会倒流的时候，它确实就发生了。我们一般假定时间不会倒流，但是如果你过分依赖这个特性，可能就会导致一些问题，这种情况常常出现设定了自动校准时间的电脑上，电脑的时间走快了，然后到达一定的差距后会触发校准程序，这时就会出现“时间倒流”的现象，比如 time(NULL) 这种依赖于电脑时间的函数，在这种情况下函数返回值就会变小，出现不单调性。 总结 关于时间的操作真的太多了，我居然发现一种名为 operator&quot;&quot;h 的操作符，与数字连用表示小时，有兴趣的话可以自己扩展学习一下。 durations、clocks 和 time points 三种有关时间操作的定义相互之间是有引用的，需要理清其中的关系。 需要了解闰秒、闰年、天文时、原子时、协调时产生的原因，这样就可以做到熟悉原理，心里不慌。 在测试的例子中出现了时区的概念，其实是人们为了生产生活主动创造出来以适应自然现象的。 这里抛出一个疑问，我之前刚接触时晕乎了很久，后来渐渐才明白，有些时间函数的说明中会提到与时区无关，比如 time(NULL)、还有今天学习的 system_clock，但是当我修改电脑时区的时候会发现，这些函数的返回值会发生突变，大家有探究过其中的原因吗？ 我们都是追逐时间奔跑的蝼蚁，改变世界的同时也被时间改变着。]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>C++11</tag>
        <tag>chrono</tag>
        <tag>时间</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Win10通过带命令行的安全模式清除顽固的广告弹窗文件]]></title>
    <url>%2Fblog%2F2020%2F04%2F02%2FWin10%E9%80%9A%E8%BF%87%E5%B8%A6%E5%91%BD%E4%BB%A4%E8%A1%8C%E7%9A%84%E5%AE%89%E5%85%A8%E6%A8%A1%E5%BC%8F%E6%B8%85%E9%99%A4%E9%A1%BD%E5%9B%BA%E7%9A%84%E5%B9%BF%E5%91%8A%E5%BC%B9%E7%AA%97%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[前言最近电脑开机后偶尔会出现一个弹窗，这种广告弹窗见的多了也就麻木了，本来也没放在心上，随手一关就准备去做其他事情了，但是点击关闭按钮后这个广告弹窗居然还弹出了二次确认框，想想也忍了，毕竟广告商做半天就是为了让你多看几眼，当我用鼠标的光标接近这个确认按钮时，确认框消失了，整个广告页面居然还在！ 一开始我还以为自己手滑点错了，后来试了3、4次之后发现，这个二次确认框从出来到消失不到1秒钟，以我的手速试了这么多次就没点到，这次暴脾气上来了，再也不忍了，我必须找到你是哪个软件的广告页，然后把你干掉！ 战斗经历本以为找到软件直接卸载就完事了，没想到碰上硬茬了，这个软件大有来头，真不是随随便便能搞定的。 查找广告来源这一步比较简单，这个打开的广告页在任务栏上有个图标，鼠标光标放到图标上会显示缩略图，就像下面这样： 在图标上单击右键，然后在弹出菜单中将光标移到最上面的选项继续单击右键，这时会在弹出一个菜单，如果一次不行就多试几次： 这时点击菜单上的属性按钮会弹出这个广告页对应程序的属性页面： 开始删除程序让我找到你了吧，目录是 D:\Program Files (x86)\MyDrivers\DriverGenius\ksoft，看来是驱动精灵软件带来的广告页，直接进入目录删除： 尴尬！提示“你需要提供管理员权限才能删除此文件”，点击“继续”按钮试试： 依旧不行，提示“你需要权限执行此操作”、“你需要Administrators提供的权限才能对此文件进行更改”，真是有点诡异，一个普通软件居然还要管理员权限才能删。 找管理员帮忙没办法了，提权吧！我把沉睡的管理员账号的都开启了，再试一次还是不行，我可是 Administrator 啊，在这个电脑中还有什么是我不能干的吗？ 微软：“你能干什么你说了不算，我说了算！”。 右键单击软件查看属性是不是只读了呢？没有啊！这时我还没意识到它究竟有多难缠，以为简简单单设置几个属性就能把它删掉，于是一拍脑袋决定，这种情况下一般需要修改权限啊，然后在属性面板中点击了“安全”选项卡： 然后点击“高级按钮”，弹出了很多教程中都给出的界面，长成下面这个样子： 这时要点击“更改”开始修改权限了，接着神奇的一幕发生了，当前界面一闪没有弹出修改界面，而原来的“更改”两个字也变成灰色不能再使用了。 有点慌了啊，试试命令行吧，一个 del 强制删除试试，丝毫未动，删除请求被拒绝了： 再试试别的文件，删除一个失败，再试一个又失败，最后发现这个文件夹中，我连个日志文件都删不掉，不仅发出了灵魂拷问，我真的是管理员吗？我的 Administrator 不会是假的吧？打开文件夹左看看、右看看没有发现什么可疑的地方，忽然我发现文件夹外面一层有个齿轮，难道被当成系统配置了，这是什么骚操作？ 看来我的电脑已经被这个软件给控制住了，一个做驱动的，在操作系统启动时早早的被唤醒，牢牢的控制住了局面，设置了一道道钩子，将可能影响到的它生存的途径全部堵死，这可能就是我修改权限时，界面闪了一下就再也修改不了的原因吧。 之前还碰到过一个软件比较坑，也是不让删除，在任务管理器强行关闭时会提示拒绝访问，最后发现一个名称比较相似的服务一直在启动着，然后尝试关闭这个服务，结果有趣的事情发生了，只要我点禁用服务一刷新，它又会重启，不知道还有哪个匿名的进程在默默的帮助它。 进入安全模式没办法了，本来想快速解决战斗，改改权限后直接删除了，哪里想到它这么顽强，既然是涉及到了驱动，谁知道你在系统启动时搞了什么鬼，我就在另一个世界把你搞掉吧，从安全模式启动，让你原来的小算盘只能在硬盘里乖乖的躺着了，说到这怎么有一种从四维空间看三维世界的感觉。 关于怎么进入安全模式的命令行，之前在XP和Win7上好像是开机就可以选，在Win10上开机没有看到，之前也没操作过，不过网络上有大量的教程，我发现其中有两个比较有意思的，一个是要我用U盘做系统盘，然后假装给电脑做系统，在配置界面打开命令行进行设置然后重启，这有点太麻烦了吧。 还有一种更好玩就是让你在电脑启动的时候直接按电源键关机，反复尝试2-3次等电脑感觉到自己异常了，就能看到安全模式的选项了，这就好比让你借梯子你借不到，就在家里放了把火，结果借来了消防队的云梯，有可能损失惨重啊。 这里说一个我感觉最简单的方法吧，使用 Win+R 组合键，调出 windows 运行窗口，然后输入 shutdown /r /o，回车等着电脑重启就可以了。 接着电脑会出现下面这个画面，选择其中的“疑难解答”选项： 然后界面变化进入下面展示的“高级选项”界面，选择其中的“启动设置”选项： 最后在启动设置的详细界面上选择“重启”按钮，短暂运行之后，电脑上开始出现下面的选项： 这时就可以选择进入系统的模式了，使用 F1~F9 来进行选择，F4 就是进入安全模式，不加载多余的驱动，F6 是带命令提示符的安全模式： 我们可以按键盘上的 F6 选择带命令提示符的安全模式，然后界面上就出现了下面这个“黑框框”： 彻底删除文件有了黑框框就可以删除文件，先通过 cd 命令进入待删除文件所在目录，然后使用 del 命令删除文件： 12345C:\Windows\System32&gt;d:D:\&gt;cd "Program Files (x86)\MyDrivers\DriverGenius\ksoft"D:\Program Files (x86)\MyDrivers\DriverGenius\ksoft&gt;del /f znb.exe 没有任何报错，世界都安静了，输入 shutdown /r /t 0 重启电脑，正常进入操作系统，这时就会发现刚刚统治了我的电脑的可执行程序，已经被我干掉不存在了。 总结 这些顽固广告真是厉害，一般删除文件的办法还真删不掉它们。 不光普通方法删不掉，连一些“流氓卫士”的文件粉碎功能都拿它们没办法。 不过电脑毕竟在用户手中，总有一些非常规办法可以干掉这些不正常的文件。 修理电脑时没有什么是重启电脑不能解决的，如果真的有，那就请你重装系统。 别放弃，坚持朝着目标一步一步的走就好了~]]></content>
      <categories>
        <category>windows</category>
      </categories>
      <tags>
        <tag>Win10</tag>
        <tag>del</tag>
        <tag>exe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git stash帮你在切换分支前暂存不想提交的修改]]></title>
    <url>%2Fblog%2F2020%2F03%2F25%2Fgit-stash%E5%B8%AE%E4%BD%A0%E5%9C%A8%E5%88%87%E6%8D%A2%E5%88%86%E6%94%AF%E5%89%8D%E6%9A%82%E5%AD%98%E4%B8%8D%E6%83%B3%E6%8F%90%E4%BA%A4%E7%9A%84%E4%BF%AE%E6%94%B9%2F</url>
    <content type="text"><![CDATA[前言偶然间发现这个命令，正好解决了最近遇到的问题，使用 Git 管理代码时有这样一种场景，你正在分支 branch2 上开发新功能，突然刚刚提交测试的 branch1 分支上报了严重的BUG，需要尽快修改，这时候就需要切换到 branch1 分支上去修复BUG，但是你刚刚在分支 branch2 修改的文件还没有提交，接下来该怎么办？ 如果本地的修改正好到达一个比较完整的阶段，可以直接提交，然后切换分支改BUG，那再好不过了。可是发生这种情况的时候往往是函数写了一半，或者功能大致写完但是还没来得及测试，这样的代码你敢提交吗？我感觉最好还是不要提交吧，那么如果这时候切换分支会有什么后果呢？一般会遇到两种情况：第一种是你在 branch2 分支上所做的修改与 branch1 上做过的修改不冲突，这时切换分支会将本地修改带到 branch1 分支，如果冲突了就是第二种情况，git checkout branch1 命令会被拒绝，当然你可以添加 -f 参数强行切换分支是能成功切换的，代价就是你会丢掉本地的所有修改。 git stash上面提到的切换分支时遇到的两种情况一般都不是我们想要的，之前说过“在 Git 中没有真正的方法来做任何事情，这就是它的妙处！”，但是关于切换分支有这样一个建议，那就是在切换分支时尽量保证你的工作区和暂存区是干净的，而 git stash 命令就是用来做这件事的。 当我们遇到这种状况，本地的修改我不能提交，不想带到新切换的分支，更不想直接丢掉，只想把他们暂存到一个地方，等我切换完分支修改好BUG，再切换回来迎接他们。使用 SVN 想保存本地修改可以使用 patch，而使用 Git 想要解决这种情况更加方便，那就是利用 git stash 命令。 使用方法这个命令的使用方法非常简单，最常用的 git stash push 和 git stash pop 就能应付大部分情况了，其中 push 这个单词还可以省略，使用起来可以说是相当方便了，接下来尝试一下具体用法。 本地有修改时切换分支的两种情况之前提到过这两种情况，一种是将当前分支修改带到要切换的分支，另一种是切换会导致冲突，本次切换操作被拒绝，下面具体操作一下。 将当前分支修改带到要切换的分支首先以 dev 分支为基础新建 feature 分支 12345678910albert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.nothing to commit, working tree cleanalbert@homepc MINGW64 /d/gitstart (dev)$ git checkout -b featureSwitched to a new branch 'feature' 在 feature 分支上修改文件，再切换回 dev 分支，可以正常切换，git status 查看状态，发现修改的文件被带到了 dev 分支上 123456789101112131415161718192021222324252627282930albert@homepc MINGW64 /d/gitstart (feature)$ echo "test checkout"&gt;&gt;README.mdalbert@homepc MINGW64 /d/gitstart (feature)$ git statusOn branch featureChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (feature)$ git checkout devSwitched to branch 'dev'M README.mdYour branch is up to date with 'origin/dev'.albert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a") 这里要注意一点，在切换到 dev 分支的时候，有一行 M README.md的内容，表示这个文件在切换过来的时候就是修改的。 如果你想要的效果就是这样，就可以直接提交了，比如修改了代码发现分支弄错了，可以这样带着修改的内容切换分支，假设就是这种情况，我们直接在 dev 分支提交修改。 123456789101112131415albert@homepc MINGW64 /d/gitstart (dev)$ git add README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git commit -m"add comments"[dev 5f4181e] add comments 1 file changed, 1 insertion(+)gitalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is ahead of 'origin/dev' by 1 commit. (use "git push" to publish your local commits)nothing to commit, working tree clean 切换分支操作被拒绝上面一种情况，在 feature 分支的修改被带到 dev 分支提交，我们在此基础上切换回 feature 分支看一下： 12345678albert@homepc MINGW64 /d/gitstart (dev)$ git checkout featureSwitched to branch 'feature'albert@homepc MINGW64 /d/gitstart (feature)$ git statusOn branch featurenothing to commit, working tree clean 发现此时 feature 分支上没有任何修改了，我们再改一次，然后切换到 dev 分支上试试： 12345678910111213141516171819albert@homepc MINGW64 /d/gitstart (feature)$ echo "second try"&gt;&gt;README.mdalbert@homepc MINGW64 /d/gitstart (feature)$ git statusOn branch featureChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (feature)$ git checkout deverror: Your local changes to the following files would be overwritten by checkout: README.mdPlease commit your changes or stash them before you switch branches.Aborting 看到了吧，切换分支的操作被拒绝了，原因是这次切换可能导致本地的修改被覆盖，你可以在切换分支前尝试 commit 你的修改或者 stash 你的修改，等等，这里出现了 stash 这个单词，其实之前我都没注意到，不是修改好提交了就是直接加 -f 参数放弃了所做的修改，没想到还有这样神奇 stash 命令帮我渡过难关。 stash 一般操作接下来展示一下 git stash 最常用的操作，也就是标题中提到的——在切换分支前暂存不想提交的修改，继续在上面的环境下操作，现在 feature 分支上修改了 README.md 文件，切换到 dev 分支时因为可能产生冲突而被拒绝，我们先来看一下文件状态。 12345678910111213141516171819202122albert@homepc MINGW64 /d/gitstart (feature)$ git statusOn branch featureChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (feature)$ git diffwarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directorydiff --git a/README.md b/README.mdindex 76a124a..4c2bfb8 100644--- a/README.md+++ b/README.md@@ -1,2 +1,3 @@ learn git branch command m2+second try 存储临时修改对比显示我们增加了一行，然后执行 git stash 命令，再查看一下文件状态： 12345678910albert@homepc MINGW64 /d/gitstart (feature)$ git stashwarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directorySaved working directory and index state WIP on feature: 6ae97d0 Revert "modify README 1"albert@homepc MINGW64 /d/gitstart (feature)$ git statusOn branch featurenothing to commit, working tree clean 执行完 git stash 之后我们发现，刚才的修改不见了，本地状态提示为 nothing to commit, working tree clean，这时我们再来切换分支： 12345678910111213albert@homepc MINGW64 /d/gitstart (feature)$ git checkout devSwitched to branch 'dev'Your branch is ahead of 'origin/dev' by 1 commit. (use "git push" to publish your local commits)albert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is ahead of 'origin/dev' by 1 commit. (use "git push" to publish your local commits)nothing to commit, working tree clean 这次切换就没有被拒绝，成功的切换到了 dev 分支，你可以在 dev 分支上进行想要的操作，全部操作完成后再切换回 feature 分支，我们这里就不操作了，直接切回 feature 分支查看一下状态： 12345678albert@homepc MINGW64 /d/gitstart (dev)$ git checkout featureSwitched to branch 'feature'albert@homepc MINGW64 /d/gitstart (feature)$ git statusOn branch featurenothing to commit, working tree clean 还原临时修改我们看到工作区很干净，这时如果想还原刚才在 feature 分支的修改，可以使用 git stash pop 命令，我们执行一下然后查看状态： 1234567891011121314151617181920albert@homepc MINGW64 /d/gitstart (feature)$ git stash popOn branch featureChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")Dropped refs/stash@&#123;0&#125; (bd500adb74d57a3d916a89ff2cd4536cf4eaf6ae)albert@homepc MINGW64 /d/gitstart (feature)$ git statusOn branch featureChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a") 刚刚被临时暂存的修改又恢复了，我们可以在 feature 分支上继续愉快地开发了。 stash 进阶操作作为这么神奇的命令，stash 肯定不止这么一点点用法，接下来再列举几个较为常用的参数组合： 查看临时存储的所有条目 git stash list当你使用几次 git stash 命令之后就会发现，这个命令有点像建立还原点，所以暂存命令不止可以用一次，当使用多次暂存命令之后就会形成一个暂存列表，这时可以使用 git stash list 命令查看所有的暂存操作，执行命令后大概就是下面的样子： 1234albert@homepc MINGW64 /d/gitstart (feature)$ git stash liststash@&#123;0&#125;: WIP on feature: 84dfd79 add test filestash@&#123;1&#125;: WIP on feature: 6ae97d0 Revert "modify README 1" 这个列表的构成很像一个栈，stash@{0} 是栈顶元素，stash@{1} 是栈顶下面的一个元素，当使用 git stash 命令时会把新的临时存储信息压入栈顶，原来的信息向栈底移动，当使用 git stash pop 命令的时候又会把栈顶的元素弹出，恢复到工作区和暂存区。 临时存储未追踪的新文件 git stash -u在开发过程中新添加的文件不属于任何一个分支，在不冲突的文件情况下也可以在切换分支的时候带到新的分支，默认在使用 git stash 命令的时候不会把这些文件临时存起来，如果想要存起来加上 -u 参数就可以了，执行之后你会发现这个新加的文件在工作区中消失了。 临时存储被忽略的文件 git stash -a被忽略的文件在默认情况下也不会被 git stash 命令存储，想要临时存储这部分文件只要使用 -a 参数就可以了，这样不仅会把忽略的文件临时存储，连未追踪的文件也存储了起来。 stash 操作的标号前面的 git stash list 命令也提到了，使用 git stash 命令的结果会形成一个栈形式的列表，其中 stash@{n} 就是每次临时存储对应的标号，针对于这些标号的操作也有很多，如果不加这些标号默认使用 stash@{0} ，也就是栈顶元素。 查看临时修改的具体内容 git stash show stash@{0}这个查询过程和查询提交日志的形式有点像，主要展示了某次临时存储时改了哪些内容： 123456789albert@homepc MINGW64 /d/gitstart (feature)$ git stash show stash@&#123;0&#125; test.txt | 1 + 1 file changed, 1 insertion(+)albert@homepc MINGW64 /d/gitstart (feature)$ git stash show stash@&#123;1&#125; README.md | 1 + 1 file changed, 1 insertion(+) 恢复指定标号的临时修改 git stash apply stash@{0}在恢复临时存储的修改时不仅可以使用 git stash pop 命令来恢复栈顶那一次修改，也可以按照标号恢复指定的某次修改，测试如下： 123456789101112131415161718192021albert@homepc MINGW64 /d/gitstart (feature)$ git stash apply stash@&#123;1&#125;On branch featureChanges not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (feature)$ git stash liststash@&#123;0&#125;: WIP on feature: 84dfd79 add test filestash@&#123;1&#125;: WIP on feature: 6ae97d0 Revert "modify README 1"albert@homepc MINGW64 /d/gitstart (feature)$ git stash apply stash@&#123;1&#125;error: Your local changes to the following files would be overwritten by merge: README.mdPlease commit your changes or stash them before you merge.Aborting 这个命令在执行后，指定标号的修改会被恢复到工作区和暂存区，但是临时存储的列表不会被删除，这时可以尝试再次恢复相同标号的修改到工作区，你会发现本次操作因为修改了相同的文件而被拒绝。 刪除指定标号的临时存储的修改 git stash drop stash@{0}可以在临时存储列表中删除指定标号的一些修改，可以测试一下看看效果： 123456789101112albert@homepc MINGW64 /d/gitstart (feature)$ git stash liststash@&#123;0&#125;: WIP on feature: 84dfd79 add test filestash@&#123;1&#125;: WIP on feature: 6ae97d0 Revert "modify README 1"albert@homepc MINGW64 /d/gitstart (feature)$ git stash drop stash@&#123;1&#125;Dropped stash@&#123;1&#125; (8408e56305fabcd82c1d05db18e177c89c47c5ac)albert@homepc MINGW64 /d/gitstart (feature)$ git stash liststash@&#123;0&#125;: WIP on feature: 84dfd79 add test file 利用临时存储的修改内容新建分支 git stash branch &lt;branchname&gt; [&lt;stash&gt;]一般这种情况就是使用过多次 git stash push 命令，而本地分支还修改了其他内容，直接恢复之前的修改不太合适，所以利用这个命令新建一个分支，分支的内容以指定的存储标号 &lt;stash&gt; 对应的提交 commit-id 为基础，然后应用 &lt;stash&gt; 的修改，实际上就是新建了一个对应 &lt;stash&gt; 的分支，继续之前未完成的工作，&lt;stash&gt; 默认为 stash@{0}，测试如下： 12345678910111213141516albert@homepc MINGW64 /d/gitstart (feature)$ git stash branch feature1Switched to a new branch 'feature1'M README.mdOn branch feature1Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.md modified: test.txtno changes added to commit (use "git add" and/or "git commit -a")Dropped refs/stash@&#123;0&#125; (2922b3eeeda44c98316453b93fcf07c1fcfffca4)albert@homepc MINGW64 /d/gitstart (feature1)$ git stash list 这个操作会消耗掉对应 &lt;stash&gt; 标号的临时存储的内容，将这些内容从存储列表中移除。 stash 的注意事项这个命令不仅可以在同一分支上存储和还原，也可用于不同分支之间，这时就可以有一个应用，当我们发现在错误的分支上开发了代码，可以先 git stash push 将这些修改临时存储起来， 然后切换到正确的分支，再执行 git stash pop 命令将刚才的修改引用到现在的分支上。 git stash push 命令默认是存储工作区和暂存区的修改内容的，但是 git stash pop 命令在还原是默认将所有的修改还原到工作区，如果想还原到对应的暂存区，需要加额外的参数，像这样 git stash pop --index。 总结 这个命令挺有用的，在合作开发的时候经常碰到临时问题需要处理，切换分支暂存一下很方便 感觉这个命令其实和 commit 也很像的，在操作过程中你会发现，它也有自己的 hash-id，但是不会放到 commit 列表中 这个命令参数也有好多个，不过记住常用的就可以面对大多数情况了，简单列举下 git stash push 会将当前本地的修改临时保存起来，push 可以省略 git stash list 查看当前stash push操作的记录 git stash pop 取出最近一次修改，并应用到本地 git stash apply stash@{n} 应用 stash@{n} 对应的修改，但是不删除这条记录 git stash show stash@{n} 展示 stash@{n} 对应的修改的实际修改内容]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>checkout</tag>
        <tag>stash</tag>
        <tag>merge</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[没想到C++中的std::remove_if()函数历史还挺悠久]]></title>
    <url>%2Fblog%2F2020%2F03%2F19%2F%E6%B2%A1%E6%83%B3%E5%88%B0C-%E4%B8%AD%E7%9A%84std-remove-if-%E5%87%BD%E6%95%B0%E5%8E%86%E5%8F%B2%E8%BF%98%E6%8C%BA%E6%82%A0%E4%B9%85%2F</url>
    <content type="text"><![CDATA[前言看到 remove 这个单词的第一反应是什么意思？我的第一感觉是删除、去掉的意思，就像一个程序员看到 string 就会说是字符串，而不会说它是线、或者细绳的意思，可是C++里居然有个函数叫 std::remove()，调用完这个函数什么也没删除，这我就奇怪了，打开有道词典查询一下： 不查不要紧，一查吓一跳，以下是词典给出的三个释义： vt. 移动，迁移；开除；调动 vi. 移动，迁移；搬家 n. 移动；距离；搬家 及物动词、不及物动词、名词给出的含义都是移动，只有一个开除的意思和删除有点像，难道我穿越了？我之前一直以为它是删除的意思啊，很多函数还是用它命名的呢！ 赶紧翻翻其他的字典，给高中的英语老师打个电话问问，最终还是在一些释义中找到了删除的意思，还有一些用作删除的例句，有趣的是在有道词典上，所有的单词解释都和移动有关，所有的例句都是和删除有关。 remove_if的历史为什么要查单词的 remove 的意思，当然是被它坑过了，本来想从 std::vector&lt;T&gt; 中删除指定的元素，考虑到迭代器失效的问题，放弃了循环遍历的复杂处理，选择直接使用算法函数 std::remove_if()来进行删除，之前对于 std::remove() 和 std::remove_if() 有过简单的了解，不过记忆还是出现了偏差。 一直记得 std::remove() 函数调用之后需要再使用 erase() 函数处理下，忘记了 std::remove_if() 函数也要做相同的处理，于是在出现问题的时候一度怀疑这个函数的功能发生了变更，开始找这个函数历史迭代的版本，这里推荐一个网站 C++标准函数查询 - std::remove_if()，用来查询函数的定义、所在头文件和使用方法非常方便。 文档中有这样两句： 1) Removes all elements that are equal to value, using operator== to compare them.3) Removes all elements for which predicate p returns true. 解释函数作用时用到的单词都是 remove ，你说神不神奇，这里应该都是取的移动的意思。 这两句话对应的函数声明应该是： 12345template&lt; class ForwardIt, class T &gt;ForwardIt remove( ForwardIt first, ForwardIt last, const T&amp; value ); // (until C++20)template&lt; class ForwardIt, class UnaryPredicate &gt;ForwardIt remove_if( ForwardIt first, ForwardIt last, UnaryPredicate p ); // (until C++20) 这两个函数后面都有相同的说明—— (until C++20) ，意思大概就是说这两个函数一直到 C++20 版本都存在，在我的印象中 std::remove_if() 函数比较新，最起码得比 std::remove() 函数年轻几岁，可是他们到底是哪个版本添加到c++标准的的呢？中途的功能有没有发生变更，继续回忆！ 第一次看到这两个函数应该是在看《Effective STL》这本书的时候，大概是5年前了，正好这个本书就放在手边，赶紧翻目录查一下，打开对应章节发现其中确实提到了删除 std::vector&lt;T&gt; 中的元素时，在调用了这两个函数之后都需要再调用 erase() 函数对待删除的元素进行擦除。 看看书的出版时间是2013年，难道是 C++11 的标准加上的，不对，看一下翻译者写得序，落款时间2003年，不能是 C++03 的标准吧？不过这是一本翻译书籍，再看看原作者 Scott Meyers 写的前言，落款时间2001年，好吧，看来这两个函数肯定在 C++98的版本中就已经存在了，我有点惊呆了，这确实颠覆了我的记忆和认知。 造成这种认知错误主要有两方面原因，第一方面就是受到了开发环境的限制，从一开始学习的时候Turob C 2.0、VC++ 6.0、VS2005、VS2008、VS2010就很少接触 C++11 的知识，Dev-C++ 和 Code::Blocks 也是在特定的情况下使用，没有过多的研究，结果在刚开始工作的时候开发工具居然是VS2003，这个版本我之前都没听说过，还好一步步升级到了08、13、17版本。 第二方面就是这两个函数常常与 Lambda 表达式，auto 关键字一起用，这都是 C++11 里才有的，让人感觉好像这个 std::remove_if() 函数也是 C++11 版本中的内容，造成了错觉。总来说还是用的少，不熟悉，以后多看多练就好了。 remove_if的实现要想更深入的学习 std::remove_if() 函数， 那这个函数实现的细节有必要了解一下，这有助于我们理解函数的使用方法，下面给出两个版本可能的实现方式，也许下面的实现与你查到的不一样，但是思想是相通的，有些实现细节中使用了 std::find_if() 函数，这里没有列举这个版本，下面这两个版本的代码更容易让人明白，它究竟做了哪些事情。 123456789101112131415// C++98 版本template &lt;class ForwardIterator, class UnaryPredicate&gt; ForwardIterator remove_if (ForwardIterator first, ForwardIterator last, UnaryPredicate pred)&#123; ForwardIterator result = first; while (first!=last) &#123; if (!pred(*first)) &#123; *result = *first; ++result; &#125; ++first; &#125; return result;&#125; 123456789101112131415// C++11 版本template &lt;class ForwardIterator, class UnaryPredicate&gt; ForwardIterator remove_if (ForwardIterator first, ForwardIterator last, UnaryPredicate pred)&#123; ForwardIterator result = first; while (first!=last) &#123; if (!pred(*first)) &#123; *result = std::move(*first); ++result; &#125; ++first; &#125; return result;&#125; 对比两段代码有没有发现区别——只改了半行代码，将赋值语句中的 *first 在 C++11 版本中替换成了 std::move(*first)，这只能发生在 C++11 之后，因为 std::move() 函数是 C++11 才加入的。 这代码乍一看挺唬人的，其实仔细分析一下还挺简单的，只是这些符号看起来有些生疏，其实可以把 ForwardIterator 看成一个指针类型，UnaryPredicate 是一个函数类型，我们改写一下: 12345678910111213int* remove_if (int* first, int* last, func_type func)&#123; int* result = first; for (;first!=last;++first) &#123; if (!func(*first)) &#123; *result = *first; ++result; &#125; &#125; return result;&#125; 这代码是不是就比较接地气了，想象一下，一个是包含10个元素的数组，让你删除其中的偶数怎么做？其实就是遍历一遍数组，从开始位置到结束位置逐个判断，如果不是偶数就不进行操作，如果是偶数就把当前的偶数向前移动到结果指针上就好了，结果指针向后移动准备接受下一个奇数，这个判断是不是偶数的函数就是上面代码中的 func()。 最后结果指针 result 停在有效元素后面一个位置上，这个位置到结尾指针 last 的位置上的元素都应该被删除，这就是为什么常常将 std::remove_if() 函数的返回值作为 erase() 函数的第一个参数，而将 last 指针作为 erase() 函数的第二个参数，实际作用就是将这些位置上的元素擦除，从头擦到尾，达到真正删除的目的。 具体使用说了这么多，接下来看看具体怎么用，我们将 std::remove_if() 函数和 erase() 函数分开使用，主要看一下调用 std::remove_if() 函数之后的 vector 中元素的值是怎么变的。 1234567891011121314151617181920212223242526272829303132333435#include &lt;iostream&gt;#include &lt;vector&gt;#include &lt;algorithm&gt;bool isEven(int n) // 是否是偶数&#123; return n % 2 == 0;&#125;int main()&#123; std::vector&lt;int&gt; vecTest; for (int i = 0; i &lt; 10; ++i) vecTest.push_back(i); for (int i = 0; i &lt; vecTest.size(); ++i) std::cout &lt;&lt; vecTest[i] &lt;&lt; " "; std::cout &lt;&lt; std::endl; // 移动元素 std::vector&lt;int&gt;::iterator itor = std::remove_if(vecTest.begin(), vecTest.end(), isEven); // 查看移动后的变化 for (int i = 0; i &lt; vecTest.size(); ++i) std::cout &lt;&lt; vecTest[i] &lt;&lt; " "; std::cout &lt;&lt; std::endl; // 删除元素 vecTest.erase(itor, vecTest.end()); for (int i = 0; i &lt; vecTest.size(); ++i) std::cout &lt;&lt; vecTest[i] &lt;&lt; " "; return 0;&#125; 运行结果为： 0 1 2 3 4 5 6 7 8 91 3 5 7 9 5 6 7 8 91 3 5 7 9 从结果可以看出，第二步调用 std::remove_if() 函数之后，vector 中的元素个数并没有减少，只是将后面不需要删除的元素移动到了 vector 的前面，从第二行结果来看，调用 std::remove_if() 函数之后返回的结果 itor 指向5，所以擦除从5所在位置到结尾的元素就达到了我们的目的。 这段代码在 C++98、C++11、C++14 环境下都可以编译运行，在这里推荐一个在线编译器 C++ Shell，可以测试各个版本编译器下运行结果，界面简洁明了，方便测试。 上面的代码其实写得有些啰嗦，如果使用 C++11 语法之后，可以简写为： 1， 运行结果： 0 1 2 3 4 5 6 7 8 91 3 5 7 9 总结 对于模糊的知识要花时间复习，避免临时用到的时候手忙脚乱出问题 对于一些心存疑虑的函数可以看一下具体的实现，知道实现的细节可以让我们更加清楚程序都做了哪些事情 对于新的技术标准可以不精通，但是必须花一些时间进行了解，比如新的 C++ 标准 对于违反常识的代码，先不要否定，即使在你的运行环境中报错，说不定人家是新语法呢？ 曾经看到一段在类的定义时初始化非静态变量的代码，一度认为编译不过，但后来发现在 C++11 中运行的很好]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>历史</tag>
        <tag>remove</tag>
        <tag>remove_if</tag>
        <tag>删除</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python操作Excel工作簿(\*.xlsx)]]></title>
    <url>%2Fblog%2F2020%2F03%2F14%2FPython%E6%93%8D%E4%BD%9CExcel%E5%B7%A5%E4%BD%9C%E7%B0%BF%2F</url>
    <content type="text"><![CDATA[前言Excel 作为流行的个人计算机数据处理软件，混迹于各个领域，在程序员这里也是常常被处理的对象，可以处理 Excel 格式文件的 Python 库还是挺多的，比如 xlrd、xlwt、xlutils、openpyxl、xlwings 等等，但是每个库处理 Excel 的方式不同，有些库在处理时还会有一些局限性。 接下来对比一下几个库的不同，然后主要记录一下 xlwings 这个库的使用，目前这是个人感觉使用起来比较方便的一个库了，其他的几个库在使用过程中总是有这样或那样的问题，不过在特定情况下使用也是挺不错的。 EXCEL文件Excel 被称为电子表格，其实际可以保存的格式分为很多种，但是“Excel 工作簿(*.xlsx)”和“Excel 97-2003 工作簿(*.xls)”是其中比较常用的两种，可以认为 .xls 格式的表格是 03版Excel 之前常用的格式，而 .xlsx 是 03版之后，一般指 07版Excel 之后常用的格式。 一般的 Excel 程序对于上述的两种格式都可以打开编辑，也可以相互转化存储，不过还是建议在没有特殊要求的情况下使用新版本的格式，一方面新的稳定版本可能会修复之前的一些BUG，同时也会带来进行一些优化。 我也是在写这篇总结之前才发现，一个空的 .xlsx 格式的文件大小有 7KB，而一个空的 .xls 格式的文件大小有 24KB，当我分别写入一个相同的汉字后，两个文件大小变成了 10KB 和 30KB，差距还是不小的，还有一个问题就是在将 .xlsx 格式的文件另存为 .xls 格式时还会有兼容性提示，提醒用户有些设置可能会丢失，所以能选新版本还是尽量用新版本吧。 测试环境因为很多应用程序是不断迭代的，相对应的 Python 库也是不断迭代的，这里尽可能的给出版本号，不同的版本可能会有不同的问题： 操作系统: Windows 10 随意版 Python: 3.75 xlrd: 1.2.0 xlwt: 1.3.0 xlutils: 2.0.0 openpyxl: 3.0.3 xlwings: 0.18.0 以上各个程序库使用之前自行安装就行，安装方法就不赘述了，不过可以提供一个可以快速安装镜像源，使用 pip install -i https://pypi.doubanio.com/simple 库名 可以尽可能解决下载安装缓慢的问题。 Excel具体操作关于使用 Python 具体操作 Excel 的方法可以分为三组，配合使用 xlrd、xlwt、xlutils 操作作为第一组，使用库 openpyxl 作为第二组，而 xlwings 作为第三组，这篇总结重点总结 xlwings 的使用，其他两组简单了解。 xlrd、xlwt、xlutils这一组操作 Excel 的库名字很形象，一个读、一个写、一个小工具，凑到一起就可以对 Excel 肆意妄为了，下面做个小练习，打开一个 Excel 文件然后修改第一个单元格的值，再另存为一个新文件，代码如下: 123456789101112131415import xlrdimport xlwtimport xlutils.copydef save_as_new_file(file_name, new_file_name): # 打开Excel文件 rb = xlrd.open_workbook(file_name) # 创建一个可写入的副本 wb = xlutils.copy.copy(rb) # 获得第一个sheet页签 ws = wb.get_sheet(0) # 第一个单元格写入测试值 ws.write(0, 0, 'test value') # 另存为一个新文件 wb.save(new_file_name) 上述代码无论是操作 .xlsx 文件还是操作 .xls 文件都不会报错，但是另存为的 .xlsx 格式的文件会打不开，同时你会发现正常存储的 .xls 文件打开后格式全都没了，怎么办，改个参数试试，将打开文件的代码修改如下： 1rb = xlrd.open_workbook(file_name, formatting_info=True) 其中参数 formatting_info=True 就表示打开Excel时保留原有的格式，但是这是相对于 .xls 格式的文件，对于 .xlsx 格式的文件直接跑出异常 raise NotImplementedError(&quot;formatting_info=True not yet implemented&quot;)，就因为处理不了 .xlsx 格式的文件，我暂时没有使用这几个库操作 Excel。 还有一点，这几个库操作单元格时，行和列的索引是从0开始的。 openpyxl首先说这个库主要用来操作 .xlsx 格式的文件，对于 .xls 格式的文件无法打开，会报 openpyxl does not support the old .xls file format 这样的错误，但是可以存储成这样的格式，再次打开时会有格式不匹配的警告，但是基础的数据还在，所以还是优先用来操作 .xls 格式的文件吧。 写一个新文件的常见用法： 1234567891011121314151617181920from openpyxl import Workbookfrom openpyxl import load_workbookfrom openpyxl.styles import Font, Fill, Alignment, PatternFilldef write_new_excel(file_name): # 创建一个excel文档 wb = Workbook() # 获得当前激活的sheet对象 ws = wb.active # 给A2单元格赋值 ws['A2'] = 'This is A2 cell' # 一行添加多列数据 ws.append([1, 2, 'hello']) # 添加新的sheet ws = wb.create_sheet(title='NewInfo',index=0) # 设置单元格的值 ws['A1'] = 'This is new sheet' # 保存excel wb.save(file_name) 读取和改写一个原有文件的常见用法： 12345678910111213141516171819202122232425262728def read_update_excel(file_name): # 加载Excel表 wb = load_workbook(file_name) # 打印sheet数量 print('sheet count:', len(wb.sheetnames)) # 打印所有sheet名字 print('sheet name list:', wb.sheetnames) # 获取第一个sheet对象 ws = wb[wb.sheetnames[0]] # 打印sheet表行数和列数 print('rows count:', ws.max_row, 'cols count:', ws.max_column) # 更新单元格A1的内容 ws['A1'] = 'this is A1' # 在第二行位置插入一行 ws.insert_rows(2) # 删除第五行 ws.delete_rows(5) # 获取单元格对象，对应B2单元格 cell = ws.cell(2,2) # 设置单元格内容 cell.value = 'this is B2' # 修改字体格式为粗体 cell.font = Font(bold=True) # 修改单元格格式 cell.fill = PatternFill("solid", fgColor="F0CDCD") # 保存原文件或另存一个文件 wb.save(file_name) 使用这个库遇到的情况，存储带有样式的数据没有发现问题，但是当加入一个计算公式后，另存为一个文件时明显文件尺寸变小了，但是数据和公式没有发现有问题。 有资料说处理速度真的很慢，因为我处理的文件比较小，但是没有发现这方面的问题，还有一个问题就是说Excel中的宏全部丢失，这个测试的时候确实是丢了，只不过这个好像和文件格式有关，要想保存宏需要存储为 .xlsm 格式，但是 openpyxl 使用来操作 .xlsx 文件的，存储时会导致宏丢失，强行存储为 .xlsm 格式会导致最终的文件打不开。 还有一点，这个库操作单元格时，行和列的索引是从1开始的。 xlwings这个库在操作的首先要创建一个 App，通过这个创建出来的 App 对象来操作 Excel，非常像把 Excel 的各种操作 api 封装到一起，然后通过这个 App 对象来调用，如果在创建 App 的时候不设置隐藏参数，是会正常打开 Excel 程序的。 使用 xlwings 的基本方式：1234567891011import xlwings as xw# 设置Excel程序不可见app = xw.App(visible=False, add_book=False)# 通过 app 操作 Excel文件# app.bala bala bala .....# app.bala bala bala .....# 优雅的退出app.quit() 创建一个新的 Excel 文件并写入数据：12345678910111213141516def write_new_excel(app, file_name): # 创建新的 Excel 表 wb = app.books.add() # 获取当前活动的sheet ws = wb.sheets.active # 初始化二维区域的值 arr_data = [[1, 2, 3], [4, 5, 6], [7, 8, 'end']] # 设置到新建的Excel中 ws.range('A1:B3').value=arr_data # 设置单独一个单元格的值 ws.range('A4').value='this is A4' # 设置单独一个单元格的值 ws[3,1].value='this is B4' # 保存Excel文件 wb.save(file_name) wb.close() 需要注意的是通过行索引和列索引修改单元格时，起始索引是0。 读入已有 Excel 表格并修改1234567891011121314151617181920212223242526272829303132333435363738394041def read_update_excel(app, file_name): # 加载已有的表格 load_wb = app.books.open(file_name) # 获取Excel表中第一个sheet load_ws = load_wb.sheets[0] # 打印sheet的名字 print(load_ws.name) # 根据sheet名字获取sheet对象 load_ws = load_wb.sheets[load_ws.name] # 获取当前活动的sheet load_ws = load_wb.sheets.active # 获取存在数据的行数和列数 rows = load_ws.api.UsedRange.Rows.count cols = load_ws.api.UsedRange.Columns.count print('rows count:', rows, 'cols count:', cols) # 修改指定单元格数据（A1单元格） load_ws[0,0].value='this is A1' # 有空行或空列时获取准确的行列数量 print(load_ws.used_range.shape) # 从A1单元格开始扩展到非空行空列，最后的行数和列数 print((load_ws.range('A1').expand().last_cell.row, load_ws.range('A1').expand().last_cell.column)) # 从A1单元格开始扩展到非空行空列，最后的行数和列数 print((load_ws.range('A1').expand().last_cell.row, load_ws.range('A1').expand().last_cell.column)) # 从A1单元格开始扩展到非空行空列，最后形状 print(load_ws.range(1,1).expand().shape) # 从A1单元格开始扩展到非空行空列，最后的行数和列数 print((load_ws.range('A1').expand('table').rows.count, load_ws.range('A1').expand('table').columns.count)) # 保存修改后的Excel load_wb.save(file_name) load_wb.close() Excel 增加删除行和列1234567891011121314151617181920def insert_delete_rowscols(app, file_name): # 加载已有的表格 load_wb = app.books.open(file_name) # 获取当前活动的sheet load_ws = load_wb.sheets.active # 从第2行开始插入4行，也就是说2-5行变成新插入的空行 load_ws.api.rows('2:5').insert # 删除第6行和第7行 load_ws.api.rows('6:7').delete # 插入一个单元格，实际测试效果是B列从B2开始向下移动，B2为新添加的单元格 load_ws.range('B2').api.insert # 插入新的一列 load_ws.api.columns('B').insert # 删除一列 load_ws.api.columns('C').delete # 保存修改后的Excel load_wb.save(file_name) load_wb.close() 单元格宽高查询设置与合并12345678910111213141516171819202122232425262728293031def cell_operation(app, file_name): # 加载已有的表格 load_wb = app.books.open(FILE_PATH_ROOT + file_name) # 获取当前活动的sheet load_ws = load_wb.sheets.active # 合并单元格 load_ws.range('A2:A3').api.merge #获取单元格 cell = xw.Range('B2') # 打印单元格所在的行和列 print("row is:", cell.row, "col is:", cell.column) # 打印当前格子的高度和宽度 print("cell.width:", cell.width, "cell.height:", cell.height) # 设置当前格子的高度和宽度 cell.row_height = 32 cell.column_width = 64 # 指定单元格的高度和宽度自适应 cell.columns.autofit() cell.rows.autofit() # 再次打印当前格子的高度和宽度 print("cell.width:", cell.width, "cell.height:", cell.height) # 保存修改后的Excel load_wb.save(file_name) load_wb.close() 几个库支持情况对比虽然前面写了这么多方法，但是遇到一个实际的问题时还是会犹豫，到底用哪种方式呢？下面做一个简单的对比，只是根据我做的实验来简单对比，如果有不准确甚至是错误的地方，欢迎大家指出来，我会尽快改正的。 情景/库 xlrd、xlwt、xlutils openpyxl xlwings 读取.xls 可以带有样式读取 不支持 可以读取 保存.xls 可以带有样式保存 可以保存，但是提示文件扩展名不匹配，可以看到原始数据 可以保存，但是提示文件扩展名不匹配，可以看到原始数据 读取.xlsx 可以读取，但没有样式 可以带有样式读取 可以带有样式读取 保存.xlsx 保存后打不开 可以带有样式保存 可以带有样式保存 读取.xlsm 可以读取，但没有样式和宏 可以读取，但没有宏 可以读取包含宏的表格 保存.xlsm 保存后打不开，存成 .xls 格式宏丢失 保存后打不开，存成 .xls想 格式宏丢失 存储后宏还在 增删行和列 没有直接方法 支持 支持 另存后大小 .xls 文件没有变化 .xlsx 文件会变小 .xls、.xlsx 文件没有变化 使用建议 只操作.xls文件可以考虑 只操作.xlsx文件可以考虑，不能带有宏 一个比较好的选择，使用时感觉速度稍微有点慢 总结 Excel 表格程序经过版本的更替发生了很大的变化，出现了相同内容时 .xls 比 .xlsx 格式的文件大很多的情况 基于上一点考虑，如果能使用的新版的表格，那么就放弃旧的格式的吧 还有一个神奇的情况，一个带有少量数据的 .xlsx 格式的表格要比一个空表格还要小，这是什么情况，暂时没弄明白怎么回事，求知道的大神告知一二]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Excel</tag>
        <tag>xlrd</tag>
        <tag>xlutils</tag>
        <tag>xlwings</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git checkout/git reset/git revert/git restore常用回退操作]]></title>
    <url>%2Fblog%2F2020%2F03%2F03%2Fgit-checkout-git-reset-git-revert-git-restore%E5%B8%B8%E7%94%A8%E5%9B%9E%E9%80%80%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[在 Git 中没有真正的方法来做任何事情，这就是它的妙处！ 前言经常会听到别人说，如果时光可以倒流，我将会如何如何，可是现阶段的科技还达不到时光倒流的目的，或许在《三体》世界的四维裂缝里可以试一下。现实的世界中找不到后悔药，但是在代码的世界里却可以轻松实现，错误的BUG修改、砍掉的做了一半的功能都可以轻松回退，不留一丝痕迹，回滚之后一切又可以重新开始了。 代码回退大型编程项目的开发往往伴随着版本工具的使用，其实引入代码版本控制工具，有一部分原因也是为了方便回退，回退操作每天都发生的，只是有时是我们显式的操作，有时却自然而然的进行着，我们切换着分支很可能就是从开发版本回退到一个稳定版本，我们查询日志，实际上是在记忆上回退我们整个的开发过程，找寻其中的问题和修改的内容。 Git管理下的各种文件状态Git的使用中，由于一个文件存在好几种状态的变化，所以处理起回退要分情况进行，有些各式各样的命令最终分析起来其实作用是一样的。 说起Git常常会提到工作区、暂存区、版本库的概念，这是很通用的说法，其实工作区一般就是指我们能看到的文件、本地操作文件所在的目录，我们正常编写的代码文件、管理的资源文件都是在工作区里操作，这里的文件也不是全都平等的，又细分为受版本控制的文件和不受版本控制的文件。 提到暂存区就和index文件建立起了联系，工作区的新文件和已经修改的受版本控制的文件，使用 git add file_name 就可以加到暂存区，相当于登记报个名，以后提交到版本库的时候会把这些登记的文件都带上，实际上执行了 git add 命令的文件都生成了对应的 object 对象，放在.git/objects目录下，状态变成了 staged， 当提交到版本库时，分支会引用这些对象。 版本库就是文件修改的目的地了，最终的修改会提交到版本库，这时提交的文件状态变成 committed，其实也是一种 unmodified 状态，一路走来，版本库中记录了你的每一次提交，可以追溯你每一次修改的内容。 其实还有一个远程仓库的概念，一般确定本地仓库的修改没有问题了，或者要将本地代码远程备份时，可以将自己修改的分支推送到远程仓库，因为有时候我们也想回退已经推送到远程仓库的修改，所以这里先提一下远程仓库。 总结起来一个文件的状态通常可以分为： 不受版本控制的 untracked 状态 受版本控制并且已修改的 modified 状态 受版本控制已修改并提交到暂存区的 staged 状态 从暂存区已经提交到本地仓库的 committed 状态 提交到本地仓库未修改或者从远程仓库克隆下来的 unmodified 状态 Git回退命令上面提到了在 Git 这个版本控制工具下文件的各种状态，其实回退操作就是通过命令实现这些文件状态的“倒退”，进而达到回退操作的目的，下面一起先来了解下这些可以实现回退的命令。 git checkout这个命令又出现了，上次是总结 git branch 分支操作的时候，git checkout 可以用来新建或者切换分支，这次总结回退版本的命令，git checkout 也可以用来回退文件版本，很神奇吧。 其实这个命令的作用就是它单词的本义——检出，他的常用操作也取自这个意思，比如 git checkout branch_name 切换分支操作，实际上就是把指定分支在仓库中对应的所有文件检出来覆盖当前工作区，最终表现就是切换了分支。 而针对于文件的检出可以使用 git checkout -- file_name，当不指定 commit id 就是将暂存区的内容恢复到工作区，也就可以达到回退本地修改的作用。 不过，这个身兼数职的 git checkout 命令现在可以轻松一些了，从 Git 2.23 版本开始引入了两个新的命令： git switch 用来切换分支，git restore用来还原工作区的文件，这个后面还会提到。 git revertrevert 这个词的意思是：归还，复原，回退，它和后面即将提到的 restore 在意思上简直无法区分，为了区别他们两个这里可以把 git revert 看成归还的意思，对某次提交执行 git revert 命令就是对这次修改执行一个归还操作，其实就是反向再修改一次。 要理解 git revert 就要从反向修改的含义来看，当我们再一个文件中添加一行内容，并提交到版本库后，产生一个提交id——commit-id-a，如果这时使用 git revert commit-id-a 命令，就相当于在工作区中的那个文件将刚在新加的一行内容删除掉，然后再进行一个提交。 注意，这个操作是会改变分支记录的，因为产生了新的提交。 git restore这个命令是 Git 2.23 版本之后新加的，用来分担之前 git checkout 命令的功能，作用就是用暂存区或者版本库中的文件覆盖本地文件的修改可以达到回退修改的目的，同时也可以使用版本库中的文件覆盖暂存区的文件，达到回退git add 命令的目的。 注意，这个操作是不会影响分支记录的，就是相当于之前的 git checkout 命令重新检出一份文件来覆盖本地的修改。 git resetreset 重新设置的意思，其实就是用来设置分支的头部指向，当进行了一系列的提交之后，忽然发现最近的几次提交有问题，想从提交记录中删除，这是就会用到 git reset 命令，这个命令后面跟 commit id，表示当前分支回退到这个 commit id 对应的状态，之后的日志记录被删除，工作区中的文件状态根据参数的不同会恢复到不同的状态。 --soft: 被回退的那些版本的修改会被放在暂存区，可以再次提交。 --mixed: 默认选项，被回退的那些版本的修改会放在工作目录，可以先加到暂存区，然后再提交。 --hard: 被回退的那些版本的修改会直接舍弃，好像它们没有来过一样。 这样来看，git set 命令好像是用来回退版本的，但是如果使用 git rest HEAD file_name 命令就可以将一个文件回退到 HEAD 指向版本所对应的状态，其实就是当前版本库中的状态，也就相当于还原了本地的修改。 git rm临时插播的命令，本来删除不能算是回退，但是如果它和某些命令反着来就是一种回退，比如对一个新文件使用 git add newfile_name 命令，然后再使用 git rm --cached newfile_name 就可以将这个文件从暂存区移除掉，但是在工作区里没有消失，如果不加 --cached 参数，就会从工作区和版本库暂存区同时删除，相当于执行了 rm newfile_name 和 git add new_file 两条命令。 具体回退操作说了这么多肯定有点懵，特别是一个相同的需求可以使用很多命令来实现的时候，接下来看一些具体需求，整个测试过程用上一篇总结《git branch常用分支操作》使用的 git 仓库来进行，远程地址是 git@gitee.com:myname/gitstart.git，下面测试开始，我们看一下这些情况怎么进行还原： 初始状态12345678910111213141516171819202122albert@homepc MINGW64 /d/gitstart (dev)$ lsREADME.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.nothing to commit, working tree cleanalbert@homepc MINGW64 /d/gitstart (dev)$ git branch -a* dev master remotes/origin/dev remotes/origin/masteralbert@homepc MINGW64 /d/gitstart (dev)$ git branch -vv* dev 3226b63 [origin/dev] add readme file master 3226b63 [origin/master] add readme file 还原00：工作区中未加到暂存区和版本库的文件，还原今天所做的修改实话实说，办不到，没有加到过暂存区就没有被追踪，它的任何修改是没有办法回退的，可是使用 Ctrl+Z 碰碰运气，没准就退回到了你想要的状态。 还原01：工作区中未加到暂存区和版本库的文件，执行了 git add 操作这种情况可以使用git rm --cached newfile、git restore --staged newfile 或者 git reset HEAD newfile 命令，使用后两个命令的时候不能是版本库的第一个文件。 git rm1234567891011121314151617181920212223242526272829303132albert@homepc MINGW64 /d/gitstart (dev)$ echo "test data"&gt;new.txtalbert@homepc MINGW64 /d/gitstart (dev)$ git add new.txtwarning: LF will be replaced by CRLF in new.txt.The file will have its original line endings in your working directoryalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes to be committed: (use "git restore --staged &lt;file&gt;..." to unstage) new file: new.txtalbert@homepc MINGW64 /d/gitstart (dev)$ git rm --cached new.txtrm 'new.txt'albert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Untracked files: (use "git add &lt;file&gt;..." to include in what will be committed) new.txtnothing added to commit but untracked files present (use "git add" to track) git restore12345678910111213141516171819202122232425262728albert@homepc MINGW64 /d/gitstart (dev)$ git add new.txtwarning: LF will be replaced by CRLF in new.txt.The file will have its original line endings in your working directoryalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes to be committed: (use "git restore --staged &lt;file&gt;..." to unstage) new file: new.txtalbert@homepc MINGW64 /d/gitstart (dev)$ git restore --staged new.txtalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Untracked files: (use "git add &lt;file&gt;..." to include in what will be committed) new.txtnothing added to commit but untracked files present (use "git add" to track) git reset12345678910111213141516171819202122232425262728albert@homepc MINGW64 /d/gitstart (dev)$ git add new.txtwarning: LF will be replaced by CRLF in new.txt.The file will have its original line endings in your working directoryalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes to be committed: (use "git restore --staged &lt;file&gt;..." to unstage) new file: new.txtalbert@homepc MINGW64 /d/gitstart (dev)$ git reset HEAD new.txtalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Untracked files: (use "git add &lt;file&gt;..." to include in what will be committed) new.txtnothing added to commit but untracked files present (use "git add" to track) 还原02：版本库中的文件，修改或删除后未执行 git add 操作我们直接修改 README.md 文件吧，删除刚才添加的未受版本管理的 new.txt，在 README.md 文件中添加内容，然后试着还原，这种情况常常出现在修改一个功能还未提交，但是先不要求修改了，可以直接还原。 这种情况可以使用git restore file_name、git checkout -- file_name 或者 git reset --hard HEAD 命令，最后的git reset 命令带有 --hard 参数不能再加文件目录，只能将工作区全还原。 git restore123456789101112131415161718192021222324albert@homepc MINGW64 /d/gitstart (dev)$ echo "new line"&gt;&gt;README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (dev)$ git restore README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.nothing to commit, working tree clean git checkout123456789101112131415161718192021222324albert@homepc MINGW64 /d/gitstart (dev)$ echo "new line"&gt;&gt;README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (dev)$ git checkout -- README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.nothing to commit, working tree clean git reset1234567891011121314151617181920212223242526272829albert@homepc MINGW64 /d/gitstart (dev)$ echo "new line"&gt;&gt;README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (dev)$ git reset --hard HEAD README.mdfatal: Cannot do hard reset with paths.albert@homepc MINGW64 /d/gitstart (dev)$ git reset --hard HEADHEAD is now at 3226b63 add readme filealbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.nothing to commit, working tree clean 还原03：版本库中的文件，修改或删除后执行了 git add 操作使用了 git add 命令之后，文件的改变就放到了暂存区，这种情况可以使用git restore --staged file_name 或者 git reset HEAD file_name 命令。 git restore执行 git restore --staged file_name 实际上是使用版本库中的文件覆盖暂存区中的数据，执行结束后文件状态变成了 &lt;还原02&gt; 中的情况。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051albert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.nothing to commit, working tree cleanalbert@homepc MINGW64 /d/gitstart (dev)$ echo "test add"&gt;&gt;README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (dev)$ git add README.mdwarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directoryalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes to be committed: (use "git restore --staged &lt;file&gt;..." to unstage) modified: README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git restore --staged README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a") git resetgit reset 命令如果加上 --hard 参数不能再加文件目录，只能将工作区全还原，如果不加默认参数为 --mixed，执行之后修改的文件状态变成了 &lt;还原02&gt; 中的情况。 12345678910111213141516171819202122232425262728293031323334353637383940414243albert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (dev)$ git add README.mdwarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directoryalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes to be committed: (use "git restore --staged &lt;file&gt;..." to unstage) modified: README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git reset HEAD README.mdUnstaged changes after reset:M README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a") 还原04：版本库中的文件，修改或删除后执行了 git add、git commit 操作git commit 命令一旦执行了之后就形成了“历史”，我们叫做提交日志，要想回退就得有篡改历史的能力，很幸运 Git 给了我们这种能力，其实提交之后我们可以把本地文件反向修改，然后再提交一次，但是我们说的还原，一般都是只倒退，既然是错误的提交，我们就像把这段“历史”抹去，这时就要用到 git reset HEAD^ 命令。 执行这个命令之后，刚刚的提交记录就被抹掉了，文件状态就回到了 &lt;还原02&gt; 的情况，如果加上参数 --soft 就会回到 &lt;还原03&gt; 的情况，如果加上参数 --hard ，就不能添加 file_name 这个文件名，然后整个工作区倒退到上一次修改之前，其他两种参数 --mixed 和 --soft 就可以指定添加名字。 这里的 HEAD^ 表示最新版本的前一版，也就是倒数第二版本，可以类推，HEAD^^ 表示倒数第三版本，HEAD^^^ 表示倒数第四版本。 另外还有另一种写法 HEAD~1 表示最新版本的前一版，也就是倒数第二版本，HEAD~2 表示倒数第三版本，HEAD~3 表示倒数第四版本。 其中 ^ 和 ~ 的含义并不相同，涉及到合并分支的概念，有兴趣的话可以多了解下，这里就不展开了，继续还原当前这种情况，我们选择 git reset HEAD^ 命令，先提交看下： 12345678910111213141516171819202122232425262728293031323334353637383940414243albert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (dev)$ git add README.mdwarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directoryalbert@homepc MINGW64 /d/gitstart (dev)$ git commit -m"modify readme 1"[dev 8a40f22] modify readme 1 1 file changed, 1 insertion(+)albert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is ahead of 'origin/dev' by 1 commit. (use "git push" to publish your local commits)nothing to commit, working tree cleanalbert@homepc MINGW64 /d/gitstart (dev)$ git log -2commit 8a40f229881da037ff99070fa205d7819ba9f51b (HEAD -&gt; dev)Author: albert &lt;qianxuan101@163.com&gt;Date: Sat Mar 7 15:46:32 2020 +0800 modify readme 1commit 3226b63185a16398a02d5eaea47c95309ba49588 (origin/master, origin/dev, release, master)Author: albert &lt;qianxuan101@163.com&gt;Date: Wed Feb 26 00:36:35 2020 +0800 add readme file 然后再还原试试： 123456789101112131415161718192021222324albert@homepc MINGW64 /d/gitstart (dev)$ git reset HEAD^Unstaged changes after reset:M README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (dev)$ git log -2commit 3226b63185a16398a02d5eaea47c95309ba49588 (HEAD -&gt; dev, origin/master, origin/dev, release, master)Author: albert &lt;qianxuan101@163.com&gt;Date: Wed Feb 26 00:36:35 2020 +0800 add readme file 怎么样，历史被我们抹除了，需要注意的是，如果想还原“历史”，那么 git set 命令后面不能跟文件名，也就是说必须整个还原到上一版本，否则就相当于将单个文件简单反向修改添加到暂存区，而之前对文件的修改保留在本地，文件的日志并没有回退，具体的文件状态还得你自己操作感受一下。 还原05：版本库中的文件，修改或删除后执行了 git add、git commit、git push 操作这种情况就是还原远程仓库的日志记录了，实际上操作步骤先按照 &lt;还原04&gt; 来处理，然后将本地分支情况推送到远程分支即可。 我们先把刚才的修改提交，然后推送到远程分支，使用 git status 可以看到本地分支已经领先远程分支了(Your branch is ahead of ‘origin/dev’ by 1 commit.)， git push 操作之后两个分支同步了。 1234567891011121314151617181920212223242526272829303132albert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is ahead of 'origin/dev' by 1 commit. (use "git push" to publish your local commits)nothing to commit, working tree cleanalbert@homepc MINGW64 /d/gitstart (dev)$ git logcommit a5b6c18db71a0487f6316f5db4304a99984f2ab3 (HEAD -&gt; dev)Author: albert &lt;qianxuan101@163.com&gt;Date: Sat Mar 7 15:51:56 2020 +0800 modify readme 1commit 3226b63185a16398a02d5eaea47c95309ba49588 (origin/master, origin/dev, release, master)Author: albert &lt;qianxuan101@163.com&gt;Date: Wed Feb 26 00:36:35 2020 +0800 add readme filealbert@homepc MINGW64 /d/gitstart (dev)$ git pushWarning: Permanently added the ECDSA host key for IP address '180.97.125.228' to the list of known hosts.Enumerating objects: 5, done.Counting objects: 100% (5/5), done.Writing objects: 100% (3/3), 286 bytes | 286.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)remote: Powered by GITEE.COM [GNK-3.8]To gitee.com:myname/gitstart.git 3226b63..a5b6c18 dev -&gt; dev 这时通过远程仓库的管理软件，你可以看到远程分支已经有了最新的提交，然后我们可以参考 &lt;还原04&gt; 的情况，先将本地日志还原，再推送到远程仓库。 1234567891011121314151617181920212223242526272829303132333435albert@homepc MINGW64 /d/gitstart (dev)$ git reset HEAD^Unstaged changes after reset:M README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is behind 'origin/dev' by 1 commit, and can be fast-forwarded. (use "git pull" to update your local branch)Changes not staged for commit: (use "git add &lt;file&gt;..." to update what will be committed) (use "git restore &lt;file&gt;..." to discard changes in working directory) modified: README.mdno changes added to commit (use "git add" and/or "git commit -a")albert@homepc MINGW64 /d/gitstart (dev)$ git logcommit 3226b63185a16398a02d5eaea47c95309ba49588 (HEAD -&gt; dev, origin/master, release, master)Author: albert &lt;qianxuan101@163.com&gt;Date: Wed Feb 26 00:36:35 2020 +0800 add readme filealbert@homepc MINGW64 /d/gitstart (dev)$ git pushTo gitee.com:myname/gitstart.git ! [rejected] dev -&gt; dev (non-fast-forward)error: failed to push some refs to 'git@gitee.com:myname/gitstart.git'hint: Updates were rejected because the tip of your current branch is behindhint: its remote counterpart. Integrate the remote changes (e.g.hint: 'git pull ...') before pushing again.hint: See the 'Note about fast-forwards' in 'git push --help' for details. 和想象的不太一样的，这种情况是远程仓库的记录领先，无法直接推送，此时可以添加 -f 参数，用本地提交记录覆盖远程分支记录： 123456albert@homepc MINGW64 /d/gitstart (dev)$ git push -fTotal 0 (delta 0), reused 0 (delta 0)remote: Powered by GITEE.COM [GNK-3.8]To gitee.com:myname/gitstart.git + a5b6c18...3226b63 dev -&gt; dev (forced update) 这次再查询远程分支记录，发现也被回退了，目的达成。 还原06：两次git commit 之后产生两条日志，只还原第一次提交这种情况其实发生了两次修改和两次提交，和 &lt;还原05&gt; 情况不同的是要还原的提交不是最后一次，如果使用 git reset 命令必然将最后一次修改也还原了，虽然不能直接完成，但是给我们提供了解决问题的思路： 第一种方法：直接使用 git reset HEAD^^ 命令还原两次提交，然后在工作区将文件按第二次修改再改一次进行提交，这种方法适用于想要抹除第一次提交历史的情况。 第二种方法：如果你不在意提交历史，只是想还原第一次修改，那么可以使用 git revert HEAD^ 命令来反向修改那一次变化，修改之后会自动添加到暂存区，等待提交。 先来修改提交两次，产生两次记录： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758albert@homepc MINGW64 /d/gitstart (dev)$ git statusOn branch devYour branch is up to date with 'origin/dev'.nothing to commit, working tree cleanalbert@homepc MINGW64 /d/gitstart (dev)$ echo "m1"&gt;&gt;README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git add README.mdwarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directoryalbert@homepc MINGW64 /d/gitstart (dev)$ git commit -m"modify README 1"[dev e570df1] modify README 1 1 file changed, 1 insertion(+)albert@homepc MINGW64 /d/gitstart (dev)$ echo "m2"&gt;&gt;README.mdalbert@homepc MINGW64 /d/gitstart (dev)$ git add README.mdwarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directoryalbert@homepc MINGW64 /d/gitstart (dev)$ git commit -m"modify README 2"[dev 140547f] modify README 2 1 file changed, 1 insertion(+)gialbert@homepc MINGW64 /d/gitstart (dev)$ git logcommit 140547f8d0b10d9a388beaf2ce522c38c878a839 (HEAD -&gt; dev)Author: albert &lt;qianxuan101@163.com&gt;Date: Sat Mar 7 16:26:17 2020 +0800 modify README 2commit e570df134b39ee7424bc8c48c1067e72c3fb9637Author: albert &lt;qianxuan101@163.com&gt;Date: Sat Mar 7 16:26:07 2020 +0800 modify README 1commit 3226b63185a16398a02d5eaea47c95309ba49588 (origin/master, origin/dev, release, master)Author: albert &lt;qianxuan101@163.com&gt;Date: Wed Feb 26 00:36:35 2020 +0800 add readme filealbert@homepc MINGW64 /d/gitstart (dev)$ cat README.mdlearn git branch commandm1m2 然后使用 git revert HEAD^ 还原第一次修改记录： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647albert@homepc MINGW64 /d/gitstart (dev)$ git revert HEAD^Auto-merging README.mdCONFLICT (content): Merge conflict in README.mderror: could not revert e570df1... modify README 1hint: after resolving the conflicts, mark the corrected pathshint: with 'git add &lt;paths&gt;' or 'git rm &lt;paths&gt;'hint: and commit the result with 'git commit'albert@homepc MINGW64 /d/gitstart (dev|REVERTING)$ vi README.mdalbert@homepc MINGW64 /d/gitstart (dev|REVERTING)$ git add README.mdalbert@homepc MINGW64 /d/gitstart (dev|REVERTING)$ git commit[dev 6ae97d0] Revert "modify README 1" 1 file changed, 1 deletion(-)albert@homepc MINGW64 /d/gitstart (dev)$ git logcommit 6ae97d0e136abc1ed241854298037ca9d1c4460c (HEAD -&gt; dev)Author: albert &lt;qianxuan101@163.com&gt;Date: Sat Mar 7 16:31:50 2020 +0800 Revert "modify README 1" This reverts commit e570df134b39ee7424bc8c48c1067e72c3fb9637.commit 140547f8d0b10d9a388beaf2ce522c38c878a839Author: albert &lt;qianxuan101@163.com&gt;Date: Sat Mar 7 16:26:17 2020 +0800 modify README 2commit e570df134b39ee7424bc8c48c1067e72c3fb9637Author: albert &lt;qianxuan101@163.com&gt;Date: Sat Mar 7 16:26:07 2020 +0800 modify README 1commit 3226b63185a16398a02d5eaea47c95309ba49588 (origin/master, origin/dev, release, master)Author: albert &lt;qianxuan101@163.com&gt;Date: Wed Feb 26 00:36:35 2020 +0800 add readme file 因为修改了同一个文件，还原的时候还产生了冲突，解决冲突之后才提交，看日志发现这是一条新的记录，在实际操作的过程中可能会发生比这还要麻烦的场景，多练就好了。 常用集合使用 Git 进行版本管理时，遇到的回退情况远不止这么多，这只是我目前常见的，之后遇到还会补充，每种情况我们其实不止有一种解决方式，接下来对于每种情况给一个我个人常用的处理方式，因为 git checkout 的作用被逐渐拆分成更具体的 git switch 和 git restore，我们尽量选择功能明确的命令： 还原00：工作区中未加到暂存区和版本库的文件，还原今天所做的修改 尝试下Ctrl+z吧，不行就找找自动保存的缓存文件，看看能不能找到之前版本 还原01：工作区中未加到暂存区和版本库的文件，执行了 git add 操作 直接使用 git restore --staged file_name 命令，如果版本不支持则使用 git rm --cached file_name 还原02：版本库中的文件，修改或删除后未执行 git add 操作 直接使用 git restore file_name 命令，如果版本不支持则使用 git checkout -- file_name 还原03：版本库中的文件，修改或删除后执行了 git add 操作 直接使用 git restore --staged file_name 命令，按 &lt;还原02&gt; 情况处理 还原04：版本库中的文件，修改或删除后执行了 git add、git commit 操作 直接使用 git reset HEAD^ 命令，按 &lt;还原02&gt; 情况处理，或者使用 git reset --soft HEAD^ 命令，按 &lt;还原03&gt; 情况处理 还原05：版本库中的文件，修改或删除后执行了 git add、git commit、git push 操作 先按照 &lt;还原04&gt; 情况处理，然后使用 git push -f 命令 还原06：两次git commit 之后产生两条日志，只还原第一次提交 使用 git revert HEAD^ 命令，解决冲突后提交，revert 后面跟具体的 commit id 也可以。 总结 参考这些具体的例子你会发现，很多操作选择在使用 git status 之后都有列举 所以说 git status 是一个可以提示你做选择的强大帮手，不知所措时可以试试它 Git 2.23版本之后学会用 git switch 和 git restore 命令，因为之前 git checkout 背负了太多了 最后放一幅图吧，只画了主要的，没有画出全部情况，否则会很乱，可以对照着练习一下]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>checkout</tag>
        <tag>reset</tag>
        <tag>revert</tag>
        <tag>restore</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[git branch常用分支操作]]></title>
    <url>%2Fblog%2F2020%2F02%2F25%2Fgit-branch%E5%B8%B8%E7%94%A8%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言最近代码的版本控制工具由SVN换成了Git，只用管理个人项目常用的灵魂三步git add、git commit、git push看来是行不通了，之前虽然也一直在用 git，但是用法很有限，主要集中在前面提到的三步，所以为了更好的工作，我决定还是好好总结一下。 分支在Git的操作里有着很重要的地位，代表了不同的开发线路，创建一个分支，也就多了一个索引文件，相比于SVN分支拷贝全部文件来说来方便的多，所以Git使得按功能分支的开发模式变得非常简单，在开发过程中常常需要对分支进行操作。 远程仓库本来就几个分支，操作上也没有太麻烦，但是加入了远程仓库以后，事情变得复杂起来。有了远程仓库一般意味着代码开发需要多人合作了，这时候常常会产生冲突，分支合并时也变得不那么容易了。 远程仓库其实也很好理解，就是放在远处用来保存代码资源的一个仓库，其实和本地的代码库没有什么区别，这个远程仓库主要是为了把大家修改的代码都合并到一起，给大家提供一个统一的目标点。 远程仓库究竟有多远，常见的代码托管平台：github、gitlab、码云都可以提供远程仓库，如果你在月球上放置一台可以联网的代码仓库服务器，那么距离就是38.4万千米，但是远程仓库也可以很近，你也可以把本机电脑的D盘里的代码仓库作为E盘的代码仓库的远程仓库，或许远程仓库可能只和你隔了一个文件夹。 由于网络的原因，github 和 gitlab 访问常常很慢，所以为了做练习测试推送，我在码云创建了一个仓库 gitstart，它的地址大概是这个样子：git@gitee.com:myname/gitstart.git，创建的方法一搜一大把，上面提到的几个托管平台，在哪创建都可以，一定要记住地址，因为后面还要用到。 建立联系本地创建文件夹并进入12345678albert@homepc MINGW64 /d$ mkdir gitstartalbert@homepc MINGW64 /d$ cd gitstart/albert@homepc MINGW64 /d/gitstart$ 这里的文件夹名字可以和远程仓库不同，但是为了看起来方便对应，还是取相同的名字好一点。 初始化仓库123456albert@homepc MINGW64 /d/gitstart$ git initInitialized empty Git repository in D:/gitstart/.git/albert@homepc MINGW64 /d/gitstart (master)$ 临时插播好奇心（不在流程中）目前这个状态有点意思，初始化完之后，(master) 这个字符串表示当前是在 master分支，查一下日志看看： 123456albert@homepc MINGW64 /d/gitstart (master)$ git logfatal: your current branch 'master' does not have any commits yetalbert@homepc MINGW64 /d/gitstart (master)$ 提示也是正确的，说 master分支没有任何提交，但是我们查询一下分支看看： 12345albert@homepc MINGW64 /d/gitstart (master)$ git branch -aalbert@homepc MINGW64 /d/gitstart (master)$ 居然是空的，没有分支，查询 .git\HEAD 文件发现里面有一行 ref: refs/heads/master，说明当前分支时 master，但是为什么查询分支没有结果呢？ 打开 .git\refs\heads 目录，发现这个文件夹下根本没有 master文件，其实想想也对，Git 中的分支其实对应着 commit id，现在什么都没有提交，master 也就找不到 commit id，所以就是有 master 文件，里面也不知道写什么。 查询远程仓库12345albert@homepc MINGW64 /d/gitstart (master)$ git remote -valbert@homepc MINGW64 /d/gitstart (master)$ 依旧什么内容都没有，说明还没有和远程仓库建立联系。 与远程仓库建立对应关系12345678910albert@homepc MINGW64 /d/gitstart (master)$ git remote add origin git@gitee.com:myname/gitstart.gitalbert@homepc MINGW64 /d/gitstart (master)$ git remote -vorigin git@gitee.com:myname/gitstart.git (fetch)origin git@gitee.com:myname/gitstart.git (push)albert@homepc MINGW64 /d/gitstart (master)$ 这一步需要注意，origin看起来就是一个远程仓库的别名，代表着 git@gitee.com:myname/gitstart.git 这个代码仓库，刚刚提到过，这个远程仓库也可以是本地的，所以你添加git remote add origin d:/test 也是可以的，就表明 gitstart 的远程仓库是本地的 test 仓库。 第一个分支刚刚说过，现在本地库的状态有些特殊，实际上刚刚在码云上创建的 git@gitee.com:myname/gitstart.git 库也很特殊，他们都没有真正的分支，这时只要我们成功提交一次，创建一个commit id，就相当于初始化了master分支。 添加README文件12345678910111213albert@homepc MINGW64 /d/gitstart (master)$ echo "learn git branch command"&gt;README.mdalbert@homepc MINGW64 /d/gitstart (master)$ git add README.mdwarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directoryalbert@homepc MINGW64 /d/gitstart (master)$ git commit -m"add readme file"[master (root-commit) 3226b63] add readme file 1 file changed, 1 insertion(+) create mode 100644 README.md 查询当前分支123albert@homepc MINGW64 /d/gitstart (master)$ git branch -a* master 这次可以是出现了，分支为 master，前面的 * 表示为当前分支。 将分支推送到远程仓库12345678910albert@homepc MINGW64 /d/gitstart (master)$ git push -u origin masterEnumerating objects: 3, done.Counting objects: 100% (3/3), done.Writing objects: 100% (3/3), 248 bytes | 248.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)remote: Powered by GITEE.COM [GNK-3.8]To gitee.com:myname/gitstart.git * [new branch] master -&gt; masterBranch 'master' set up to track remote branch 'master' from 'origin'. 至此，本地仓库和远程仓库就建立了联系，下面可以开始学习 Git 分支命令了。 分支操作新建分支新建分支可以使用 git branch branch_name 命令，以下就是一个创建名为 release 分支的命令： 12albert@homepc MINGW64 /d/gitstart (master)$ git branch release 也可以使用 git checkout -b branch_name 来创建一个新分支，创建完会自动切换到新分支： 123456albert@homepc MINGW64 /d/gitstart (master)$ git checkout -b devSwitched to a new branch 'dev'albert@homepc MINGW64 /d/gitstart (dev)$ 切换分支这是一个很奇怪的命令，命令格式为 git checkout branch_name，总感觉 checkout 子命令包揽了不属于自己的工作，如果在git branch的基础上加一个参数会更合理的一点，但这和切换分支的实际含义可能还有关系，切换分支其实就是修改HEAD文件中的 commit id，而没有真正的发生切换。 12345678910albert@homepc MINGW64 /d/gitstart (dev)$ git checkout releaseSwitched to branch 'release'albert@homepc MINGW64 /d/gitstart (release)$ git checkout devSwitched to branch 'dev'albert@homepc MINGW64 /d/gitstart (dev)$ 查看本地分支像刚才我们创建的 release 分支和 dev 分支都是在本地创建的，这样的分支通过 git branch 命令就可以查看 12345albert@homepc MINGW64 /d/gitstart (dev)$ git branch* dev master release 这样就列举了本地的所有分支，在当前分支名字 dev 前面哈还有一个 * 作为标记 查看远程分支只要在上面的命令基础上加上 -r 参数就行了 123albert@homepc MINGW64 /d/gitstart (dev)$ git branch -r origin/master 查询到的分支只有 origin/master 一个，这个分支是一开始我们进行第一次提交产生 master 分支之后，通过 git push -u origin master 推送到远程仓库的，所以现在只有一个。 查看所有分支所有分支包括本地分支和远程分支，将 -r 参数换成 -a 参数就可以了 123456albert@homepc MINGW64 /d/gitstart (dev)$ git branch -a* dev master release remotes/origin/master 将本地分支推送到远程仓库其实之前已经操作过了，可以试着复习一下，git push -u origin branch_name，其实这是一个简写，-u 可以写成 --set-upstream 表示设置上游分支，其实就是和远程仓库的分支建立联系。 branch_name 也是 local_branch_name:remote_branch_name的一种简写，冒号前表示本地分支，冒号后面表示远程分支，如果只写一个就表示两个分支名相同，远程仓库中如果没有这个分支就会新建一个。 也就是说 git push -u origin dev 和 git push--set-upstream origin dev:dev 是一样的，下面来试一下，然后查看一下分支： 1234567891011121314151617albert@homepc MINGW64 /d/gitstart (dev)$ git push -u origin devTotal 0 (delta 0), reused 0 (delta 0)remote: Powered by GITEE.COM [GNK-3.8]remote: Create a pull request for 'dev' on Gitee by visiting:remote: https://gitee.com/myname/gitstart/pull/new/myname:dev...myname:masterTo gitee.com:myname/gitstart.git * [new branch] dev -&gt; devBranch 'dev' set up to track remote branch 'dev' from 'origin'.albert@homepc MINGW64 /d/gitstart (dev)$ git branch -a* dev master release remotes/origin/dev remotes/origin/master 冒号前后的米名字是不是一定相同呢？完全没有必要，我们可以让本地的 release 分支对应远程的 master 分支，只不过这样怪怪的，但是操作上完全可以的。 12345678albert@homepc MINGW64 /d/gitstart (dev)$ git checkout releaseSwitched to branch 'release'albert@homepc MINGW64 /d/gitstart (release)$ git push -u origin release:masterEverything up-to-dateBranch 'release' set up to track remote branch 'master' from 'origin'. 查看本地分支与远程分支对应关系这个也是刚刚知道的，可以使用 git branch -vv 命令，注意是两个 v: 12345albert@homepc MINGW64 /d/gitstart (release)$ git branch -vv dev 3226b63 [origin/dev] add readme file master 3226b63 [origin/master] add readme file* release 3226b63 [origin/master] add readme file 执行这个命令之后可以看出，本地的 master 和 release 分支都对应着远程的 master 分支 删除本地分支我们先复习一下新建分支，然后把它推送到远程仓库，再使用 git branch -d branch_name 命令进行删除 12345678910111213141516171819202122albert@homepc MINGW64 /d/gitstart (release)$ git checkout -b feature_testSwitched to a new branch 'feature_test'albert@homepc MINGW64 /d/gitstart (feature_test)$ git push origin feature_testTotal 0 (delta 0), reused 0 (delta 0) remote: Powered by GITEE.COM [GNK-3.8]remote: Create a pull request for 'feature_test' on Gitee by visiting:remote: https://gitee.com/myname/gitstart/pull/new/myname:feature_test...myname:masterTo gitee.com:myname/gitstart.git * [new branch] feature_test -&gt; feature_testalbert@homepc MINGW64 /d/gitstart (feature_test)$ git branch -a dev* feature_test master release remotes/origin/dev remotes/origin/feature_test remotes/origin/master 开始删除分支，删除之前记得切换到别的分支，否则删除不成功 1234567891011121314151617albert@homepc MINGW64 /d/gitstart (feature_test)$ git checkout devSwitched to branch 'dev'Your branch is up to date with 'origin/dev'.albert@homepc MINGW64 /d/gitstart (dev)$ git branch -d feature_testDeleted branch feature_test (was 3226b63).albert@homepc MINGW64 /d/gitstart (dev)$ git branch -a* dev master release remotes/origin/dev remotes/origin/feature_test remotes/origin/master 删除远程分支通过上面的操作我们发现只删除了本地的分支，远程的分支还在，要想删除远程分支，需要使用 git push origin --delete branch_name 命令 12345678910111213albert@homepc MINGW64 /d/gitstart (dev)$ git push origin --delete feature_testremote: Powered by GITEE.COM [GNK-3.8]To gitee.com:myname/gitstart.git - [deleted] feature_testalbert@homepc MINGW64 /d/gitstart (dev)$ git branch -a* dev master release remotes/origin/dev remotes/origin/master 这次再查看时发现远程分支也被删掉了。 获取远程主分支到本地其实 Git 的克隆命令默认就是把远程仓库的主分支下载到本地，我们可以使用 git clone 远程地址 本地文件夹 命令来克隆一个仓库，如果本地文件夹省略，则默认新建一个与仓库名相同的文件夹： 1234567891011121314151617albert@homepc MINGW64 /d$ git clone https://gitee.com/myname/gitstart.git gitstartcopyCloning into 'gitstartcopy'...remote: Enumerating objects: 3, done.remote: Counting objects: 100% (3/3), done.remote: Total 3 (delta 0), reused 0 (delta 0)Unpacking objects: 100% (3/3), done.albert@homepc MINGW64 /d$ cd gitstartcopy/albert@homepc MINGW64 /d/gitstartcopy (master)$ git branch -a* master remotes/origin/HEAD -&gt; origin/master remotes/origin/dev remotes/origin/master 获取远程其他分支到本地从上面命令执行后的结果来看，当前本地仓库中只有 master 分支，其他的分支都是在远程仓库上，这时可以用 git checkout branch_name 命令来下载远程分支： 1234567891011121314151617albert@homepc MINGW64 /d/gitstartcopy (master)$ git checkout devSwitched to a new branch 'dev'Branch 'dev' set up to track remote branch 'dev' from 'origin'.albert@homepc MINGW64 /d/gitstartcopy (dev)$ git branch -a* dev master remotes/origin/HEAD -&gt; origin/master remotes/origin/dev remotes/origin/masteralbert@homepc MINGW64 /d/gitstartcopy (dev)$ git branch -vv* dev 3226b63 [origin/dev] add readme file master 3226b63 [origin/master] add readme file 看到这里可能会疑惑了，git checkout branch_name 不是切换分支的命令吗？实际上当 branch_name 分支在本地不存在而远程仓库存在时，这个命令与 git checkout -b &lt;branch&gt; --track &lt;remote&gt;/&lt;branch&gt; 含义相同，会在本地新建一个分支，并与远程分支建立联系。 常用集合 新建分支：git checkout -b branch_name 切换分支：git checkout branch_name 查看分支：git branch -a 删除分支：git branch -d branch_name 推送分支到远程：git push origin branch_name 删除远程的分支：git push origin --delete branch_name 拉取远程分支到本地：git checkout branch_name 查询分支的对应关系：git branch -vv 总结 以上这些命令都是在本地测试过的，可能考虑的不太全面，不过没关系，以后的分支操作还会补充到这里。 这些命令在有些特殊的情况下使用可能会遇到问题，如果大家发现了问题请及时指出，我会尽快修改的。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>branch</tag>
        <tag>checkout</tag>
        <tag>push</tag>
        <tag>remote</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[挥一挥衣袖，开始一段新的旅程]]></title>
    <url>%2Fblog%2F2020%2F02%2F16%2F%E6%8C%A5%E4%B8%80%E6%8C%A5%E8%A1%A3%E8%A2%96%EF%BC%8C%E5%BC%80%E5%A7%8B%E4%B8%80%E6%AE%B5%E6%96%B0%E7%9A%84%E6%97%85%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[悄悄的我走了，正如我悄悄的来；我挥一挥衣袖，不带走一片云彩。 前言钱钟书老先生在《围城》中说道:“天下只有两种人。比如一串葡萄到手，一种人挑最好的先吃，另一种人把最好的留到最后吃。照例第一种人应该乐观，因为他每吃一颗都是吃剩的葡萄里最好的；第二种人应该悲观，因为他每吃一颗都是吃剩的葡萄里最坏的。不过事实却适得其反，缘故是第二种人还有希望，第一种人只有回忆”。 而我在反思自己时却发现，无法将自身完全归于这两种人的一类，如果非要选一种，我更像是老先生提到的第二种人，总喜欢把最好的留到最后。按理说这样的人应该总是向前充满希望的，但是我却热衷于收集回忆，记录生活中的点点滴滴，认真记下生活中的每一笔支出，写下人生中一次次感动… 其实一开始我并没有这方面的爱好，不知从何时起，儿时的记忆渐渐和梦境中的画面杂糅在了一起，有些事情已经分不清是之前确实发生的，还是曾经在梦境中悄悄的来到过，所以慢慢地我养成了这样的习惯，记录生活中一切想要被回忆的事情，期待着有一天能与对此感兴趣的人一起分享这些点点滴滴。 缘由技术博客中很少写自己的生活，这一次其实也和技术有关，在一个工作岗位上勤勤恳恳工作六年之后，今年终于鼓足勇气决定出来找找新的机会，确定了新的目标之后回头看看这六年收获了很多，同时在这段找工作的经历中也学会了不少东西，新的工作基本定下来了，现在总结一下工作以来的经历以及面试中遇到的问题，方便后续复盘时能有个参照。 懵懵懂懂的6年前走出校门从大四学期便开始走出校门，一切按照教学大纲进行着，大四这年是企业实训，我们被安排到一家机构进行学习，学习结束已经13年的深冬，我们一群小伙伴作为花朵开始走出曾经的温室。 其实从实训的后半段我们已经开始在北京各大高校“流窜”，参加了很多不请自来的校招，进行了一轮轮的笔试，但很少有人从中得到满意的工作机会，我也尝试过几次，但是感觉自己真的很渺小，经过努力得到了一个大厂的面试邀请，我怀着激动的心情前去面试，走的时候还换上了自己都觉得怪异的正装，好在面试官并不在意我的这份不自然，完全投入身心开始进行面试。 很幸运我通过了一面，但是在去参加二面的路上我才发现后背已经被汗水浸湿了，之前也参加过几次面试，但是这一次确实是让我身心俱疲，从中也渐渐体会到了不同公司之间的技术差距，我一心想加入这个团体，但是二面的结果又把我拉回了现实，二面的过程很糟糕，有一道题我至今还记得，那就是关于数据库的连接，但是回答的很模糊，由于自己的知识储备不足，我怀疑自己当时连题目都没有弄懂。 走进社会大厂失利后，开始寻找其他的机会，毕竟工作是现在的第一要务，放弃了保研机会一心想着早点参加工作，如果连工作都找不到岂不是让人笑话了，时间不久便通过了几家面试，其中有意向可以试试的有两家，一家是做偏硬件的软件，另一家就是做游戏开发的，工资待遇差不多，相比较而言第一家要高一些，但是当时沉迷于Dota的我经过“深思熟虑”之后，委婉的谢绝了第一家的邀请，进入了这家游戏公司，也就是后来我工作了6年的公司。 开始工作我的人生很幸运，我一直这样觉得，在这里我碰到了我工作的中的第一位导师，都说师傅领进门，修行在个人，那么他就是我进入社会环境的那个师傅，但是他比我也大不了几岁，我更愿意称呼他为兄长。 时光荏苒，岁月如梭，即便转眼已经过去了6年多，但是工作第一天他让我修改的第一个BUG我至今还记得，那是一把“罪恶坑的钥匙”，BUG具体的细节并不重要，而是他处理的方式让我记忆犹新。 开发环境配置好之后，兄长便指给我一个BUG，让我尝试修改，便是那个“罪恶坑的钥匙”，第二天他就过来询问BUG的修改情况，我告诉他我的修改思路A，他说可以这样改，但是这种修改方式可能会给后面带来一些不利于扩展的问题，然后在他的电脑上给我看了他建议的修改思路B，然后让我按照这个思路去修改，我比较之后确实思路B更好一些。问题的关键是这个BUG他已经想好了修改方案，并且尝试修改过，他指定让我修改完全是为了帮我熟悉问题的处理方式而非完成工作。 之后也和一些其他领导沟通过工作，但是能这样带我入门的兄长就只此一个，其他人大多是就是完成工作即可，很少有人再想教我的什么东西了。我是幸运的，在我懵懂的年纪碰上了这样一位领路人，之后我们在项目组之间分分合合，但始终工作在同一个屋檐下。 勤勤恳恳的6年初入职场刚刚参见工作，一切都显得那么新鲜，经常会有这样的感叹：原来游戏中的这个功能是这样实现的！开始的时候对于工作的状态还是有点不适应，印象最深的就是下午的时候总是昏昏沉沉的，当时可以用“熬”这个字来形容，但是随着后面工作内容的铺开，大脑在紧张的处理这些问题时，犯困的毛病就改掉了。 工作之前写的项目很多是个人完成的，就是几个人合伙做一个项目，基本上也不太大，所有的代码也都很了解，但是刚接触这个游戏项目时感觉它太大了，所有的代码只能不断的搜索才能找到，仿照已有的功能开发了两个新功能之后，渐渐的找到了感觉。 很长一段时间之后再回过头来看自己的代码时会发出这样的感叹：这段代码是我写的吗？现在整个流程我已经清楚了，但是当时写这段代码的时候是怎么找到这里的。其实一开始写代码完全是照葫芦画瓢，很多语句不知道什么意思，但是功能类似，这样写完就可以用了。 当时还有一个情况就是开发环境是没有网络的，有问题不能上网去查，好在分配给我的没有太复杂的功能，依照原来的系统都可以完成，并且我喜欢做笔记，常用的那些代码实现都让我记在了本子里，有些还记了不止一遍，这些笔记我至今还留着，现在看起来显得过于幼稚，但却是我工作以来的痕迹。 渐入佳境工作一年以后，对整个游戏已经比较熟悉了，可以独自完成很多功能，稳定下来的游戏也逐渐对接多个平台开始蓬勃发展，那时的我真的是干劲十足，每天像打了鸡血一样，作为服务器开发的我开始偶尔“插手”客户端的开发工作。 期间还养成了每天读书的习惯，其实这个习惯的养成是被动的，原因是分配给我的电脑比较卡，我提过几次但是一直没有换的机会，每天早上开机至少得10分钟左右才能正常顺畅的工作，所以后来我一般会早来一会，开机这期间我就会把旁边同事的书拿过来看看，后来同事的书看完了，我就买一些相同类型的技术书籍来看，再后来开始扩展知识面，买一些流行技术的书，这个习惯就一直保留了下来，一直到现在每年都会看几本技术书籍，有些是不朽的经典，有些是新进的技术。 其实很多书的内容我只是有大概的印象，具体的内容早就忘记了，偶有几本书感觉有意思会回过头来再次翻看，每次看都会有不同的感受，我喜欢在纸质书上做笔记，想到什么就写什么，有些章节会被我划的很乱。在我看书的时候总有同事问我，你看那么多书都记得吗？都学会了吗？这时我常常会自嘲一般的回答：“看着玩而已，早都不记得了”。 实际上记不记得重要吗？今天吃了有营养的东西，明天依旧会饿，你会因为明天还会吃饭就放弃今天的美食吗？我想不会的吧，我感觉看书也是一样，我今天看了明白了一些事情，或者读到一个故事感动了很久，明天忘了就忘了，毕竟我曾经学会过，曾经也感动过。这些东西会消失的无影无踪吗？我想也不会的吧，吃过的美食总会有一部分营养进入了我们的细胞，成为了肉体的一部分，而曾经读过的书会忘得一干二净吗？当然不会，那些使我们印象深刻的文字总会在未来的某个深刻，在我们的脑子中再次迸发出来。 再入蛮荒天下没有不散的筵席，参加工作时就参与开发的这个项目终于到了最后的维护阶段，这个阶段距离我刚进公司时已经过去了2年半的时间，此时原项目不再进行新的开发只进行必要的维护，原项目组的人也被分成了两部分，现在的有两个新项目，一个是相同技术栈不同玩法的端游项目，一个是紧追潮流的手游项目。我当时想去做手游，最终也确实分到了手游组，就是从这时起，我与之前的兄长分到了不同的项目。 事实证明这个公司向手游进军的项目确实是一条蛮荒的道路，整个技术链遇到了前所未有的挑战，我们一步步探索着前进的道路，试图越过一个个技术的深坑，而真实情况却是多少次我都陷在了里面。 在这个项目组我遇到了很多新的伙伴，有的乐观、有的开放、有的乐于奉献、有的精益求精，在这我看到了相同而又不同的服务器程序，之前的程序被改的面目全非，我又得重新适应，面对全新的客户端也有太多的新知识需要学习，每天必须打起十二分精神来应对工作。 一次次的否定自我，一次次的推到重建，在项目的紧要关头，升级引擎、重建UI、优化逻辑，最终还是把这款游戏送上了线，但事实却如昙花一般，一闪而过，失败了，我们没有做出成功的产品，仅仅是做了一次失败的尝试，此时距离进入这个项目组过了1年半的时间。 并入源头手游组的失败尝试使我有了到外面大世界看看的想法，就在这时，和我们一同开始的另一个项目组已经完成了一次轮回，很明显他们成功了，作为同时开始的两个项目，一成一败的比较对于我们的打击很大，而那个成功的项目组也进入维护阶段，领导决定合并两个项目组继续完成手游的开发，这使我又打消了出门找工作的念头。 两个项目虽然一成一败，但是各有优势，因为最终做的是手游，所以原来的手游组有技术优势，而另一个成功的项目有成功的游戏内容，两者一合并应该很快就能出一个产品，更重要的是，这两拨人有很多都是曾经的好友，好友联手打造一个游戏也是很有意思的事情。 可是理想很丰满，现实很骨感，事实证明做出一款游戏是多么的不容易，虽然两部分好友合并到一起没有什么磨合的问题，但是游戏内容的一次次修改不断冲击着之前制定的开发计划，整个开发计划不断修改，时间节点在不断修改的需求面前显得那么渺小，常常被无情的践踏。 终于看到胜利的曙光了，在不断调整了2年之后，游戏迎来了上线的的一天，之后开始根据线上反馈进行调整，在我看来游戏开发到这已经基本完成，虽然达不到爆款的要求，但终究是一款中规中矩的游戏，没有大的问题，也没有太闪光的点，我在这的修行也要告一段落了。 离开这里的一个导火索是游戏内容一次大的调整，本来现阶段不可能大面积修改功能了，可是在计划中还是出现了太多看不懂的修改内容，因为之前有了完成游戏就离开的想法，看到这里仿佛又要开启一个新游戏了，我也就没有再留下的必要了，是时候到外面的世界去看看了。 信心满满的6年后外出求索19年底，在第一家也是唯一一家公司呆了6年之后，我开始外出面试了，从一开始的信心满满到后面的发奋图强，我逐渐认识到了，我必须出来闯闯了，我在一个安逸的地方待了太久，虽然每天都在学习，但事实上优秀的人比你还要努力，以下简单介绍下面试过程，对于需要掌握的知识进行一个梳理，便于日常复习警醒自己，大概面了几家，以下按一面时间先后排列以下T、D、Y、W、Z、H：，全部以字母代替就不列出公司名了，有兴趣的可以进一步交流下。 T公司 很抱歉一开始把公司名看错了，当时还在想一家旅游公司怎么还做游戏，但是毕竟是第一家在招聘APP上给我发面试邀请的公司，怎么也要去看看，后来了解了一下这是一家主营棋牌类的公司，面试当天早早就来到了这家公司，顺便再楼下吃个了饭，面试开始先填个表格，内容跟查户口一样，我只填了其中的必要信息，接着做笔试题，包括后面几家面试，这是我唯一做的一套笔试题，内容不难，可能就是一个简单了解。 我还没写完面试官就来了，我看他特别像我初中的化学老师，整个过程很轻松，聊聊笔试题、曾经的项目，面试官还介绍了他们公司的情况，他表示了对我的肯定，问我有没有兴趣转Golang语言，我内心是拒绝的，其实嘴上也拒绝了，因为我一直使用C++，之后又是其他一个组的负责人来面试，他们使用的Python，整个过程依旧轻松加愉悦，还向他请教了分布式服务器的知识，最终因为我不想放弃C++而结束，他问原因是什么？我开玩笑说：可能是情怀吧！ 涉及到笔试面试部分内容，列举在此主要为了重温复盘，如果你想做游戏开发也可以看看这些知识： 不同类型数据内存占用大小 估算PC机上1秒钟可能执行的空的for循环次数 linux下常用搜索文件命令 常用的设计模式 字符串翻转 扑克牌中挑最长顺子 回旋排列矩阵 分布式服务器设计 linux中的lvs 服务器横向扩展 从头实现一个服务期 websocket 玩家背包怎样设计 D公司 这个公司完全是抱着学习的心态去的，因为公司本身很大并且不是做游戏的，来这家公司完全是因为他们的技术总监在招聘APP给我发了面试邀请，我本来觉得不合适，人家说可以来试试，抱着学习的态度我就去了，为了这次面试还看了好几个调度算法，最终也没用上。 本来10点半的面试，7点多我就出发了，期间地铁还坐反了，还好出门早，来到西二旗发现手机都没有信号，出门都骑不了自行车，走了很久才找到一辆，开锁出发一气呵成，9点多就到公司楼下了，旁边便利店买了个菜团子，对于干吃的我来说太大了，10点左右进入公司，大公司就是不一样，进门登记后还要贴一个签，这是怕我乱跑啊。 面试不久后进行，来了一个小哥哥，年纪应该不大，很沉稳的样子，带了一台笔记本电脑，这个好像是标配，提倡无纸化办公吧，我的一切反馈他都会记录在上面，整个过程对于他来说应该是轻松的，但是对于我来说有些窘迫，整个过程对我的评价就是，很多东西用的很熟，但是对于原理掌握的还不够，算是没有达到他们的要求，这也在我的意料之中，毕竟就是来学习的。涉及到的面试内容大概有如下问题： 开源项目源码的阅读情况 动态库加载路径 编译的过程 线程崩溃为什么会导致进程挂掉？一定会挂掉吗？ 加权最短路径 打印过程中出现中断 中断信号怎么处理 怎么理解多态 编译时多态和运行时多态 模板和基础类型的效率比较 gdb调试 为什么先构造基类 析构函数的调用顺序 非阻塞的write什么时候返回 如果连不上服务器会有那些情况 注意wireshark的使用 listen的backlog参数 Y公司 这个公司有自己成熟的产品线，涉及到卡牌、MMORPG等等，同样是在招聘APP上收到面试邀请，但这次招人的是一个SLG游戏组，整个给人的感觉无论是公司的氛围还是项目的情况与我当前公司很像，一共来公司面了两次，第一次两个技术Leader分别进行面试，然后又和HR聊了一下，技术面主要围绕曾经的项目，后来第二次面试跟游戏制作人聊了一下，感觉和之前的公司更像了，当时就打了退堂鼓，最终婉言谢绝了这家公司的Offer，面试主要技术内容： 技能设计 redis缓存 指针用法 二分法思想 项目熟练度 W公司 这个公司是游戏开发中的大厂了，首先是在招聘APP上，HR和我沟通之后要去了简历想要看看，后来收到了面试电话确定了面试时间，面试当天也是早早的来到了公司，这天在周围没有找到吃饭的地方，要饿着肚子了，等待了一会被HR小姐姐带去二楼等了半小时，后来她跑过来告诉我位置错了，确实有点尴尬。 之后我被带去了正确的位置，然后开始了面试过程，面试官是一个小哥哥，整个面试的过程感觉表现的不是很好，有些问题回答的不太完整，但是却从中学习到了很多东西，临走时问了几个面试问题的正解，并且冒昧的问了小哥哥的工作年限，得知才比我大两岁就已经在游戏大厂当主程之后，深感我们之间的差距还很大，同时也激起了我努力学习的意志。 面试后好几天也没有消息，本来我感觉这次面试可能失败了，但是几天后我又收到了该公司的二面邀请，收到邀请时挺高兴的，当时还有另外几家面试，之前已经约好了时间，所以这次二面不得不向后推了几天，因为是第二次去，路线熟悉了很多，又是早早来到公司，本来以为还是技术面，但是交流几个问题之后发现问的都是之前的项目，和人员之间的沟通的问题，后来对方主动说明他是项目负责人，整个聊天过程比较轻松，谈过之后让回去等消息。 第二天收到HR视频面试的邀请，本来想约晚一点回家好好面试，但是因为HR小姐姐还有其他安排，我只得将面试时间提前，在公司旁边找了个安静的地方进行视频面试，主要聊了一下目前的薪资待遇以及项目情况，能够入职的时间等等，整个过程很愉快，并且得知其实是一个工作室在招聘，我问了一些相关的问题，面试结束回到家我仔细考虑了这个机会，第二天又找该项目的负责人了解了项目的详细情况，觉得这是一个很好的学习机会，与目前的工作内容有很强的互补性，可以试一试。 Gitflow使用方法 gcc编译过程 extern和static的作用 多态、虚函数、多继承虚函数 大根堆创建和插入 排序找出接近当前数的较大数 迭代器的理解、迭代器都是指针吗？ 字符编码、unicode、utf8 指针数组、数组指针、函数指针 引用和指针的区别 网络4次挥手、为什么要4次？ 函数阻塞是否占用资源–挂起不占用 Z公司 这个公司不是游戏公司，近两年异常火爆，有专门的游戏部门，但是我面试的职位不是游戏岗位，而是时下非常火的中台岗位，其实是在尝试新的领域。起初是猎头在招聘APP上要了我的简历，然后接到了公司HR小姐姐的电话，约定了面试时间，相互加了微信，面试之前和HR小姐姐交流了不少，知道公司技术面大概有3面，因为心里没底，抱着学习的态度考虑能过两面就行，如果实在太难能过一面也行，作为一个求知者，知道各个公司都需要哪些知识也就有了学习的目标。 可现实总是太残酷，这个面试我算通过了半面，什么叫半面，由于我的“出色”表现，我感觉正常的一轮面试并没有结束就被礼貌的请出来了，因为几个问题之后我也感觉出来了，我之前学的技术和他们开发思想差的有点多，所以出于礼貌，面试官也没说什么，还给出了一些建议，人真的不错，大公司的涵养还是有的。 你开发的最满意的系统 –道具系统 map和hashmap的区别 stl的使用 vector的扩容，是不是线程安全的？ 遍历删除vector元素，迭代器失效 有没有用过redis的有序集合 redis中hash插入的时间复杂度 设计一个红包系统 –评价为原始的面向对象方式，有些过时 给出建议这个红包系统必须要考虑redis、分布式、容灾、备份 建议如果想转向互联网需要准备的很多，可以先看下现有的解决方案 H公司 这个公司的面试机会是猎头推荐的，主要做战争题材的游戏比较多，现在也有卡牌和休闲，本来约的面试时间比较早，但是由于个人原因回了次老家，结果这个面试不得不向后推了，面试当天来到公司，前台居然一个人都没有，之后电话联系到面试官，首先表达了之前改约的歉意开始了面试过程。 面试主要围绕之前的项目进行，对具体的系统实现问的很详细，通过对细节的了解，对我之前的工作内容有很多不理解，感觉有很多内容不符合他的认知，整个过程倒还轻松，没有太多的技术问题，总体感觉不是一路人，很可能走不到一起。 聊了大概一小时，换HR继续聊，还是问了之前项目、期望薪资以及入职时间等等，确定了是卡牌组再招人，问了一些当前公司情况之后，按照流程回去等消息，但个人觉得可能不太合适。 面向对象要求比较高，C+Class的方式不被认可 着重问了一个游戏系统的实现方式（押镖） 面相对象设计技能系统 强调游戏充值实现的重要性，以及可能出现的多种情况 认为只有DBA才有权利修改数据库结构 准备离开出去面试一圈基本确定了新的工作，是时候离开了，先跟带自己入门的兄长道个别，我们两个聊了很久，对于我离开去学习新知识，兄长表示支持，他不仅是我工作上的领路人，同时脾气特别好，平时处理问题也很妥当，一直是我学习的榜样。 紧接着便向老大提出了离职，准备年前离职后去新公司入职，而老大的意思是再等等，年前太仓促了，先看看现在公司的情况，年后回来如果还想走再办离职吧，考虑到还有一段时间的就要放假了，为了更好的完成了交接工作，我答应了老大的请求。 即将离开过年期间考虑了好久，还是准备出去闯一闯，今年春节的新型冠状病毒疫情非常严重，很多公司都推迟了上班时间，虽然2号之后就回来上班了，但是很多同事由于封路的原因都还没回来，离职手续也一直没有办成，年后又找老大聊了一次，毕竟工作了6年，虽然不舍，但是确实该离开了，期待下周的情况能好一些，能顺利办完手续开始新的旅程。 挥挥手再出发 更新于2020年2月15日22:45:51 挥手告别事情办得比较顺利，经过前期的准备，周一便完成了工作交接，上传了交接文档，周二开始办理离职手续，由于新型冠状病毒疫情的原因，公司依旧没有什么人，好在办理离职的人员都在，签字、签字、再签字，成功在下午拿到离职证明，不过唯一遗憾的是，工牌和门禁卡同时上交了，不能给我留个纪念了，毕竟是在身上装了6年的工牌，6年了几乎没有离开过…… 因为很多同事也没来，加之疫情的严重性，散伙饭并没有吃成，前一天下班的时候专门去旁边的簋街转了一圈，发现除了几家仅有的外卖之外，都是黑着灯的，这可是簋街啊，是让人们可以排队等到凌晨2点的簋街，现在居然这样冷冷清清的，找不到吃饭的地方，散伙饭只能作罢。 下班前跟仅有的几个来上班的好友道了别，当然其中还有我那位可敬的兄长，当所有人都在关心你飞的高不高时，只有朋友关心你累不累，兄长就是这样的朋友，临走了还关心地问我社保能不能接上，只因为我之前和他提过一次担心社保断缴的问题。因为很多人还没来上班，剩下的关系好的小伙伴，在我晚上回家后，通过微信开始了与他们的远程云分别。 还看今朝告别了过去的工作，自然要步入新的旅程，为尽量避免人员接触，新的公司在周五为我在线办理了入职手续，两位帮忙办理入职的新同事真的非常友好，整个流程遇到不懂的都会及时解答，这让我非常期待下周一正式工作后的生活，新的旅程即将开始，又要在一个地方生根发芽了~]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>总结</tag>
        <tag>工作</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用__declspec(dllexport)和__declspec(dllimport)在Windows平台编写和使用DLL的小例子]]></title>
    <url>%2Fblog%2F2020%2F02%2F05%2F%E5%88%A9%E7%94%A8-declspec-dllexport-%E5%92%8C-declspec-dllimport-%E5%9C%A8Windows%E5%B9%B3%E5%8F%B0%E7%BC%96%E5%86%99%E5%92%8C%E4%BD%BF%E7%94%A8DLL%E7%9A%84%E5%B0%8F%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[前言关于 __declspec(dllexport) 和 __declspec(dllimport) 这两个关键字在上大学期间就没见过几次面，直到毕业后在公司项目的代码中又遇到过几次，每次也是绕着走，生怕和它产生什么联系，只知道它和动态链接库 DLL 有关，但是当前这个项目中几乎没有用到自己写的动态链接库，所以我也就心安理得的躲了它这么久。 最近看一些开源项目的源码时又发现了这两个关键字，此时凭借自己掌握的知识和学习方法再来看这两个关键字，发现也没有什么值得害怕的地方，其实简单来说就是 __declspec(dllexport) 是用来说明指定类和函数需要从 DLL 中导出的，而 __declspec(dllimport) 是用来说明指定的类和函数是从DLL中导入的。 说明 __declspec(dllexport) 和 __declspec(dllimport) 只在 Windows 平台才有，用来说明类或函数的导出和导入。 在 Linux 平台上源文件中的所有函数都有一个的visibility属性，默认导出。如果要隐藏所有函数导出，则需要在GCC编译指令中加入 -fvisibility=hidden 参数。 生成 dll 的同时还会生成对应的 lib 文件，一般是一些索引信息，记录了 dll 中函数的入口和位置，这在之前还真的不知道，原来一直以为 lib 只是静态库文件呢。 疑问 为什么要导入导出，直接把代码拿过来一起编译不好吗？ 想要一起编译前提是你得有源代码，如果人家就给你一个动态库或者静态库，你想把源代码放到一起编译的愿望根本实现不了。 为什么要分为静态库和动态库？搞这么麻烦，还要导入导出。 这具体的就要查查他们两者的优缺点了，每种事务的产生必要有其产生的原因，比如静态库，很可能就是一个程序员今天在A工程写了一个读取文件的类，过一段时间又在B工程写了一个读取文件的类，代码都差不多，不久又在C工程中直接把代码复制过来改一改又写了一份，这时想到干脆了写个“静态库”这种东西吧，相同的代码直接封装到库中，哪个工程需要就直接拿过来编译，也不需要再复制代码了。 又比如动态库，前面的静态库解决了代码重复开发和维护的问题，但是读取文件的静态库中的代码在A、B、C三个工程中都存在一份，导致每个可执行程序都很大，可不可以共用一份呢？结果又发明了动态库，在编译时只指定函数的入口地址，运行时才加载动态库，这样就使得可执行程序体积大大缩小。 以上内容纯粹我个人想像的，真正发明静态库和动态库是由于什么原因，大家可以自行去了解… 动态库要比静态库好吗？ 个人感觉合适的才是最好的，不存在动态库要比静态库好的说法，最起码不是全都好，动态库的代码是在可执行程序运行时才载入内存的，在编译过程中仅简单的引用，因此代码体积较小，但是运行时要去加载库会花费一定的时间，执行速度相对会慢一些，总的来说静态库是牺牲了空间换时间，而动态库是牺牲了时间换空间。 .h（头文件） .lib（库文件） .dll（动态链接库文件） 之间的联系和区别 .h 文件是编译时需要的， .lib 是链接时需要的， .dll 是运行时需要的。如果有 .dll 文件，那么 .lib 一般是一些索引信息，记录了 .dll 中函数的入口和位置，.dll 中是函数的具体的执行内容。如果只有 .lib 文件，那么这个 .lib 文件是静态编译出来的，索引和实现都在文件中。 DLL的编写与使用前面说了这么多，其实就是想带大家先了解一下动态链接库 DLL ，接下来开始编写一个DLL并在另一个工程中使用它，前提是你已经会使用开发工具VS，如果不会先查查教程。 测试环境 VS2013随意版（个人感觉这个版本启动能快一点） Win10畅想版（我也不知道啥版本） 编写DLL编写 DLL 的方法不知一种，这里只简单介绍一种，对于直接写 .def 文件的方法这里不会展开，尽量依靠开发工具一步步向下执行就好，其实当你理解了开发工具的是怎样工作的，一切就没有那么神秘了，有些步骤直接修改配置文件也是可以实现的，只不过开发工具给我们提供了界面，操作起来更加方便了而已，下面我们开始编写： 打开VS新建项目，选择Win32项目，项目名称GenDLL，解决方案名称DLLExample，点击确定： 直接下一步，应用程序类型选择DLL，点击完成： 项目会自动创建一个GenDLL.cpp文件，我们在手动创建一个GenDLL.h文件，两个文件中编写如下代码： 123456789// GenDLL.h#ifdef GENDLL_EXPORTS#define TEST_API __declspec(dllexport)#else#define TEST_API __declspec(dllimport)#endifTEST_API int add(int a, int b); 123456789// GenDLL.cpp : 定义 DLL 应用程序的导出函数。#include "stdafx.h"#include "GenDLL.h"TEST_API int add(int a, int b)&#123; return a + b;&#125; 这段代码中有一个 TEST_API 是我在头文件中自定义的，当存在GENDLL_EXPORTS宏时， TEST_API 代表 __declspec(dllexport) 也就是导出函数，当不存在GENDLL_EXPORTS宏时， TEST_API 代表 __declspec(dllimport) 表示导入函数，而 GENDLL_EXPORTS 这个宏是与项目名相关的，自动生成的宏，在 DLL 项目中存在格式为 “大写项目名_EXPORTS”。 也就是说同一个头文件中计算加法的函数 add 在 GenDLL 这个生成 DLL 的项目中表示导出函数，在其他使用这个 DLL 的项目中表示导入函数。 编译看输出发现有GenDLL.lib和GenDLL.dll两个文件： 123456781&gt;------ 已启动生成: 项目: GenDLL, 配置: Debug Win32 ------1&gt; stdafx.cpp1&gt; dllmain.cpp1&gt; GenDLL.cpp1&gt; 正在创建库 c:\users\administrator\documents\visual studio 2013\Projects\DLLExample\Debug\GenDLL.lib 和对象 c:\users\administrator\documents\visual studio 2013\Projects\DLLExample\Debug\GenDLL.exp1&gt; GenDLL.vcxproj -&gt; c:\users\administrator\documents\visual studio 2013\Projects\DLLExample\Debug\GenDLL.dll========== 生成: 成功 1 个，失败 0 个，最新 0 个，跳过 0 个 ========== 使用DLL 在DLLExample这个解决方案下添加一个新项目，命名为UseDLL，然后点击确定： 直接下一步，应用程序类型选择“控制台应用程序”，点击完成： 在文件UseDLL.cpp文件中引用之前GenDLL项目的头文件，编写使用 add 函数的代码： 123456789101112// UseDLL.cpp : 定义控制台应用程序的入口点。#include "stdafx.h"#include &lt;iostream&gt;#include "../GenDLL/GenDLL.h"int _tmain(int argc, _TCHAR* argv[])&#123; std::cout &lt;&lt; "100+1=" &lt;&lt; add(100, 1) &lt;&lt; std::endl; system("pause"); return 0;&#125; 编译代码发现报错，提示有一个无法解析的外部命令： 1234567891&gt;------ 已启动生成: 项目: UseDLL, 配置: Debug Win32 ------1&gt; UseDLL.cpp1&gt; stdafx.cpp1&gt; 正在生成代码...1&gt;UseDLL.obj : error LNK2019: 无法解析的外部符号 &quot;__declspec(dllimport) int __cdecl add(int,int)&quot; (__imp_?add@@YAHHH@Z)，该符号在函数 _wmain 中被引用1&gt;c:\users\administrator\documents\visual studio 2013\Projects\DLLExample\Debug\UseDLL.exe : fatal error LNK1120: 1 个无法解析的外部命令========== 生成: 成功 0 个，失败 1 个，最新 0 个，跳过 0 个 ========== 提示这个错误本意就是说链接没有找到函数实现，链接需要什么文件，前面提到需要lib文件，那么我们设置一下，让UseDLL工程能够找到GenDLL.lib文件。 打开UseDLL工程的属性，在“配置属性-&gt;链接器-&gt;输入-&gt;附加依赖项”中添加GenDLL.lib: 然后在“配置属性-&gt;链接器-&gt;常规-&gt;附加库目录”中添加GenDLL.lib所在路径“../Debug”即可成功编译： 直接运行就可以看到调用DLL的结果，因为这两个工程在同一解决方案下，所以最终UseDLL.exe和GenDLL.dll在同一目录下，这样不会报找不到DLL的错误 如果是不同的目录就会像下图那样，提示找不到GenDLL.dll，只要把GenDLL.dll复制到和UseDLL.exe相同目录即可： 加载DLL上面提到当运行程序找不到 DLL时可以把 DLL 放到可执行程序程序的目录，有时运行大型软件找不到 DLL 时，我们也会下载一个放到System32目录，其实程序在加载 DLL 的时候是会按照一定顺序的，这些目录包括：包含exe文件的目录、进程的当前工作目录、Windows系统目录、Windows目录、Path环境变量中的一系列目录等等，这些目录的搜索顺序还会受到安全 DLL 搜索模式是否启用的影响。 所以说如果不是对DLL 放置的位置有特殊要求，那么直接放在exe文件所在的目录就好了，一般也是会优先搜索的。 总结 Windows上才有 __declspec(dllexport) 和 __declspec(dllimport) .h 文件是编译时需要的， .lib 是链接时需要的， .dll 是运行时需要的 程序运行时加载 DLL 一般优先从exe文件的所在目录优先加载]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>dllexport</tag>
        <tag>dllimport</tag>
        <tag>DLL</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020年的春节，我们一起抗击新型冠状病毒]]></title>
    <url>%2Fblog%2F2020%2F01%2F29%2F2020%E5%B9%B4%E7%9A%84%E6%98%A5%E8%8A%82%EF%BC%8C%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%8A%97%E5%87%BB%E6%96%B0%E5%9E%8B%E5%86%A0%E7%8A%B6%E7%97%85%E6%AF%92%2F</url>
    <content type="text"><![CDATA[终于到了什么都不用做，在家躺着就能为国家做贡献的时候了！ 前言新型冠状病毒，一个看起来陌生的词语，使得原本最热闹的春季变得异常冷清，随着疫情范围的扩大，这个本来陌生的词语一次次冲击着人们的认知。这个病毒到底是什么，为什么扩散起来这么凶猛？ 2019-nCoV新型冠状病毒，在各种媒体上还会以“2019-nCoV”的名字出现，人感染了冠状病毒后常见体征有呼吸道症状、发热、咳嗽、气促和呼吸困难等。在较严重病例中，感染可导致肺炎、严重急性呼吸综合征、肾衰竭，甚至死亡。 引用百度百科中文字，对其描述为： 2019新型冠状病毒，即“2019-nCoV”，因2019年武汉病毒性肺炎病例而被发现，2020年1月12日被世界卫生组织命名。冠状病毒是一个大型病毒家族，已知可引起感冒以及中东呼吸综合征（MERS）和严重急性呼吸综合征（SARS）等较严重疾病。新型冠状病毒是以前从未在人体中发现的冠状病毒新毒株。 目前掌握的情况： 传染源: 野生动物，可能为中华菊头蝠 传播途径: 经呼吸道飞沫传播，亦可通过接触传播 易感人群: 人群普遍易感。老年人及有基础疾病者感染后病情较重，儿童及婴幼儿也有发病 潜伏期: 1 ~ 14 天，平均 10 天，潜伏期内存在传染性 2019-nCoV与SARS这个新型冠状病毒导致的肺炎传播速度如此之快，很多人拿它和03年的非典（SARS）相比，确实这两个病毒有很多相似的地方，同样都是新型冠状病毒，同样都会引起肺炎，甚至连发生的时间都非常相似，非典是02年11月出现病例，而2019-nCoV出现的时间大概是12月。 那它们两个这么像，能不能用相同的方法和药物治疗呢？目前来看是办不到的，两者虽然很相似，但是毕竟都是新型病毒，我们知道一种病毒变异后原来的药物很可能就起不到作用了，更何况这是两种不同的病毒，但是也有好的一面，毕竟在抗击非典时我们积累了宝贵的经验，对于防控类似的疾病能够提供很大的帮助。 比如当年非典时期,北京市在小汤山就建立起了一座封闭式的医院,就是小汤山医院，而武汉参照北京“小汤山模式” 神速建造了“火神山医院”，从开工到投入使用预计会花费10天左右，这个速度也是令人惊叹了，没有之前的经验积累是很难办到的。 为什么传播的这么快其实一开始我们都没有重视这场战斗，导致这个新型冠状病毒钻了空子，传播速度之快达到了让人心惊的地步，感觉主要有下面几方面的原因吧： 华南海鲜市场存在大量新型冠状病毒，源头上就很广 起初没有得到足够重视，认为不存在人传人的可能，导致接触者甚至医务人员被感染 病毒在潜伏期也有可能传播，这是与非典不同的，导致一些携带病毒的人在无意识的情况下成了传染源 正好赶上春节返乡高峰，而武汉作为九省通衢的枢纽，反倒为病毒散播提供了便捷的条件，扩散范围很快就达到了全国 目前的形式新型冠状病毒疫情已经开始进入初期扩散阶段，并呈上升趋势，但是应对措施也已经铺开，延长假期，控制人员流动，积极研制疫苗，组织医疗救援队赶赴武汉等等，相信不久疫情就能够控制住。 本来春节是一年中最忙碌的日子，今年却异常的冷清了，为了大家的健康，今年周围的人都取消了拜年聚会活动，村口也安排了人专门劝返探亲人员，因为这样我们反而多了一些陪伴家人的时间，而我居然有时间来码字了，往年不是在这喝酒就是在那聚会的，现在这样安安静静的待在家里感觉也不错。 引用网上一段顺口溜，写的不错与大家分享： 国家有难，咱不添乱。坐在家里，就是贡献。亲戚不走，来年还有。朋友不聚，回头再叙。利人利己，互不传染。吃好睡好，悠闲过年。坚持几天，你我平安。 新型冠状病毒最新消息目前新型冠状病毒处于蔓延的趋势，各种消息满天飞，真真假假难以辨认，所以我单独建了一个项目用来收集最新的消息，尽可能保证消息的准确，其中包含最新的疫情地图、最新疫情新闻、以及正规的捐助渠道等等，有兴趣的小伙伴可以一起舔砖加瓦。 抗击2019-nCoV最新情报-ChineseVictory 更新于2020年1月29日21:25:30 今天看到一个同类型的记录武汉抗击新型冠状病毒的项目，已经有3000多的star了，我们两个项目创建的时间很接近，再看看我的项目情况有点惨淡啊！贴个图，大家感兴趣可以来逛逛，不过人家那个项目确实很规范，我还有很多东西可以学习。 从star数为0来看确实惨淡，再放一遍项目地址-ChineseVictory，感兴趣可以来看看;)]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>病毒</tag>
        <tag>武汉</tag>
        <tag>春节</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019！一份迟到的年终总结]]></title>
    <url>%2Fblog%2F2020%2F01%2F03%2F2019%EF%BC%81%E4%B8%80%E4%BB%BD%E8%BF%9F%E5%88%B0%E7%9A%84%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[长大了就要为小时候吹过的牛而奋斗~ 前言2019即将过去，瞅一眼桌面右下角的时间，距离2020年还有63分51秒，这是我第一次这么强烈地想在一年结束之际写下点什么。本身是一个喜欢收集和总结知识的性格，但对自己的人生却少有总结，一方面感觉没什么可写，一方面也确实对自己太过宽容。 每年年初总是在朋友圈和各大平台浏览着一个个新年展望，而每年年末总是在相同的位置看着他们把年初展望的日期向后推一年，这是个段子，同样也是事实，很多人的生活过得平平淡淡，我们都是人群中的大多数，平庸而碌碌无为。 迟到之所以在年终总结前冠以“迟到”二字，是因为我突然意识到这份总结早就应该做了，对于参加工作已经6年的我来说，刚刚意识到需要做年终总结确实有些不应该。作为普通人的我来说记忆能力有限，小时候吹过的牛早就忘了，如果能及时的做年终总结，或许我还可以为了去年吹过的牛奋斗一把，可是我没有，我连去年的想法也忘得差不多了，此时此刻才刚刚意识到曾经的失误。 得与失既然是总结就要回想一下在过去的一年中我得到了什么，失去了什么，而在新的一年中我想获得什么，回想即将过去的2019年发现，今年确实发生了很多往年没有发生过的事情，这可能也是我突然非常想写点东西，记录下来的原因。 回顾2019这一年发生的事情太多，相互之间纠葛不断，不过还是从最简单的分类：工作、学习、生活这三个方面来聊聊吧，虽然很多事情不能完全归为某一类，但是贴一个标签总能清楚一点。 工作上依旧是踏踏实实，勤勤恳恳的一年，做了整整一年的游戏开发几乎颗粒无收，这已经不是第一年没有收成了，有时候真的有点后悔为了工作侵占了陪家人的时间，特别是看不到回报的时候。 从年初就开始做收尾工作，几次上线几次调整，不知不觉我们又过了一个年，在我心中这款游戏的开发工作已经接近尾声，这样的状态不应该再持续下去了。 学习上作为一个好学的程序猿，深知“学如逆水行舟，不进则退”的道理，今年在CSDN上写了42篇原创博客，算是高产的一年了，也终于迈进了总排名前一万名的大关，截个图记录一下： 有点小遗憾，访问量差几百才到50万，不过新年第一天应该差不多啦，不仅仅是知识的总结，由于加了CSDN的博客群，今年还认识了许多有意思的小伙伴，比如：铁柱同学（一个冒充小白的大佬）、第三女神（粉丝炸裂式增长）、TRHX（网站做的特漂亮），还有很多小伙伴就不一一列举啦。 关于读书，我只喜欢读纸质的书籍，喜欢那种在书上乱画，随便记笔记的方式，当然有一点不好，就是想查一个知识点，知道是哪一本书，不得不翻一翻才能找到，好希望纸质书能有个搜索按钮，不过这个问题找个电子版就能解决了。 今年一共读了7本关于编程技术的书籍： Redis入门指南(第2版) 图解HTTP 自动化平台测试开发 ——Python测试开发实践 图解密码技术 图解TCP/IP 漫画算法 ——小灰的算法之旅 MySQL必知必会 推荐这本《小灰的算法之旅》，可以把学知识当做一种乐趣，绝对能达到事半功倍的效果。 附上 我的完整书单 生活上今年在生活上发生的事情好像比之前几年加起来都要多，年中得到了一个特别可爱的宝宝，为了解决宝宝上学问题，之前从没考虑买房的我到了售楼处就买了一套，几乎都没挑就定下了，当然这么冲动的行为必须要付出代价，因此背上了近百万的债务，从此变成了一个给银行打工按月还款的房奴。 说实话宝宝刚出生时并不好看，可是越长越可爱，现在已经7个月大了，开始会爬了，真想不去上班一直陪她玩，有时候确实有一种为了她放弃全世界的冲动，宝宝今天有点发烧，凌晨一点了还没有睡，陪我一起跨年总结了，好在这会儿烧退了一些，快点好起来吧！ 2019年生活上发生的另外一件很重要的事情就是投资，入市有风险，投资需谨慎，这不是一句玩笑话，今年年初股市行情一片大好，正当我们陶醉其中的时候，贸易大棒直接挥下，给准备一飞冲天的行情当头一棒，还好跑得快，不然年初那波行情的盈利在贸易战初期就会飞烟灭了。 年初的基金行情也异常火爆，在支付宝买了点指数基金，贸易战开始之后就抛掉了，并没有多少盈利： 说完赚钱的接下来就是赔钱的，P2P暴雷给我炸的遍体鳞伤，从5月份出事到现在毫无音信，真应了那句话，你看上了人家的高息，而人家看上的是你的本金，P2P今年可谓损失惨重。 因为赚钱心切，今年还投资了一点数字货币，结果因爆仓而结束，每次都是到了爆仓点位迅速反弹，好像在提示我压根就不是我应该玩的，不过从这次投资来看，我才明白为什么有钱的人越来越有钱，而穷人一辈子很难翻身。 一句话，穷人没有东山再起的资本和承担风险的能力，举个例子：我和一个富有的人同时买一只数字货币，而我们都只花了500块来买相同的点位，不同的是富有的人保证金更多一些，这样当行情来到我的爆仓点位时，我和富有的人损失相同的钱，但是我爆仓了，而他没有，待到行情迅速反弹，他却赚的盆满钵满。 或者换一种情况，我们两个同时爆仓，他立马在低位投入2倍的钱，迅速赚回损失，而我只能眼睁睁的看着行情反弹却没有投资的砝码，忽然觉得T+1好像真的是帮助我们这些散户的。 展望20202019已经过去，面对着已经到来的2020年，我们需要踏上新的征程，我还没有适应给自己定出量化的目标，不过可以暂时写下大致的方向，也算是给自己一个时刻的提醒。 对工作新的一年不能再碌碌无为，真的需要去闯一闯了，最近和一些互联网公司的员工沟通过，仿佛我们不是生活在一个地球，外面的世界真的很大，外面的机会真的很多，是时候出去看看了，浏览一下世界的另一面，当然，脚踏实地的工作风格不能丢弃。 对学习经过一段时间的与大牛们的沟通，我渐渐的明白了自己的差距，也大致了解了需要重点学习哪些知识，所以简单列举如下： 巩固基础知识，对于一些函数不仅要会用，还应该花时间探究实现的方式，往深处挖掘，比如listen函数backlog参数意义。 阅读 redis 源码，这是很多人都提到的一点，适当可以看一下 STL 源码 看两本有关分布式知识的图书 对生活 尽最大可能陪陪家人 投资达到2019的水平（只看赚的，不看赔的） 总结接触了一些大牛之后备受打击，可是以往的岁月已经无法改变，只要认清了自己从现在开始就不晚，2019悄然离开，2020已经隆重登场！加油~]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>总结</tag>
        <tag>工作</tag>
        <tag>学习</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单继承、多继承、菱形继承的虚函数表]]></title>
    <url>%2Fblog%2F2020%2F01%2F03%2F%E5%8D%95%E7%BB%A7%E6%89%BF%E3%80%81%E5%A4%9A%E7%BB%A7%E6%89%BF%E3%80%81%E8%8F%B1%E5%BD%A2%E7%BB%A7%E6%89%BF%E7%9A%84%E8%99%9A%E5%87%BD%E6%95%B0%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[前言最近被问到一个关于多继承虚函数表的问题，当时回答是可能存在多个虚函数表，应该是顺序排列的，但具体怎么排列还是有些疑惑的，回答的时候到有点儿心虚。之后查了资料，做了简单的实验，可以确定的是对于继承了多个含有虚函数基类的子类来说，指向虚函数表的指针应该不止一个。 问题虚函数表的问题是从C++多态的概念引出的，要想实现多态有3个条件： 存在继承：没有继承就没有多态（运行时），在多态中必须存在有继承关系的父类和子类。 重写函数：父类中需要定义带有 virtual 关键字的函数，而在子类中重写一个名字和参数与父类中定义完全相同的函数。 向上转型：将父类的指针和引用指向子类的对象。 满足以上三个条件，当使用父类的指针调用带有 virtual 关键字的函数时，就会产生多态行为。 实现这种多态表现的核心内容就是虚函数表，对于带有 virtual 关键字的函数地址会被放入一个表格，而在类中会有一个指向虚函数表的指针指向这个表格，表明这个表格属于类的一部分。 对于父类来说，这个表格中都是自己类的虚函数，而对于子类来说，首先这个虚函数表包含父类中所有的虚函数，当子类重写某个虚函数时就会用子类重写后的函数地址替换原来父类中定义的函数地址，同时在子类的虚函数表中还会包含子类独有的虚函数。 由此可见虚函数表的不同和复杂性还是体现在子类上，所以之后会分别测试单继承、多继承、菱形继承三种情况下虚函数表的不同，主要看一下虚函数表的个数和内存布局情况。 测试环境首先来说明一下测试环境，测试工具是VS2013，对于int *p; sizeof(p)的结果是4，说明编译环境是32位的，这个对后面查看内存结构非常关键。 开始测试使用VS2013查看类的内存布局非常方便，因为类的大小在编译期间就已经确定了，不用运行就可以通过添加编译选项知道类的大小和布局，而指向虚函数表的指针也会占用类的大小，如果说编译的时候确定了类的大小，那从侧面也说明了在编译期间虚函数表实际上也确定了。 使用VS2013查看类的布局时，可以在项目的属性页：“配置属性”–&gt;“C/C++”–&gt;“命令行”中输入以下任意一个命令， /d1reportAllClassLayout ：这个选项可以在VS的输出窗口显示所有相关联的类结构，因为一些外部类也会显示，最终的内容会非常多，需要自己辨别有用的信息。 /d1reportSingleClassLayoutXXX ：这个选项只会在输出窗口显示指定的类结构，只需要将XXX替换成想显示的类的名字即可，缺点就是无法同时显示多个想查看的类。 无虚函数简单类结构在查看虚函数表的结构之前，先使用之前的编译参数来查看一下简单的类结构，排除虚函数的干扰，能更清楚的了解类成员在类中的布局情况，有一点需要提一下，成员变量会占用类的大小，但是成员函数不会，如果有虚函数，所有的虚函数会被放入一个表格，而在类中放置一个指向虚函数表的指针，来看一下简单代码： 123456789101112131415class CBase&#123;public: void func() &#123;&#125;public: int m_var1;&#125;;class CDerived : public CBase&#123;public: void func() &#123;&#125;public: int m_var2;&#125;; 编译输出的类的内存布局为： 1234567891011121&gt; class CBase size(4):1&gt; +---1&gt; 0 | m_var11&gt; +---1&gt;1&gt; class CDerived size(8):1&gt; +---1&gt; | +--- (base class CBase)1&gt; 0 | | m_var11&gt; | +---1&gt; 4 | m_var21&gt; +--- 从上面的输出内容来看，很清楚的可以看到基类 CBase 的大小 size(4) 占用4个字节，只有一个成员变量 m_var1，在类中偏移量为0的位置，而派生类 CDerived 占用8个字节大小，第一个成员继承自基类 CBase 的 m_var1，在类中偏移量为0的位置，还有一个子类独有的成员变量 m_var2，在类中偏移量为4的位置。 掌握着这种简单类的查看类结构的方法，接下来开始看一下包含虚函数的类的内存布局。 包含虚函数的类结构查看包含虚函数的类结构相对来说麻烦一点，先来说两个符号，免得一会看见结构发懵，vfptr 表示类中指向虚函数表的指针，通常放在类的起始位置，比成员变量的位置都要靠前， vftable 表示类中引用的虚函数表，在具体分析是还有有一些修饰符，用来表明是谁的虚函数表。 单继承这种情况的下的子类的虚函数表很简单，在该子类的内存布局上，最开始的位置保存了一个指向虚函数表的指针，虚函数表中包含了从父类继承的虚函数，当子类中重写父类虚函数时会将虚函数表中对应的函数地址替换，最后添加上自己独有的虚函数地址，下面上代码分析一下： 12345678910111213141516171819class CBase&#123;public: void func0() &#123;&#125; virtual void func1() &#123;&#125; virtual void func2() &#123;&#125;public: int m_var1;&#125;;class CDerived : public CBase&#123;public: virtual void func2() &#123;&#125; virtual void func3() &#123;&#125; void func4() &#123;&#125;public: int m_var2;&#125;; 上面这两个类的内存布局情况如下： 123456789101112131415161718192021222324252627282930313233341&gt; class CBase size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | m_var11&gt; +---1&gt;1&gt; CBase::$vftable@:1&gt; | &amp;CBase_meta1&gt; | 01&gt; 0 | &amp;CBase::func11&gt; 1 | &amp;CBase::func21&gt;1&gt; CBase::func1 this adjustor: 01&gt; CBase::func2 this adjustor: 01&gt;1&gt;1&gt; class CDerived size(12):1&gt; +---1&gt; | +--- (base class CBase)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | m_var11&gt; | +---1&gt; 8 | m_var21&gt; +---1&gt;1&gt; CDerived::$vftable@:1&gt; | &amp;CDerived_meta1&gt; | 01&gt; 0 | &amp;CBase::func11&gt; 1 | &amp;CDerived::func21&gt; 2 | &amp;CDerived::func31&gt;1&gt; CDerived::func2 this adjustor: 01&gt; CDerived::func3 this adjustor: 0 看起来是不是比没有虚函数时复杂多了，不过不要着急，从上到下慢慢分析就好了，这次的基类 CBase 大小是8个字节，首先是{vfptr}这个指向虚函数表的指针，在类中的偏移量是0，接下来是成员变量 m_var1，在类中偏移量是4。 然后是 CBase::$vftable@ 表示基类 CBase 的虚函数表，其中第一行 &amp;CBase_meta 看起来怪怪的，这里我们不展开（因为我也没弄太懂），应该是和虚函数表相关的元数据，第二行是一个0，看起来是一个偏移量，这里没有偏移，当出现偏移时我们再试着分析（相信我，马上就会出现），第三行内容 &amp;CBase::func1 是自己类的虚函数，前面有一个0，应该是指该虚函数在虚函数表中索引，第四行也是相同的情况。 接下来出现了两行非常相似的内容，看一下CBase::func1 this adjustor: 0，这句代码中的关键是 adjustor，其实有是一个偏移量，据说涉及到thunk技术，据说“thunk其实就是一条汇编指令，操作码是0xe9，就是jmp，后面紧跟操作数”，这里我们就不展开了，如果后面弄明白了可以单独写一篇总结，到此为止基类的内存结构就分析完了。 继续看派生类 CDerived，它的大小是12个字节，内部结构首先是 {vfptr} 一个指向虚函数表的指针，偏移量为0，m_var1 是从父类继承的成员变量，偏移量为4，而 m_var2 是自己类独有的成员变量，偏移量是8。 然后看派生类对应的虚函数表 CDerived::$vftable@，跳过前两行直接看一下后面几个函数，发现只有 func1 是基类的，而函数 func2 和 func3 都是派生类的，出现这种情况的原因是子类重写了函数 func2 和 func3 ，所以用重写后的函数地址替换了从基类继承的虚函数，造成了目前看到的状况。 最后又出现了两行 adjustor，很奇怪为什么 func1 函数没有 adjustor，貌似这个 adjustor 只对当前类有效，先留个疑问，接下来看一下多继承。 多继承当多个父类中都包含虚函数的时候，和子类关联的虚函数表就不止一个了，这个情况是可以通过使用sizeof(子类)来简单验证的： 这一部分是在没有VS的情况下预先写下的，本来考虑使用VS展开布局后，这一段就没有什么必要了，但是后来想想还是留着吧，因为这一段使用的g++编译器，64位环境，每个指针占用8个字节，通过不同的环境调试，更加可以证明，多继承下的多个虚函数表的存在性： 1234567class W&#123;public: long n;public: void func()&#123;&#125;&#125;; 对于这样的一个简单类，sizeof(W) = 8，类的大小等于成员变量的大小。 123456789101112131415class W1&#123;public: long n1;public: virtual void func1()&#123;&#125;&#125;;class W2&#123;public: long n2;public: virtual void func2()&#123;&#125;&#125;; 对于上面这两个简单的包含虚函数的类，sizeof(W1) = 16，sizeof(W2) = 16，因为每个类都除了一个 long 类型的成员变量以外，还包含了指向虚函数的一个指针，所以类的大小是16个字节。 1234567class WW : public W1, public W2&#123;public: long nn;public: virtual void func()&#123;&#125;&#125;; 而继承了 W1 和 W2 这两个父类的子类 WW 在继承了两个成员变量 n1 和 n2 之外，还有自己的成员变量 nn，三个变量占用字节24个，而计算类 WW 的的大小 sizeof(W1) = 40，也就是说除了成员变量24个字节，还剩余了16个字节的空间没有着落，我们知道它至少包含一个指向虚函数表的指针，占用8个字节的大小，还剩8个字节没有找到用处，从此处分析应该还有一个指向虚函数表的指针，具体的情况可以看一下内存分布。 接下来和单继承的分析方法一样，写代码编译查看布局： 123456789101112131415161718192021222324252627282930313233class CBase0&#123;public: void func0() &#123;&#125; virtual void func1() &#123;&#125; virtual void func2() &#123;&#125; virtual void func3() &#123;&#125;public: int m_var0;&#125;;class CBase1&#123;public: void func0() &#123;&#125; virtual void func2() &#123;&#125; virtual void func3() &#123;&#125; virtual void func4() &#123;&#125;public: int m_var1;&#125;;class CDerived : public CBase0, public CBase1&#123;public: virtual void func1() &#123;&#125; virtual void func2() &#123;&#125; virtual void func4() &#123;&#125; virtual void func5() &#123;&#125; void func6() &#123;&#125;public: int m_var2;&#125;; 上面3个类描述了一个简单的多继承的情况，之所以写这么多函数就是构建一种，既有虚函数覆盖，又有单独不被覆盖的情况，下面展示了这段代码的内存布局。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566671&gt; class CBase0 size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | m_var01&gt; +---1&gt;1&gt; CBase0::$vftable@:1&gt; | &amp;CBase0_meta1&gt; | 01&gt; 0 | &amp;CBase0::func11&gt; 1 | &amp;CBase0::func21&gt; 2 | &amp;CBase0::func31&gt;1&gt; CBase0::func1 this adjustor: 01&gt; CBase0::func2 this adjustor: 01&gt; CBase0::func3 this adjustor: 01&gt;1&gt;1&gt; class CBase1 size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | m_var11&gt; +---1&gt;1&gt; CBase1::$vftable@:1&gt; | &amp;CBase1_meta1&gt; | 01&gt; 0 | &amp;CBase1::func21&gt; 1 | &amp;CBase1::func31&gt; 2 | &amp;CBase1::func41&gt;1&gt; CBase1::func2 this adjustor: 01&gt; CBase1::func3 this adjustor: 01&gt; CBase1::func4 this adjustor: 01&gt;1&gt;1&gt; class CDerived size(20):1&gt; +---1&gt; | +--- (base class CBase0)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | m_var01&gt; | +---1&gt; | +--- (base class CBase1)1&gt; 8 | | &#123;vfptr&#125;1&gt; 12 | | m_var11&gt; | +---1&gt; 16 | m_var21&gt; +---1&gt;1&gt; CDerived::$vftable@CBase0@:1&gt; | &amp;CDerived_meta1&gt; | 01&gt; 0 | &amp;CDerived::func11&gt; 1 | &amp;CDerived::func21&gt; 2 | &amp;CBase0::func31&gt; 3 | &amp;CDerived::func51&gt;1&gt; CDerived::$vftable@CBase1@:1&gt; | -81&gt; 0 | &amp;thunk: this-=8; goto CDerived::func21&gt; 1 | &amp;CBase1::func31&gt; 2 | &amp;CDerived::func41&gt;1&gt; CDerived::func1 this adjustor: 01&gt; CDerived::func2 this adjustor: 01&gt; CDerived::func4 this adjustor: 81&gt; CDerived::func5 this adjustor: 0 内容很多，前面两个基类 CBase0 和 CBase1 的布局很简单，参照之前的分析很容易看懂，直接从派生类看起吧。 我们发现派生类 CDerived 中确实有两个指向虚函数表的指针，接下来看一下这两个虚函数表，这个虚函数表和前面遇到的格式一样，除了第一行的元数据，第二行的诡异偏移量0，剩下的虚函数指针有的是从基类继承来的，有的是被当前派生类覆盖的，还有派生类自己独有的。 而第二个虚函数表就有点意思了，首先是少了 &amp;CDerived_meta 这一行，然后偏移量终于不是0了，而是-8，从派生类 CDerived 的内存布局上来看，以下开始大胆假设，至于小心求证的部分放到以后来做（看自己的进步状态了）。 第二个指向虚函数表的指针是不是距离类的起始偏移量是8，我猜这个-8的意思就是指的这个偏移量，这个值有可能被后面使用，第二行出现了 &amp;thunk: this-=8; goto CDerived::func2，其中包含 thunk 字样，表示这个 func2 不归我管，你去-8偏移量的那个虚函数表里找一找。 还有一点你有没有发现 func5 这个函数只在第一个虚函数表中出现，而没有出现在第二个虚函数表中，这也是一个规则，自己独有的虚函数放到第一个虚函数表中，这可能也是为什么只有第一个虚函数表包含元数据行。 最后一点，我们发现对于函数 func4 来说 adjustor 终于不是0了，而值变成了8，仿佛在说这个虚函数只在偏移量的为8的位置。 菱形继承对于这一部分，并没有太多新的内容，只是简单的菱形继承中，最初的基类在最终的子类中会包含两份，而虚函数的样子并没有太大的不同，接下来简单看一下代码和对应的内存布局即可，因为菱形继承并不被提倡，所以也不用花太多时间来分析这个问题。 123456789101112131415161718192021222324252627282930313233343536class CSuper&#123;public: virtual void func0() &#123;&#125; virtual void func1() &#123;&#125;public: int m_var;&#125;;class CBase0 : public CSuper&#123;public: virtual void func1() &#123;&#125; virtual void func2() &#123;&#125;public: int m_var0;&#125;;class CBase1 : public CSuper&#123;public: virtual void func1() &#123;&#125; virtual void func3() &#123;&#125;public: int m_var1;&#125;;class CDerived : public CBase0, public CBase1&#123;public: virtual void func1() &#123;&#125; virtual void func3() &#123;&#125; virtual void func4() &#123;&#125;public: int m_var2;&#125;; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091921&gt; class CSuper size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | m_var1&gt; +---1&gt;1&gt; CSuper::$vftable@:1&gt; | &amp;CSuper_meta1&gt; | 01&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CSuper::func11&gt;1&gt; CSuper::func0 this adjustor: 01&gt; CSuper::func1 this adjustor: 01&gt;1&gt;1&gt; class CBase0 size(12):1&gt; +---1&gt; | +--- (base class CSuper)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | m_var1&gt; | +---1&gt; 8 | m_var01&gt; +---1&gt;1&gt; CBase0::$vftable@:1&gt; | &amp;CBase0_meta1&gt; | 01&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CBase0::func11&gt; 2 | &amp;CBase0::func21&gt;1&gt; CBase0::func1 this adjustor: 01&gt; CBase0::func2 this adjustor: 01&gt;1&gt;1&gt; class CBase1 size(12):1&gt; +---1&gt; | +--- (base class CSuper)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | m_var1&gt; | +---1&gt; 8 | m_var11&gt; +---1&gt;1&gt; CBase1::$vftable@:1&gt; | &amp;CBase1_meta1&gt; | 01&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CBase1::func11&gt; 2 | &amp;CBase1::func31&gt;1&gt; CBase1::func1 this adjustor: 01&gt; CBase1::func3 this adjustor: 01&gt;1&gt;1&gt; class CDerived size(28):1&gt; +---1&gt; | +--- (base class CBase0)1&gt; | | +--- (base class CSuper)1&gt; 0 | | | &#123;vfptr&#125;1&gt; 4 | | | m_var1&gt; | | +---1&gt; 8 | | m_var01&gt; | +---1&gt; | +--- (base class CBase1)1&gt; | | +--- (base class CSuper)1&gt; 12 | | | &#123;vfptr&#125;1&gt; 16 | | | m_var1&gt; | | +---1&gt; 20 | | m_var11&gt; | +---1&gt; 24 | m_var21&gt; +---1&gt;1&gt; CDerived::$vftable@CBase0@:1&gt; | &amp;CDerived_meta1&gt; | 01&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CDerived::func11&gt; 2 | &amp;CBase0::func21&gt; 3 | &amp;CDerived::func41&gt;1&gt; CDerived::$vftable@CBase1@:1&gt; | -121&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;thunk: this-=12; goto CDerived::func11&gt; 2 | &amp;CDerived::func31&gt;1&gt; CDerived::func1 this adjustor: 01&gt; CDerived::func3 this adjustor: 121&gt; CDerived::func4 this adjustor: 0 虚继承解决菱形继承的一个常用的办法就是改为虚继承，实际上虚继承中就是将从最基类中继承的公共部分提取出来放在最子类的末尾，然后在提取之前的位置用一个叫做vbptr的指针指向这里。 之前看到过一种说法： 虚继承内部实现也相当复杂，似乎破坏了OO的纯洁性 至于复杂不复杂，看看后面的内存布局就很清楚了，那是相当复杂，其中出现了各种偏移，简单了解下就行了，如果不是维护老代码，谁现在还写这样的结构。 123456789101112131415161718192021222324252627282930313233343536class CSuper&#123;public: virtual void func0() &#123;&#125; virtual void func1() &#123;&#125;public: int m_var;&#125;;class CBase0 : virtual public CSuper&#123;public: virtual void func1() &#123;&#125; virtual void func2() &#123;&#125;public: int m_var0;&#125;;class CBase1 : virtual public CSuper&#123;public: virtual void func1() &#123;&#125; virtual void func3() &#123;&#125;public: int m_var1;&#125;;class CDerived : public CBase0, public CBase1&#123;public: virtual void func1() &#123;&#125; virtual void func3() &#123;&#125; virtual void func4() &#123;&#125;public: int m_var2;&#125;; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281&gt; class CSuper size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | m_var1&gt; +---1&gt;1&gt; CSuper::$vftable@:1&gt; | &amp;CSuper_meta1&gt; | 01&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CSuper::func11&gt;1&gt; CSuper::func0 this adjustor: 01&gt; CSuper::func1 this adjustor: 01&gt;1&gt;1&gt; class CBase0 size(20):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | &#123;vbptr&#125;1&gt; 8 | m_var01&gt; +---1&gt; +--- (virtual base CSuper)1&gt; 12 | &#123;vfptr&#125;1&gt; 16 | m_var1&gt; +---1&gt;1&gt; CBase0::$vftable@CBase0@:1&gt; | &amp;CBase0_meta1&gt; | 01&gt; 0 | &amp;CBase0::func21&gt;1&gt; CBase0::$vbtable@:1&gt; 0 | -41&gt; 1 | 8 (CBase0d(CBase0+4)CSuper)1&gt;1&gt; CBase0::$vftable@CSuper@:1&gt; | -121&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CBase0::func11&gt;1&gt; CBase0::func1 this adjustor: 121&gt; CBase0::func2 this adjustor: 01&gt;1&gt; vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; CSuper 12 4 4 01&gt;1&gt;1&gt; class CBase1 size(20):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | &#123;vbptr&#125;1&gt; 8 | m_var11&gt; +---1&gt; +--- (virtual base CSuper)1&gt; 12 | &#123;vfptr&#125;1&gt; 16 | m_var1&gt; +---1&gt;1&gt; CBase1::$vftable@CBase1@:1&gt; | &amp;CBase1_meta1&gt; | 01&gt; 0 | &amp;CBase1::func31&gt;1&gt; CBase1::$vbtable@:1&gt; 0 | -41&gt; 1 | 8 (CBase1d(CBase1+4)CSuper)1&gt;1&gt; CBase1::$vftable@CSuper@:1&gt; | -121&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CBase1::func11&gt;1&gt; CBase1::func1 this adjustor: 121&gt; CBase1::func3 this adjustor: 01&gt;1&gt; vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; CSuper 12 4 4 01&gt;1&gt;1&gt; class CDerived size(36):1&gt; +---1&gt; | +--- (base class CBase0)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | &#123;vbptr&#125;1&gt; 8 | | m_var01&gt; | +---1&gt; | +--- (base class CBase1)1&gt; 12 | | &#123;vfptr&#125;1&gt; 16 | | &#123;vbptr&#125;1&gt; 20 | | m_var11&gt; | +---1&gt; 24 | m_var21&gt; +---1&gt; +--- (virtual base CSuper)1&gt; 28 | &#123;vfptr&#125;1&gt; 32 | m_var1&gt; +---1&gt;1&gt; CDerived::$vftable@CBase0@:1&gt; | &amp;CDerived_meta1&gt; | 01&gt; 0 | &amp;CBase0::func21&gt; 1 | &amp;CDerived::func41&gt;1&gt; CDerived::$vftable@CBase1@:1&gt; | -121&gt; 0 | &amp;CDerived::func31&gt;1&gt; CDerived::$vbtable@CBase0@:1&gt; 0 | -41&gt; 1 | 24 (CDerivedd(CBase0+4)CSuper)1&gt;1&gt; CDerived::$vbtable@CBase1@:1&gt; 0 | -41&gt; 1 | 12 (CDerivedd(CBase1+4)CSuper)1&gt;1&gt; CDerived::$vftable@CSuper@:1&gt; | -281&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CDerived::func11&gt;1&gt; CDerived::func1 this adjustor: 281&gt; CDerived::func3 this adjustor: 121&gt; CDerived::func4 this adjustor: 01&gt;1&gt; vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; CSuper 28 4 4 0 总结 虚函数表是用来实现多态的核心内容。 多继承很强大但是不要滥用，当多个基类都含有虚函数时，派生类会有多个指向虚函数表的指针。 忘记菱形继承吧，为了取消二义性引入虚继承，结果造成内存分布复杂而又难以理解，大道至简，回归本质吧！]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>继承</tag>
        <tag>多态</tag>
        <tag>虚函数表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ STL中map的[]操作符使用时的一个坑]]></title>
    <url>%2Fblog%2F2019%2F12%2F14%2FC-STL%E4%B8%ADmap%E7%9A%84-%E6%93%8D%E4%BD%9C%E7%AC%A6%E4%BD%BF%E7%94%A8%E6%97%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91%2F</url>
    <content type="text"><![CDATA[前言学习C++，自从发现了map这个结构以后，就深深的被这种键值对的方式吸引了，写代码时也渐渐离不开这种结构了，一次偶然的机会发现这个map还有个 [] 运算符，仿佛又发现了新大陆一样，写代码更加方便了，殊不知一个深深的大坑正在前面等着我。 问题一开始学到map的时候还是中规中矩的使用函数插入删除，比如定义一个map，先引入头文件和命名空间： 1234#include &lt;map&gt;using namespace std;map&lt;int, int&gt; mapTest; 上面就轻松定义了一个map结构对象，是一个整数到另一个整数的映射，这种映射有什么用呢？举个简单的例子，这个映射可以作为学生的学号和成绩的对应关系，这样只要知道学号，就可以从map中直接获得对应的成绩很方便。 最开始学习插入时通常有以下两种方式： 12mapTest.insert(map&lt;int, int&gt;::value_type(1001, 100));mapTest.insert(make_pair(1002, 98)); 但是学了 map 的 [] 操作符以后，上述代码可以写成： 12mapTest[1001] = 100;mapTest[1002] = 98; 查找一个元素的时候需要用到find()函数，一般写成 123map&lt;int, int&gt;::const_iterator itor = mapTest.find(1001);if (itor != mapTest.end()) return itor-&gt;second; 但是学了 map 的 [] 操作符以后，上述代码就可以简写成： 1return mapTest[1001]; 特别的在插入一个元素的时候，比如用来计数，每次给一个键对应的值加1时，可以直接写成： 1mapTest[1001] += 1; 根本不用检查 1001 这个键是否存在，使用 [] 操作符，在使用前会先默认成0，然后执行+1操作，这个比先使用find()查找，然后+1操作后再插入方便多了。 其实这只是使用map结构的一种语法糖，但是这语法糖简直太好使了，太甜了，让人欲罢不能，所以我就含着这块糖掉进了坑里，因为调用 map 的有时会产生副作用，如果查找一个键不在 map 中，则会在map中对应的这个键的位置插入默认值，接下来看一下例子就明白了。 测试过程测试代码在VS2015中编译运行，C++11标准，如果编译不正确可以看一下环境是否不同，尝试修改代码实现即可，测试的例子也是上面提到的，使用 map 来存储学生学号和成绩的对应关系，下面来简单实现一个类，描述这种关系： 编写测试类1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;map&gt;#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;class CReportCard&#123;public: CReportCard() &#123; m_mapStuNo2Score.clear(); &#125; ~CReportCard() &#123; m_mapStuNo2Score.clear(); &#125;public: void LoadScores(); // 模拟录入成绩 int GetScoreByStudentNo(const int nStudentNo); // 根据学号查询成绩 void PrintReportCard(); // 打印成绩单private: map&lt;int, int&gt; m_mapStuNo2Score;&#125;;void CReportCard::LoadScores()&#123; m_mapStuNo2Score[1001] = 99; m_mapStuNo2Score[1002] = 94; m_mapStuNo2Score[1004] = 89; m_mapStuNo2Score[1005] = 92; m_mapStuNo2Score[1007] = 80;&#125;int CReportCard::GetScoreByStudentNo(const int nStudentNo)&#123; return m_mapStuNo2Score[nStudentNo];&#125;void CReportCard::PrintReportCard()&#123; cout &lt;&lt; "show report card start-----&gt;" &lt;&lt; endl; std::for_each(m_mapStuNo2Score.begin(), m_mapStuNo2Score.end(), [](std::map&lt;int, int&gt;::reference socrepair) &#123; std::cout &lt;&lt; socrepair.first &lt;&lt; "'s score = " &lt;&lt; socrepair.second &lt;&lt; "\n"; &#125;); cout &lt;&lt; "show report card end&lt;------" &lt;&lt; endl;&#125; 这个类的内容很简单，使用 map 类型的对象 m_mapStuNo2Score 来存储学号和成绩的对应关系，LoadScores()函数中使用 [] 操作符向 map 中插入元素，模拟成绩录入过程；GetScoreByStudentNo()函数同样使用了 [] 操作符模拟成绩查询过程；PrintReportCard()函数遍历 map 打印成绩单信息。 看似正常的调用接下来编写一个函数来使用这个类，测试如下： 123456789101112int main(int argc, char* argv[])&#123; CReportCard obj; obj.LoadScores(); cout &lt;&lt; "student no = 1001, score = " &lt;&lt; obj.GetScoreByStudentNo(1001) &lt;&lt; endl; cout &lt;&lt; "student no = 1004, score = " &lt;&lt; obj.GetScoreByStudentNo(1004) &lt;&lt; endl; obj.PrintReportCard(); return 0;&#125; 首先调用 LoadScores()函数来加载数据，然后通过 GetScoreByStudentNo() 函数来查找学号为 1001 和 1004 的两个学生的成绩，最后打印一下成绩单，接下来看一下运行结果： student no = 1001, score = 99student no = 1004, score = 89show report card start—–&gt;1001’s score = 991002’s score = 941004’s score = 891005’s score = 921007’s score = 80show report card end&lt;—— 以上结果正常的打印出了查询的分数和成绩单，一切看起来毫无问题，如果查询的学号不存在又会怎么样呢？ 出现问题的调用修改上面的测试函数，将学生学号改成不存在的数值，修改如下： 12345678910111213int main(int argc, char* argv[])&#123; CReportCard obj; obj.LoadScores(); cout &lt;&lt; endl; cout &lt;&lt; "student no = 1011, score = " &lt;&lt; obj.GetScoreByStudentNo(1011) &lt;&lt; endl; cout &lt;&lt; "student no = 1014, score = " &lt;&lt; obj.GetScoreByStudentNo(1014) &lt;&lt; endl; obj.PrintReportCard(); return 0;&#125; 大部分的内容并没有发生变化，只将学号改成了不存在的情况，测试结果如下： student no = 1011, score = 0student no = 1014, score = 0show report card start—–&gt;1001’s score = 991002’s score = 941004’s score = 891005’s score = 921007’s score = 801011’s score = 01014’s score = 0show report card end&lt;—— 不存在的学号对应的分数是0，这应该也说的过去，因为键不存在，所以对 map 使用 [] 操作符查找时，寻找的键不存在则返回了整型的默认值0，但是在打印成绩单的时候居然多了两项，这充分暴露了 [] 操作符可能产生的副作用。 在查找返回时，[] 操作符并不是找不到返回对应类型默认值就完了，还会把查找的键和默认值作为一对，插入到待查的 map，这种操作一般是我们不需要的，所以在你明确不需要这个副作用时，查找 map 元素不要使用 [] 操作符。 亡羊补牢上面说到，[] 操作符查找不到就插入的副作用一般我们不使用，所以在查找时还是使用 find() 函数更规范一些，修改 GetScoreByStudentNo() 函数如下： 123456int CReportCard::GetScoreByStudentNo(const int nStudentNo)&#123; //return m_mapStuNo2Score[nStudentNo]; map&lt;int, int&gt;::const_iterator itor = m_mapStuNo2Score.find(nStudentNo); return itor != m_mapStuNo2Score.end() ? itor-&gt;second : 0;&#125; 此时再运行上面的例子就正常了，成绩单中也不会插入无效值了。 总结 map 的 [] 操作符会有副作用，当查找的键不存在时，会在对应键位置插入默认值 时刻保持清醒的头脑，过分的方便或许会给你自己埋下深深的坑 敬畏自然、敬畏生命、敬畏你写下的每一行代码]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>find</tag>
        <tag>中括号</tag>
        <tag>insert</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中全局变量、会话变量、用户变量和局部变量的区别]]></title>
    <url>%2Fblog%2F2019%2F12%2F03%2FMySQL%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E3%80%81%E4%BC%9A%E8%AF%9D%E5%8F%98%E9%87%8F%E3%80%81%E7%94%A8%E6%88%B7%E5%8F%98%E9%87%8F%E5%92%8C%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言之前在项目的存储过程中发现有通过 DECLARE 关键字定义的变量如DECLARE cnt INT DEFAULT 0;，还有形如 @count 这样的变量，存储过程中拿过来直接就进行设置，像这样set @count=1;，这两种类型的变量究竟有什么区别却弄不清楚，赶紧上网查询资料，发现还有@@sql_mode这样的变量，这一个圈俩圈的到底是什么啊？会不会出现三个圈的情况？ 变量分类与关系经过一段时间学习和测试，再配合官方的文档，现在大致弄清楚了这些变量的区别，一般可以将MySQL中的变量分为全局变量、会话变量、用户变量和局部变量，这是很常见的分类方法，这些变量的作用是什么呢？可以从前往后依次看一下。 首先我们知道MySQL服务器维护了许多系统变量来控制其运行的行为，这些变量有些是默认编译到软件中的，有些是可以通过外部配置文件来配置覆盖的，如果想查询自编译的内置变量和从文件中可以读取覆盖的变量可以通过以下命令来查询: 1mysqld --verbose --help 如果想只看自编译的内置变量可以使用命令： 1mysqld --no-defaults --verbose --help 接下来简单了解一下这几类变量的应用范围，首先MySQL服务器启动时会使用其软件内置的变量（俗称写死在代码中的）和配置文件中的变量（如果允许，是可以覆盖源代码中的默认值的）来初始化整个MySQL服务器的运行环境，这些变量通常就是我们所说的全局变量，这些在内存中的全局变量有些是可以修改的。 当有客户端连接到MySQL服务器的时候，MySQL服务器会将这些全局变量的大部分复制一份作为这个连接客户端的会话变量，这些会话变量与客户端连接绑定，连接的客户端可以修改其中允许修改的变量，但是当连接断开时这些会话变量全部消失，重新连接时会从全局变量中重新复制一份。 其实与连接相关的变量不只有会话变量一种，用户变量也是这样的，用户变量其实就是用户自定义变量，当客户端连接上MySQL服务器之后就可以自己定义一些变量，这些变量在整个连接过程中有效，当连接断开时，这些用户变量消失。 局部变量实际上最好理解，通常由DECLARE 关键字来定义，经常出现在存储过程中，非常类似于C和C++函数中的局部变量，而存储过程的参数也和这种变量非常相似，基本上可以作为同一种变量来对待。 变量的修改先说全局变量有很多是可以动态调整的，也就是说可以在MySQL服务器运行期间通过 SET 命令修改全局变量，而不需要重新启动 MySQL 服务，但是这种方法在修改大部分变量的时候都需要超级权限，比如root账户。 相比之下会话对变量修改的要求要低的多，因为修改会话变量通常只会影响当前连接，但是有个别一些变量是例外的，修改它们也需要较高的权限，比如 binlog_format 和 sql_log_bin，因为设置这些变量的值将影响当前会话的二进制日志记录，也有可能对服务器复制和备份的完整性产生更广泛的影响。 至于用户变量和局部变量，听名字就知道，这些变量的生杀大权完全掌握在自己手中，想改就改，完全不需要理会什么权限，它的定义和使用全都由用户自己掌握。 测试环境以下给出MySQL的版本，同时使用root用户测试，这样可以避免一些权限问题。 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 变量查询与设置全局变量这些变量来源于软件自编译、配置文件中、以及启动参数中指定的变量，其中大部分是可以由root用户通过 SET 命令直接在运行时来修改的，一旦 MySQL 服务器重新启动，所有修改都被还原。如果修改了配置文件，想恢复最初的设置，只需要将配置文件还原，重新启动 MySQL 服务器，一切都可以恢复原来的样子。 查询查询所有的全局变量： 1show global variables; 一般不会这么用，这样查简直太多了，大概有500多个，通常会加个like控制过滤条件： 12345678910111213141516171819mysql&gt; show global variables like 'sql%';+------------------------+----------------------------------------------------------------+| Variable_name | Value |+------------------------+----------------------------------------------------------------+| sql_auto_is_null | OFF || sql_big_selects | ON || sql_buffer_result | OFF || sql_log_off | OFF || sql_mode | STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION || sql_notes | ON || sql_quote_show_create | ON || sql_safe_updates | OFF || sql_select_limit | 18446744073709551615 || sql_slave_skip_counter | 0 || sql_warnings | OFF |+------------------------+----------------------------------------------------------------+11 rows in set, 1 warning (0.00 sec)mysql&gt; 还有一种查询方法就是通过select语句： 1select @@global.sql_mode; 当一个全局变量不存在会话变量副本时也可以这样 1select @@max_connections; 设置设置全局变量也有两种方式： 1set global sql_mode=''; 或者 1set @@global.sql_mode=''; 会话变量这些变量基本来自于全局变量的复制，与客户端连接有关，无论怎样修改，当连接断开后，一切都会还原，下次连接时又是一次新的开始。 查询类比全局变量，会话变量也有类似的查询方式，查询所有会话变量 1show session variables; 添加查询匹配，只查一部分会话变量： 1show session variables like 'sql%'; 查询特定的会话变量，以下三种都可以： 123select @@session.sql_mode;select @@local.sql_mode;select @@sql_mode; 设置会话变量的设置方法是最多的，以下的方式都可以： 123456set session sql_mode = '';set local sql_mode = '';set @@session.sql_mode = '';set @@local.sql_mode = '';set @@sql_mode = '';set sql_mode = ''; 用户变量用户变量就是用户自己定义的变量，也是在连接断开时失效，定义和使用相比会话变量来说简单许多。 查询直接一个select语句就可以了： 1select @count; 设置设置也相对简单，可以直接使用set命令： 12set @count=1;set @sum:=0; 也可以使用select into语句来设置值，比如： 1select count(id) into @count from items where price &lt; 99; 局部变量局部变量通常出现在存储过程中，用于中间计算结果，交换数据等等，当存储过程执行完，变量的生命周期也就结束了。 查询也是使用select语句： 12declare count int(4);select count; 设置与用户变量非常类似： 1234declare count int(4);declare sum int(4);set count=1;set sum:=0; 也可以使用select into语句来设置值，比如： 12declare count int(4);select count(id) into count from items where price &lt; 99; 其实还有一种存储过程参数，也就是C/C++中常说的形参，使用方法与局部变量基本一致，就当成局部变量来用就可以了 几种变量的对比使用 操作类型 全局变量 会话变量 用户变量 局部变量（参数） 文档常用名 global variables session variables user-defined variables local variables 出现的位置 命令行、函数、存储过程 命令行、函数、存储过程 命令行、函数、存储过程 函数、存储过程 定义的方式 只能查看修改，不能定义 只能查看修改，不能定义 直接使用，@var形式 declare count int(4); 有效生命周期 服务器重启时恢复默认值 断开连接时，变量消失 断开连接时，变量消失 出了函数或存储过程的作用域，变量无效 查看所有变量 show global variables; show session variables; - - 查看部分变量 show global variables like &#39;sql%&#39;; show session variables like &#39;sql%&#39;; - - 查看指定变量 select @@global.sql_mode、select @@max_connections; select @@session.sql_mode;、 select @@local.sql_mode;、 select @@sql_mode; select @var; select count; 设置指定变量 set global sql_mode=&#39;&#39;;、 set @@global.sql_mode=&#39;&#39;; set session sql_mode = &#39;&#39;;、 set local sql_mode = &#39;&#39;;、 set @@session.sql_mode = &#39;&#39;;、 set @@local.sql_mode = &#39;&#39;;、 set @@sql_mode = &#39;&#39;;、 set sql_mode = &#39;&#39;; set @var=1;、 set @var:=101;、 select 100 into @var; set count=1;、 set count:=101;、 select 100 into count; 相信看了这个对比的表格，之前的很多疑惑就应该清楚了，如果发现其中有什么疑惑的地方可以给我留言，或者发现有什么错误也可以一针见血的指出来，我会尽快改正的。 总结 MySQL 中的变量通常分为：全局变量、 会话变量、 用户变量、 局部变量 其实还有一个存储过程和函数的参数，这种类型和局部变量基本一致，当成局部变量来使用就行了 在表格中有一个容易疑惑的点就是无论是全局变量还是会话变量都有select@@变量名的形式。 select@@变量名这种形式默认取的是会话变量，如果查询的会话变量不存在就会获取全局变量，比如@@max_connections 但是SET操作的时候，set @@变量名=xxx 总是操作的会话变量，如果会话变量不存在就会报错]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>全局变量</tag>
        <tag>会话变量</tag>
        <tag>用户变量</tag>
        <tag>局部变量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库导入、导出、复制表、重命名表]]></title>
    <url>%2Fblog%2F2019%2F11%2F30%2FMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%BC%E5%85%A5%E3%80%81%E5%AF%BC%E5%87%BA%E3%80%81%E5%A4%8D%E5%88%B6%E8%A1%A8%E3%80%81%E9%87%8D%E5%91%BD%E5%90%8D%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[前言提前说明这是一篇小白总结，高手勿喷请绕行，写这篇总结的原因是发觉自己有时候确实眼高手低了，大道至简，花了很多时间去看索引、缓存、主从等等，等到出现实际问题的时候却发现自己磨磨蹭蹭写出的SQL语句居然有语法错误，看来还得稳扎稳打从基础入手，因为实际工作的用到的SQL并不多，现在把常用的几条总结一下，即使下次不能立马写出来，也能在这篇文章中的快速找到想要的。 正如标题中的提到的这些，数据库的导入和导出在紧急处理线上数据时很常用，而复制表基本上也是为了不影响原数据的情况下进行问题排查，重命名表是为了导入多份备份数据时原数据不被覆盖，比如想对比两天的A表数据，可以先把第一天的数据导入，然后将A表名修改成Aold，接着直接再导入第二天的数据库数据，这样就可以将数据库中表Aold和A进行对比了，可以避免两个数据库中的同一个表进行对比时写很长的SQL。 测试环境 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 11Server version: 5.7.28-log MySQL Community Server (GPL)Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 测试过程为了说明实现这些要求的具体SQL，我们先建立一个测试数据库，然后创建测试表格，插入测试数据，最后在这个数据库上依次实现这些要求。 创建测试数据创建测试数据库和表格1234567891011121314151617181920mysql&gt; create database dbtest;Query OK, 1 row affected (0.00 sec)mysql&gt; use dbtestDatabase changedmysql&gt; create table a(id int, num int);Query OK, 0 rows affected (0.02 sec)mysql&gt; create table b(id int, name varchar(32));Query OK, 0 rows affected (0.01 sec)mysql&gt; show tables;+--------------+| Tables_in_zz |+--------------+| a || b |+--------------+2 rows in set (0.00 sec) 插入测试数据1234567891011121314151617181920212223242526272829mysql&gt; insert into a values(1, 100);Query OK, 1 row affected (0.02 sec)mysql&gt; insert into a values(2, 200);Query OK, 1 row affected (0.01 sec)mysql&gt; select * from a;+------+------+| id | num |+------+------+| 1 | 100 || 2 | 200 |+------+------+2 rows in set (0.01 sec)mysql&gt; insert into b values(1, 'albert');Query OK, 1 row affected (0.01 sec)mysql&gt; insert into b values(2, 'tom');Query OK, 1 row affected (0.01 sec)mysql&gt; select * from b;+------+--------+| id | name |+------+--------+| 1 | albert || 2 | tom |+------+--------+2 rows in set (0.00 sec) 数据库导出数据库导出时使用的最基础的工具叫mysqldump，这是单独的工具不是mysql命令，刚学MySQL的时候居然在MySQL的命令行中使用mysqldump，现在只能当笑话看了。 导出指定数据库中所有表结构和数据在系统的命令行工具下输入以下命令，敲入回车输入密码，再回车就可以将数据库dbtest的结构和数据导出到dbtest.sql文件中： 1&gt;mysqldump -uroot -h192.168.1.101 -p dbtest &gt; dbtest.sql 打开dbtest.sql文件，显示如下：文件内容比较长，里面包含了数据库的表结构和其中的数据信息： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273-- MySQL dump 10.13 Distrib 5.7.21, for Win64 (x86_64)---- Host: localhost Database: dbtest-- -------------------------------------------------------- Server version 5.7.21-log/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;/*!40101 SET NAMES utf8 */;/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;/*!40103 SET TIME_ZONE='+00:00' */;/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;---- Table structure for table `a`--DROP TABLE IF EXISTS `a`;/*!40101 SET @saved_cs_client = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `a` ( `id` int(11) DEFAULT NULL, `num` int(11) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8;/*!40101 SET character_set_client = @saved_cs_client */;---- Dumping data for table `a`--LOCK TABLES `a` WRITE;/*!40000 ALTER TABLE `a` DISABLE KEYS */;INSERT INTO `a` VALUES (1,100),(2,200);/*!40000 ALTER TABLE `a` ENABLE KEYS */;UNLOCK TABLES;---- Table structure for table `b`--DROP TABLE IF EXISTS `b`;/*!40101 SET @saved_cs_client = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `b` ( `id` int(11) DEFAULT NULL, `name` varchar(32) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8;/*!40101 SET character_set_client = @saved_cs_client */;---- Dumping data for table `b`--LOCK TABLES `b` WRITE;/*!40000 ALTER TABLE `b` DISABLE KEYS */;INSERT INTO `b` VALUES (1,'albert'),(2,'tom');/*!40000 ALTER TABLE `b` ENABLE KEYS */;UNLOCK TABLES;/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;-- Dump completed on 2019-11-30 11:32:23 只导出指定数据库中所有表的结构只导出表结构的方法和上面是一样的，只是加上 -d 选项就可以了，运行下面命令就可以将dbtest数据库中的所有表结构导出到 dbteststructure.sql 中，因为和上面类似，文件中的内容就不贴了，只比 dbtest.sql 文件少了插入数据的内容： 1&gt;mysqldump -uroot -h192.168.1.101 -p -d dbtest &gt; dbteststructure.sql 只导出指定数据库中的一个表只导出数据库中指定表，可以是一个也可以是多个，在数据库名字后面跟表的名字就可以了，比如导出表a： 1&gt;mysqldump -uroot -h192.168.1.101 -p dbtest a &gt; dbtest_a.sql 导出多个数据库数据出多个数据库数据需要加上 --databases 选项，然后在后面依次跟上数据库名字就行： 1&gt;mysqldump -uroot -h192.168.1.101 -p --databases dbtest dbtest2 &gt; db_more.sql 导出所有数据库数据导出所有的数据库时不需要加数据库的名字，加上 --all-databases 选项就可以了 1&gt;mysqldump -uroot -h192.168.1.101 -p --all-databases &gt; db_all.sql 数据库导入数据库的导入比较简单，实际上就是把sql文件在MySQL中执行一下，可以使用以下两种方式： 系统命令行导入一般需要指定导入的数据库dbtest和sql文件的路径，在Linux上举例： 1&gt;mysql -uroot -h192.168.1.101 -p dbtest &lt; /home/albert/dbtest.sql --default-character-set=utf8 在Windows上举例，主要是路径需要注意，Windows上使用正斜杠/和反斜杠\都可以，默认是反斜杠，如果路径中包含空格可以用双引号将整个路径包起来： 1&gt;mysql -uroot -h192.168.1.101 -p dbtest &lt; D:\albert\dbtest.sql --default-character-set=utf8 注意--default-character-set=utf8是指定默认的字符集，主要是防止导入时出现编码错误，之前总结过，在此复习一下。 MySQL命令行导入首先连接MySQL服务器进行登陆： 1&gt;mysql -uroot -h192.168.1.101 -p --default-character-set=utf8 输入密码登陆后再使用source命令直接导入sql文件就可以： 1mysql&gt; source D:\albert\dbtest.sql 数据表复制数据表的复制可以分为结构复制和完全复制，其中完全复制时可以先复制结构，再将数据复制到新表中： 只复制表结构 使用LIKE语句，只不过5.0版本之后才支持，之前的版本无法使用 1CREATE TABLE new_table LIKE old_table; 1234567891011121314151617181920212223mysql&gt; select * from a;+------+------+| id | num |+------+------+| 1 | 100 || 2 | 200 |+------+------+2 rows in set (0.01 sec)mysql&gt; create table a2 like a;Query OK, 0 rows affected (0.04 sec)mysql&gt; desc a2;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.02 sec)mysql&gt; select * from a2;Empty set (0.00 sec) 使用 SELECT 语句加不成立的条件实现 1CREATE TABLE new_table SELECT * FROM old_table WHERE FALSE; 123456789101112131415mysql&gt; create table a3 select * from a where false;Query OK, 0 rows affected (0.07 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc a3;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.01 sec)mysql&gt; select * from a3;Empty set (0.01 sec) 复制表结构和数据 可以先按照上面的语句复制结构，然后再讲数据复制过去： 12CREATE TABLE new_table SELECT * FROM old_table WHERE FALSE;INSERT INTO new_table SELECT * FROM old_table; 123456789101112mysql&gt; insert into a2 select * from a;Query OK, 2 rows affected (0.07 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; select * from a2;+------+------+| id | num |+------+------+| 1 | 100 || 2 | 200 |+------+------+2 rows in set (0.00 sec) 直接将结构和数据全部复制 1CREATE TABLE new_table SELECT * FROM old_table; 123456789101112131415161718192021mysql&gt; create table a4 select * from a;Query OK, 2 rows affected (0.06 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; desc a4;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.01 sec)mysql&gt; select * from a4;+------+------+| id | num |+------+------+| 1 | 100 || 2 | 200 |+------+------+2 rows in set (0.00 sec) 数据表重命名使用 ALTER 命令实现1ALTER TABLE old_table RENAME [TO|AS] new_table; 这个语句中的TO和AS是可选的，加不加都行，也可以选择其中一个，效果是一样的，测试如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344mysql&gt; show tables;+------------------+| Tables_in_dbtest |+------------------+| a || b |+------------------+5 rows in set (0.02 sec)mysql&gt; alter table b rename c;Query OK, 0 rows affected (0.04 sec)mysql&gt; show tables;+------------------+| Tables_in_dbtest |+------------------+| a || c |+------------------+5 rows in set (0.00 sec)mysql&gt; alter table c rename to d;Query OK, 0 rows affected (0.02 sec)mysql&gt; show tables;+------------------+| Tables_in_dbtest |+------------------+| a || d |+------------------+5 rows in set (0.00 sec)mysql&gt; alter table d rename as e;Query OK, 0 rows affected (0.02 sec)mysql&gt; show tables;+------------------+| Tables_in_dbtest |+------------------+| a || e |+------------------+5 rows in set (0.00 sec) 使用RENAME命令1RENAME TABLE old_table TO new_table; 这个语句中TO就不能省略了，否则会报语法错误，测试如下： 123456789101112131415161718192021mysql&gt; show tables -&gt; ;+------------------+| Tables_in_dbtest |+------------------+| a || e |+------------------+5 rows in set (0.00 sec)mysql&gt; rename table e to f;Query OK, 0 rows affected (0.11 sec)mysql&gt; show tables;+------------------+| Tables_in_dbtest |+------------------+| a || f |+------------------+5 rows in set (0.01 sec) 总结 数据库的导出、导入、数据表的复制、重命名都是MySQL操作的基础，需要熟练掌握 数据库导出：mysqldump -uroot -h192.168.1.101 -p dbtest &gt; dbtest.sql 数据库导入：mysql -uroot -h192.168.1.101 -p dbtest &lt; /tmp/dbtest.sql --default-character-set=utf8 数据表复制：CREATE TABLE new_table SELECT * FROM old_table; 表格重命名：RENAME TABLE old_table TO new_table;]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>导入</tag>
        <tag>导出</tag>
        <tag>复制表</tag>
        <tag>重命名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql导入数据库时报错ERROR: Unknown command ' ']]></title>
    <url>%2Fblog%2F2019%2F11%2F20%2FMysql%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%BA%93%E6%97%B6%E6%8A%A5%E9%94%99ERROR-Unknown-command-0%2F</url>
    <content type="text"><![CDATA[前言之前查询数据问题时多次使用过数据库导出导入命令，从来没发生过这种错误，那是一个风和日丽的上午，忽然来了一个紧急的任务，线上数据出问题了，需要马上处理一下，连上数据库备份服务器，找到备份数据直接下载下来，优雅（cong mang）地处理着这一切，本打算在Windows上直接导入查询处理一下算了，结果忙中添乱，导入数据库时居然报了一大堆错误，其中最扎眼的就是一连串的ERROR: Unknown command ‘\0’，没办法了，先找一台Linux服务器，上传导入数据分析处理一气呵成，处理完线上问题终于有时间回头来看看这个问题了。 测试环境数据库版本 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 9Server version: 5.7.28-log MySQL Community Server (GPL)Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 系统版本 Win10马马虎虎版本来打算用来快速处理的，结果添了不少乱 问题出现过程直接使用cmd命令行输入mysql -uroot -h192.168.1.101 -p，然后输入密码后成功登录，接着选择数据库use dbtest，导入数据库文件source E:\onlinedb.sql，结果意外发生了，出现了一大堆的如下错误： …………ERROR:Unknown command ‘\0’.ERROR:Unknown command ‘\0’.ERROR:Unknown command ‘\0’.ERROR:Unknown command ‘\0’.ERROR 1064 (42000): You have an error in your SQL syntax; check the manual … 命令行界面中出现了多次错误提醒ERROR: Unknown command &#39;\0&#39;.，最后有一个常见的语法错误提醒，看到这个&#39;\0&#39;，这个字节中的0，程序中nullptr，我猜到可能是编码问题，而最后的语法错误也是由于编码不同而部分解析导致的，于是查了一些资料发现果然是编码问题，只要在客户端连接Mysql服务器时指定UTF8编码就可以了。 问题结果过程导入的流程不变，只要在客户端连接Mysql服务器时指定编码就可以避免前面遇到的错误，连接时的命令修改为mysql -uroot -h192.168.1.101 -p --default-character-set=utf8就没问题了，上面提到的语法错误也不存在了。 其实这种跨平台的坑有很多，因为平台之间的哲学思想不同，导致对一些默认值的处理不太一样，同样的文件在Windows平台上导入报错，但是我换到Linux服务器上就没有任何问题，接触多了自然就释然了。 总结 导入sql文件时报错ERROR: Unknown command &#39;\0&#39;需在Mysql命令行客户端连接服务器时指定编码 连接时指定编码的格式为mysql -uroot -h192.168.1.101 -p --default-character-set=utf8]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>ERROR</tag>
        <tag>source</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中Blob类型字段的插入、查看、截取和拼接]]></title>
    <url>%2Fblog%2F2019%2F11%2F20%2FMysql%E4%B8%ADBlob%E7%B1%BB%E5%9E%8B%E5%AD%97%E6%AE%B5%E7%9A%84%E6%8F%92%E5%85%A5%E3%80%81%E6%9F%A5%E7%9C%8B%E3%80%81%E6%88%AA%E5%8F%96%E5%92%8C%E6%8B%BC%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[前言本来并没有太注意到Blob这个类型，在游戏的开发中存储数据常常使用这个类型，这里的使用其实是“机械”的使用，因为应用程序和Mysql数据库之间的逻辑已经封装好了，我只要把对应的数据扔到接口里就行了，可是最近发生了点问题，所以决定深入研究一下Blob类型的操作方法。 问题是这样的，由于应用程序的一个逻辑错误，导致Mysql数据库中有一个Blob类型的字段的前几个字节被写入了错误的值，当然这个问题，我们可以通过应用程序处理，在逻辑中读出Blob字段的值，修改为正确值以后再写回到数据库中，可是这样有些麻烦，并且这些处理逻辑与业务无关。 为了更方便的解决问题，决定使用SQL语句直接修改数据库，将错误的数据恢复正常，因为之前没有直接用SQL修改过Blob类型的字段，所以多花了一点时间用来测试，现在把整个过程记录一下，方便下次直接操作。 在整个处理的过程中用到了查看、截取和拼接三种操作，为了让例子看起来更加精炼，我们把插入也测一下，然后创造出我们想要的精简后的数据，首先还是来看一下数据库版本。 数据库版本 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.28-log MySQL Community Server (GPL)Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 创建测试表测试的表格结构很简单，只需要带有一个Blob类型的字段就尅可以了，为了操作方便再添加一个id，操作的SQL语句如下： 1234567891011mysql&gt; create table bloboperation(id int, data blob);Query OK, 0 rows affected (0.36 sec)mysql&gt; desc bloboperation;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || data | blob | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.07 sec) 插入数据因为知道Blob是二进制数据，所以首先插入两条用十六进制表示的字节串试一下，提示成功插入，插入两条一样的数据是为了之后修改的时候对比方便： 12345mysql&gt; insert into bloboperation values(1, 0x01020304FFFFFFFF0000000CAACB0000);Query OK, 1 row affected (0.06 sec)mysql&gt; insert into bloboperation values(2, 0x01020304FFFFFFFF0000000CAACB0000);Query OK, 1 row affected (0.04 sec) 插入字节串没有问题，那插入字符串和数字看看会有什么结果，测试语句如下，最后发现均可以正常插入： 12345mysql&gt; insert into bloboperation values(3, 'hellworld');Query OK, 1 row affected (0.04 sec)mysql&gt; insert into bloboperation values(4, 0);Query OK, 1 row affected (0.03 sec) 查看数据上面插入了4条不同类型的数据都成功了，我们简单来查一下看看数据和我们插入的是否一样： 12345678910mysql&gt; select * from bloboperation;+------+------------------+| id | data |+------+------------------+| 1 | ÿÿÿÿ ? || 2 | ÿÿÿÿ ? || 3 | hellworld || 4 | 0 |+------+------------------+4 rows in set (0.00 sec) 这究竟是什么鬼，除了第3、4条和我们插入的数据一样，前两条数据看起来和我们之前插入数据时完全不一样，其实这时候需要用到一个hex()函数来看Blob类型的数据，查询结果如下： 12345678910mysql&gt; select id,hex(data),length(data) from bloboperation;+------+----------------------------------+--------------+| id | hex(data) | length(data) |+------+----------------------------------+--------------+| 1 | 01020304FFFFFFFF0000000CAACB0000 | 16 || 2 | 01020304FFFFFFFF0000000CAACB0000 | 16 || 3 | 68656C6C776F726C64 | 9 || 4 | 30 | 1 |+------+----------------------------------+--------------+4 rows in set (0.02 sec) 这回前两条数据正常了，可是后两条数据为什么又看起来不一样了呢，如果你产生了这样的疑问，就需要好好理解一下内存值和表现值的对应关系了，第4条插入语句的中数据0，实际上是被当做字符串存储的，而字符’0’的ASCII码是十进制的48，表示成十六进制就是0x30，也就是上面查到的这样，同理这个打错了的字符串’hellworld’也是这样存储的。 截取数据本来以为截取数据需要一个特别的函数，没想到用的是字符串截取函数substring(str,startpos,length)，第一个参数是需要截取的字符串或字节串，第二个参数起始位置从1开始，第三个参数就是截取的长度。 以第一条数据为例，截取第4到第8个一共5个字节，测试如下： 1234567mysql&gt; select id,hex(substring(data,4,5)) from bloboperation where id=1;+------+--------------------------+| id | hex(substring(data,4,5)) |+------+--------------------------+| 1 | 04FFFFFFFF |+------+--------------------------+1 row in set (0.00 sec) 拼接数据看到上一个函数之后，你应该有所察觉，这个Blob类型的数据处理起来并不麻烦，那么拼接函数会不会用的是concat()这个处理字符串的函数呢？恭喜你，答对了，就是使用这个函数，我们来把前四个字节和最后四个字节拼接到一起，测试如下： 1234567mysql&gt; select id,hex(concat(substring(data,1,4),substring(data,13,4))) from bloboperation where id=1;+------+-------------------------------------------------------+| id | hex(concat(substring(data,1,4),substring(data,13,4))) |+------+-------------------------------------------------------+| 1 | 01020304AACB0000 |+------+-------------------------------------------------------+1 row in set (0.00 sec) 进制转换我们看到id为1的数据有16个字节，实际上在应用程序的内存中对应了4个int类型，每个int类型占用四个字节，为了修改数据，我们需要知道原数据在程序中代表的数字是多少，这就用到进制转换函数conv，可以先进行一个简单转换，16进制转10进制的例子： 1234567mysql&gt; select conv('FF',16,10);+------------------+| conv('FF',16,10) |+------------------+| 255 |+------------------+1 row in set (0.00 sec) 通过上面的转换十六进制的FF被转换成了十进制的255，应用到Blob字段也是一样，我们看下id为1的数据第一个int保存的数据是多少: 12345678mysql&gt; select id,conv(hex(concat(substring(data,4,1),substring(data,3,1),substring(data,2,1),substring(data,1,1))),16,10) as firstint from bloboperation where id=1;+------+----------+| id | firstint |+------+----------+| 1 | 67305985 |+------+----------+1 row in set (0.01 sec) 现在我们就得到了第一个int类型的值是67305985，可能有的同学会有疑惑，为什么不直接截取前4个字节，而要一个一个的拼接呢？这就涉及到大端数据和小端数据知识了，我们使用的PC机通常是小端的，数据的地位存储在低内存，数据的高位存储在高内存，所以需要把四个字节反过来拼接在一起再进行转换。 实际处理理解了上面的知识，就可以处理之前遇到的问题了，假设这16个字节代表的4个int类型分别是A，B，C，D，需要处理的问题是当变量D的值是52138的时候把变量B清0。 通过分析判断D变量的值之前有类似的，按照刚才第一个变量那样处理，把B变量清零可以通过A变量拼接0，然后再拼接C变量和D变量得到，具体的执行语句如下： 12345678910111213141516171819mysql&gt; update bloboperation set data=concat(substring(data,1,4), 0x00000000, substring(data,9,8))whereconv( hex(concat(substring(data,16,1),substring(data,15,1),substring(data,14,1),substring(data,13,1))), 16,10)=52138and id=1;Query OK, 1 row affected (0.06 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select id,hex(data),length(data) from bloboperation;+------+----------------------------------+--------------+| id | hex(data) | length(data) |+------+----------------------------------+--------------+| 1 | 01020304000000000000000CAACB0000 | 16 || 2 | 01020304FFFFFFFF0000000CAACB0000 | 16 || 3 | 68656C6C776F726C64 | 9 || 4 | 30 | 1 |+------+----------------------------------+--------------+4 rows in set (0.00 sec) 执行更新后查询发现，第5到8个字节对应的变量B确实被清0了，也就是我们的目标达到了。 总结 Blob类型字段的处理常用到的函数hex()、substring()、concat()、conv() 注意conv()函数的第一个参数需要是十六进制表示的字符串，不需要带0x]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>Blob substring</tag>
        <tag>hex</tag>
        <tag>concat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[.bat批处理（八）：各种形式的变量%0、%i、%%i、var、%var%、!var!的含义和区别]]></title>
    <url>%2Fblog%2F2019%2F11%2F08%2Fbat%E6%89%B9%E5%A4%84%E7%90%86%EF%BC%88%E5%85%AB%EF%BC%89%EF%BC%9A%E5%90%84%E7%A7%8D%E5%BD%A2%E5%BC%8F%E7%9A%84%E5%8F%98%E9%87%8F-0%E3%80%81-i%E3%80%81-i%E3%80%81var%E3%80%81-var-%E7%9A%84%E5%90%AB%E4%B9%89%E5%92%8C%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言最近使用批处理程序处理文件的时候，发现这 bat中的变量形式真是“变化多端”，有时候加1个百分号%，有时候加2个百分号%%，还有的时候加感叹号!，真是让初学者一头雾水，于是查询资料做了一些小测试，终于大致弄清楚了这些变量的含义，接下来一一列举出来。 变量对比下面通过一些具体的例子来看下标题中提到的这些变量什么时候使用，使用的时候有哪些注意事项。 %0这个是批处理程序中的固定用法，类似于C++程序main函数中argv变量数组，类比可以知道，argv[0]表示exe程序的文件名，argv[1]表示启动程序的第1个参数，后面依次类推。而在批处理程序中%0表示这个批处理程序的文件名，%1表示调用这个批处理时传入的第1个参数，%2表示调用这个批处理时传入的第2个参数，最大可以到%9，具体用法可以参考之前的总结《.bat批处理（二）：%0 %1——给批处理脚本传递参数》，简单测试如下： 12345@echo offecho param0=%0echo param0=%1echo param0=%2 将上述代码保存在文件testparams.bat中，从cmd命令行运行批处理文件，只传入一个参数，运行结果如下： C:\Users\Administrator\Downloads&gt;testparams.bat “hello world”param0=testparams.batparam1=”hello world”param2= %i在题目所列的这些变量中，这一个比较特殊，因为它不是批处理文件中的变量，只能用于cmd命令行下的for循环中，在命令行中for循环的语法是for %variable in (set) do command [command-parameters]，其中的variable只能是单字母或者非特殊含义的字符，同样的for循环语句如果写在批处理文件中variable之前就要加两个%%了，先来看看%i的用法，直接在命令行中遍历集合打印输出： C:\Users\Administrator\Downloads&gt;for %i in (1,3,5,8) do echo %iC:\Users\Administrator\Downloads&gt;echo 11C:\Users\Administrator\Downloads&gt;echo 33C:\Users\Administrator\Downloads&gt;echo 55C:\Users\Administrator\Downloads&gt;echo 88 如果将其中的%i改成%%i，就会报语法错误，测试结果如下： C:\Users\Administrator\Downloads&gt;for %%i in (1,3,5,8) do echo %%i此时不应有 %%i。 %%i这种类型也是for循环中特有的，与%i相对，属于批处理程序的用法，换句话说就是在for循环中遍历的索引变量，如果在命令行中定义需要一个%，如果相同的语句定义在批处理文件中需要2个%%，语法为for %%variable in (set) do command [command-parameters]，variable同样只能是单个字母或者普通字符，至于为什么同样含义的变量在批处理中要多加一个%，至今也没有找到官方的说法，查找MSDN也没有发现说明，不过就我个人理解可能就像我们在命令行中打印一个%，可以正常打印输出，如果通过printf()想输出%就需要2个%的原理一样吧，测试如下： 1for %%i in (1,3,5,8) do echo %%i 运行结果： C:\Users\Administrator\Downloads&gt;testfor.batC:\Users\Administrator\Downloads&gt;for %i in (1 3 5 8) do echo %iC:\Users\Administrator\Downloads&gt;echo 11C:\Users\Administrator\Downloads&gt;echo 33C:\Users\Administrator\Downloads&gt;echo 55C:\Users\Administrator\Downloads&gt;echo 88 观察运行结果发现，运行批处理文件的时候，实际上去掉了%%i变量的1个%，将文件中代码改为1个%试下： 1for %i in (1,3,5,8) do echo %i 运行结果： C:\Users\Administrator\Downloads&gt;testfor.bat此时不应有 i。 var这个变量看起来挺正常的，也没有那么多奇奇怪怪的字符，和Lua、Python等语言中的变量长得挺像，实际上变量的这种形式很“短暂”，一般只能出现在给变量赋值的时候，也就是set语句之后，作为左值接受赋值时，或者在等号右测可评估的表达式中，举个例子，编写下面代码保存在normalVar.bat中： 1234567@echo offset var1=1set /a var2=var1+1echo var1echo var2 运行之后的结果为: C:\Users\Administrator\Downloads&gt;normalVar.batvar1var2 看完结果之后觉得很神奇是不是，为什么和我学的其他语言不一样呢，我使用set分别为var1和var2赋了值，但是输出的时候居然不是数字而是变量名，其实这就引出了之后%var%这种用法，接着往下看。 %var%在批处理中除了上面所说的在set语句后面的两种情况，再要想引用变量就需要在变量两端各加一个百分号%，明确的告诉引用者这是一个变量，使用时需要评估一下值，而不要当成字符串，上一个例子中echo后面想要输出的变量没有加%，那就被当成一个字符串处理，原样输出了，修改上个例子如下： 12345678910@echo offset var1=1set /a var2=var1+1set var3=%var2%echo %var1%echo %var2%echo %var3% 运行之后运行结果入下： C:\Users\Administrator\Downloads&gt;normalVar.bat122 看了这次的结果感觉正常多了，有一点需要注意，set var3=%var2%这一句中var2变量中的%不能省略，因为它既不属于左值也不属于被评估值的表达式，如果不加%，赋值后var3的值会变成“var2”这个字符串。 !var!这是最后一种常见的变量形式，同时也是一种不太好理解的形式，需要记住一点，这种变量与延迟环境变量扩展有关，如果没开启延迟环境变量扩展，那么!var!就是一个普通的包含5个字母的字符串，如果开启了延迟环境变量扩展，那么它就是变量var的实际值，可能说到这有的人会产生疑惑，引用变量var的值不是使用%var%吗？那么在开启延迟环境变量扩展的情况下，%var%和!var!有什么区别呢？下面举个例子测试下，编写如下代码保存在extVar.bat文件中： 1234@echo offset var1=110set var1=120&amp;echo %var1% 运行之后的结果为： C:\Users\Administrator\Downloads&gt;extVar.bat110 看到结果的时候是不是再次怀疑了世界，在打印变量var1之前明明重新赋值了120，为什么打印出来还是110呢？其实这是批处理脚本执行机制导致的，它会按行执行，在执行之前会先预处理，当执行set var1=110之后，变量var1变成了110，在执行set var1=120&amp;echo %var1%之前先预处理，将变量%var1%替换成了110，然后语句变成了set var1=120&amp;echo 110，所以就得到了我们上面测试的结果。 想要解决这个问题就需要开启延迟环境变量扩展，语句为setlocal enabledelayedexpansion，然后将引用变量的形式由%var1%改为!var1!即可，所以可以修改代码如下： 12345@echo offsetlocal enabledelayedexpansionset var1=110set var1=120&amp;echo !var1! 运行之后的结果为： C:\Users\Administrator\Downloads&gt;extVar.bat120 这回输出的结果符合预期了，开启了延迟环境变量扩展之后，!var!形式的变量在用之前才会评估确切的值，这是一个知识点，也是一个易错点，特别是在for循环中要格外注意，因为for循环语句的循环体括号中，所有的操作被看成是同一行，所以经常会用到延迟环境变量扩展。 总结 for循环在cmd命令行中的固定用法for %i in (set) do (...)，循环变量格式为%i for循环在bat处理程序中的固定用法for %%i in (set) do (...)，循环变量格式为%%i 至于为什么for语法在批处理中需要多写一个%，希望知道的小伙伴能给出答案和参考资料，不胜感激 想要变量被使用的时候再评估值需要开启延迟环境变量扩展，语法为setlocal enabledelayedexpansion，同时使用!var!形式的变量]]></content>
      <categories>
        <category>bat</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下常用的打包、压缩、解压命令（tar、gzip、bzip2、zip）]]></title>
    <url>%2Fblog%2F2019%2F11%2F06%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%B8%B8%E7%94%A8%E7%9A%84%E6%89%93%E5%8C%85%E3%80%81%E5%8E%8B%E7%BC%A9%E3%80%81%E8%A7%A3%E5%8E%8B%E5%91%BD%E4%BB%A4%EF%BC%88tar%E3%80%81gzip%E3%80%81bzip2%E3%80%81zip%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前言经常使用电脑的人常常会接触到压缩文件，不管是软件、数据还是资料，下载之后通常就是一个压缩包，在Windows平台上如果安装了WinRAR或者360压缩，不管是什么格式的压缩文件，一般点击压缩文件右键选择解压选项即可，非常地方便。正因为长时间在Windows平台上方便的解压文件，导致我对打包、压缩的概念理解错误，结果在linux操作压缩文件时有很多疑问，今天终于明白了一点，专门总结一下，同时列举常用的压缩、解压命令，方便日后查找使用。 linux上操作压缩文件也是通过命令实现的，但是压缩文件的后缀有很多，比如.tar.gz、.tar.bz2、.gz、.zip、.Z等等，而生成和解压这些文件的命令同样很多，比如tar、gzip、bzip2、zip、unzip等，看得人眼花缭乱，记忆的过程中也常常出现偏差，不是命令不对应就是参数错误，特别是一些不常用的压缩格式，经常需要查询尝试，浪费了不少时间，其实造成这些问题的原因还是由于对打包压缩的概念不太清楚，接下来先了解一下这些概念。 基础概念在Windows上经常直接在图形化界面上操作压缩和解压文件，导致我将这种操作行为带到了linux上，而实际上在linux上压缩和解压文件之外还有一个操作就是“打包”，原因就是linux的压缩和解压通常作用在一个文件上，如果想将一大堆文件压缩最终成为一个文件，需要先打成一个包，然后对这个包文件进行压缩。 打包/归档打包或者叫归档，就是将多个文件和目录（也可以是一个文件）就变成了一个总的文件，但不是将所有文件进行融合，使用tar命令。 压缩压缩是将一个大的文件通过特定的压缩算法尽可能变成一个小文件，可以减少存储空间，加快网络传输效率，使用gzip、bzip2、zip等命令。 解压解压是将压缩生成的最终的小文件还原为压缩之前的大文件，可以使用gzip、gunzip、bunzip2、unzip等命令。 打包压缩通过上面的概念解析我们可以知道，我们之前所说的压缩操作通常是指打包和压缩两个步骤，由于linux大部分的压缩命令都是只能压缩一个文件，所以在压缩之前需要将待压缩的所有文件先进行打包，生成一个文件后再进行压缩操作。 明白了打包和压缩操作的含义，我们可以通过一些约定俗成的命名规则，选择合适的压缩和解压方法，比如下面这些文件： xxx.tar：这是一个归档文件，也就是只通过tar进行了打包操作 xxx.tar.gz：这是一个压缩文件，打包之后，以gzip方式进行了压缩 xxx.tar.bz2：这是一个压缩文件，打包之后，以bzip2方式进行了压缩 xxx.gz：这是一个压缩文件，没有经过打包操作，只是gzip方式进行了压缩 如果能按照这些命名规则生成压缩文件，那么解压文件的时候会方便很多，但有时压缩文件的扩展名是不标准的，可以通过file命令查看文件实际的格式，使用方法如下： 12345[albert@localhost#15:03:05#/home/albert/compress]$file test.tar.bz2test.tar.bz2: bzip2 compressed data, block size = 900k[albert@localhost#15:03:24#/home/albert/compress]$file test.tar.gztest.tar.gz: gzip compressed data, from Unix, last modified: Wed Nov 6 12:02:05 2019 压缩解压命令压缩文件的格式和命令真的是太多，所以在此总结一份常用命令表格，方便日后需要的时候直接拿来就用，加快解决问题的速度。假设原始文件是a.log和b.txt，当前目录下还有一个output目录，可以作为解压后存放文件的目录，那么常用压缩和解压命令如下： 文件格式 压缩命令 命令备注 解压命令 命令备注 xxx.tar tar -cvf test.tar a.log b.txt - tar -xvf test.tar -C ./output 不使用-C则解包在当前目录 xxx.tar.gz tar -zcvf test.tar.gz a.log b.txt - tar -zxvf test.tar.gz -C ./output 不使用-C则解压在当前目录 xxx.tar.bz2 tar -jcvf test.tar.bz2 a.log b.txt - tar -jxvf test.tar.bz2 -C ./output 不使用-C则解压在当前目录 xxx.tar.Z tar -Zcvf test.tar.Z a.log b.txt - tar -Zxvf test.tar.Z -C ./output 不使用-C则解压在当前目录 xxx.gz gzip -c a.log &gt; test.gz、gzip a.log 前者保留a.log，后者直接删除a.log gzip -d test.gz、gunzip test.gz 不能指定解压文件存储目录 xxx.bz2 bzip2 -c a.log &gt; test.bz2、bzip2 a.log 前者保留a.log，后者直接删除a.log bzip2 -d test.bz2、bunzip2 test.bz2 不能指定解压文件存储目录 xxx.Z compress -c a.log &gt; test.Z、compress a.log 前者保留a.log，后者直接删除a.log compress -d test.Z、uncompress test.Z 不能指定解压文件存储目录 xxx.rar rar a test.rar a.log - unrar e test.rar 将e选项换成x可以指定目录 xxx.zip zip test.zip a.log b.txt - unzip test.zip -d ./output 不使用-d则解压在当前目录 分析对比上面的压缩也解压命令可以发现，tar这个命令可以将打包和压缩合并到一起，也可以将解压和解包合并到一起，只需要修改选项中的参数就可以调用不同的程序压缩或者解压，比如-cvf表示只打包不压缩，而-zcvf表示打包后使用gzip压缩，改为-jcvf表示打包后使用bzip2压缩，其实还有很多的压缩方式，可以参考一下tar命令的帮助文档，具体压缩选项如下。 压缩选项: -a, –auto-compress 使用归档后缀名来决定压缩程序 -I, –use-compress-program=PROG 通过 PROG 过滤(必须是能接受 -d 选项的程序) -j, –bzip2 通过 bzip2 过滤归档 -J, –xz 通过 xz 过滤归档 –lzip 通过 lzip 过滤归档 –lzma 通过 lzma 过滤归档 –lzop –no-auto-compress 不使用归档后缀名来决定压缩程序 -z, –gzip, –gunzip, –ungzip 通过 gzip 过滤归档 -Z, –compress, –uncompress 通过 compress 过滤归档 总结 上述这些命令只是基础用法，还有很多参数选型没有提到，比如tar -tf test.tar可以不解压直接查看归档文件中的内容。 gzip命令只能压缩一个文件，如果在命令后面添加多个文件，则会分别压缩生成多个文件。 据说compress命令是一个相当古老的 unix 档案压缩指令，现在基本被gzip命令取代了。 由于文中涉及的命令较多，难免有些笔误，为了不传播错误用法，我也进行了多次检查，如果大家还发现其他错误，欢迎批评指正。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>tar</tag>
        <tag>gzip</tag>
        <tag>bzip2</tag>
        <tag>zip</tag>
        <tag>打包</tag>
        <tag>压缩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb调试程序时跳进函数和跳出函数]]></title>
    <url>%2Fblog%2F2019%2F11%2F01%2Fgdb%E8%B0%83%E8%AF%95%E7%A8%8B%E5%BA%8F%E6%97%B6%E8%B7%B3%E8%BF%9B%E5%87%BD%E6%95%B0%E5%92%8C%E8%B7%B3%E5%87%BA%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言说实话平时在Windows平台上开发，gdb调试用的并不是很多，但是一些在linux平台才会出现的BUG，或者在linux运行时宕机产生了core文件，这些还是需要使用gdb调试的，之前的文章《linux环境下服务器程序的查看与gdb调试》列举了常用的gdb命令，基本上调试一些core文件和简单bug使用这些命令足以了，但是新的需求总是会出现。 新的需求也很常见，就是跳进一个函数，调试一部分代码后还要跳出这个函数，一般情况就是这个函数特别长，调试前几行已经明白函数的逻辑和用意，如果使用 next 命令逐行运行需要花费较多时间，所以需要跳出函数回到调用的位置，这两个操作在Visual Studio中的快捷键分别是F11和Shift+F11，使用起来非常的方便，其实在gdb调试的过程中也有对应的命令，分别是step(s)和finish(fin)，括号中的内容为命令的简写，此外还有一个return命令也可以使函数返回，接下来可以看一下它们的区别。 测试代码测试的代码很简单，只需要写一个简单的函数，并且在主函数中调用这个函数即可，代码如下： 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;int son_func()&#123; int a = 100; int b = 1; return a + b;&#125;int main()&#123; int i = 10; cout &lt;&lt; i &lt;&lt; endl; int result = son_func(); cout &lt;&lt; result &lt;&lt; endl;&#125; 代码编译编译代码时只需要注意一点，那就是加上-g选项，否则可能会影响调试： 1albert@localhost#11:56:18#/home/albert/gdbtest]$g++ -g stepfinish.cpp -o stepfinishtest step/finish组合这个组合不会影响函数的运行结果，简单的调试过程如下： 1234567891011121314151617181920212223242526272829303132333435363738394041[albert@localhost#11:32:17#/home/albert/gdbtest]$gdb stepfinishtestGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/gdbtest/stepfinishtest...done.(gdb) startTemporary breakpoint 1 at 0x400809: file stepfinish.cpp, line 13.Starting program: /home/albert/gdbtest/stepfinishtestTemporary breakpoint 1, main () at stepfinish.cpp:1313 int i = 10;Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-23.el6.x86_64(gdb) n14 cout &lt;&lt; i &lt;&lt; endl;(gdb) n1016 int result = son_func();(gdb) stepson_func () at stepfinish.cpp:66 int a = 100;(gdb) finishRun till exit from #0 son_func () at stepfinish.cpp:60x0000000000400831 in main () at stepfinish.cpp:1616 int result = son_func();Value returned is $1 = 101(gdb) n18 cout &lt;&lt; result &lt;&lt; endl;(gdb) n10119 &#125;(gdb) cContinuing.Program exited normally.(gdb) 首先使用start命令启动程序，然后使用next(n)命令让程序运行到调用函数son_func()所在的行，使用step命令进入函数，我们看到a的值为100，假设这时我们想回到这个函数被调用的位置，直接敲finish命令就可以，函数完整的执行并返回结果101，最后连续执行next(n)命令，程序正常退出，整个过程只是调试查看数据，并没有改变程序运行结果。 step/return组合这个组合有可能会影响函数的运行结果，具体要看return命令使用的位置和返回的参数： 12345678910111213141516171819202122232425262728293031323334353637383940414243[albert@localhost#11:53:42#/home/albert/gdbtest]$gdb stepfinishtestGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/gdbtest/stepfinishtest...done.(gdb) startTemporary breakpoint 1 at 0x400809: file stepfinish.cpp, line 13.Starting program: /home/albert/gdbtest/stepfinishtestTemporary breakpoint 1, main () at stepfinish.cpp:1313 int i = 10;Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-23.el6.x86_64(gdb) n14 cout &lt;&lt; i &lt;&lt; endl;(gdb) n1016 int result = son_func();(gdb) stepson_func () at stepfinish.cpp:66 int a = 100;(gdb) n7 int b = 1;(gdb) return 119Make son_func() return now? (y or n) y#0 0x0000000000400831 in main () at stepfinish.cpp:1616 int result = son_func();(gdb) n18 cout &lt;&lt; result &lt;&lt; endl;(gdb) print result$1 = 119(gdb) cContinuing.119Program exited normally.(gdb) 首先同样使用start命令启动程序，然后使用next(n)命令让程序运行到调用函数son_func()所在的行，使用step命令进入函数，我们看到a的值为100，这时再敲入next(n)命令让程序运行一步，可以看到b的值为1，假设这时我们想返回一个自定义值而不返回a+b的结果，可以直接敲命令return 119，表示直接返回119这个值，再打印返回值变量result发现是值119，跳出函数的同时，程序运行结果也已经被我们改变了。 总结 gdb中跳入函数的命令是step，相当于Visual Studio中的快捷键F11 gdb中跳出函数的命令是finish，相当于Visual Studio中的快捷键Shift+F11，函数完整执行后返回 gdb中还有一个直接返回的命令是return，它会跳过当前函数后面的语句直接返回，返回值可以自定义，紧跟在return命令后面即可]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>linux</tag>
        <tag>gdb</tag>
        <tag>step</tag>
        <tag>finish</tag>
        <tag>return</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python使用scatter函数绘制点在线的上层]]></title>
    <url>%2Fblog%2F2019%2F10%2F30%2FPython%E4%BD%BF%E7%94%A8scatter%E5%87%BD%E6%95%B0%E7%BB%98%E5%88%B6%E7%82%B9%E5%9C%A8%E7%BA%BF%E7%9A%84%E4%B8%8A%E5%B1%82%2F</url>
    <content type="text"><![CDATA[前言前几天在QQ群里发现有人问这样一个问题，使用Python的matplotlib库绘制图形时，函数 scatter() 绘制的点总是在 plot() 函数绘制的线下边，看起来样子很丑，大概就是下图这个样子，问有没有方法让点显示到线的上面。 看到这个问题一开始以为是绘制顺序的原因，调整 scatter() 函数和 plot() 函数的调用顺序并没有达到预想的效果，点还是在线的下面，原来一直没注意这个问题，是因为我一直把线和标注用的点使用了同一种颜色，所有看不出来是谁覆盖了谁，现在抛出这个问题居然让人有点不知所措，直觉上认定肯定有个属性可以设置这个显示顺序，但究竟是图的属性？坐标轴的属性？还是函数的参数呢？这个还需要查一查。 解决办法最后经过一顿查找发现函数 scatter() 和 plot() 都有个参数 zorder，这时候才恍然大悟，做游戏界面开发时常常使用这个参数来控制UI的层级，现在怎么突然忘了呢，赶紧设置一下发现与原来在游戏开发中的参数含义相同，zorder这个整数越大，显示的时候越靠上，所以写了下面的测试代码： 1234567891011121314import numpy as npimport matplotlib.pyplot as pltdef draw_point_on_line(): plt.title("draw point on line") plt.xlabel("x-axis") plt.ylabel("y-axis") X = np.linspace(1, 100, 10, endpoint=True) Y = np.random.randint(60, 100, len(X)) plt.plot(X, Y, color ='blue', linewidth=3.5, zorder=1) # 在第一层画线 plt.scatter(X, Y, 50, color ='red', zorder=2) # 在第二层画点 plt.show() 效果展示这次终于正常了，因为scatter()函数中的zorder值较大，所以放到上面绘制，效果如下： 总结 帮助他人解决问题是一个自我提升的好机会 有很多我们认为很简单的事情，其实并不是我们想的那样 代码文件前后图例代码对比-传送门]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>matplotlib</tag>
        <tag>plt</tag>
        <tag>scatter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python切割超大日志文件、保留文件最后几行]]></title>
    <url>%2Fblog%2F2019%2F10%2F24%2FPython%E5%88%87%E5%89%B2%E8%B6%85%E5%A4%A7%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E3%80%81%E4%BF%9D%E7%95%99%E6%96%87%E4%BB%B6%E6%9C%80%E5%90%8E%E5%87%A0%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[前言关于日志这个东西的存在，主要是为了记录发生的事情，编程的过程中也常常用到，记得我们在刚刚学习编程的时候，常常会出现程序错误，这时候就需要输出一下，其实这个输出也是日志的一种体现，随着编程水平的提升，各种调试工具和方法渐渐进入我们的视线，但是输出一下这种方法却一直被使用，特别是一些偶发性问题，调试工具很难捕捉到他们，这时候往往需要将中间过程输出到日志文件中，这些日志文件就是我们分析问题的基础。 随着程序规模的渐渐扩大，出现问题时需要打印的日志也越来越多，最近就出现这样一个情况，游戏程序总是莫名的崩溃，看代码找不到问题的原因，所以采用了打印日志文件的方法，有时候大约跑半天就能出现崩溃，日志文件大概600M，Windows系统自带的记事本很难打开，但是使用Notepad++等几秒钟是可以看到内容的。 比较变态的是最近一次跑了2天才崩溃，导出日志文件发现大概有3G，这次使用Notepad++打开时也卡死了，使用sublime打开时进度卡在了80%左右，据说非常强大的GVim打开文件时也毫无反应了，这就尴尬了，崩溃之前的日志内容就在文件中，可是我们却看不见。 问题出现问题很明显摆在这了，文件由于太大无法看到其中的内容，得想个办法。很直接的一个想法就进入了脑海，把文件拆开成几份，这样每个文件缩小了就可以看到了啊，所以我们找到了一个解决问题的办法，接下来使用Python来简单写一下切分文件。 分割日志文件按照文件大小分割分割文件的规则需要先确定一下，可以很简单的按照文件大小分割，一个源文件大小为10M的日志文件，可以切分成10个大小为1M的日志文件，分割的大小不用太绝对，每一份近似相等就可以，整体思路就是先获得源文件的大小，然后计算出分割结束每个文件的大小，接着不断从源文件中读内容，往目标文件中写内容，达到之前计算的字节大小时，再生成新的目标文件，简单代码如下： 12345678910111213141516171819202122import osDATA_LEN_PER_READ = 1024 * 1024def split_file_by_size(file_name, parts=3): file_size = os.path.getsize(file_name) per_file_size = file_size//parts file_size_list = [] for x in range(parts-1): file_size_list.append(per_file_size) file_size_list.append(file_size-per_file_size*(parts-1)) output_file, ext = os.path.splitext(file_name) with open(file_name, 'rb') as rfile: for n in range(parts): with open('&#123;0&#125;_part&#123;1&#125;&#123;2&#125;'.format(output_file, n+1, ext), 'wb') as wfile: read_size = 0 while read_size &lt; file_size_list[n]: want_read = min(DATA_LEN_PER_READ, file_size_list[n] - read_size) wfile.write(rfile.read(want_read)) read_size += want_read 按照文件行数分割以上按照文件大小分割的日志文件有一点小问题，不能保证行是完整的，当遇到汉字这种占用多字节的字符，甚至都不能保证汉字是完整的，所以我们可以换一个思路，尝试使用按照行数分割，整体思路就是先获得文件的行数，然后计算出分割结束每个文件的行数，接着不断从源文件中一行行读内容，往目标文件中一行行写内容，达到之前计算的文件行数时，再生成新的目标文件，简单代码如下： 12345678910111213141516171819202122232425import osdef get_file_line_count(file_name): line_count = 0 for index, line in enumerate(open(file_name, 'r')): line_count += 1 return line_countdef split_file_by_line(file_name, parts=3): total_line = get_file_line_count(file_name) per_file_line = total_line//parts file_line_list = [] for x in range(parts-1): file_line_list.append(per_file_line) file_line_list.append(total_line-per_file_line*(parts-1)) output_file, ext = os.path.splitext(file_name) with open(file_name, 'rb') as rfile: for n in range(parts): with open('&#123;0&#125;_part&#123;1&#125;&#123;2&#125;'.format(output_file, n+1, ext), 'wb') as wfile: read_line = 0 while read_line &lt; file_line_list[n]: wfile.write(rfile.readline()) read_line += 1 获取日志文件尾部内容对于分析奔溃这类问题，出现问题的日志往往就在最后几行，所以没有必要非得打开整个日志文件，也不一定需要将整个文件分割成几部分，只需将日志文件的最后一部分读出来写到新的文件中供我们分析就可以了，这时候开头几个字符的不完整也是可以接受的，所以没必要按行读取，只需按照经验，从尾部截取指定字节大小的内容就可以了，比如我们的日志，最后有用的部分也就10M左右，一般的文本文件就都能打开了。 代码思路就是先打开文件，然后将读指针定位到尾部往前10M左右，然后读取所有内容保存到新的文件中，简单的代码示例如下： 12345678import osdef tailslice(file_name, data_size= 1024): output_file, ext = os.path.splitext(file_name) with open(file_name, 'rb') as rfile: rfile.seek(-data_size, 2) with open('&#123;0&#125;_tail&#123;1&#125;'.format(output_file, ext), 'wb') as wfile: wfile.write(rfile.read()) 总结 有时候要问题需要变通一下，如果一个文件大到打不开的地步，我们就把它分割成可以接受的范围 当文件中的内容只有一部分可用时，我们完全可以不分割，直接取出可用部分即可。 代码传送门 分割超大日志文件 获取日志文件尾部内容]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>日志文件</tag>
        <tag>split</tag>
        <tag>切割</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中查询当前用户、当前数据库等基础信息]]></title>
    <url>%2Fblog%2F2019%2F10%2F14%2FMysql%E4%B8%AD%E6%9F%A5%E8%AF%A2%E5%BD%93%E5%89%8D%E7%94%A8%E6%88%B7%E3%80%81%E5%BD%93%E5%89%8D%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AD%89%E5%9F%BA%E7%A1%80%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[前言生活中有时会出现灵魂三问：我是谁？我在哪？我在做什么？特别的喝醉酒的第二天，完全不记得昨天发生了什么。而在数据库操作中也会出现这种灵魂拷问，我用的是哪个用户，为什么会没有权限？我操作的是哪个数据库，刚刚不会把线上正式服务器数据删了吧？ 上面描述的问题常常出现在切换数据库处理问题的时候，通过一个客户端连接到Mysql数据库服务器，操作数据库1，然后切换再操作数据库2，这时如果中间有人打扰，很容易忘记刚刚操作的是哪个数据库，或者中途处理个其他紧急的事情，回来连操作的用户都忘了，这时就需要一些基础信息的查询命令，帮助你来恢复记忆。 数据库基础信息查询数据库的基础信息涉及到方方面面，这里只列举几个常用的查询命令，用来回答上面的灵魂拷问，其他命令还有很多，用到了再总结吧。 查询当前操作的用户1234567mysql&gt; select user();+----------------+| user() |+----------------+| root@localhost |+----------------+1 row in set (0.07 sec) 查询当前操作的数据库1234567mysql&gt; select database();+------------+| database() |+------------+| sqltest2 |+------------+1 row in set (0.09 sec) 查询当前数据库端口1234567mysql&gt; show variables like 'port';+---------------+-------+| Variable_name | Value |+---------------+-------+| port | 3306 |+---------------+-------+1 row in set (0.07 sec) 查询当前数据库版本1234567mysql&gt; select version();+------------+| version() |+------------+| 5.7.21-log |+------------+1 row in set (0.06 sec) 数据库结构信息查询这里的结构我指的是DDL中定义的那些元素，比如表、存储过程等，有一些常用的查询命令，要是一段时间不使用还是会忘记，比如查询一个数据库中的存储过程，每次查询时都要上网搜一下，所以今天总结在一起方便查找。 查询当前数据库中的所有表1234567891011121314mysql&gt; show tables;+--------------------+| Tables_in_sqltest2 |+--------------------+| a || b || c || d || m || p || tb_test || tb_with_index |+--------------------+14 rows in set (0.11 sec) 查询创建表的sql语句12345678910mysql&gt; show create table a;+-------+----------------------------------------+| Table | Create Table |+-------+----------------------------------------+| a | CREATE TABLE `a` ( `id` int(11) DEFAULT NULL, `num` int(11) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8 |+-------+----------------------------------------+1 row in set (0.11 sec) 查询指定表中的所有字段12345678mysql&gt; desc a;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.12 sec) 查询当前数据库中的所有存储过程这个命令我得吐槽一下，为什么不能像查询当前数据库的中所有表一样，搞个show procedures;命令，非得通过where子句指定数据库呢，具体的原因还不知道，等我弄明白了再回来补充。123456789mysql&gt; show procedure status where db='sqltest2';+----------+-----------------------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+| Db | Name | Type | Definer | Modified | Created | Security_type | Comment | character_set_client | collation_connection | Database Collation |+----------+-----------------------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+| sqltest2 | fill_slow_query_test | PROCEDURE | root@localhost | 2019-03-25 11:14:01 | 2019-03-25 11:14:01 | DEFINER | | utf8mb4 | utf8mb4_general_ci | utf8_general_ci || sqltest2 | fill_tb_without_index | PROCEDURE | root@localhost | 2019-03-18 09:53:32 | 2019-03-18 09:53:32 | DEFINER | | utf8mb4 | utf8mb4_general_ci | utf8_general_ci || sqltest2 | fill_tb_with_index | PROCEDURE | root@localhost | 2019-03-18 09:53:33 | 2019-03-18 09:53:33 | DEFINER | | utf8mb4 | utf8mb4_general_ci | utf8_general_ci |+----------+-----------------------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+3 rows in set (0.17 sec) 查询创建存储过程的sql语句1234567891011121314151617mysql&gt; show create procedure fill_tb_with_index;+--------------------+----------------------------------------------------------------+-------------------+----------------------+----------------------+--------------------+| Procedure | sql_mode | Create Procedure | character_set_client | collation_connection | Database Collation |+--------------------+----------------------------------------------------------------+-------------------+----------------------+----------------------+--------------------+| fill_tb_with_index | STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION |CREATE DEFINER=`root`@`localhost` PROCEDURE `fill_tb_with_index`()BEGIN DECLARE i int default 1; WHILE i &lt;= 100000 do insert into tb_with_index values(i, i, i); set i = i + 1; END WHILE;END | utf8mb4 | utf8mb4_general_ci | utf8_general_ci |+--------------------+----------------------------------------------------------------+-------------------+----------------------+----------------------+--------------------+1 row in set (0.09 sec) 查询指定表上的索引123456789mysql&gt; show index from tb_with_index;+---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| tb_with_index | 1 | id_index | 1 | id | A | 100035 | NULL | NULL | YES | BTREE | | || tb_with_index | 1 | num_index | 1 | num | A | 98715 | NULL | NULL | YES | BTREE | | || tb_with_index | 1 | money_index | 1 | money | A | 100035 | NULL | NULL | YES | BTREE | | |+---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+3 rows in set (0.03 sec) 查询当前用户连接的权限1234567mysql&gt; show grants;+---------------------------------------------------------------------+| Grants for root@localhost |+---------------------------------------------------------------------+| GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' WITH GRANT OPTION || GRANT PROXY ON ''@'' TO 'root'@'localhost' WITH GRANT OPTION |+---------------------------------------------------------------------+ 查询指定用户连接的权限1234567mysql&gt; show grants for 'guest';+---------------------------------------------------------------------------------------------------------------+| Grants for guest@% |+---------------------------------------------------------------------------------------------------------------+| GRANT ALL PRIVILEGES ON *.* TO 'guest'@'%' IDENTIFIED BY PASSWORD '*6C8DE74065898C44C21EF74D67A834C5256BFA1C' |+---------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 总结 以上总结的查询语句都是我经常用到，相比Mysql所有查询语句来说简直是冰山一角，总结到一起主要是方便日后查找，同时也希望给他人带来帮助 查看这些语句会发现，有些是select开头，有些是show开头，实际上很多show开头的都是对information_schema数据库数据的封装 information_schema 数据库是Mysql系统自带的数据库，记录了整个数据库实例上所有数据结构信息，更像是记录数据库的数据库，包含表结构、字符集，权限等太多的信息，有机会后续找时间聊聊这个数据库，在此就不展开了 正因为很多show开头的都是对information_schema数据库数据的封装，所以这些查询语句基本都可以通过在information_schema数据库查询得到，比如show procedure status where db=&#39;sqltest2&#39;;就可以改写成select routine_name from information_schema.routines where routine_schema=&#39;sqltest2&#39;; 此时此刻，我正在距离天安门500多米的现场等待阅兵仪式的开始，一边学习一边为祖国庆生的感觉真好！（注：500多米多了5公里，现场是卧室床前的电视机旁，这么近的距离不知道一会能不能看见接受检阅的飞机o(\￣︶￣*)o）*]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>用户</tag>
        <tag>当前信息</tag>
        <tag>表结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下C++代码打印函数堆栈调用情况]]></title>
    <url>%2Fblog%2F2019%2F09%2F06%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8BC-%E4%BB%A3%E7%A0%81%E6%89%93%E5%8D%B0%E5%87%BD%E6%95%B0%E5%A0%86%E6%A0%88%E8%B0%83%E7%94%A8%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[前言关于什么是函数调用堆栈在上篇文章《windows环境下C++代码打印函数堆栈调用情况》中已经介绍过了，简单的来说就是可以展现出函数之间的调用关系，上篇文章展示了如何在windows上打印出函数调用堆栈，其中用到了windows系统上的API，这些接口在linux上是无法使用的，因为工作的关系，也常常需要在linux的调试程序，所以本文介绍一下如何在linux上打印出C++程序的调用堆栈。 实现打印堆栈信息的函数在linux系统上想打印函数调用堆栈信息，需要引用头文件&lt;execinfo.h&gt;，然后利用函数backtrace、backtrace_symbols来获取当时的函数调用堆栈信息，以下的代码实现了一个简单的打印堆栈新的函数，堆栈深度最大同样设置为12层。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;execinfo.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#define STACK_INFO_LEN 1024void ShowTraceStack(const char* szBriefInfo)&#123; static const int MAX_STACK_FRAMES = 12; void *pStack[MAX_STACK_FRAMES]; static char szStackInfo[STACK_INFO_LEN * MAX_STACK_FRAMES]; char ** pStackList = NULL; int frames = backtrace(pStack, MAX_STACK_FRAMES); pStackList = backtrace_symbols(pStack, frames); if (NULL == pStackList) return; strcpy(szStackInfo, szBriefInfo == NULL ? "stack traceback:\n" : szBriefInfo); for (int i = 0; i &lt; frames; ++i) &#123; if (NULL == pStackList[i]) break; strncat(szStackInfo, pStackList[i], STACK_INFO_LEN); strcat(szStackInfo, "\n"); &#125; printf("%s", szStackInfo); // 输出到控制台，也可以打印到日志文件中&#125;void func2()&#123; bool isError = true; if (isError) &#123; ShowTraceStack("error in func2\n"); &#125; else &#123; printf("this is func2\n"); &#125;&#125;void func1()&#123; int sum = 0; for (int i = 0; i &lt; 100; ++i) sum += i; func2();&#125;int main(int argc, char* argv[])&#123; printf("hello world\n"); func1(); return 0;&#125; 显示堆栈调用信息上面的测试代码中函数的调用逻辑为：main()函数调用func1()函数，然后func1()函数调用func2()函数，当func2()中发生问题的时候打印当时的堆栈信息，然后我们编译一下查看运行结果 12345678910[albert@localhost#10:59:03#/home/albert/test/backtrace]$g++ -rdynamic linuxtraceback.cpp -o linuxtraceback[albert@localhost#10:59:05#/home/albert/test/backtrace]$./linuxtracebackhello worlderror in func2./linuxtraceback(_Z14ShowTraceStackPKc+0x25) [0x400a19]./linuxtraceback(_Z5func2v+0x1c) [0x400b06]./linuxtraceback(_Z5func1v+0x32) [0x400b46]./linuxtraceback(main+0x1e) [0x400b66]/lib64/libc.so.6(__libc_start_main+0xfd) [0x7fbbcae43d1d]./linuxtraceback() [0x400939] 上面的运行结果已经展示了程序函数的调用关系，其中编译选项中的-rdynamic是很重要的，它实际上是一个链接选项，作用是把所有符号（而不仅仅只是程序已使用到的外部符号）都添加到动态符号表里，以便那些通过 dlopen() 或 backtrace()这样的函数使用，换句话说就是如果不加这个选项在调用堆栈中就可能看不到函数名。 上面的调用堆栈中函数名大致能看出来，但是有些奇怪的字母，可以通过工具c++fileter来处理，处理之后就可以看到正常的函数名了，具体使用方式如下：123456789[albert@localhost#10:59:12#/home/albert/test/backtrace]$./linuxtraceback | c++filthello worlderror in func2./linuxtraceback(ShowTraceStack(char const*)+0x25) [0x400a19]./linuxtraceback(func2()+0x1c) [0x400b06]./linuxtraceback(func1()+0x32) [0x400b46]./linuxtraceback(main+0x1e) [0x400b66]/lib64/libc.so.6(__libc_start_main+0xfd) [0x7f73aea34d1d]./linuxtraceback() [0x400939] 编译时无法添加-rdynamic选项如果是自己写的小项目或者小程序，编译选项是可以随便改的，没有什么关系，需要查看堆栈信息加上-rdynamic就可以了，但是如果是公司的大型项目，编译选项是不会随便改的，可能是直接使用automake生成的，先来看一下不添加-rdynamic选项编译之后的运行结果 12345678910[albert@localhost#11:22:15#/home/albert/test/backtrace]$g++ linuxtraceback.cpp -o linuxtraceback[albert@localhost#11:22:18#/home/albert/test/backtrace]$./linuxtracebackhello worlderror in func2./linuxtraceback() [0x4007d9]./linuxtraceback() [0x4008c6]./linuxtraceback() [0x400906]./linuxtraceback() [0x400926]/lib64/libc.so.6(__libc_start_main+0xfd) [0x7f4e12ba2d1d]./linuxtraceback() [0x4006f9] 可以看到不添加-rdynamic选项编译之后运行虽然能显示出调用堆栈，但都是一些函数地址，无法看到函数名，这时可以通过工具addr2line帮助我们定位问题，这个工具的作用就是将函数地址转换成函数所在的行，使用方法就是在命令行运行addr2line 0x4008c6 -e ./linuxtraceback，具体使用时替换函数地址和可运行程序的名字即可 说实话这个小程序中使用运行addr2line 0x4008c6 -e ./linuxtraceback没有看到我想要的，只显示了??:0，仿佛被优化掉了，但是我在正式的项目中使用这个方法是可以得到函数所在行的，这也帮助我查到了一个隐藏很深的BUG。 总结 linux平台下可以利用函数backtrace、backtrace_symbols、backtrace_symbols_fd来获取当时的函数调用堆栈信息 使用上述函数时，需要引用头文件&lt;execinfo.h&gt;，编译时最好加上-rdynamic选项 如果实在无法添加-rdynamic，可以通过addr2line辅助查找问题 程序源码打印堆栈信息–源码传送门]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>linux</tag>
        <tag>函数</tag>
        <tag>堆栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows环境下C++代码打印函数堆栈调用情况]]></title>
    <url>%2Fblog%2F2019%2F09%2F03%2Fwindows%E7%8E%AF%E5%A2%83%E4%B8%8BC-%E4%BB%A3%E7%A0%81%E6%89%93%E5%8D%B0%E5%87%BD%E6%95%B0%E5%A0%86%E6%A0%88%E8%B0%83%E7%94%A8%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[前言程序运行的过程中，函数之间的是会相互调用的，在某一时刻函数之间的调用关系，可以通过函数调用堆栈表现出来，这个调用堆栈所展现的就是函数A调用了函数B，而函数B又调用了函数C，这些调用关系在代码中都是静态的，不需要程序运行就可以知道。 既然函数之间的调用关系可以通过分析代码就可以知道，那么查看函数调用的堆栈是不是作用不大了呢？事实上恰恰相反，查看函数调用堆栈的作用非常大。因为在较大型的项目中，函数之间的调用不是简单的一条线，常常会出现复杂的网状结构，这时如果函数C被调用了，可能不是仅仅是B函数调用过来的，也有可能是D、E、F等函数调用了C函数，所以知道在程序运行时究竟是哪个函数调用了C函数显得很重要，特别是有众多函数会调用C函数的时候。 查看函数堆栈的作用举个例子就明白了，假如C函数中逻辑的执行需要一些特殊条件状态，理论上执行C函数时这些条件都应该满足的，但是程序在运行的过程中有时运行C函数时条件就是不满足的，那就说明有些调用C函数的逻辑分支有问题，无法满足C函数中逻辑所需条件，这时候知道是谁调用C函数导致条件不满足就是确定问题的关键。 如果是在VS调试状态下，在C函数不满足条件的逻辑中打一个断点，然后运行程序等待断点触发时，就可以通过VS工具自带的调用堆栈窗口，就可以看到程序从主函数main()开始怎样一步步调用的出错的函数C的。 可实际项目中，出错的时候不总是在VS的调试状态下，也有可能发生在程序实际的工作环境中，这时没有办法通过加断点来查看调用堆栈，如果此时有一个函数，可以打印当前的函数调用堆栈那就太好了，这样我就可以在需要调试的逻辑中，调用这个函数，将当时的函数调用堆栈信息打印到文件中，方便查找程序逻辑问题，这篇文章要做的就是在Windows环境下，利用现有的API实现这样一个函数。 实现打印堆栈信息的函数在Windows系统上想打印函数调用堆栈信息，需要引用头文件&lt;dbghelp.h&gt;，添加库引用DbgHelp.Lib，然后利用函数CaptureStackBackTrace、SymFromAddr、SymGetLineFromAddr64来获取当时的函数调用堆栈信息，以下的代码实现了一个简单的打印堆栈新的函数，堆栈深度最大设置为12层，实际情况肯定是越深越好，设置为12一般就可以查到问题了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;windows.h&gt;#include &lt;dbghelp.h&gt;#include &lt;stdio.h&gt;#if _MSC_VER#define snprintf _snprintf#endif#define STACK_INFO_LEN 1024void ShowTraceStack(char* szBriefInfo)&#123; static const int MAX_STACK_FRAMES = 12; void *pStack[MAX_STACK_FRAMES]; static char szStackInfo[STACK_INFO_LEN * MAX_STACK_FRAMES]; static char szFrameInfo[STACK_INFO_LEN]; HANDLE process = GetCurrentProcess(); SymInitialize(process, NULL, TRUE); WORD frames = CaptureStackBackTrace(0, MAX_STACK_FRAMES, pStack, NULL); strcpy(szStackInfo, szBriefInfo == NULL ? "stack traceback:\n" : szBriefInfo); for (WORD i = 0; i &lt; frames; ++i) &#123; DWORD64 address = (DWORD64)(pStack[i]); DWORD64 displacementSym = 0; char buffer[sizeof(SYMBOL_INFO)+MAX_SYM_NAME * sizeof(TCHAR)]; PSYMBOL_INFO pSymbol = (PSYMBOL_INFO)buffer; pSymbol-&gt;SizeOfStruct = sizeof(SYMBOL_INFO); pSymbol-&gt;MaxNameLen = MAX_SYM_NAME; DWORD displacementLine = 0; IMAGEHLP_LINE64 line; line.SizeOfStruct = sizeof(IMAGEHLP_LINE64); if (SymFromAddr(process, address, &amp;displacementSym, pSymbol) &amp;&amp; SymGetLineFromAddr64(process, address, &amp;displacementLine, &amp;line)) &#123; snprintf(szFrameInfo, sizeof(szFrameInfo), "\t%s() at %s:%d(0x%x)\n", pSymbol-&gt;Name, line.FileName, line.LineNumber, pSymbol-&gt;Address); &#125; else &#123; snprintf(szFrameInfo, sizeof(szFrameInfo), "\terror: %d\n", GetLastError()); &#125; strcat(szStackInfo, szFrameInfo); &#125; printf("%s", szStackInfo); // 输出到控制台，也可以打印到日志文件中&#125;void func2()&#123; bool isError = true; if (isError) &#123; ShowTraceStack("error in func2\n"); &#125; else &#123; printf("this is func2\n"); &#125;&#125;void func1()&#123; int sum = 0; for (int i = 0; i &lt; 100; ++i) sum += i; func2();&#125;int main(int argc, char* argv[])&#123; printf("hello world\n"); func1(); return 0;&#125; 显示堆栈调用信息上面的测试代码中函数的调用逻辑为：main()函数调用func1()函数，然后func1()函数调用func2()函数，当func2()中发生问题的时候打印当时的堆栈信息，然后我们查看一下打印结果 hello worlderror in func2 ShowTraceStack() at e:\vs2013projects\trackback\windowstrackback\windowstrackback.cpp:24(0xe01440) func2() at e:\vs2013projects\trackback\windowstrackback\windowstrackback.cpp:59(0xe01840) func1() at e:\vs2013projects\trackback\windowstrackback\windowstrackback.cpp:74(0xe017c0) main() at e:\vs2013projects\trackback\windowstrackback\windowstrackback.cpp:82(0xe018c0) __tmainCRTStartup() at f:\dd\vctools\crt\crtw32\dllstuff\crtexe.c:626(0xe01d40) mainCRTStartup() at f:\dd\vctools\crt\crtw32\dllstuff\crtexe.c:466(0xe020c0) error: 487 error: 487 error: 487 总结 Windows平台下可以利用函数CaptureStackBackTrace、SymFromAddr、SymGetLineFromAddr64来获取当时的函数调用堆栈信息 使用上述函数时，需要引用头文件&lt;dbghelp.h&gt;，添加库引用DbgHelp.Lib 程序源码打印堆栈信息–源码传送门]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>函数</tag>
        <tag>堆栈</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[.bat批处理（七）：PC端从手机内复制文件到本地]]></title>
    <url>%2Fblog%2F2019%2F08%2F21%2Fbat%E6%89%B9%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9APC%E7%AB%AF%E4%BB%8E%E6%89%8B%E6%9C%BA%E5%86%85%E5%A4%8D%E5%88%B6%E6%96%87%E4%BB%B6%E5%88%B0%E6%9C%AC%E5%9C%B0%2F</url>
    <content type="text"><![CDATA[前言解决方案都是在实际工作中遇到问题时想出来解决方法，很多方法乍一看根本用不上，但实际操作中发现真的很有用，今天提到的这个方法就是这种类型的。 游戏开发中常常会将一些关键信息或者调试信息写入到日志文件中，这样可以在出现BUG的情况时，通过分析日志文件来进一步定位问题的原因，在真机上跑游戏时就需要将手机中的日志文件导出到电脑上，方便查看，这就是这篇文章所讲的内容。 可能有人会说，现在手机连接电脑很方便，直接插一根数据线，在“我的电脑”里找到手机，然后就可以像从其他文件夹复制一下，从手机中把文件复制下来，可事实上并不是这样的，手机连接电脑有个缓存的毛病。 这种问题就是第一次连接的时候查看文件是正常，但是复制删除几次文件以后就会出现缓存的现象，我明明新建了一个文件就是找不到，比如产生了新的日志文件，通过数据线连接电脑以后，在文件夹中看不到，这时可以通过adb命令复制出来，虽然看不到，但是文件是确实存在的。 准备条件 需要电脑安装adb，常用来调试手机的电脑一定会安装过这个东西，有些版本直接可以使用，具体怎么安装，网上的教程有很多。 手机需要打开USB调试模式，打开模式前可能需要开启开发者选项，同样开启USB调试的教程也有很多。 实现代码1234567891011121314151617@SET LOG_FILE_NAME=project_%date:~0,4%%date:~5,2%%date:~8,2%%time:~0,2%%time:~3,2%%time:~6,2%.logadb pull /storage/emulated/0/project2.log ./%LOG_FILE_NAME%@echo offecho running result:if %errorlevel%==0 goto endSuccess:endFailecho Copy data from phone to pc falied!!!pauseexit /b 1:endSuccessecho Copy data from phone to pc success!!!pauseexit /b 0 代码分析其实这一大段中核心的代码只有一句adb pull /storage/emulated/0/project2.log ./%LOG_FILE_NAME%，之前的变量LOG_FILE_NAME是为了解决多次导出文件时同名会覆盖的问题，加上时间字符串可以防止重名出现，adb pull 手机中路径+文件名 本地PC路径+文件名就是实际复制的过程 如果复制过程中不报错就会走到:endSuccess代码段，如果报错就会走到:endFail代码段，两段代码会返回不同的值供调用者判断，整个代码文件加了一些提示消息，如果嫌麻烦的话直接使用adb pull /storage/emulated/0/project2.log ./%LOG_FILE_NAME%也是可以的。 代码测试直接在cmd命令行中运行就可以，假设以上的bat文件名为CopydataPhone2PC.bat，手机根目录下有文件project.log，我们可以尝试拷贝project.log和project2.log两个文件到手机看看效果，当然project2.log文件是不存在的肯定会失败 拷贝成功1234567E:\batTool&gt;CopydataPhone2PC.batE:\batTool&gt;adb pull /storage/emulated/0/project.log ./project_20190822102324.log124 KB/s (1284 bytes in 0.010s)running result:Copy data from phone to pc success!!!请按任意键继续. . . 拷贝失败1234567E:\batTool&gt;CopydataPhone2PC.batE:\batTool&gt;adb pull /storage/emulated/0/project2.log ./project_20190822102422.logremote object '/storage/emulated/0/project2.log' does not existrunning result:Copy data from phone to pc falied!!!请按任意键继续. . . 总结有些领域真的很奇妙，如果你之前没有接触过，直接告诉你，手机里有个很普通的文件，但是你就是看不到，你会不会觉得很奇怪，针对于这些奇怪的问题其实别人可能早就有了解决方案，百思不得其解时不妨浏览一下。]]></content>
      <categories>
        <category>bat</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[std::bind（二）：包装成员函数]]></title>
    <url>%2Fblog%2F2019%2F08%2F15%2Fstd-bind%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%8C%85%E8%A3%85%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言关于std::bind()对普通函数的包装作用，在之前的总结文章《std::bind（一）：包装普通函数》已经举例说明过了，后来发现丢下了普通函数嵌套包装的情况，所以在这篇文章中继续说明一下，然后重点总结std::bind()函数对成员函数的包装，在面向对象的大潮还未褪去的今天，还是成员函数见到的更多一些，所以讲讲对它的包装。 普通函数嵌套包装实际上就是普通函数包装的变形和组合，直接写个例子吧，如果test1_1()、test1_2()、test1_3()三个函数的输出结果都答对了就说明已经掌握了。12345678910111213141516171819202122232425262728293031323334353637void func(int n1, int n2, int n3)&#123; cout &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; endl;&#125;int calc_value(int c1)&#123; return c1 * c1;&#125;void calc_value2(int c1)&#123; int result = c1 * c1;&#125;void test1_1()&#123; auto f1 = std::bind(func, placeholders::_1, 101, std::bind(calc_value, placeholders::_2)); f1(11, 2); // same as call func(11, 101, calc_value(2))&#125;void test1_2()&#123; int n = 2; auto f1 = std::bind(func, placeholders::_1, 101, std::bind(calc_value, std::ref(n))); n = 4; f1(11, 2); // same as call func(11, 101, calc_value(44)) 多出的参数2无人使用&#125;void test1_3()&#123; auto f1 = std::bind(func, placeholders::_1, 101, std::bind(calc_value2, placeholders::_2)); //f1(11, 2); // 编译出错，无法将参数 3 从“void”转换为“int”&#125;// 11 101 4// 11 101 16 第一个test1_1函数的逻辑应该很容易理解，就是把函数calc_value(2)的返回值作为函数func的第三个参数，而函数test1_2中利用了std::ref()传递引用的功能，将变量n作为引用变量进行传递，在包装调用之前可以感知到参数n的变化。 其实难点在第三个函数test1_3，可能大家知道这里会报错，因为我们需要返回值但是却包装了一个没有返回值的函数，但其实把第二行注释掉之后，程序就可以成功编译，也就是说包装错误的函数如果不被调用，是不会报错的，这一点和模板函类不使用就不会创建很相似，最终是相同的。 包装类成员在深入学习std::bind()这个函数之前一直以为它只能用来包装函数，后来通过进一步了解发现它还能用来包装成员变量，我们一起来看一下简单的实现方法。 成员函数的包装这里我们不考虑静态成员函数，因为静态函数没有this指针，和普通的函数基本一样，在用法上也没有很大的差异，所以此处的包装只考虑成员非静态函数，可以尝试分析以下几个例子。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class CTest&#123;public: CTest() &#123;&#125; ~CTest() &#123;&#125;public: void func1(int n1, int n2) &#123; cout &lt;&lt; "func1 " &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; endl; &#125; int n_public;private: void func2(int n1, int n2) &#123; cout &lt;&lt; "func2 " &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; endl; &#125; int n_private;&#125;;void test2_1()&#123; CTest testObj; auto f2 = std::bind(&amp;CTest::func1, testObj, 101, placeholders::_1); f2(1); // same as call testObj.func1(101, 1)&#125;void test2_2()&#123; CTest testObj; auto f2 = std::bind(&amp;CTest::func1, &amp;testObj, 101, placeholders::_1); f2(2); // same as call testObj.func1(101, 2)&#125;void test2_3()&#123; CTest testObj; CTest&amp; obj = testObj; auto f2 = std::bind(&amp;CTest::func1, obj, 101, placeholders::_1); f2(3); // same as call testObj.func1(101, 3)&#125;void test2_4()&#123; CTest testObj; auto f2 = std::bind(&amp;CTest::func1, placeholders::_1, placeholders::_2, 101); f2(testObj, 4); // same as call testObj.func1(4, 101)&#125;void test2_5()&#123; CTest testObj; // auto f2 = std::bind(&amp;CTest::func2, &amp;testObj, 101, placeholders::_1); // 编译错误，func2不可访问&#125;//func1 101 1//func1 101 2//func1 101 3//func1 4 101 前三个函数tes2_1()、tes2_2()、tes2_3()的作用基本一致，就是将一个类的非静态成员函数和对象绑定，并且可以动态绑定一些参数，三种调用方式都可以，暂时没有发现什么问题，大家知道区别的可以指导我一下，我补充上来，需要注意的是函数std::bind()参数个数需要在原函数参数个数的基础上加两个，第一个很明显就是函数名，而第二个必须是调用这个函数的对象，至于传递的是指针还是引用都没有什么问题，这两个参数过后才是真正的原函数的参数。 函数test2_4()相对于前三个来说更加灵活，将对象也最为参数在调用时传入，这就相当于把一个成员函数看成，一个普通函数然后在第一个参数前加this指针的形式，后面这种调用方式在查看C++调用堆栈时应该很容易看到，本质上是一样，其实这里还有一个对象传递的问题，我们在成员变量时再测试一下。 函数test2_5()出现了编译错误，原因是在使用函数std::bind()的时候也要考虑到原函数的访问权限，在测试函数中访问对象的私有函数显然是不可以的。 成员变量的包装1234567891011121314151617181920212223242526272829303132333435void test3_1()&#123; CTest testObj; auto f3 = std::bind(&amp;CTest::n_public, testObj); f3(1) = 10; cout &lt;&lt; f3(1) &lt;&lt; endl; cout &lt;&lt; testObj.n_public &lt;&lt; endl;&#125;void test3_2()&#123; CTest testObj; auto f4 = std::bind(&amp;CTest::n_public, placeholders::_1); f4(testObj) = 4; cout &lt;&lt; f4(testObj) &lt;&lt; endl; cout &lt;&lt; testObj.n_public &lt;&lt; endl;&#125;void test3_3()&#123; CTest testObj; auto f3 = std::bind(&amp;CTest::n_public, std::ref(testObj)); f3(1) = 11; cout &lt;&lt; f3(1) &lt;&lt; endl; cout &lt;&lt; testObj.n_public &lt;&lt; endl;&#125;//10//-858993460//4//4//11//11 这个成员变量的绑定测试结果，有没有让人意想不到呢？或者说这种f3(1) = 10;写法已经让人很惊讶了，其实我在写例子的时候就是简单试试，没想到这样写居然可以，看起来好像把一个值赋值给了一个函数一样。 函数test3_1()的第二个输出可能有点想不到，但是看到结果是有些人可能就明白了，因为在上一篇里提到“std::bind()函数中的参数在被复制或者移动时绝不会以引用的方式传递，除非你使用了std::ref()或者std::cref()包装的参数”。 因为没有使用std::ref()函数包装，所以std::bind()函数绑定的testObj对象实际上是原对象的副本，那么针对于副本的操作和修改自然就不会反应到原对象上，这也就是打印testObj.n_public会输出随机值的原因。 函数test3_2()在绑定时并没有具体到特定的对象，而是使用了placeholders::_1占位符，这样生成的函数，在调用的时候再传入操作对象，那么此时修改对象属性就可以起作用了。 函数test3_3()是针对于函数test3_1()的，添加了std::cref()包装的原对象，可以通过绑定后的函数修改。 总结 std::bind()函数可以嵌套绑定 std::bind()函数绑定成员函数时，函数名参数后面需要紧跟着类的对象作为参数 std::bind()不仅可以绑定普通函数、成员函数、还可以绑定成员变量 完整代码代码传送门]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>bind</tag>
        <tag>placeholders</tag>
        <tag>class</tag>
        <tag>object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[雷电模拟器一键宏实现循环点击]]></title>
    <url>%2Fblog%2F2019%2F08%2F09%2F%E9%9B%B7%E7%94%B5%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%80%E9%94%AE%E5%AE%8F%E5%AE%9E%E7%8E%B0%E5%BE%AA%E7%8E%AF%E7%82%B9%E5%87%BB%2F</url>
    <content type="text"><![CDATA[前言今天在使用雷电模拟器测试游戏的时候，有一个领奖界面需要点击领奖100次，程序猿作为解放劳动力的先锋，必须想个办法解决这个事情，按键精灵是个好东西，但是重装系统之后还没有安装，然后发现这个雷电模拟器里除了简单的按键映射，还有一键宏的功能，那就用它解决了。 解决过程关于雷电模拟器的按键操控功能，官方论坛-帮助教程已经写得很清楚了，一键宏怎么设置教程里也写的很清楚，唯一的缺点就是各个截图中的代码太模糊了，根本看不清，所以我在尝试的过程中还花了点时间，其中遇到了几个坑和大家分享下。 我用的模拟器版本是3.54，这个版本在编写一键宏的时候可以直接在界面上获得对应点的坐标，非常的方便，在开始写一键宏的时候有一个误区，就是怎么控制我写的这段宏代码的开始与结束，起初我还控制按键的按下和抬起，发现没有什么用，最后测试发现，就是设置的按键按下时执行，如果存在循环就一直执行，按键抬起时执行结束，简单粗暴。 代码编写其实这个一键宏也算不上代码，最多也就算个伪代码，然后通过模拟器解析一下，要实现循环点击的功能需要的指令不多，只有4个： size：指定模拟器的分辨率 loop：说明以下的指令开始循环 touch：点击屏幕上的像素点 wait：休息一下，防止点击过快，单位是毫秒 其中坑人最深的就是size这个命令，我一开始以为是设置分辨率的，而我玩游戏默认的分辨率是1600X900，所以设置的点击位置也是在这个分辨率下取的点，然后就没加这个指令，结果一键宏一直不生效，后来加上了size 1600 900这一句才好使，这时我才明白这个指令不是设置分辨率的，而是告诉以下指令，当前的分辨率是多少，在操作像素点时不至于选错，宏的内容很简单，只有四句： 1234size 1600 900looptouch 1400 350wait 1000 这个宏组合的意思也很清楚，在分辨率1600X900的情况下，循环点击(1400, 350)这个像素点，每次点击间隔1s，防止点击过快。 总结 一键宏设置完成后，按键按下执行，如果是循环指令，则按键抬起结束 size指令并不是设置分辨率，而是说明现在的分辨率]]></content>
      <categories>
        <category>game</category>
      </categories>
      <tags>
        <tag>雷电</tag>
        <tag>模拟器</tag>
        <tag>按键操控</tag>
        <tag>一键宏</tag>
        <tag>loop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[std::bind（一）：包装普通函数]]></title>
    <url>%2Fblog%2F2019%2F08%2F01%2Fstd-bind%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%8C%85%E8%A3%85%E6%99%AE%E9%80%9A%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言不知道大家在做项目写程序的过程中有没有遇到这样的情况，别的模块类提供了一个拥有很多参数接口函数，但是我这个功能只用到其中几个，其他的参数都是固定的，可是为了调用这个接口函数，不得不将所有的参数写一遍，每次写一堆固定参数都感觉在浪费生命。 有的人可能想到默认参数，的确，默认参数可以解决部分问题，因为默认参数只能出现参数列表的尾部，如果4个参数中，我需要传递的参数是第4个，而前3个参数想默认的话，默认参数是做不到这种效果的，并且别人的接口函数也不一定会有默认参数。 函数封装，这是一个办法，我们在自己的模块中添加一个对接口函数进行包装后的函数，将不变的参数进行固定，然后只留可变的参数供我们自己调用，如果我们有3种常用的调用方式可能就需要定义3个函数，这种方法可行，不过比较麻烦，而std::bind()函数就是为了包装函数而生的，使用起来更加方便。 std::bind()的作用std::bind()的作用就是对原函数进行包装，可以将参数值固定，调换顺序然后生成新的函数供我们调用。举个例子，一块铁片你可以拿它来做很多事情，打造一下可以做成一把刀，敲敲打打可以做成一个桶，甚至直接拿来就可以挡窗户上的洞。std::bind()的作用就是把这块铁的作用固定，比如给她安上一个刀把，这样我们每次使用就可以把这块铁片当成菜刀来使用了。 std::bind()可以包装各种函数，但是这篇文章只总结一下包装普通函数的方法，因为在学习的过程中我发现单单是包装普通函数也会遇到很多问题，所以为了列举出诸多可能，说明各种注意事项，本文还是只关注于普通函数的包装，至于成员函数的包装还是放到以后的文章，给自己埋下一个坑。 在包装普通函数时，std::bind()的第1个参数就是原函数的名字，当然也可以是指向函数的指针，或者函数引用，从第2个参数开始，填写的内容依次对应原函数中的各个参数，所以说如果原函数是3个参数，如果想包装它，那么std::bind()需要传入4个参数，如果原函数是8个参数，那么包装它的std::bind()就需要传入9个参数，这里为了将原函数和包装后的函数参数建立联系，需要引入命名空间std::placeholders。 placeholders的作用std::placeholders的命名空间下有多个参数占位符，比如placeholders::_1、placeholders::_2等等，最大为placeholders::_20，在包装普通函数时，固定的参数很好说，就是填写固定值就可以，但是要想原函数的参数和包装后函数的参数建立联系就需要用到刚刚提到的占位符， placeholders::_1就表示包装后函数的调用时的第1个参数，同理placeholders::_2就表示包装后函数的调用时的第2个参数。 有了占位符的概念，我们就可以推断出，包装后的函数与原函数相比，不但可以减少函数参数，也可以增加函数参数，虽然暂时没有想到什么实际的使用场景，但是理论上是可行的。 std::bind()使用测试首先需要先引入头文件，免得找不到命名空间和函数定义123#include &lt;iostream&gt;#include &lt;functional&gt;using namespace std; 固定参数、调换顺序1234567891011121314151617181920void func1(int n1, int n2, int n3)&#123; cout &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; endl;&#125;void test1_1()&#123; auto f1 = std::bind(func1, placeholders::_1, 101, placeholders::_2); f1(11, 22); // same as call func1(11, 101, 22)&#125;void test1_2()&#123; auto f1 = std::bind(func1, placeholders::_2, 101, placeholders::_1); f1(11, 22); // same as call func1(22, 101, 11)&#125;// 输出//11 101 22//22 101 11 函数test1_1()展示了std::bind()函数最常见的用法，其中参数n2被固定为101，参数n1使用占位符placeholders::_1表示，表示包装后函数的第1个参数会传给形参n1使用，同理包装后函数的第2个参数会传给形参n3使用，所以调用函数f1(11, 22) 就等同于调用函数 func1(11, 101, 22)，test1_2()函数简单展示了调换参数顺序的方法，只要明白了placeholders的作用，这两个例子也就明白了。 包装后函数的参数个数可增可减123456789101112131415161718192021222324252627void func2(int n1, int n2, int n3)&#123; cout &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; endl;&#125;void test2_1()&#123; auto f2 = std::bind(func2, placeholders::_3, 101, placeholders::_1); f2(11, 22, 33); // same as call func2(33, 101, 11)&#125;void test2_2()&#123; auto f2 = std::bind(func2, placeholders::_1, 101, placeholders::_1); f2(11); // same as call func2(11, 101, 11)&#125;void test2_3()&#123; auto f2 = std::bind(func2, placeholders::_1, 101, placeholders::_2); f2(11); // 报错，因为没有参数传给placeholders::_2&#125;// 输出//33 101 11//11 101 11//编译错误 其实在理解了placeholders的作用之后，这个测试结果也能想到的，函数test2_1()中使用了placeholders::_3，所以包装后函数的参数至少要传3个才不会报错，而test2_2()函数中使用了placeholders::_1，所以被包装函数调用时只需要传入一个参数，最后是函数test2_3()，绑定时引用了placeholders::_2，而在调用时只传了一个参数，所以出现编译错误。 bind()绑定时参数个数固定，类型需匹配12345678910111213141516171819202122void func3(int n1, int n2, int n3)&#123; cout &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; endl;&#125;void test3_1()&#123; auto f3 = std::bind(func3, placeholders::_1, 101); //f3(11); // 编译错误，因为bind函数中少了一个参数&#125;void test3_2()&#123; auto f3 = std::bind(func3, placeholders::_1, 101, 102, 103); //f3(11); // 编译错误，因为bind函数中多了一个参数&#125;void test3_3()&#123; auto f3 = std::bind(func3, placeholders::_1, "test", placeholders::_1); //f3(11); // 编译错误，第二个参数类型不匹配，无法将参数 2 从“const char *”转换为“int”&#125; 看了之前的测试之后，是不是觉得参数的个数很随意，可以随便增加和减少，所以在绑定的时候也不好好写了，结果发现上述3个函数全部编译错误，test3_1()函数中因为绑定时少了一个参数而报错，test3_2()函数中因为绑定时多了一个参数而报错，而test3_3()函数中因为绑定时第二个参数的类型不匹配而报错，所以参数个数的增减只能是包装后的函数，而绑定时必须严格与原函数的参数个数以及类型相匹配。 普通函数的参数中有引用类型弄明白上面的例子之后，可能会产生一种我会了的错觉，想象一下如果原函数参数中包含引用类型应该怎样写，可以自己先想一下，然后看看下面的例子1234567891011121314151617181920212223242526272829303132333435363738394041424344void func4(int n1, int n2, int&amp; n3)&#123; cout &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; endl; n3 = 101;&#125;void test4_1()&#123; int n = 10; auto f4 = std::bind(func4, 11, 22, n); n = 33; f4(); // same as call func4(11, 22, 10) cout &lt;&lt; "n = " &lt;&lt; n &lt;&lt; endl;&#125;void test4_2()&#123; const int n = 30; auto f4 = std::bind(func4, 11, 22, n); f4(); // same as call func4(11, 22, 30)&#125;void test4_3()&#123; int n = 30; auto f4 = std::bind(func4, 11, 22, ref(n)); n = 33; f4(); // same as call func4(11, 22, n) cout &lt;&lt; "n = " &lt;&lt; n &lt;&lt; endl;&#125;void test4_4()&#123; const int n = 30; auto f4 = std::bind(func4, 11, 22, ref(n)); //f4(); // 编译错误，无法将参数 3 从“const int”转换为“int &amp;”&#125;// 输出//11 22 10//n = 33//11 22 30//11 22 33//n = 101 如果能准确说出test4_1()函数的输出结果，那么后面的内容应该是不需要看了，如果只回答对了部分内容，或者干脆全错了，那么我们还有很长的路要走。 在std::bind()的官方文档中有这样一句话，std::bind()函数中的参数在被复制或者移动时绝不会以引用的方式传递，除非你使用了std::ref()或者std::cref()包装的参数，如果知道了这个限定，就很容易明白函数test4_1()函数的输出结果了。 在函数test4_1()中std::bind(func4, 11, 22, n)就相当于std::bind(func4, 11, 22, 10)，所以输出结果为11 22 10，可是函数func4()中还有一句 n3 = 101;，这就很让人奇怪了，我们知道常数是没办法作为参数传递给可变引用变量的，如果说把10作为参数传递给参数int&amp; n3肯定会报错，而函数test4_1()却正常执行，没有任何问题。 我们猜测常数10到参数int&amp; n3并不是直接传递，而是发生了拷贝，而函数func4()中修改的n3变量也是修改的拷贝内容，所以我们做了test4_2()这个实验，发现将变量n改为常量也是可以正常执行的，甚至直接写成std::bind(func4, 11, 22, 10)也是没问题的，这也验证了我们上面的想法。 既然文档了提到了std::ref()和std::cref()函数，那么我们想传递引用给原函数只能使用它们了，看下函数test4_3()的实现，这才是正确传递引用变量的方式，变量n被函数 std::ref() 包装之后，既能够感受到本函数中变量n的变化，也能够传入到原函数中被原函数的逻辑改变，并将结果反映回来。 函数test4_4()只是一个常量传递的简单测试，将一个常量作为可变引用变量来传递肯定是无法通过编译的，这在函数调用时很明确，但是在std::bind()加入之后显得有些混乱，只要记住一点，常量不应该被改变，如果传递之后内容可能会变化，那么很可能这种写法就是错误的。 总结 其实std::bind()函数测试到现在远远没有结束，配合std::ref()和std::cref()函数会产生多种组合情况，不过主要的问题上面都提到了一些，出现问题的时候对照着定义和概念看看应该就能理解了。 需要理解std::placeholders的占位作用，它们是std::bind()函数最基本的用法。 完整代码代码传送门]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>bind</tag>
        <tag>placeholders</tag>
        <tag>auto</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中char和varchar的区别]]></title>
    <url>%2Fblog%2F2019%2F07%2F27%2FMysql%E4%B8%ADchar%E5%92%8Cvarchar%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言这个标题起的过于俗套，前一段时间我还写了一篇总结《Mysql5.7版本中数据表字段可用的类型》来批判这种对比，原因是对比时没有指明数据库，内容写的是char、varchar和nvarchar的对比，结果我测试了半天发现Mysql当前版本根本没有nvarchar，浪费来了不少时间。 问题起因真香定律来的总是这么快，这才过了几天，我也来写写Mysql中char和varchar究竟有什么区别，起因是看到CSDN好友“铁柱同学”一篇关于innodb主键长度最大为767字节的讲解，里面涉及到一个char类型最大存储255个字符，按照utf8编码来看最大的字节数应该是255*3=765个字节的知识点。现在来看767的来源好像并不是256*3-1，而是255*3+2，这个2就是存储char类型字段中实际有多少个字节的。 有点跑题了，实际上是在研究索引长度的过程中，我发现我对char和varchar这两个类型一直存在着误解，因为一直做游戏开发的缘故，游戏数据的存储一般使用varbinary来存，导致我把字符和字节有点弄混了，所以我一直认为在utf8编码下char(9)可以存储9个英文字符，或者3个中文汉字，实际我做完实验后发现char(9)也可以正常存储9个汉字。 提到字符和字节，初学者可能会有点蒙，实际上它们两者之间是需要通过编码来转换的，之前做过游戏的多语言版本，所以对这一块还是比较熟的，字节就是计算机中的8个二进制位，而字符是每个语言中的不可分割的单元，字符转换成字节需要依赖编码，实际上编码就是一本大字典，里面对应了每个字符在当前编码下转换成字节是什么样的，ANSI是一本字典，UTF8也是一本字典，编码的类型还有很多，每种编码都记录了各自的转换结果。 举个例子，“中”这个字是汉字中的一个字符，在ANSI这本字典中对应的是2个字节，而在UTF8这本字典中对应的是3个字节，而C这个字母是英文中的一个字符，在ANSI这本字典中对应的是1个字节，而在UTF8这本字典中对应的同样是1个字节，从这个例子中可以简单理解下字节与字符的关系。 多说一句，不要认为UTF8编码中汉字转换成字节都是3个字节，实际情况是常用字一般都占用了3个字节，但是中国语言博大精深，光语言平面就单独占了好几个，有些汉字转换成UTF8编码可能需要4个字节，5个字节甚至是6个字节，这一点不要形成思维定式，认为汉字在UTF8编码下都是3个字节。 length 和 char_length今天之前我是不知道Mysql还有一个char_length函数的，发现这个函数后越发感觉Mysql的强大，这两个函数的区别就是length用来统计字段中的字节数，char_length用来统计字段中的字符数，接下来我们用一个例子来看看这两个函数以及char、varchar的区别。 测试环境 Windows 10Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 10Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 测试过程 首先创建一个带有char和varchar类型的测试表，查看表结构发现编码为utf8 1234567891011121314mysql&gt; create table diff(id int, s1 char(10), s2 varchar(10));Query OK, 0 rows affected (0.07 sec)mysql&gt; show create table diff;+-------+------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------+| diff | CREATE TABLE `diff` ( `id` int(11) DEFAULT NULL, `s1` char(10) DEFAULT NULL, `s2` varchar(10) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------+1 row in set (0.07 sec) 插入少于10个字符的测试数据，然后查看结果，发现字节数为10，字符数为6 12345678910mysql&gt; insert into diff values(1, "测试test", "测试test");Query OK, 1 row affected (0.01 sec)mysql&gt; select id, s1, length(s1), char_length(s1), s2, length(s2), char_length(s2) from diff;+----+----------+------------+-----------------+----------+------------+-----------------+| id | s1 | length(s1) | char_length(s1) | s2 | length(s2) | char_length(s2) |+----+----------+------------+-----------------+----------+------------+-----------------+| 1 | 测试test | 10 | 6 | 测试test | 10 | 6 |+----+----------+------------+-----------------+----------+------------+-----------------+1 row in set (0.06 sec) 增加插入长度后发现，可以超过10个字节，可以完整存储10个汉字 1234567891011mysql&gt; insert into diff values(2, "测试策划和开发做游戏", "测试策划和开发做游戏");Query OK, 1 row affected (0.01 sec)mysql&gt; select id, s1, length(s1), char_length(s1), s2, length(s2), char_length(s2) from diff;+----+----------------------+------------+-----------------+----------------------+------------+-----------------+| id | s1 | length(s1) | char_length(s1) | s2 | length(s2) | char_length(s2) |+----+----------------------+------------+-----------------+----------------------+------------+-----------------+| 1 | 测试test | 10 | 6 | 测试test | 10 | 6 || 2 | 测试策划和开发做游戏 | 30 | 10 | 测试策划和开发做游戏 | 30 | 10 |+----+----------------------+------------+-----------------+----------------------+------------+-----------------+2 rows in set (0.10 sec) 分别增加s1和s2字段长度后发现，均无法正常插入，Mysql给出报错信息 12345mysql&gt; insert into diff values(2, "测试策划和开发做游戏OK", "测试策划和开发做游戏");1406 - Data too long for column 's1' at row 1mysql&gt; insert into diff values(2, "测试策划和开发做游戏", "测试策划和开发做游戏OK");1406 - Data too long for column 's2' at row 1mysql&gt; 至此没有看出区别，在插入内容前后都加上空格测试一下 123456789mysql&gt; select id, s1, concat('#', s1, '$'), length(s1) as len_s1, char_length(s1) as clen_s1, s2, concat('#', s2, '$'), length(s2) as len_s2, char_length(s2) as clen_s2 from diff;+----+----------------------+------------------------+--------+---------+----------------------+------------------------+--------+---------+| id | s1 | concat('#', s1, '$') | len_s1 | clen_s1 | s2 | concat('#', s2, '$') | len_s2 | clen_s2 |+----+----------------------+------------------------+--------+---------+----------------------+------------------------+--------+---------+| 1 | 测试test | #测试test$ | 10 | 6 | 测试test | #测试test$ | 10 | 6 || 2 | 测试策划和开发做游戏 | #测试策划和开发做游戏$ | 30 | 10 | 测试策划和开发做游戏 | #测试策划和开发做游戏$ | 30 | 10 || 3 | OK | # OK$ | 3 | 3 | OK | # OK $ | 4 | 4 |+----+----------------------+------------------------+--------+---------+----------------------+------------------------+--------+---------+ 这一次出现了区别，char类型的字段去掉了尾部的空格，而varcahr了类型的字段原样存储，没有去掉尾部空格，两者对于头部的空格都是存储的，这导致两者显示的字节数和字符数都不相同了。 分别使用不带空格、带头部空格，头尾都带空格进行测试12345678910111213141516171819202122232425262728293031323334353637mysql&gt; select * from diff where s1 = 'OK ';Empty setmysql&gt; select * from diff where s2 = 'OK ';Empty setmysql&gt; select * from diff where s1 = ' OK ';+----+-----+------+| id | s1 | s2 |+----+-----+------+| 3 | OK | OK |+----+-----+------+1 row in set (0.05 sec)mysql&gt; select * from diff where s2 = ' OK ';+----+-----+------+| id | s1 | s2 |+----+-----+------+| 3 | OK | OK |+----+-----+------+1 row in set (0.05 sec)mysql&gt; select * from diff where s1 = ' OK';+----+-----+------+| id | s1 | s2 |+----+-----+------+| 3 | OK | OK |+----+-----+------+1 row in set (0.05 sec)mysql&gt; select * from diff where s2 = ' OK';+----+-----+------+| id | s1 | s2 |+----+-----+------+| 3 | OK | OK |+----+-----+------+1 row in set (0.04 sec) 测试结果可能让人出乎意料，虽然s1和s2中存储的内容不同（差一个空格），但是查找时的行为却完全一样，这说明查找时尾部的空格并不会被考虑。 char和varchar区别做了半天试验发现char和varchar还是没有多大区别，实际上有些区别通过表面数据是测试不出来的，具体区别整理如下： 行为 char字段 varchar字段 最大长度 255字符 65535个字节，所以括号中最大的字符数还得通过编码来算 是否定长 定长，不足的部分用隐藏空格填充 不定长 空间使用 会有浪费 更加节省 查找效率 高 低 尾部空格 插入时省略 插入时不会省略，查找时省略 like查找 语句中like后的’ ‘不会省 语句中like后的’ ‘不会省，字段结尾的空格也不会省 总结 char(n)中的n是字符数，范围是0~255（额外需要1到2个字节来存长度） varchar(n)中的n也是字符数，但是最大值需要通过编码来算，不能超过65535字节（从中还需要拿出1到2个字节来存长度） 一般定长的数据选用char类型，比如身份证号，手机号，电话等，长度变化很大的可以使用varchar类型 注意尾部空格的匹配，特别是插入时和使用like查找时]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>char</tag>
        <tag>varchar</tag>
        <tag>length</tag>
        <tag>char_length</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时分秒针在一天之内重合多少次]]></title>
    <url>%2Fblog%2F2019%2F07%2F23%2F%E6%97%B6%E5%88%86%E7%A7%92%E9%92%88%E5%9C%A8%E4%B8%80%E5%A4%A9%E4%B9%8B%E5%86%85%E9%87%8D%E5%90%88%E5%A4%9A%E5%B0%91%E6%AC%A1%2F</url>
    <content type="text"><![CDATA[前言分析问题之前先给出问题的答案：2次，送给急需要知道答案又不求甚解的朋友。 这个问题之前听过类似的，一直没有当回事，今天在解题的时候发现了这道题，于是动脑筋想了一下，从12点位置时分秒3个表针重合开始，第一次应该在1点5分之后，那是分针转了一圈快追上时针了，再稍微走一点就能追上，然后秒针再转过来就完成了第一次重合，同理在2点10分之后也有一次，在3点15之后还有一次，这样算下来12小时之内有11次，那么一天24小时就有22次。 正在为自己的想法得意时，查了一下参考答案发现我被幼稚的想法打败了，实际上一天24小时内，时分秒针只重合了2次，原因就是我设想从12点开始到1点5分，分针转了一圈快追上时针了，此刻时针与分针确实会有一次相遇，但是此时的秒针却没办法跟他们相逢，因为三个表针是联动的，针对于每个精确到秒的时间，三个针都有固定的位置，不是想重合就能重合的。 在1点5分附近的情况就是，时针和分针快要重合了，然后秒针匆匆赶来，然后时针和分针重合了，秒针还差一点才能到，然后秒针继续走，但是秒针走会继续带动分针和时针运动，然后秒针赶到了分针时针相遇的附近，却发现它俩已经“分手”了，秒针只能大步流星的一个个越过它们俩，期待着下次它们仨能相遇在一处。 时针和分针的相遇在考虑时分秒三针重合情况之前，我们可以先想一下一天24小时内，分针和时针相遇了多少次，其实这才是我刚才想的那个答案22次，知道了次数之后我们还想知道具体的时间，可不可以算出来呢？当然可以！ 接下来我们以一种通俗的方式来解这个问题，那就是列方程式求解，首先将时间作为连续值来看待，我们设时针的角速度是ω，因为时针走1格，分针会走1圈，也就是12格，所以分针的角速度是12ω，分针转了一圈追上时针用的是t，时针和分针转过角度差为1圈，也就是2π，那么此时可以列出方程： $$12ωt-ωt=2π$$ 关于角速度ω的值，因为1圈的角度是2π，转一圈需要花的时间是12小时，所以ω=2π/12小时，带入方程得到t=12小时/11，同理如果分针转两圈追上时针，那么方程式为： $$12ωt-ωt=4π$$ 可以求得t=24小时/11，由此我们就得到了，时针分针相遇时刻与分针转的圈数i的关系： $$t=i*12小时/11$$ 代码实现有了上面的分析，我们可以写代码计算一下一天之中时针和分针相遇具体时刻，因为开着lua编辑器，顺手就用lua写了，代码如下： 123456789101112function print_meet(id, meet) local h = math.floor(meet) local t = meet - h; local ts = t * 3600; local m = ts // 60; local s = ts - m * 60; print(string.format("%02dth meet, time = %02d:%02d:%05.2f", id, h, m, s));endfor i=1,24 do print_meet(i, i * 12 / 11)end 运行结果 01th meet, time = 01:05:27.2702th meet, time = 02:10:54.5503th meet, time = 03:16:21.8204th meet, time = 04:21:49.0905th meet, time = 05:27:16.3606th meet, time = 06:32:43.6407th meet, time = 07:38:10.9108th meet, time = 08:43:38.1809th meet, time = 09:49:05.4510th meet, time = 10:54:32.7311th meet, time = 12:00:00.0012th meet, time = 13:05:27.2713th meet, time = 14:10:54.5514th meet, time = 15:16:21.8215th meet, time = 16:21:49.0916th meet, time = 17:27:16.3617th meet, time = 18:32:43.6418th meet, time = 19:38:10.9119th meet, time = 20:43:38.1820th meet, time = 21:49:05.4521th meet, time = 22:54:32.7322th meet, time = 24:00:00.0023th meet, time = 25:05:27.2724th meet, time = 26:10:54.55 分析从上面的结果来看，处于一天内的时间相遇时刻只有前22次，12点之后第一次相遇是在01:05:27.27，此时虽然时针和分针相遇，但是秒针大概在27秒的位置，离他们还很远，同理分针时针第二次相遇时刻02:10:54.55，秒针也没有跟他们在一起，但是有两次例外，那就是12:00:00.00和24:00:00.00，这两次时针、分针、秒针完全重合了，所以我们也得到了本文标题中的答案。 总结 时分秒针在一天之内重合2次 从连续的时间来看，时针和分针在一天之内重合22次 有一种现实情况就是表盘上的时间是离散的，不连续的，最小的时间间隔是1秒，此时我们计算的第一次相遇时间01:05:27.27是不存在的，01:05:27的时候分针在时针之前，而01:05:28的时候分针在时针之后，它们也错过了，所以时针和分针考虑离散的情况，一天之后也只是重合2次。]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Lua</tag>
        <tag>time</tag>
        <tag>interview</tag>
        <tag>clock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSI七层模型中各层协议及作用]]></title>
    <url>%2Fblog%2F2019%2F07%2F18%2FOSI%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B%E4%B8%AD%E5%90%84%E5%B1%82%E5%8D%8F%E8%AE%AE%E5%8F%8A%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言OSI七层模型在网络这门学科中占有很大的比重，最近在看《图解TCP/IP》这本书，其中对模型中的各个层的作用和对应的协议讲的很详细，而自己有时候总是记错，所以想总结一下，巩固记忆，毕竟好记性不如烂笔头嘛，现在烂笔头不好找了，应该说烂键盘吗？ 各层简析对比 名称 作用 常用协议或标准 相关设备 传输单位 应用层 特定应用对接收数据的处理 HTTP、FTP、SMTP 终端、服务器 - 表示层 设备数据格式与网络标准数据格式转换 LPP、GIF、JPEG 终端、服务器 - 会话层 通信管理，建立和断开通信连接 RPC、SSL、TLS 终端、服务器 - 传输层 管理两个网络终端之间的数据传输 TCP、UDP 终端、服务器 段 网络层 网络地址管理和路由选择 IP/IPv6、ICMP 路由器、三层交换机 分组、包 数据链路层 互联设备之间传送和识别数据帧 ARP、PARP 网桥、二层交换机 帧 物理层 比特流与电子信号之间的转换 IEEE 802.3/802.2 网卡、网线、集线器、中继器、调制解调器 比特位 总结 这里只是我看书之后的基础理解与总结，后续关系紧密的内容也会更新到这里。 本文很多内容中掺杂着个人的理解，如果有不正确的地方欢迎批评指正，我会尽快修改，这也是一种有效的学习方式。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Network</tag>
        <tag>OSI</tag>
        <tag>七层模型</tag>
        <tag>网络协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++自定义全部替换函数replace]]></title>
    <url>%2Fblog%2F2019%2F07%2F16%2FC-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%85%A8%E9%83%A8%E6%9B%BF%E6%8D%A2%E5%87%BD%E6%95%B0replace%2F</url>
    <content type="text"><![CDATA[前言今天遇到一个问题，需要把源字符串中的所有A串替换成B串，可能是最近写脚本写的太多了，第一反应就是使用replace()函数就完成了，在 Lua 和 Python 中确实如此，但是我现在正在写C++啊，查询std::string发现确实有一个repalce()函数，但是查看定义后发现事情却不像想象的那样简单。 C++中的这个replace()函数显得过于“原始”，相比于其他脚本语言来说，用起来显得不太方便，不过很符合基础工具语言的特点，这个自带的repalce(pos, len, dst)函数的作用是从源字符串的第pos个字符开始，往后数len个字符，然后将这一部分替换成dst串。 有了这个替换函数，我们完全可以使用循环和查找函数完成全部替换，查找函数可以选择string::find()，从返回的找到的位置开始替换即可，若没有找到则会返回 string::npos，这时也就完成了所有的替换。 函数实现代码很简单，就是利用循环、string::find()函数、string::replace()函数来进行适当的组合，逻辑很清晰，代码如下：1234567891011121314#include &lt;string&gt;#include &lt;iostream&gt;using namespace std;string replace(string&amp; base, string src, string dst)&#123; int pos = 0, srclen = src.size(), dstlen = dst.size(); while ((pos = base.find(src, pos)) != string::npos) &#123; base.replace(pos, srclen, dst); pos += dstlen; &#125; return base;&#125; 关于是否需要返回值完全看你自己定义，我这里加了返回值只要是为了测试输出方便。 测试函数12345678910111213141516int main()&#123; string base1 = "1.0.0.1"; cout &lt;&lt; replace(base1, ".", "[.]") &lt;&lt; endl; string base2 = "1【.】0【.】0【.】1"; cout &lt;&lt; replace(base2, "【.】", "[.]") &lt;&lt; endl; string base3 = "1【.】0【.】0【.】1"; cout &lt;&lt; replace(base3, "【.】", ".") &lt;&lt; endl; string base4 = "this is a book"; cout &lt;&lt; replace(base4, "is", "are") &lt;&lt; endl; return 0;&#125; 运行结果 1[.]0[.]0[.]11[.]0[.]0[.]11.0.0.1thare are a book 总结 注意string::replace()函数与脚本中常用替换函数的不同 使用string::find()函数查找不到待查串时会返回string::npos]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>字符串</tag>
        <tag>替换</tag>
        <tag>replace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb使用watch命令设置数据断点]]></title>
    <url>%2Fblog%2F2019%2F07%2F16%2Fgdb%E4%BD%BF%E7%94%A8watch%E5%91%BD%E4%BB%A4%E8%AE%BE%E7%BD%AE%E6%95%B0%E6%8D%AE%E6%96%AD%E7%82%B9%2F</url>
    <content type="text"><![CDATA[前言“数据断点”这个说法是沿用在Visual Studio中学到的设置断点的方法，在gdb中一般被叫做“硬件断点”，算是断点调试中一种较为高级的调试方法了，这个方法起初是在VS中学会的，属于有需求必有响应的产物。刚开始调试程序的时候只会设置普通断点，就是在要调试的程序代码所在行设置断点，然后等程序运行到断点处可以单步执行，查看内存变量，遇到多个位置修改一个变量并且要查看是谁改变了变量的时候，就要设置多个断点，当时就想如果可以设置一个断点，当变量值被改变就触发这个断点那该多好啊。 当年果然是太年轻，后来发现这个功能就是VS中的数据断点，同样作用的还有gdb工具的中硬件断点，硬件断点不仅可以处理上面提到的需求，更是查找内存写超过的强大工具，要想知道一个正常的变量如何被“不正常”地修改了，硬件断点可以说是最佳工具了。 数据变化断点在gdb工具中设置普通断点的语法是b 变量名/函数名/文件位置，设置数据变化断点（硬件断点）语法也很简单，只需要一个watch命令即可，写法为watch 变量名，但是与普通断点不同的是，数据断点必须在程序运行时设置，在敲入r命令之前对变量设置数据断点会提示找不到符号。 编写测试程序代码 首先新建测试文件watchtest.cpp然后添加下面的代码： 123456789101112131415161718#include &lt;iostream&gt;using namespace std;int main()&#123; int k = 1; int n; n = 1; k = 2; cout &lt;&lt; n &lt;&lt; "," &lt;&lt; k &lt;&lt; endl; n = 3; k = 4; cout &lt;&lt; n &lt;&lt; "," &lt;&lt; k &lt;&lt; endl; return 0;&#125; 将C++源代码编译成可执行文件，为了调试记得加-O0 -g选项 1[albert@localhost#17:08:00#/home/albert/test]$g++ watchtest.cpp -O0 -g -o watchtest 加数据断点并调试 以下为gdb添加数据变化断点（硬件断点）并调试的整个过程，(gdb)后面的内容为敲入的命令： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[albert@localhost#17:52:47#/home/albert/test]$gdb watchtestGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/test/watchtest...done.(gdb) b watchtest.cpp : 6Breakpoint 1 at 0x40085c: file watchtest.cpp, line 6.(gdb) watch nNo symbol "n" in current context.(gdb) rStarting program: /home/albert/test/watchtestBreakpoint 1, main () at watchtest.cpp:66 int k = 1;Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-23.el6.x86_64(gdb) watch nHardware watchpoint 2: n(gdb) cContinuing.Hardware watchpoint 2: nOld value = 0New value = 1main () at watchtest.cpp:1010 k = 2;(gdb) cContinuing.1,2Hardware watchpoint 2: nOld value = 1New value = 3main () at watchtest.cpp:1414 k = 4;(gdb) cContinuing.3,4Watchpoint 2 deleted because the program has left the block inwhich its expression is valid.0x00007ffff72c6d1d in __libc_start_main () from /lib64/libc.so.6(gdb) qA debugging session is active. Inferior 1 [process 18567] will be killed.Quit anyway? (y or n) y[albert@localhost#17:55:04#/home/albert/test]$ 总结 设置数据断点需要在程序启动之后，在运行r命令之前设置断点给出信息：No symbol &quot;n&quot; in current context. 当程序运行到监控变量的作用域之外以后，断点自动被删除，这一点观察执行q命令之前的文字可以看出 添加数据变化断点（硬件断点）格式：watch 变量名]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>linux</tag>
        <tag>gdb</tag>
        <tag>watch</tag>
        <tag>断点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql5.7版本中数据表字段可用的类型]]></title>
    <url>%2Fblog%2F2019%2F07%2F02%2FMysql5-7%E7%89%88%E6%9C%AC%E4%B8%AD%E6%95%B0%E6%8D%AE%E8%A1%A8%E5%AD%97%E6%AE%B5%E5%8F%AF%E7%94%A8%E7%9A%84%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[前言为什么会有这个总结，因为在测试Mysql的字符串函数时发现，char 和 varchar 有些不同，网上搜索一番发现了各种char、varchar、nvarchar 类型的对比，还有一些奇奇怪怪的这里就不说了，然后我就开始了对这几种类型字符串的测试，接着就悲剧了，测试多次之后发现创建为nvarchar类型的字段居然是varchar类型的，再查询官方文档后发现，当前版本（5.7.21）的Mysql根本就没有nvarchar类型的字段，白白浪费了时间，所以要把Mysql支持的字段列举在这里，方便后面查找使用。 从13年开始工作到现在，数据库主要使用Mysql，关于常使用的字段类型无非 int、char、varchar、blob、datetime 这几种，工作之前用的最多的是SqlServer，其次就是Oracle和db2了，当时数据库的规模也不大，也没有注意到字段都有哪些类型，基本也是使用上述几种，因为今天在Mysql中的数据类型这栽了跟头，所以查了下官方文档，看看到底都有哪些类型。 支持类型真是不查不知道，查询后发现当前版本（5.7.21-log MySQL Community Server）支持的数据类型居然有40种，这还是超出我的想象的，以字典排序列举在此方便查找： bigint，binary，bit，blob，char，date，datetime，decimal，double，enum，float，geometry，geometrycollection，int，integer，json，linestring，longblob，longtext，mediumblob，mediumint，mediumtext，multilinestring，multipoint，multipolygon，numeric，point，polygon，real，set，smallint，text，time，timestamp，tinyblob，tinyint，tibytext，varbinary，varchar，year。 类型简述数字类型 BIT[(M)]比特值类型，M默认为1，范围是[1,64]。 TINYINT[(M)] [UNSIGNED] [ZEROFILL]单字节整数，有符号时范围是[-128,127]，无符号时范围是[0,255]。 BOOL, BOOLEAN布尔值类型，需要注意的是创建表时如果指定这两种类型会被自动转为TINYINT类型，0代表false，非0代表true。 SMALLINT[(M)] [UNSIGNED] [ZEROFILL]两字节整数，有符号时范围是[-32768,32767]，无符号时范围是[0,65535]。 MEDIUMINT[(M)] [UNSIGNED] [ZEROFILL]三字节整数，有符号时范围是[-8388608,8388607]，无符号时范围是[0,16777215]，这个类型在编程语言中很少见。 INT[(M)] [UNSIGNED] [ZEROFILL]四字节整数，有符号时范围是[-2147483648,2147483647]，无符号时范围是[0,4294967295]，与INTEGER等价。 BIGINT[(M)] [UNSIGNED] [ZEROFILL]八字节整数，有符号时范围是[-9223372036854775808,9223372036854775807]，无符号时范围是[0, 18446744073709551615]。 SERIAL是BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE类型的别名，感觉可以直接拿来做主键。 DECIMAL[(M[,D])] [UNSIGNED] [ZEROFILL]用于存储精确小数，M表示有效数字位数，范围是[1,65]，默认是10，D表示小数点后位数，范围是[0,30]，默认是0。 NUMERIC[(M[,D])] [UNSIGNED] [ZEROFILL]是DECIMAL的别名，同样含义的还有DEC[(M[,D])] [UNSIGNED] [ZEROFILL]、FIXED[(M[,D])] [UNSIGNED] [ZEROFILL]。 FLOAT[(M,D)] [UNSIGNED] [ZEROFILL]单精度浮点数，M表示有效数字位数，D表示小数点后位数，范围有三部分[-3.402823466E+38,-1.175494351E-38]，0，[1.175494351E-38,3.402823466E+38]，该类型属于Mysql自己的扩展，依赖硬件和操作系统，指定UNSIGNED表示禁用负数。 FLOAT(p) [UNSIGNED] [ZEROFILL]单精度浮点数，p用来表示精度，取值为0-24等价于没有M和D的FLOAT，取值为25-53等价于没有M和D的DOUBLE。 DOUBLE[(M,D)] [UNSIGNED] [ZEROFILL]双精度浮点数，表示有效数字位数，D表示小数点后位数，范围有三部分[-1.7976931348623157E+308,-2.2250738585072014E-308]，0，[2.2250738585072014E-308, 1.7976931348623157E+308]，该类型属于Mysql自己的扩展，依赖硬件和操作系统，指定UNSIGNED表示禁用负数。等价于DOUBLE PRECISION[(M,D)] [UNSIGNED] [ZEROFILL]。 REAL[(M,D)] [UNSIGNED] [ZEROFILL]一般情况等价于DOUBLE[(M,D)] [UNSIGNED] [ZEROFILL]，但如果SQL mode指定了REAL_AS_FLOAT，那么它等价于FLOAT[(M,D)] [UNSIGNED] [ZEROFILL]。 日期和时间类型 DATE日期类型，展示格式为’YYYY-MM-DD’，支持的范围是[‘1000-01-01’ , ‘9999-12-31’]。 DATETIME[(fsp)]日期时间格式，展示格式为’YYYY-MM-DD hh:mm:ss[.fraction]，支持范围是[‘1000-01-01 00:00:00.000000’, ‘9999-12-31 23:59:59.999999’]，fsp表示小数位数，默认是0，取值范围是[0,6]。 TIMESTAMP[(fsp)]时间戳，范围是[‘1970-01-01 00:00:01.000000’ UTC, ‘2038-01-19 03:14:07.999999’ UTC]，注意到起始秒数从1开始，是因为0被保留用来代表’0000-00-00 00:00:00’了，fsp表示小数位数，默认是0，取值范围是[0,6]。 TIME[(fsp)]时间类型，展示格式为 ‘hh:mm:ss[.fraction]’，支持的范围是[‘-838:59:59.000000’, ‘838:59:59.000000’]，fsp表示小数位数，默认是0，取值范围是[0,6]。 YEAR[(4)]代表年份类型，展示格式为’YYYY’，支持的范围是[1901, 2155]和0000。 字符串类型 [NATIONAL] CHAR[(M)] [CHARACTER SET charset_name] [COLLATE collation_name]固定长度的字符串，M表示字符串最大长度，范围是(0,255]，若实际长度不足M，实际串右侧会填充空格，M默认为1。 [NATIONAL] VARCHAR(M) [CHARACTER SET charset_name] [COLLATE collation_name]可变长度的字符串，M表示字符串最大长度，范围是(0, 65535],当存储UTF8编码中文时，一般需要3个字节存储一个汉字。 BINARY[(M)]与CHAR类似，只是存储的是二进制字节串而非普通的字符串。 VARBINARY(M)]与VARCHAR类似，只是存储的是二进制字节串而非普通的字符串。 TINYBLOB字节串，最大长度是255。 TINYTEXT [CHARACTER SET charset_name] [COLLATE collation_name]字符串，最大长度是255。 BLOB[(M)]字节串，最大长度64K-1，若指定M，则会创建一个能存储M字节最小的BLOB类型，比如TINYBLOB。 TEXT[(M)] [CHARACTER SET charset_name] [COLLATE collation_name]字符串，最大长度64K-1，若指定M，则会创建一个能存储M字节最小的BLOB类型，比如TINYTEXT。 MEDIUMBLOB字节串，最大长度16M-1。 MEDIUMTEXT [CHARACTER SET charset_name] [COLLATE collation_name]字符串，最大长度16M-1。 LONGBLOB字节串，最大长度4G-1。 LONGTEXT [CHARACTER SET charset_name] [COLLATE collation_name]字符串，最大长度4G-1。 ENUM(‘value1’,’value2’,…) [CHARACTER SET charset_name] [COLLATE collation_name]枚举值，一个字符串代表一个值，内部通过整数实现，理论上最多可以有65535个不同的值，但实际上这个值小于3000。 SET(‘value1’,’value2’,…) [CHARACTER SET charset_name] [COLLATE collation_name]集合，包含一组字符串，其内部还是呈现为一个整数，最大可以有64个不同的字符串对象。 特殊数据类型 Mysql提供了GEOMETRY、POINT、LINESTRING、POLYGON等特殊类型来与OpenGIS类一一对应，用来存储一些图形数据，同时还有MULTIPOINT、MULTILINESTRING、MULTIPOLYGON、GEOMETRYCOLLECTION可以表示这些集合，我感觉我是没机会用这些了，用到了再展开说吧。 Json数据类型 自从Mysql5.7.8之后添加的一种类型，可以存储{“k1”: “val”, “k2”: 110}形式的数据。 常用数据类型大小 类型 存储数据范围（只考虑无符号） 单位 TINYINT 0-255 整数 SMALLINT 0-65535 整数 MEDIUMINT 0-16777215 整数 INT 0-4294967295 整数 BIGINT 0-18446744073709551615 整数 DATETIME 1000-01-01 00:00:00.000000 -&gt; 9999-12-31 23:59:59.999999 时间点 TIMESTAMP 1970-01-01 00:00:01.000000 UTC -&gt; 2038-01-19 03:14:07.999999 UTC. 时间点 TIME -838:59:59.000000 -&gt; 838:59:59.000000 时间点 CHAR 0-255 字符数 VARCHAR 0-65535 字符数 BINARY 0-255 字节数 VARBINARY 0-65535 字节数 TINYBLOB 255 字节数 BLOB 65535(64K-1) 字节数 MEDIUMBLOB 16777215(16M-1) 字节数 LONGBLOB 4294967295(4G-1) 字节数]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>char</tag>
        <tag>varchar</tag>
        <tag>blob</tag>
        <tag>varbinary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逐步砍掉树杈的堆排序]]></title>
    <url>%2Fblog%2F2019%2F06%2F29%2F%E9%80%90%E6%AD%A5%E7%A0%8D%E6%8E%89%E6%A0%91%E6%9D%88%E7%9A%84%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言在实现堆排序之前，我们先来看看常见的数据结构，在网上我看到了一个特别全的版本：数组，栈，链表，队列，树，堆，图，散列表，本着鸡蛋里挑骨头的态度，我们来看看数组和链表，这两个到底算不算数据结构，貌似它们应该算是线性表这个结构，它们更应该被称作是一个实现结构的元素，比如通过数组和链表可以实现线性表、队列、栈，二叉树等等，可是看看数据结构的定义是计算机存储、组织数据的方式，貌似它们又算是数据结构，反正这个概念模模糊糊，不太清楚，要按我的理解常见结构应该只有线性表、栈、队列、树、图，其他的像堆其实是一种树，散列表很多的内部实现也是树。 好了，数据结构的事情也放一边，今天的目的是排序，主角是堆，那么究竟什么是堆呢？它的形状和山一样，只不过比山要“便宜”，比如土堆、煤堆、垃圾堆，这和金山、银山、绿水青山是没法比的，但是形状相似，只是小一点而已，上边小下边大，尖尖的，从侧面看就是第一个三角形。堆排序中的堆也是这种形状，上边窄下边宽呈现出一个三角形，其本质是一颗完全二叉树，一个n层的二叉树只有最后一层叶子节点可能不完整，但是都靠左排列，最多只有一个单叶子节点，如果说到这里你根本不知道什么是完全二叉树，甚至对树结构都是一头雾水，那么请去补补课，查询一下相关的定义就明白了。 一棵树要想被称为堆结构，光满足完全二叉树还不够，其中的元素也有要求，如果每个父节点都大于等于左右子节点被称为大根堆，如果每个父节点都小于等于左右子节点被称为小根堆，这样我们就知道在堆这个结构中，堆的顶端不是最大的值就是最小的值。 堆顶元素恰恰是堆排序的关键，试想一个有大根堆，我们把堆顶的数据拿下来放到一旁，把剩下的元素再调整成一个大根堆，然后再把堆顶数据拿下来放在刚才拿出那个元素的前面，再调整剩下的元素，反复这样操作，最后拿出来的这些元素就构成了一个有序序列，也就达到了排序的目的。 在进行升序排列时常使用大根堆，降序排列时常使用小根堆，这个知识点不是绝对的，也不需要记忆，只是这样操作更加方便，当你理解了堆排序的流程之后，很自然就能明白这样的用意，并且到那时候你完全可以反着操作来提升自己，不过效果和可读性可能会差一点。 堆排序树结构可以用数组表示出来，特别是完全二叉树用数组表示起来更加方便，从上往下，从左往右依次把数据放入数组，我们就把一颗完全二叉树塞进了一维数组里，本来打算一个图都不画的，但是突然良心发现了，不能对你们太残忍，还是画一个吧，下面这个图展示了完全二叉树与数组的对应关系，这可是本文中唯一的一个图了，可要珍惜一下，把这个图弄明白，之后我们就只操作数组，不再画树了，因为我太懒了。 1234567891011graph TB 2--&gt;3; 2--&gt;9; 3--&gt;4; 3--&gt;7; 9--&gt;12; 9--&gt;6; 4--&gt;1; 4--&gt;11; 7--&gt;5; 7--&gt;8; idx_0 idx_1 idx_2 idx_3 idx_4 idx_5 idx_6 idx_7 idx_8 idx_9 idx_10 2 3 9 4 7 12 6 1 11 5 8 这个用数组表示的完全二叉树有一个性质，这个性质是我编的，你之前可能没有听过，那就是从后面删除n个节点之后，剩下的元素还是一颗完全二叉树，这一点隐含在堆排序的整个过程中，并且二叉树的父节点都排列在数组前面，叶子节点都排在数组后边，父节点和子节点对应的索引满足一定的关系： 假设父节点索引是i，左节点索引=2*i+1 假设父节点索引是i，右节点索引=2*i+2 假设子节点索引是i，父节点的索引=(int)((i-1)/2) 明白了上面的关系，先简单描述一下堆排序的整个过程，操作的数据源就是这个数组，长度n=11，先将整个数组表示的完全二叉树调整成一个大根堆，这时树的根节点也就是数组的第一个元素就是最大值，把它和数组的最后一个元素交换，之后不再管最后这个数据，相当于把这个树杈砍掉了，根据上段提到的性质，砍掉最后一个叶子节点的二叉树仍然是一颗完全二叉树，调整数据使得前n-1个节点再次成为一个大根堆，继续把根节点索引为0的元素，也就是这个次最大值，与倒数第二个元素交换，之后也放弃倒数第二个元素了，相当于再次砍掉了这棵二叉树的一个树杈，如此反复操作，当“砍”到根节点时，整个数组也就从小到大排好序了。 排序过程通过上面描述可能还是不太明白堆排序的过程，接下来可以通过一个例子来实际操作一次，看看数组是怎样在不断调整大根堆的过程中慢慢变成有序的，数组的初始状态是： idx_0 idx_1 idx_2 idx_3 idx_4 idx_5 idx_6 idx_7 idx_8 idx_9 idx_10 2 3 9 4 7 12 6 1 11 5 8 先将数组代表的完全二叉树调整成一个大根堆 首先需要确认的是这个调整应该从下往上调整，先看最下边的子树，调整父节点和子节点的数据，使得父节点数据最大，然后再看前一个子树，继续把父子节点的数据调整好，这样一直调整到根节点时，整个完全二叉树的最大值就被调整到根节点了。这个过程有点像冒泡，从下往上，把最大的数据慢慢的冒到最上面。 反过来想想，如果是从上往下挨个子树来看，当从根节点调整到最后一个（最下最右）子树，并不能保证根节点数据最大，只是把较大数据向上整体移动了一次，所以还是要从下往上调整。 知道了这一点以后就要找到最后一个子树的位置，其实就是找到最后一个父节点，这个节点之前的数据都在非叶子节点上，这个节点之后的数据都在叶子节点上，只要调整这个最后父节点以及前面的所有节点就可以影响所有数据，关键是找到这个节点的位置。 要想找到最后一个父节点需要用到之前我们提到的公式，整个数组的元素个数n=11，最后一个元素的索引为n-1，那么其父节点就是最后一个子树的父节点，其索引应该为(int)((n-1-1)/2)，也就是n/2-1，这就是最后一个子树父节点的在数组中的索引，其数值为4，接着从这个节点开始从后往前调整子树： 子树父节点，索引i=4时，调整父节点和右孩子的值（从左右孩子中找一个较大的值，并且要大于父节点） |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|9|4|7(parent)|12|6|1|11|5(left)|8(right)| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|9|4|8(parent)|12|6|1|11|5(left)|7(right)| 子树父节点，索引i=3时，调整父节点和右孩子的值 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|9|4(parent)|8|12|6|1(left)|11(right)|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|9|11(parent)|8|12|6|1(left)|4(right)|5|7| 子树父节点，索引i=2时，调整父节点和左孩子的值 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|9(parent)|11|8|12(left)|6(right)|1|4|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|12(parent)|11|8|9(left)|6(right)|1|4|5|7| 子树父节点，索引i=1时，调整父节点和左孩子的值，这时左孩子同时也是下面子树的父节点，所以还要调整一下该节点作为父节点的子树 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3(parent)|12|11(left)|8(right)|9|6|1|4|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|11(parent)|12|3(left)|8(right)|9|6|1|4|5|7| 左子树节点作为父节点进行调整 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|11|12|3(tmp parent)|8|9|6|1(tmp left)|4(tmp right)|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|11|12|4(tmp parent)|8|9|6|1(tmp left)|3(tmp right)|5|7| 子树父节点，索引i=0时，调整父节点和右孩子的值，这时右孩子同时也是下面子树的父节点，同样还要调整一下该节点作为父节点的子树 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2(parent)|11(left)|12(right)|4|8|9|6|1|3|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||12(parent)|11(left)|2(right)|4|8|9|6|1|3|5|7| 右子树节点作为父节点进行调整 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||12|11|2(tmp parent)|4|8|9(tmp left)|6(tmp right)|1|3|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||12|11|9(tmp parent)|4|8|2(tmp left)|6(tmp right)|1|3|5|7| 到此为止整个大根堆就调整完成了，为了看的更加清楚。我不得不打脸再画一个图了，有时候还是看图更加方便，一图胜千言啊： |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||12|11|9|4|8|2|6|1|3|5|7| 1234567891011graph TB 12--&gt;11; 12--&gt;9; 11--&gt;4; 11--&gt;8; 9--&gt;2; 9--&gt;6; 4--&gt;1; 4--&gt;3; 8--&gt;5; 8--&gt;7; 将大根堆根节点保存的最大值与当前大根堆最后一个节点进行交换，然后将这个节点“砍掉” 交换数据后，将剩余的这个完全二叉树继续调整成大根堆，既然已经打脸了，那就再画个图，这个砍树杈的动作已经和标题呼应了，每次生成大根堆后，将根节点和堆的最后一个结点交换，然后砍掉这个树杈，等整棵树被砍的只剩下根节点，排序也就完成了。 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||12(head)|11|9|4|8|2|6|1|3|5|7(tail)| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||7(head)|11|9|4|8|2|6|1|3|5|12(tail)| 1234567891011graph TB 7--&gt;11; 7--&gt;9; 11--&gt;4; 11--&gt;8; 9--&gt;2; 9--&gt;6; 4--&gt;1; 4--&gt;3; 8--&gt;5; 8--&gt;|X|12; 重复上面的步骤，循环执行调整剩余元素为大根堆，首位交换，砍掉末尾元素这三步 这里需要注意的是除了第一次初始化成大根堆的过程比较麻烦，后面重复调整成大根堆的过程都很容易，因为只有这一个根节点不满足大根堆的定义，所以只从这个节点调整就可以，同时递归调整其不符合条件的子树即可。 每次交换之后都会“砍掉”树杈，所以大根堆每次都会减少元素，交换的索引也发生这变化，第一个是array[0]和array[n-1]，然后是array[0]和array[n-2]，最后一直交换到array[0]和array[1]，也就完成了整体的排序。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*功能： 交换两个变量参数： element1--被交换的第一个元素的地址 element2--被交换的第二个元素的地址返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void swap_data(int* element1, int* element2)&#123; int middle_value = *element1; *element1 = *element2; *element2 = middle_value;&#125;/*功能： 从start到end构成最大堆，前提是start之后的部分已满足最大堆， 也就是说start存在左右子树的情况下，子树已经是最大堆参数： array--表示待排序的数组，此处会退化成指针 start--需要调整的父节点索引 end --最后一个可以被调整的节点索引，当形成最大堆后，第一个节点与当前最后节点交换后，那么这个当前最后节点下一轮就不能被调整了返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void max_heapify(int array[], int start, int end)&#123; int parent_index = start; int child_index = start * 2 + 1; while (child_index &lt;= end) &#123; if (child_index + 1 &lt;= end &amp;&amp; array[child_index] &lt; array[child_index + 1]) ++child_index; // 如果右边的孩子更大，选择右边的 if (array[parent_index] &gt; array[child_index]) break; swap_data(&amp;array[parent_index], &amp;array[child_index]); parent_index = child_index; child_index = parent_index * 2 + 1; &#125;&#125;/*功能： 堆排序，实现数组元素从小到大排列参数： array--表示待排序的数组，此处会退化成指针 count--数组元素的个数返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void heap_sort(int array[], int count)&#123; for (int pos = count / 2 - 1; pos &gt;= 0; --pos) max_heapify(array, pos, count - 1); for (int target_pos = count - 1; target_pos &gt; 0; --target_pos) &#123; swap_data(&amp;array[0], &amp;array[target_pos]); max_heapify(array, 0, target_pos - 1); &#125;&#125; 代码分析堆排序其实是一种选择排序，但是堆排序的代码比选择排序要复杂一下，其实理解了算法思路这些代码还是很容易看懂的，函数heap_sort是堆排序的主体逻辑，第一个for循环是从最后一个父节点开始调整，将父节点与较大的子节点交换，一直调整到根节点，初始化成一个大根堆。 第二个for循环就是重复做交换首尾元素，然后调整剩余元素使其成为大根堆这两件事，重复n-1轮，排序过程也就完成了。 运行测试在线编辑器是一个很方便的测试代码的环境，如果想本地调试一下，也可以直接下载堆排序–源码，在本地编译后进行调试，其实单步调试是理解算法思路很有效的方式。]]></content>
      <categories>
        <category>Sort</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>算法</tag>
        <tag>概念</tag>
        <tag>Sort</tag>
        <tag>堆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[float的精度和取值范围]]></title>
    <url>%2Fblog%2F2019%2F06%2F27%2Ffloat%E7%9A%84%E7%B2%BE%E5%BA%A6%E5%92%8C%E5%8F%96%E5%80%BC%E8%8C%83%E5%9B%B4%2F</url>
    <content type="text"><![CDATA[前言关于float的精度和取值范围这个问题，我查询了很多次，每次都是用完就忘了，等到再使用的时候还需要再次查询，关键是这个问题大家给出的结果并不都是一致的，我得从众多的资料当中选择出正确的观点，这还要额外花一些时间，所以我决定也总结一次，方便我以后拿来直接用了，如果能给大家带来帮助那就更好了。下面提到一些说法很多都是我个人的理解，如果大家有疑义，欢迎讨论。 精度限制首先考虑下为什么会产生精度问题，是因为存储数据的空间有限，以一个四字节整数int n;为例，一共有32位，取值范围是 [-2147483648‬, 21474836487] ，一共是4,294,967,296种可能，它的精度可以说是小数点后一位都不保留，也就是只有整数，换句话说变量n可以表示实数范围内的4,294,967,296个数值。 如果换成float类型呢？一个变量float f所能表示多少个数呢？实际上由于存储空间未发生变化，同样是4字节32位，那么float类型也只能表示，或者说精确表示4,294,967,296个数值（实际上由于一些特殊的规则，最终所表示的数字个数还要少），说到这里很多人可能会疑惑，因为他知道float可以表示比4,294,967,296大的数，同时也能表示小数，如果只有4,294,967,296种可能，那究竟是怎么做到的呢？ 这里也就开始提到精度了，整数很好理解，每个数字的间隔都是1，int类型所表示的4,294,967,296个数字都是等间距的，步长为1。而float也只能表示4,294,967,296个数字，同时要表示比int还大的范围，一个很直观的想法就是把间距拉大，这样范围就大了，但是float还要表示小数，像0.2、0.4这样的数字间距明显要小于1啊，想要存储小数貌似要把间距缩小，这就和前面矛盾了啊。 实际上float类型存储数据的间隔不是等间距的，而是在0的附近间距小，在远离0的位置间距大，为什么会这样，一会我们看一下float类型数据的存储规则就明白了，这里先来看一下int类型和float类型所表示数字的范围对比，这只是一个示意图。 1234//int [ * * * 0 * * * ]//float[ * * * * * * * * * * * 0 * * * * * * * * * * * ] 上面的示意图就是两者表示数字范围的差异，每个星号*就表示一个数字，float通过这种不等间距的分布，既扩大了范围也表示了小数，那么有没有问题呢？ 当然有问题，饭就这么多，人多了自然不够吃了，因为远离0的位置间距越来越大，当要表示间距中间的一个数字时，只能找它附近离它最近的一个可以表示的数字来代替，这就导致了精度问题，比如我给一个float类型变量分别赋值为 4294967244 和 4294967295 ，再次输出时都变成了 4294967296，因为超过了精度，所以只能找最接近的数字代替。 float存储方式这部分内容基本上各篇文章说的都一致，我也简单描述下，后面根据这部分的定义来推算一下float的精度和取值范围。 首先我们知道常用科学计数法是将所有的数字转换成(±)a.b x $10^c$ 的形式，其中a的范围是1到9共9个整数，b是小数点后的所有数字，c是10的指数。而计算机中存储的都是二进制数据，所以float存储的数字都要先转化成(±)a.b x $2^c$，由于二进制中最大的数字就是1，所以表示法可以写成(±)1.b x $2^c$的形式，float要想存储小数就只需要存储(±)，b和c就可以了。 float的存储正是将4字节32位划分为了3部分来分别存储正负号，小数部分和指数部分的： Sign（1位）：用来表示浮点数是正数还是负数，0表示正数，1表示负数。 Exponent（8位）：指数部分。即上文提到数字c，但是这里不是直接存储c，为了同时表示正负指数以及他们的大小顺序，这里实际存储的是c+127。 Mantissa（23位）：尾数部分。也就是上文中提到的数字b。 三部分在内存中的分布如下，用首字母代替类型 S E E E E E E E E M M M M M M M M M M M M M M M M M M M M M M 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 float存储示例以数字6.5为例，看一下这个数字是怎么存储在float变量中的： 先来看整数部分，模2求余可以得到二进制表示为110。 再来看小数部分，乘2取整可以得到二进制表示为.1（如果你不知道怎样求小数的二进制，请主动搜索一下）。 拼接在一起得到110.1然后写成类似于科学计数法的样子，得到1.101 x $2^2$。 从上面的公式中可以知道符号为正，尾数是101，指数是2。 符号为正，那么第一位填0，指数是2，加上偏移量127等于129，二进制表示为10000001，填到2-9位，剩下的尾数101填到尾数位上即可 S E E E E E E E E M M M M M M M M M M M M M M M M M M M M M M 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 内存中二进制数01000000 11010000 00000000 00000000表示的就是浮点数6.5 float范围明白了上面的原理就可求float类型的范围了，找到所能表示的最大值，然后将符号为置为1变成负数就是最小值，要想表示的值最大肯定是尾数最大并且指数最大，那么可以得到尾数为 0.1111111 11111111 11111111，指数为 11111111，但是指数全为1时有其特殊用途，所以指数最大为 11111110，指数减去127得到127，所以最大的数字就是1.1111111 1111111 11111111 x $2^{127}$，这个值为 340282346638528859811704183484516925440，通常表示成 3.4028235E38，那么float的范围就出来了： [-3.4028235E38, 3.4028235E38] float精度float 类型的数据精度取决于尾数，相信大家都知道这一点，但是精度怎么算我也是迷糊了好久，最近在不断尝试的过程中渐渐的明白了，首先是在不考虑指数的情况下23位尾数能表示的范围是[0, $2^{23}-1$]，实际上尾数位前面还隐含了一个”1”，所以应该是一共24位数字，所能表示的范围是[0, $2^{24}-1$]（因为隐含位默认是”1”，所以表示的数最小是1不是0，但是先不考虑0，后面会特殊介绍，这里只按一般值计算），看到这里我们知道这24位能表示的最大数字为$2^{24}$-1，换算成10进制就是16777215，那么[0, 16777215]都是能精确表示的，因为他们都能写成1.b x $2^c$的形式，只要配合调整指数c就可以了。 16777215 这个数字可以写成1.1111111 11111111 1111111 $2^{23}$，所以这个数可以精确表示，然后考虑更大的数16777216，因为正好是2的整数次幂，可以表示1.0000000 00000000 00000000 $2^{24}$，所以这个数也可以精确表示，在考虑更大的数字16777217，这个数字如果写成上面的表示方法应该是 1.0000000 00000000 00000000 1 * $2^{24}$，但是这时你会发现，小数点后尾数位已经是24位了，23位的存储空间已经无法精确存储，这时浮点数的精度问题也就是出现了。 看到这里发现 16777216 貌似是一个边界，超过这个数的数字开始不能精确表示了，那是不是所有大于16777216的数字都不能精确表示了呢？其实不是的，比如数字 33554432 就可以就可以精确表示成1.0000000 00000000 00000000 * $2^{25}$，说道这里结合上面提到的float的内存表示方式，我们可以得出大于 16777216 的数字（不超上限），只要可以表示成小于24个2的n次幂相加，并且每个n之间的差值小于24就能够精确表示。换句话来说所有大于 16777216 的合理数字，都是[0, 16777215]范围内的精确数字通过乘以$2^n$得到的，同理所有小于1的正数，也都是 [0, 16777215] 范围内的精确数字通过乘以$2^n$得到的，只不过n取负数就可以了。 16777216 已经被证实是一个边界，小于这个数的整数都可以精确表示，表示成科学技术法就是1.6777216 * $10^{7}$，从这里可以看出一共8位有效数字，由于最高位最大为1不能保证所有情况，所以最少能保证7位有效数字是准确的，这也就是常说float类型数据的精度。 float小数从上面的分析我们已经知道，float可表示超过16777216范围的数字是跳跃的，同时float所能表示的小数也都是跳跃的，这些小数也必须能写成2的n次幂相加才可以，比如0.5、0.25、0.125…以及这些数字的和，像5.2这样的数字使用float类型是没办法精确存储的，5.2的二进制表示为101.0011001100110011001100110011……最后的0011无限循环下去，但是float最多能存储23位尾数，那么计算机存储的5.2应该是101.001100110011001100110，也就是数字 5.19999980926513671875，计算机使用这个最接近5.2的数来表示5.2。关于小数的精度与刚才的分析是一致的，当第8位有效数字发生变化时，float可能已经无法察觉到这种变化了。 float特殊值我们知道float存储浮点数的形式是(±)1.b x $2^c$，因为尾数位前面一直是个1，所以无论b和c取什么样的值，都无法得到0，所以在float的表示方法中有一些特殊的约定，用来表示0已经其他的情况。 float的内存表示指数位数有8位，范围是[0, 255]，考虑偏移量实际的指数范围是[-127,128]，但实际情况下指数位表示一般数字时不允许同时取0或者同时取1，也就是指数位的实际范围是[-126,127]，而指数取-127和128时有其特殊含义，具体看下面表格： 符号位 指数位 尾数位 数值 含义 0 全为0 全为0 +0 正数0 1 全为0 全为0 +0 负数0 0 全为0 任意取值f $0.f * 2^{-126}$ 非标准值，尾数前改为0，提高了精度 1 全为0 任意取值f $-0.f * 2^{-126}$ 非标准值，尾数前改为0，提高了精度 0 全为1 全为0 +Infinity 正无穷大 1 全为1 全为0 -Infinity 负无穷大 0/1 全为1 不全为0 NaN 非数字，用来表示一些特殊情况 总结 float的精度是保证至少7位有效数字是准确的 float的取值范围[-3.4028235E38, 3.4028235E38]，精确范围是[-340282346638528859811704183484516925440, 340282346638528859811704183484516925440] 一个简单的测试float精度方法，C++代码中将数字赋值给float变量，如果给出警告warning C4305: “=”: 从“int”到“float”截断，则超出了float的精度范围，在我的测试中赋值为16777216及以下整数没有警告，赋值为16777217时给出了警告。]]></content>
      <categories>
        <category>concepts</category>
      </categories>
      <tags>
        <tag>float</tag>
        <tag>精度</tag>
        <tag>取值范围</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中使用count加条件统计]]></title>
    <url>%2Fblog%2F2019%2F06%2F03%2FMysql%E4%B8%AD%E4%BD%BF%E7%94%A8count%E5%8A%A0%E6%9D%A1%E4%BB%B6%E7%BB%9F%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[前言最近发现在处理Mysql问题时，count()函数频繁上镜，常常出现在分组统计的情景下，但是有时候并不是使用group by分好组就可以直接统计了，比如说一个常见的需求，统计每个班级男生所占的比例，这种情况一般会按照班级分组，但是分组内不但要统计班级的人数，还要统计男生的人数，也就是说统计是有条件的，之前确实没有考虑过怎样实心，后来查询了资料，总结在这里，方便日后查找使用。 Mysql中count()函数的一般用法是统计字段非空的记录数，所以可以利用这个特点来进行条件统计，注意这里如果字段是NULL就不会统计，但是false是会被统计到的，记住这一点，我们接下来看看几种常见的条件统计写法。 测试环境 Windows 10Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 准备工作 新建一个Mysql数据表a，包含id和num两个字段 12mysql&gt; create table a(id int, num int);Query OK, 0 rows affected (0.04 sec) 插入测试数据，为了看count()函数的效果，我们插入两个空数据 123mysql&gt; insert into a values (1,100),(2,200),(3,300),(4,300),(8,null),(9,null);Query OK, 6 rows affected (0.01 sec)Records: 6 Duplicates: 0 Warnings: 0 查询表a中的数据，与后面的统计做比较 123456789101112mysql&gt; select * from a;+----+------+| id | num |+----+------+| 1 | 100 || 2 | 200 || 3 | 300 || 4 | 300 || 8 | NULL || 9 | NULL |+----+------+6 rows in set (0.09 sec) 调用count()函数看效果，如果使用count(*)会查询出所有的记录数，但如果使用count(num)发现只有4条数据，num为NULL的记录并没有统计上 123456789101112131415mysql&gt; select count(*) from a;+----------+| count(*) |+----------+| 6 |+----------+1 row in set (0.03 sec)mysql&gt; select count(num) from a;+------------+| count(num) |+------------+| 4 |+------------+1 row in set (0.04 sec) 条件统计 count()函数中使用条件表达式加or null来实现，作用就是当条件不满足时，函数变成了count(null)不会统计数量 1234567mysql&gt; select count(num &gt; 200 or null) from a;+--------------------------+| count(num &gt; 200 or null) |+--------------------------+| 2 |+--------------------------+1 row in set (0.22 sec) count()函数中使用if表达式来实现，当条件满足是表达式的值为非空，条件不满足时表达式值为NULL; 1234567mysql&gt; select count(if(num &gt; 200, 1, null)) from a;+-------------------------------+| count(if(num &gt; 200, 1, null)) |+-------------------------------+| 2 |+-------------------------------+1 row in set (0.05 sec) count()函数中使用case when表达式来实现，当条件满足是表达式的结果为非空，条件不满足时无结果默认为NULL; 1234567mysql&gt; select count(case when num &gt; 200 then 1 end) from a;+---------------------------------------+| count(case when num &gt; 200 then 1 end) |+---------------------------------------+| 2 |+---------------------------------------+1 row in set (0.07 sec) 总结使用count()函数实现条件统计的基础是对于值为NULL的记录不计数，常用的有以下三种方式，假设统计num大于200的记录 select count(num &gt; 200 or null) from a; select count(if(num &gt; 200, 1, null)) from a select count(case when num &gt; 200 then 1 end) from a]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>count</tag>
        <tag>条件统计</tag>
        <tag>if</tag>
        <tag>casewhen</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb启动多进程程序并切换调试进程]]></title>
    <url>%2Fblog%2F2019%2F05%2F24%2Fgdb%E5%90%AF%E5%8A%A8%E5%A4%9A%E8%BF%9B%E7%A8%8B%E7%A8%8B%E5%BA%8F%E5%B9%B6%E5%88%87%E6%8D%A2%E8%B0%83%E8%AF%95%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言gdb是linux环境下调试C/C++程序的强大工具，但是最近在使用gdb启动一个多进程程序的时候总是意外退出，显示信息中包含Detaching after fork from child process 25377.这一句，而用attach命令附加到正在运行的进程却没有问题，因为需要调试启动逻辑的部分代码，所以必须使用gdb启动多进程程序，后来发现可以通过gdb的follow-fork-mode选项来切换进程，达到调试指定进程的目的。 使用方法1set follow-fork-mode [parent|child] 这个命令只要gdb启动程序之后，在运行r命令之前敲入即可，如果不设置默认是parent模式，如果调试的child模式，就需要手动切换，我遇到的问题就是，程序启动使用fork()函数创建出子进程之后就把父进程退出了，gdb默认调试parent进程，也跟着结束了，所以出现了之前所说的Detaching after fork from child process 25377.信息，接下来可以写个简单的例子测试一下。 测试环境123456789101112131415[albert@localhost#20:15:45#/home/albert/gdbtest]$cat /etc/issueCentOS release 6.3 (Final)Kernel \r on an \m[albert@localhost#20:16:25#/home/albert/gdbtest]$gdb --versionGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.[albert@localhost#20:16:36#/home/albert/gdbtest]$^C 具体例子 先写一个简单的多进程程序，模拟我遇到的问题，父进程退出，子进程继续工作 1234567891011121314151617181920212223242526#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;int main ()&#123; pid_t pid; //pid表示fork函数返回的值，会根据不同进程返回不同值 pid = fork(); if (pid &lt; 0) &#123; exit(-1); &#125; else if (pid == 0) // 子进程返回pid为0 &#123; unsigned int u = 0; while(true) &#123; ++u; sleep(1); &#125; &#125; else // 父进程返回pid为子进程的id，大于0 &#123; exit(1); &#125; return 0;&#125; 将代码编译成可执行程序 1[albert@localhost#20:04:31#/home/albert/gdbtest]$g++ multiprocess.cpp -o multiprocess gdb启动程序并运行，其中我只输入了r和q两个gdb命令，发现程序运行r之后输出几行信息就退出了 1234567891011121314151617181920212223242526[albert@localhost#20:04:45#/home/albert/gdbtest]$gdb ./multiprocessGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/gdbtest/multiprocess...(no debugging symbols found)...done.(gdb) rStarting program: /home/albert/gdbtest/multiprocesswarning: the debug information found in "ld-2.12.so.debug" does not match "ld-linux-x86-64.so.2" (CRC mismatch).warning: the debug information found in "ld-2.12.so.debug" does not match "ld-linux-x86-64.so.2" (CRC mismatch).warning: the debug information found in "libm-2.12.so.debug" does not match "libm.so.6" (CRC mismatch).warning: the debug information found in "libm-2.12.so.debug" does not match "libm.so.6" (CRC mismatch).warning: the debug information found in "libc-2.12.so.debug" does not match "libc.so.6" (CRC mismatch).warning: the debug information found in "libc-2.12.so.debug" does not match "libc.so.6" (CRC mismatch).Detaching after fork from child process 25377.Program exited with code 01.Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-18.el6_9.2.x86_64(gdb) q[albert@localhost#20:05:03#/home/albert/gdbtest] 使用set follow-fork-mode child命令调试子进程，在r之前输入即可，这次发现程序停在了[New process 27522]，此时就可以打断点调试了 12345678910111213141516171819202122232425262728[albert@localhost#20:23:12#/home/albert/gdbtest]$gdb ./multiprocessGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/gdbtest/multiprocess...(no debugging symbols found)...done.(gdb) set follow-fork-mode child(gdb) rStarting program: /home/albert/gdbtest/multiprocesswarning: the debug information found in "ld-2.12.so.debug" does not match "ld-linux-x86-64.so.2" (CRC mismatch).warning: the debug information found in "ld-2.12.so.debug" does not match "ld-linux-x86-64.so.2" (CRC mismatch).warning: the debug information found in "libm-2.12.so.debug" does not match "libm.so.6" (CRC mismatch).warning: the debug information found in "libm-2.12.so.debug" does not match "libm.so.6" (CRC mismatch).warning: the debug information found in "libc-2.12.so.debug" does not match "libc.so.6" (CRC mismatch).warning: the debug information found in "libc-2.12.so.debug" does not match "libc.so.6" (CRC mismatch).[New process 27522]^CProgram received signal SIGINT, Interrupt.[Switching to process 27522]0x00007ffff7354c30 in __nanosleep_nocancel () from /lib64/libc.so.6Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-18.el6_9.2.x86_64(gdb) b multiprocess.cpp:17 总结 gdb调试多进程程序时使用set follow-fork-mode [parent|child]命令 默认调试parent进程，想调试child进程，使用set follow-fork-mode child命令切换]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>linux</tag>
        <tag>gdb</tag>
        <tag>fork</tag>
        <tag>child</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql调优之Using filesort]]></title>
    <url>%2Fblog%2F2019%2F05%2F16%2FMysql%E8%B0%83%E4%BC%98%E2%80%94%E4%B9%8BUsing-filesort%2F</url>
    <content type="text"><![CDATA[前言在使用 explain 命令优化SQL语句的时候常常会在Extra列的描述中发现 Using filesort 选项，其实这个名字很容易造成误解，一开始我以为是“文件排序”的意思，进一步说可能就是使用了磁盘空间来进行排序，但是这个理解是错误的，Using filesort 真正含义其实只有 sort 这一个单词，和 file 没有什么关系，Mysql一般是通过内存进行排序的，不过，要是超过了配置中的限制，应该会生成临时表。 分析Using filesort 的含义很简单，就是使用了排序操作，出现这个选项的常见情况就是 Where 条件和 order by 子句作用在了不同的列上，这种情况还有优化的余地，有些场景由于数据量太小或者语句的简单性可能都不需要优化，既然说Using filesort是使用了排序的意思，那么是不是包含了 order by 子句的查询语句都会有这个选项呢？其实这个排序操作有时是可以避免的。 如果你想把一个表中的所有数据按照指定顺序输出，那么整个排序几乎是不可避免的，比如这个语句select * from a order by id，即使在id列上建立了索引，为了生成指定顺序的数据，那么整个数据的排序也是需要，不过个别时候这个排序还是可以省略的，比如id是该表的主键，并且是自增长的，数据本身就是有序的，那么直接返回数据就行了，相当于 order by id 这一部分被忽略了。 上面提到的常见情况，SQL语句通常写成这样select * from a where type = 5 order by id，这类语句一般会产生 Using filesort 这个选项，即使你在 type 和 id 上分别添加了索引。我们想一下它的工作过程，先根据type的索引从所有数据信息中挑选出满足 type = 5 条件的，然后根据id列的索引信息对挑选的数据进行排序，所以产生了Using filesort选项，想想怎样可以把后面排序的这个步骤省略掉？联合索引可以解决这个问题。 可以在 type, id 两列上建立一个联合索引，索引类型一般是 BTREE，根据Mysql索引的最左原则，可以知道一共建立了type_index和type_id_index两条索引，由于有了 type_id_index 这个联合索引，后面的排序步骤就可以省略了，在按照type = 5 条件挑选数据时，挂在type = 5 节点下的数据，其实按照id列的值也是有顺序的，我们只需要在挑选数据的同时，按照id从小到大的顺序挑选即可，最后得到的数据就是有序的，直接返回就行了，从这一点可以看出，“排序”操作并不是不存在了，只是隐含在了前面必要的步骤中，不需要单独操作了而已，下面举个简单例子，看看具体的效果。 测试环境 Windows 10Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 具体操作 先建立一个测试表格tb，一般为了加快查询速度，会在常用的字段上建立索引 12mysql&gt; create table tb(id int, type int, weight int, index t_index(type), index w_index(weight));Query OK, 0 rows affected (0.02 sec) 创建一个存储fill_test_data用来插入测试数据，创建完成调用一下 12345678910111213141516CREATE PROCEDURE `fill_test_data`()BEGIN DECLARE i int default 1; DECLARE w int default 100; DECLARE t int default 1; WHILE i &lt;= 100000 do insert into tb values(i, t, w); set i = i + 1; set w = (w + 10) % 1000; set t = (t + 1) % 10; END WHILE;ENDmysql&gt; call fill_test_data();Query OK, 1 row affected (25.36 sec) 查询数据，让 Where 条件和 order by 子句作用在不同的列上 1234567891011121314mysql&gt; select * from tb where type = 3 order by weight;+-------+------+--------+| id | type | weight |+-------+------+--------+| 193 | 3 | 20 || 293 | 3 | 20 || 393 | 3 | 20 |...| 99683 | 3 | 920 || 99783 | 3 | 920 || 99883 | 3 | 920 || 99983 | 3 | 920 |+-------+------+--------+10000 rows in set (2.22 sec) 使用 explain命令分析查询语句，就会发现Using filesort出现在了Extra条目中 123456789101112131415mysql&gt; explain select * from tb where type = 3 order by weight\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb partitions: NULL type: refpossible_keys: t_index key: t_index key_len: 5 ref: const rows: 17672 filtered: 100.00 Extra: Using index condition; Using filesort1 row in set, 1 warning (0.00 sec) 使用SQL命令给表tb的type列和id列添加联合索引 123mysql&gt; alter table tb add index tw_index(type, weight);Query OK, 0 rows affected (0.17 sec)Records: 0 Duplicates: 0 Warnings: 0 再次查询数据，看看与上一次的查询时间相比有没有变化 1234567891011121314mysql&gt; select * from tb where type = 3 order by weight;+-------+------+--------+| id | type | weight |+-------+------+--------+| 193 | 3 | 20 || 293 | 3 | 20 || 393 | 3 | 20 |...| 99683 | 3 | 920 || 99783 | 3 | 920 || 99883 | 3 | 920 || 99983 | 3 | 920 |+-------+------+--------+10000 rows in set (2.13 sec) 再次使用 explain命令分析查询语句，就会发现Using filesort选项已经消失了 123456789101112131415mysql&gt; explain select * from tb where type = 3 order by weight\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb partitions: NULL type: refpossible_keys: t_index,tw_index key: tw_index key_len: 5 ref: const rows: 17672 filtered: 100.00 Extra: Using index condition1 row in set, 1 warning (0.00 sec)]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>查询</tag>
        <tag>Usingfilesort</tag>
        <tag>排序</tag>
        <tag>调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下查看C/C++程序的堆栈信息]]></title>
    <url>%2Fblog%2F2019%2F05%2F08%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%9F%A5%E7%9C%8BC-C-%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%A0%86%E6%A0%88%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[前言经常在Windows上开发的工程师们可能已经习惯了图形化的调试界面，在源代码的编辑框上点击就可以添加断点，在调用堆栈的窗口就可以看到程序运行的堆栈信息，但是在 linux 环境下，面对命令行的天下，我们需要掌握一些命令，才能够查看C/C++程序的堆栈信息。 测试环境1234567[albert@localhost#13:58:34#/home/albert]$cat /etc/issueCentOS release 6.3 (Final)Kernel \r on an \m[albert@localhost#13:58:43#/home/albert]$g++ --versiong++ (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)Copyright ?? 2010 Free Software Foundation, Inc. 查看方法 使用gdb程序调试core文件，格式为 gdb test_proc core.proc_id 使用gdb程序附加到调试程序的进程上，格式为 gdb attach proc_id 使用pstack程序输出调试程序的堆栈信息，格式为 pstack proc_id 使用strace程序打印调试程序的运行信息，格式为 strace -p proc_id 具体实践 一般查看堆栈信息时常常面对的都是多线程的程序，所以我们也来写一个简单的多线程小程序，代码如下： 12345678910111213141516171819202122232425262728293031323334353637#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#include &lt;unistd.h&gt;static void* thread_proc(void* arg)&#123; unsigned int sum = 3; while(true) &#123; for (int idx = 0; idx &lt; 1000000000; ++idx) sum += idx; printf("thread sum = %u\n", sum); sleep(2); &#125; return 0;&#125;int main()&#123; pthread_t thread_id; pthread_create(&amp;thread_id, NULL, thread_proc, NULL); unsigned int sum = 0; while(true) &#123; for (int idx = 0; idx &lt; 1000000000; ++idx) sum += idx; printf("main sum = %u\n", sum); sleep(1); &#125; return 0;&#125; 编译程序并运行，程序开始不断的打印计算结果 1234567891011[albert@localhost#15:06:54#/home/albert/test/threadtest]$g++ threadtest.cpp -O0 -pthread -o threadtest[albert@localhost#15:08:27#/home/albert/test/threadtest]$./threadtestthread sum = 3051657987main sum = 3051657984thread sum = 1808348675main sum = 1808348672main sum = 565039360thread sum = 565039363main sum = 3616697344thread sum = 3616697347... 现在可以通过上面描述的方法来查看threadtest程序堆栈信息了，几乎所有的命令都需要进程id，所以我们可以再开一个终端先通过pidof命令来获得： 12[albert@localhost#15:39:35#/home/albert/test/threadtest]$pidof threadtest21473 gdb调试core文件 通过kill命令产生core文件 使用命令 kill -11 21473可以将正在运行的程序杀死，并且产生core文件core.21473，-11表示段错误信号，通常是访问了无效的内存导致 通过gcore命令产生core文件 使用命令 gcore 21473可以产生core文件core.21473，但是不会杀死程序，适用于调试线上程序，又不影响用户使用的情况，可以测试一下： 12345678910111213[albert@localhost#15:39:43#/home/albert/test/threadtest]$gcore 21473warning: the debug information found in "/usr/lib/debug//lib64/libm-2.12.so.debug" does not match "/lib64/libm.so.6" (CRC mismatch)warning: the debug information found in "/usr/lib/debug/lib64/libm-2.12.so.debug" does not match "/lib64/libm.so.6" (CRC mismatch)warning: the debug information found in "/usr/lib/debug//lib64/libpthread-2.12.so.debug" does not match "/lib64/libpthread.so.0" (CRC mismatch)warning: the debug information found in "/usr/lib/debug/lib64/libpthread-2.12.so.debug" does not match "/lib64/libpthread.so.0" (CRC mismatch)[New LWP 21474][Thread debugging using libthread_db enabled]warning: the debug information found in "/usr/lib/debug//lib64/libc-2.12.so.debug" does not match "/lib64/libc.so.6" (CRC mismatch)warning: the debug information found in "/usr/lib/debug/lib64/libc-2.12.so.debug" does not match "/lib64/libc.so.6" (CRC mismatch)warning: the debug information found in "/usr/lib/debug//lib64/ld-2.12.so.debug" does not match "/lib64/ld-linux-x86-64.so.2" (CRC mismatch)warning: the debug information found in "/usr/lib/debug/lib64/ld-2.12.so.debug" does not match "/lib64/ld-linux-x86-64.so.2" (CRC mismatch)0x00000000004006eb in main ()Saved corefile core.21473 然后使用gdb调试core文件： 123456789101112131415161718192021222324252627[albert@localhost#15:47:13#/home/albert/test/threadtest]$gdb threadtest core.21473GNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/test/threadtest/threadtest...(no debugging symbols found)...done.[New Thread 21474][New Thread 21473]Missing separate debuginfo forTry: yum --enablerepo='*-debug*' install /usr/lib/debug/.build-id/80/1b9608daa2cd5f7035ad415e9c7dd06ebdb0a2Reading symbols from /usr/lib64/libstdc++.so.6...(no debugging symbols found)...done.Loaded symbols for /usr/lib64/libstdc++.so.6Reading symbols from /lib64/libm.so.6......省略无关信息(no debugging symbols found)...done.Loaded symbols for /lib64/ld-linux-x86-64.so.2Core was generated by `./threadtest'.#0 0x0000000000400691 in thread_proc(void*) ()Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-18.el6_9.2.x86_64(gdb) 显示所有线程信息，可以使用gdb命令thread apply all bt： 123456789(gdb) thread apply all btThread 2 (Thread 0x7f1b4e1d2720 (LWP 21473)):#0 0x00000000004006eb in main ()Thread 1 (Thread 0x7f1b4d270700 (LWP 21474)):#0 0x0000000000400691 in thread_proc(void*) ()#1 0x00007f1b4d60caa1 in start_thread () from /lib64/libpthread.so.0#2 0x00007f1b4d359bcd in clone () from /lib64/libc.so.6 gdb附加到进程可以通过 gdb attach pid 直接附加到正在运行的程序上，然后查看线程信息thread apply all bt：123456789101112131415161718192021222324252627282930313233343536[albert@localhost#15:54:59#/home/albert/test/threadtest]$gdb attach 21473GNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...attach: 没有那个文件或目录.Attaching to process 21473Reading symbols from /home/albert/test/threadtest/threadtest...(no debugging symbols found)...done.Reading symbols from /usr/lib64/libstdc++.so.6...(no debugging symbols found)...done.Loaded symbols for /usr/lib64/libstdc++.so.6Reading symbols from /lib64/libm.so.6......省略无关信息(no debugging symbols found)...done.Loaded symbols for /lib64/ld-linux-x86-64.so.20x00007f1b4d31dc4d in nanosleep () from /lib64/libc.so.6Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-18.el6_9.2.x86_64(gdb) thread apply all btThread 2 (Thread 0x7f1b4d270700 (LWP 21474)):#0 0x00007f1b4d31dc4d in nanosleep () from /lib64/libc.so.6#1 0x00007f1b4d31dac0 in sleep () from /lib64/libc.so.6#2 0x00000000004006b6 in thread_proc(void*) ()#3 0x00007f1b4d60caa1 in start_thread () from /lib64/libpthread.so.0#4 0x00007f1b4d359bcd in clone () from /lib64/libc.so.6Thread 1 (Thread 0x7f1b4e1d2720 (LWP 21473)):#0 0x00007f1b4d31dc4d in nanosleep () from /lib64/libc.so.6#1 0x00007f1b4d31dac0 in sleep () from /lib64/libc.so.6#2 0x0000000000400721 in main () pstack输出堆栈信息如果不需要调试，只想查看运行程序当前的堆栈信息，可以使用pstack命令，输出信息很简洁：123456789[albert@localhost#15:57:53#/home/albert/test/threadtest]$pstack 21473Thread 2 (Thread 0x7f1b4d270700 (LWP 21474)):#0 0x0000000000400683 in thread_proc(void*) ()#1 0x00007f1b4d60caa1 in start_thread () from /lib64/libpthread.so.0#2 0x00007f1b4d359bcd in clone () from /lib64/libc.so.6Thread 1 (Thread 0x7f1b4e1d2720 (LWP 21473)):#0 0x00007f1b4d31dc4d in nanosleep () from /lib64/libc.so.6#1 0x00007f1b4d31dac0 in sleep () from /lib64/libc.so.6#2 0x0000000000400721 in main () strace打印程序运行情况strace输出的不是堆栈信息，而是类似于程序的运行步骤，具体信息如下：123456789101112131415161718[albert@localhost#15:57:56#/home/albert/test/threadtest]$strace -p 21473Process 21473 attachedwrite(1, "main sum = 2580918016\n", 22) = 22rt_sigprocmask(SIG_BLOCK, [CHLD], [], 8) = 0rt_sigaction(SIGCHLD, NULL, &#123;SIG_DFL, [], 0&#125;, 8) = 0rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0nanosleep(&#123;1, 0&#125;, 0x7fff56a49c50) = 0write(1, "main sum = 1337608704\n", 22) = 22rt_sigprocmask(SIG_BLOCK, [CHLD], [], 8) = 0rt_sigaction(SIGCHLD, NULL, &#123;SIG_DFL, [], 0&#125;, 8) = 0rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0nanosleep(&#123;1, 0&#125;, 0x7fff56a49c50) = 0write(1, "main sum = 94299392\n", 20) = 20rt_sigprocmask(SIG_BLOCK, [CHLD], [], 8) = 0rt_sigaction(SIGCHLD, NULL, &#123;SIG_DFL, [], 0&#125;, 8) = 0rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0nanosleep(&#123;1, 0&#125;, 0x7fff56a49c50) = 0^CProcess 21473 detached 总结 在解决实际问题的过程中，上述几种方法可以结合使用，选取合适的使用方法，比如面对程序突然崩溃，那么gdb proc core就是调试的首选方法。 如果只是想简单的查看堆栈信息，可以使用pstack pid这种方式，免去了生成巨大core文件的麻烦。 如果还想查看运行逻辑中的变量信息，那么gdb使我们可以帮助我们动态调试程序，查看一些程序运行时的状态。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>linux</tag>
        <tag>gdb</tag>
        <tag>strace</tag>
        <tag>pstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python利用requests模块实现代理访问网络]]></title>
    <url>%2Fblog%2F2019%2F05%2F05%2FPython%E5%88%A9%E7%94%A8requests%E6%A8%A1%E5%9D%97%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%90%86%E8%AE%BF%E9%97%AE%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[前言代理相信很多人都听过，即使没有自己感受到，在无形之中可能也使用过，网络代理作为一项技术，在访问互联网时被广泛使用，那是因为使用代理有着诸多好处。 使用代理IP能够突破自身的访问限制，不要把突破限制看成是坏事情，有时后恰恰是为了网络安全才使用了代理，比如内网的一台服务器只针对特定的IP提供访问权限，这时如果给内部人员分配指定的代理就可以进行访问，不比对所有的IP地址都开放，代理IP还可以进行自主管理。 使用代理IP还提高访问速度，通常代理IP服务器都配置了一个较大的硬盘缓冲区，当缓冲区中保存有用户的请求信息时，则直接由缓冲区中取出信息，返回给用户，以提高访问速度。 测试环境12PS E:\&gt; python --versionPython 3.6.7 代码实现其实在Python 3中利用requests可以很方便的使用代理访问网络，比如下面这个简单的get方法：1requests.get(target_url, proxies=proxy_data) 其中需要注意的就是 proxies 参数的值，这里换成可以代理的ip就可以了，网上流传着众多的代理IP，只要可用就可以拿来代理IP访问，不过这些免费的IP失效性非常差，常常过几分钟就失效了，下面就给出一个完整的例子，检测代理IP是否可用： 1234567891011121314151617181920212223242526272829303132import requeststest_ip = '116.209.56.118'test_port = '9999'def test_proxy_request(ip, port): # 代理IP地址 proxy_data = &#123; 'http': 'http://' + ip + ':' + port, 'https': 'http://' + ip + ':' + port, &#125; # 客户端说明 head_data = &#123; 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0', 'Connection': 'keep-alive' &#125; try: # 该返回当前的IP地址，http://icanhazip.com提供返回当前外网IP的服务 response = requests.get('http://icanhazip.com', headers=head_data, proxies=proxy_data) outer_ip = response.text.strip().replace('\n', '') return outer_ip == ip except: return Falseif __name__ == '__main__': test_result = test_proxy_request(test_ip, test_port) if test_result: print("IP代理成功 ==&gt; &#123;0&#125;:&#123;1&#125;".format(test_ip, test_port)) else: print("IP代理失败 ==&gt; &#123;0&#125;:&#123;1&#125;".format(test_ip, test_port)) 需要注意，其中只有这一句requests.get(&#39;http://icanhazip.com&#39;, headers=head_data, proxies=proxy_data)是代理的重点。 测试结果 IP代理成功 ==&gt; 116.209.56.118:9999]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>IP</tag>
        <tag>Python</tag>
        <tag>requests</tag>
        <tag>网络代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中explain命令简析]]></title>
    <url>%2Fblog%2F2019%2F04%2F27%2FMysql%E4%B8%ADexplain%E5%91%BD%E4%BB%A4%E7%AE%80%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言之前总结了Mysql慢查询日志的开启与配置方法，通过分析慢查询日志可以锁定执行效率差的SQL，但是这仅仅是发现了需要优化的部分，还要分析执行缓慢的原因，这时候就可以使用EXPLAIN命令去分析，所执行的操作究竟慢在哪里，是不是可以通过加索引或者改变查询方法来解决。 通过查询资料发现除了EXPLAIN命令，还有一个DESCRIBE命令，看起来很陌生是不是，但是如果写出简写desc应该很多人的就熟悉了，这不是查询表结构的时候常用的命令吗？实际上以上三个命令在mysql中是等价的，不过在使用时有些习惯性的偏向，通常使用 EXPLAIN 来分析SQL语句的执行缓慢的问题，而使用 DESCRIBE 或者 desc 来查看表的结构，就类似于惯用法，知道就好。 测试环境 Windows 10Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. EXPLAIN 的使用关于 EXPLAIN 使用其实很简单，就是在正常的执行语句之前加一个explain 就可以了，不过这里也存在一个疑问，就是发现很多篇文章，提到下面这种说法： explain 只能解释select查询，并不会对存储过程、insert、update、delete或其他语句做解释 但是我查阅了官方文档发现，EXPLAIN 后面可以跟 SELECT、 DELETE、 INSERT、 REPLACE、和 UPDATE语句，另外之前使用的 EXPLAIN EXTENDED 选项现在也默认开启，EXTENDED 关键字后续会在 Mysql 8.0 版本删除，应该是版本问题导致了explain语句使用的差异，所以请记住在使用新版本的Mysql时，需要分析语句执行情况的，只需要在语句前面添加一个 explain关键字即可。 不过在分析 select 语句时，explain命令会给出额外的提示信息，帮助我们优化查询语句，这也是我们需要学习的重点，先来简单看一下使用方法： 普通的查询语句 123456789mysql&gt; select * from a;+----+-----+| id | num |+----+-----+| 1 | 100 || 2 | 200 || 3 | 300 |+----+-----+3 rows in set (0.05 sec) 使用 EXPLAIN 来分析普通的查询语句 1234567mysql&gt; explain select * from a;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+| 1 | SIMPLE | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | NULL |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+1 row in set (0.04 sec) 通过上面的例子可以很清楚的知道 EXPLAIN 命令的使用方法，使用了 EXPLAIN 关键之后会生成一个分析结果的表格，该表格有id、select_type、table、partitions、type、possible_keys、key、key_len、ref、rows、filtered、Extra一共12列，而这12列中的内容代表的含义是我们学习的重点，也是我们进行优化的依据，这个结果集可能包含多行，其中每一行都是关于一个表的查询信息，可以针对于具体的表查询优化。 本来想每种情况后面紧跟一个例子的，但是发现这样会造成重点内容分散，不利于整体把握，所以还是先把各列可能的取值说清楚，然后在文末针对于上文的取值给出例子，如果看描述就能明白就可以省略例子的内容，否则可以对照着例子的写法理解一下, [eg：&lt;id-1&gt;]表示参考后面的例子&lt;id-1&gt;，想对照的话搜索即可。 EXPLAIN 各列的可能取值idid 列的取值通常是一组数字，表示select查询的序号，也有可能是一个NULL： 取值 含义 例子编号 id数字相同 优先级相同，从上往下执行 [eg：&lt;id-1&gt;] id数字不同 数字越大优先级越高，越先执行，比如包含子查询的语句，内部查询优先执行 [eg：&lt;id-2&gt;] id值为NULL 通常是使用了union，表示该行是一个结果集，不需要使用它来进行查询 [eg：&lt;id-2&gt;] select_typeselect_type 列表示查询的类型，主要是用于区分普通查询、联合查询、子查询等复杂的情况： 取值 含义 例子编号 SIMPLE 简单的查询语句，查询中不包括UNION操作和子查询 [eg：&lt;id-1&gt;] PRIMARY 在复杂查询中处于最外层的查询 [eg：&lt;id-2&gt;] UNION 查询语句中处于 UNION 关键字之后的查询 [eg：&lt;id-2&gt;] DEPENDENT UNION 查询语句中处于 UNION 关键字之后的查询，需要依赖于外部查询 [eg：`&lt;id-&gt;`]* UNION RESULT 表示 UNION 操作之后的结果，本身并不需要参与查询，通常该记录id字段为 NULL [eg：&lt;id-2&gt;] SUBQUERY 在子查询中的第一个查询 [eg：`&lt;id-&gt;`]* DEPENDENT SUBQUERY 在子查询中的第一个查询，需要依赖于外部查询 [eg：`&lt;id-&gt;`]* DERIVED 在 FROM 列表中包含的子查询 [eg：&lt;id-4&gt;] MATERIALIZED 物化子查询 [eg：&lt;id-5&gt;] UNCACHEABLE SUBQUERY 一个结果不能被缓存并且对于外部查询的每一行都需要重新评估自身的子查询 [eg：`&lt;id-&gt;`]* UNCACHEABLE UNION 查询语句中处于 UNION 关键字之后的子查询，并且其结果属于UNCACHEABLE SUBQUERY类型 [eg：`&lt;id-&gt;`]* tabletable 列表示查询所引用到的表名，如果查询中使用了别名，那么会显示别名，此外还有一些其他类型的引用： 取值 含义 例子编号 表名、别名 查询时引用了这个表 [eg：&lt;id-1&gt;] &lt;unionM,N&gt; 查询时引用了由id为M和N的两个查询的结果集构成的临时结果集 [eg：&lt;id-2&gt;] &lt;derivedN&gt; 查询时引用了id为N的查询形成的结果集 [eg：&lt;id-4&gt;] &lt;subqueryN&gt; 查询时引用了id为N的物化子查询形成的结果集 [eg：&lt;id-5&gt;] partitionspartitions 列表示查询结果集所涉及到的分区，值为 NULL 时表示该表并未分区： 取值 含义 例子编号 分区名 查询结果集引用到了这个分区 [eg：&lt;id-6&gt;] NULL 该表格并未分区，或者结果集中数据不再分区中 [eg：&lt;id-1&gt;] typetype 列表示访问类型，也就是找到所需数据所能使用的最好方式，取值类型很多，在下表中从上到下效果越来越差： 取值 含义 例子编号 NULL 查询经过优化执行时不用访问表数据，可能通过索引就搞定了，或者根本没有数据 [eg：&lt;id-8&gt;] system 在MyISAM类型的表中只有一行数据时出现，如果在 Innodb 类型表中只有一行数据通常显示 ALL [eg：&lt;id-9&gt;] const 表格使用了唯一索引或者主键，并且将其作为判定相等的筛选条件，得到一条记录 [eg：&lt;id-10&gt;] eq_ref 连接查询时，驱动表的每一条记录的条件列，与后面连接表的主键或唯一索引判定相等，后表采用的连接方式 [eg：&lt;id-11&gt;] ref 连接查询时，驱动表的每一条记录的条件列，与后面连接表的索引列判定相等，后表采用的连接方式，索引列数据不要求唯一，不连接表时就是查索引列等于一个具体的值 [eg：&lt;id-7&gt;] ref_or_null 与 ref 基本一致，另外包含查询索引列为 NULL 的记录 [eg：&lt;id-12&gt;] fulltext 包含全文索引的表的查询方式，全文索引的优先级要高于普通索引 [eg：`&lt;id-&gt;`]* index_merge 至少用到了两个索引，并且用到了索引合并优化 [eg：`&lt;id-&gt;`]* unique_subquery where条件in形式的子查询子查询返回唯一结果时，等价于将类型为 eq_ref 的查询作为子查询 [eg：`&lt;id-&gt;`]* index_subquery where条件in形式的子查询引用了非唯一索引，等价于将类型为 ref 的查询作为子查询 [eg：`&lt;id-&gt;`]* range 对于表的索引列使用范围判定的查询 [eg：&lt;id-13&gt;] index 除了查找索引树之外，与 ALL 选项基本一致，通常由于索引较小查询会快一点 [eg：&lt;id-14&gt;] ALL 完整浏览整个表格，查找符合条件的结果，属于最差的访问方式 [eg：&lt;id-1&gt;] possible_keyspossible_keys 列表示查询所需数据过程可能用到的索引名，具体是否使用还要依赖于查询过程中表的连接顺序，该值为 NULL 时表示无索引可用，此时需要考虑对表进行优化来改善查询结果情况了。 取值 含义 例子编号 索引名 查询时可能用到的索引名，是否使用取决于查询连接顺序 [eg：&lt;id-7&gt;] NULL 该查询没有可用索引，需要考虑优化 [eg：&lt;id-1&gt;] keykey 列表示查询所需数据过程确实用到的索引名，该值为 NULL 时表示无索引可用，此时也需要考虑对表进行优化。 取值 含义 例子编号 索引名 查询时确实用到的索引名 [eg：&lt;id-7&gt;] NULL 查询时没有可用索引，需考虑优化 [eg：&lt;id-1&gt;] key_lenkey_len 列表示查询所需数据过程用到的索引长度，该值为 NULL 时表示没有使用索引，由于存储格式的不同，对于可以为 NULL 的列储存索引所需空间要比不能为 NULL 列的大一个字节。 取值 含义 例子编号 索引长度 查询时确实用到的索引长度 [eg：&lt;id-7&gt;] NULL 没有使用到索引 [eg：&lt;id-1&gt;] refkey_len 列表示查询时使用常数或者某一列来和索引列比较，有时会显示 func，表示使用了一些函数的结果与索引比较，值为 NULL 时表示没用到索引比较 取值 含义 例子编号 引用列名 查询时与索引比较的列名，形式可能为&lt;subquery2&gt;.id，表示引用了子查询结果中的id列 [eg：&lt;id-5&gt;] const 查询时与索引比较的为常数 [eg：&lt;id-10&gt;] func 查询时与索引比较的一些函数结果 [eg：`&lt;id-&gt;`]* NULL 不是上述几种情况，可能没有使用索引比较 [eg：&lt;id-1&gt;] rowsrows 列表示查询符合条件的结果时所要检查的数据行数，在 InnoDB 类型的表中，这个值是一个估计值，可用来参考并不精确，值为 NULL 时表示表中无数据，或者无法找到匹配行，比如查找一条主键中不包含的数据。 取值 含义 例子编号 数字 查询时所要检查的数据行数 [eg：&lt;id-3&gt;] NULL 没有数据或者不需要检测 [eg：&lt;id-1&gt;] filteredfiltered 列表示通过筛选条件的记录数占可能参与检查的记录数，是一个估计值，该值与 rows 的乘积大概就是结果集中的记录数： 取值 含义 例子编号 数字 通过筛选条件的记录数占可能参与检查的记录数，最大为 100.00 [eg：&lt;id-3&gt;] ExtraExtra 列表示Mysql处理查询所使用的额外信息，类型很多，其中一些情况是需要进行优化的信号，对于SQL分析很有帮助： 取值 含义 例子编号 Child of &#39;tbl_name&#39; pushed join@1 当表被当做另一个表’tbl_name’的子表能被存放在 NDB 内核的时候，该值只出现在存储选项被开启的 NDB 集群上 - const row not found 当一个系统表没有数据可查的时候 - Deleting all rows 对于 DELETE 操作， MyISAM 引擎支持一个可以简单快速删除表数据的方法，如果使用了整个优化则显示此选项 - Distinct 查询时使用了 distinct 关键字，当查找到一个第一个匹配值后，相同匹配就不再搜索了 - const 当一个系统表没有数据可查的时候 - FirstMatch(tbl_name) 当 semi-join FirstMatch 访问简化策略被使用时候， 通常出现在 Where的 in 子句中，找到一个值后，后面相同值不再匹配出现 - Full scan on NULL key 当优化器不能使用索引查找访问方法时，将会显示该值，表示将子查询作为一种后备策略 - Impossible HAVING 当 HAVING 子句的条件总是不成立，无法匹配出任何数据 [eg：&lt;id-23&gt;] Impossible WHERE 当 WHERE 子句的条件总是不成立，无法匹配出任何数据 [eg：&lt;id-22&gt;] Impossible WHERE noticed after reading const tables 在读取const表和system表时，WHERE 子句的条件总是不成立 - LooseScan(m..n) 当 semi-join LooseScan 策略被使用的时候. m 和 n 是索引的编号 - No matching min/max row 在查询中包括系统函数，但是通过条件查询无法匹配出数据的时候， 比如SELECT MIN(...) FROM ... WHERE CONDITION - no matching row in const table 当连表查询时有一个空表或者没有匹配唯一索引的数据时，会给出此提示 [eg：&lt;id-18&gt;] No tables used 当查询中没有 FROM 子句或者只有 FROM DUAL子句时 [eg：&lt;id-20&gt;] Not exists 发生在左外连接的优化，当要求右侧表字段为空时，如果查找到一条不为空匹配，则停止查找匹配这项记录， 比如 SELECT * FROM t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t2.id IS NULL - Plan isn&#39;t ready yet 执行命令 EXPLAIN FOR CONNECTION 时，优化器在命名连接中还没有完成为语句执行创建执行计划 - Range checked for each record(index map: N) 当没有好的默认索引可使用时，但当我们可以将以前表中的所有列都视为常量时，可能会使用某些索引就是这种情况 - Scanned N databases 表示在执行对INFORMATION_SCHEMA表的查询时，服务器执行了多少次目录扫描，数字可以是0,1或者任何整数 - Select tables optimized away 优化器发现只有一行，并且通过索引直接皆可以获得想要的数据，而不需要真正访问表数据，比如在索引列使用聚合函数 [eg：&lt;id-16&gt;] Skip_open_table 对于 INFORMATION_SCHEMA 表的查询，不需要打开表，只需要浏览目录就可以完成查询 - Open_frm_only 对于 INFORMATION_SCHEMA 表的查询，需要打开 .frm 文件完成查询 - Open_full_table 对于 INFORMATION_SCHEMA 表的查询，需要打开 .frm, .MYD, .MYI 文件完成查询 - Start temporary,End temporary 表示使用临时表用于 semi-join Duplicate Weedout 策略 [eg：&lt;id-15&gt;] unique row not found 当一个拥有 UNIQUE 索引或者 PRIMARY 索引的表没有查到满足条件数据时 - Using filesort 无法仅通过引用索引就完成排序，需要一个额外的阶段来进行外部排序，并且按排序结果取回记录 [eg：&lt;id-17&gt;] Using index 只通过索引排序就可以取得排序后的数据，无需做额外的搜索真实记录数据的工作 [eg：&lt;id-7&gt;] Using index condition 首先通过访问索引元组的方式来读取表格，除非必要时会通过索引索引信息延迟读取整个表格数据 - Using index for group-by 索引用于处理包含 GROUP BY 和 DISTINCT 的查询，由于重复项会被快速跳过。所以非常高效 - Using join buffer (Block Nested Loop) 连接访问之前表格数据被部分读入连接缓存区，然后使用缓存中的行与当前表进行连接，括号内容为使用算法 [eg：&lt;id-1&gt;] Using join buffer (Batched Key Access) 连接访问之前表格数据被部分读入连接缓存区，然后使用缓存中的行与当前表进行连接，括号内容为使用算法 - Using MRR 表格数据会通过 Multi-Range Read 优化策略来读取 - Using sort_union(...), Using union(...), Using intersect(...) 针对于 index_merge 选项，表明索引浏览被合并的特定算法 - Using temporary 需要创建一个临时表来存储结果，通常出现在包含了作用在不同列的上的 GROUP BY 子句和 ORDER BY子句 [eg：&lt;id-2&gt;] Using where 当查询使用了 WHERE 子句来过滤结果发送给客户端的时候 [eg：&lt;id-3&gt;] Using where with pushed condition 仅适用于 NDB 类型表，它意味着NDB集群正在使用 “条件存储”优化选项来提高接近于非索引列和常量之间直接比较的效率。 - Zero limit 当查询语句包含 LIMIT 0子句并不能查到任何记录的时候 [eg：&lt;id-19&gt;] EXPLAIN 各列的可能取值对应的例子建表操作(1为了展示id取值的不同先创建 a、b两个表，然后插入测试数据，由于是测试的开始，我们分别查看表结构和数据，之后为了减少篇幅，只给出命令，不再查询表结构和数据，接着我们开始测试： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051mysql&gt; create table a(id int, num int);Query OK, 0 rows affected (0.04 sec)mysql&gt; insert into a values(1, 100),(2,200),(3,300);Query OK, 3 rows affected (0.01 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; desc a;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.02 sec)mysql&gt; select * from a;+----+-----+| id | num |+----+-----+| 1 | 100 || 2 | 200 || 3 | 300 |+----+-----+3 rows in set (0.02 sec)mysql&gt; create table b(id int, num int);Query OK, 0 rows affected (0.03 sec)mysql&gt; insert into b values(1, 100),(2,200),(4,400);Query OK, 3 rows affected (0.00 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; desc b;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.03 sec)mysql&gt; select * from b;+----+-----+| id | num |+----+-----+| 1 | 100 || 2 | 200 || 4 | 400 |+----+-----+3 rows in set (0.03 sec) &lt;id-1&gt;12345678mysql&gt; explain select * from a, b;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+| 1 | SIMPLE | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | NULL || 1 | SIMPLE | b | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | Using join buffer (Block Nested Loop) |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+2 rows in set (0.05 sec) &lt;id-2&gt;123456789mysql&gt; explain select * from a union select * from b;+------+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+------+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+| 1 | PRIMARY | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | NULL || 2 | UNION | b | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | NULL || NULL | UNION RESULT | &lt;union1,2&gt; | NULL | ALL | NULL | NULL | NULL | NULL | NULL | NULL | Using temporary |+------+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+3 rows in set (0.05 sec) &lt;id-3&gt;12345678mysql&gt; explain select id from a where id = (select id from b where num = 100);+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| 1 | PRIMARY | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 33.33 | Using where || 2 | SUBQUERY | b | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 33.33 | Using where |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+2 rows in set (0.06 sec) &lt;id-4&gt;123456789101112131415161718192021222324252627282930313233mysql&gt; select @@version;+-----------+| @@version |+-----------+| 5.6.33 |+-----------+1 row in set (0.05 sec)mysql&gt; explain select num from (select * from a) t where t.id &gt; 1;+----+-------------+------------+------+---------------+------+---------+------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+------------+------+---------------+------+---------+------+------+-------------+| 1 | PRIMARY | &lt;derived2&gt; | ALL | NULL | NULL | NULL | NULL | 3 | Using where || 2 | DERIVED | a | ALL | NULL | NULL | NULL | NULL | 3 | NULL |+----+-------------+------------+------+---------------+------+---------+------+------+-------------+2 rows in set (0.06 sec)-- 很神奇的是我在5.7版本操作了半天也没出现，内部进行了优化，相同的语句操作如下：mysql&gt; select @@version;+------------+| @@version |+------------+| 5.7.21-log |+------------+1 row in set (0.05 sec)mysql&gt; explain select num from (select * from a) t where t.id &gt; 1;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| 1 | SIMPLE | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 33.33 | Using where |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+1 row in set (0.05 sec) 建表操作(2新建两个带索引的表格 c 和 d，其中表格c带有普通索引，表格d带有主键，这两个表格会参与后面用作展示的例子： 12345678910111213mysql&gt; create table c(id int, num int, key idindex(id));Query OK, 0 rows affected (0.21 sec)mysql&gt; insert into c values(1,103),(2,203),(6,603);Query OK, 3 rows affected (0.05 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; create table d(id int, num int, primary key(id));Query OK, 0 rows affected (0.14 sec)mysql&gt; insert into d values(1,104),(2,204),(6,504);Query OK, 3 rows affected (0.11 sec)Records: 3 Duplicates: 0 Warnings: 0 &lt;id-5&gt;123456789mysql&gt; explain select id from d where id in (select id from a);+----+--------------+-------------+------------+--------+---------------+---------+---------+----------------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+--------------+-------------+------------+--------+---------------+---------+---------+----------------+------+----------+-------------+| 1 | SIMPLE | &lt;subquery2&gt; | NULL | ALL | NULL | NULL | NULL | NULL | NULL | 100.00 | Using where || 1 | SIMPLE | d | NULL | eq_ref | PRIMARY | PRIMARY | 4 | &lt;subquery2&gt;.id | 1 | 100.00 | Using index || 2 | MATERIALIZED | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | NULL |+----+--------------+-------------+------------+--------+---------------+---------+---------+----------------+------+----------+-------------+3 rows in set (0.05 sec) 建表操作(3为了测试 partitions 字段的取值，创建表格 p，其实就是创建了一个带有分区的表，这个表格会参与后面用作展示的例子： 123456mysql&gt; create table p(id int, num int) partition by range(id)(partition p0 values less than(3), partition p1 values less than(6));Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into p values(1, 111),(2,222),(4,444),(5,555);Query OK, 4 rows affected (0.01 sec)Records: 4 Duplicates: 0 Warnings: 0 &lt;id-6&gt;1234567mysql&gt; explain select * from p where id &lt; 5;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| 1 | SIMPLE | p | p0,p1 | ALL | NULL | NULL | NULL | NULL | 4 | 33.33 | Using where |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+1 row in set (0.05 sec) &lt;id-7&gt;1234567mysql&gt; explain select id from c where id = 1;+----+-------------+-------+------------+------+---------------+---------+---------+-------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+---------+---------+-------+------+----------+-------------+| 1 | SIMPLE | c | NULL | ref | idindex | idindex | 5 | const | 1 | 100.00 | Using index |+----+-------------+-------+------------+------+---------------+---------+---------+-------+------+----------+-------------+1 row in set (0.06 sec) 建表操作(4为了测试 type 字段的取值，有时需要特定的数据引擎才可以，所以创建了以 MyISAM引擎类型的表格 m，然后进行一些测试： 12mysql&gt; create table m(id int, num int)engine=myisam;Query OK, 0 rows affected (0.02 sec) &lt;id-8&gt;1234567mysql&gt; explain select * from m;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | no matching row in const table |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+1 row in set (0.03 sec) &lt;id-9&gt;12345678910mysql&gt; insert into m values(1,1001);Query OK, 1 row affected (0.00 sec)mysql&gt; explain select * from m;+----+-------------+-------+------------+--------+---------------+------+---------+------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+--------+---------------+------+---------+------+------+----------+-------+| 1 | SIMPLE | m | NULL | system | NULL | NULL | NULL | NULL | 1 | 100.00 | NULL |+----+-------------+-------+------------+--------+---------------+------+---------+------+------+----------+-------+1 row in set (0.04 sec) &lt;id-10&gt;1234567mysql&gt; explain select id from d where id = 1;+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------------+| 1 | SIMPLE | d | NULL | const | PRIMARY | PRIMARY | 4 | const | 1 | 100.00 | Using index |+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------------+1 row in set (0.04 sec) &lt;id-11&gt;12345678mysql&gt; explain select a.id from a, d where a.id = d.id;+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+-------------+| 1 | SIMPLE | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | Using where || 1 | SIMPLE | d | NULL | eq_ref | PRIMARY | PRIMARY | 4 | sqltest2.a.id | 1 | 100.00 | Using index |+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+-------------+2 rows in set (0.05 sec) &lt;id-12&gt;1234567mysql&gt; explain select id from c where id = 1 or id is null;+----+-------------+-------+------------+-------------+---------------+---------+---------+-------+------+----------+--------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+-------------+---------------+---------+---------+-------+------+----------+--------------------------+| 1 | SIMPLE | c | NULL | ref_or_null | idindex | idindex | 5 | const | 2 | 100.00 | Using where; Using index |+----+-------------+-------+------------+-------------+---------------+---------+---------+-------+------+----------+--------------------------+1 row in set (0.04 sec) &lt;id-13&gt;1234567mysql&gt; explain select id from c where id &gt; 1;+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+--------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+--------------------------+| 1 | SIMPLE | c | NULL | range | idindex | idindex | 5 | NULL | 2 | 100.00 | Using where; Using index |+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+--------------------------+1 row in set (0.04 sec) &lt;id-14&gt;1234567mysql&gt; explain select id from c;+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+| 1 | SIMPLE | c | NULL | index | NULL | idindex | 5 | NULL | 3 | 100.00 | Using index |+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+1 row in set (0.03 sec) &lt;id-15&gt;123456789mysql&gt; explain select id from c where id in (select a.id from a, d where a.id = d.id);+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+------------------------------+| 1 | SIMPLE | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | Using where; Start temporary || 1 | SIMPLE | c | NULL | ref | idindex | idindex | 5 | sqltest2.a.id | 1 | 100.00 | Using index || 1 | SIMPLE | d | NULL | eq_ref | PRIMARY | PRIMARY | 4 | sqltest2.a.id | 1 | 100.00 | Using index; End temporary |+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+------------------------------+3 rows in set (0.04 sec) &lt;id-16&gt;1234567mysql&gt; explain select min(id) from c;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | Select tables optimized away |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+1 row in set (0.05 sec) &lt;id-17&gt;1234567mysql&gt; explain select id from c order by num;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+| 1 | SIMPLE | c | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | Using filesort |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+1 row in set (0.04 sec) &lt;id-18&gt;1234567mysql&gt; explain select id from d where id = 100;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | no matching row in const table |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+1 row in set (0.04 sec) &lt;id-19&gt;1234567mysql&gt; explain select id from d limit 0;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | Zero limit |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------+1 row in set (0.04 sec) &lt;id-20&gt;1234567mysql&gt; explain select 1 from dual;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | No tables used |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+1 row in set (0.04 sec) &lt;id-22&gt;1234567mysql&gt; explain select * from a where 1 = 2;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | Impossible WHERE |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------+1 row in set (0.03 sec) &lt;id-23&gt;1234567mysql&gt; explain select sum(num) from a group by id having 1 =2;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | Impossible HAVING |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------+1 row in set (0.04 sec) 总结 关于 EXPLAIN 命令的所有可能取值后面，还有部分例子是空的，完全是由于个人水平有限，等找到所说的取值情况再补充，也欢迎大家提供例子 另外 EXPLAIN 提供的信息中没有关于触发器、存储过程的信息或者评估用户自定义函数对查询的影响情况 所有的可能取值中 possible_keys、rows、filtered中的统计信息基本是估算的，并非精确值，只能用来做优化参考 Extra 列的信息对于尝试优化起到了至关重要的作用，当出现 Using filesort、Using temporary、Using join buffer的时候一般就要考虑采取优化方案了 首先了解这些可能出现的情况，之后我们留这里利用这些说明来进行查询优化了]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>查询</tag>
        <tag>EXPLAIN</tag>
        <tag>Extra</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gcc编译生成可执行文件的过程中发生了什么]]></title>
    <url>%2Fblog%2F2019%2F04%2F16%2Fgcc%E7%BC%96%E8%AF%91%E7%94%9F%E6%88%90%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[前言一直好奇程序的编译过程到底做了哪些工作，后来学会在Ubuntu上使用gcc编译程序，知道了生成可执行文件需要分为预编译、编译、汇编和链接4个步骤，逐渐了解了其中的细节，但是过一段时间之后总是记不太清楚了，所以总结一下增强记忆，同时方便日后查找使用。 编译方式一步到位使用gcc命令可以一步将main.c源文件编译生成最终的可执行文件main_direct 1gcc main.c –o main_direct 分步执行gcc的编译流程通常认为包含以下四个步骤，实际上就是将上面的命令分成4步执行，这也是gcc命令实际的操作流程，生成的可执行文件main与上面单条命令生成的可执行文件main_direct是一模一样的 预处理，生成预编译文件（.i文件）：gcc –E main.c –o main.i 编译，生成汇编代码（.s文件）：gcc –S main.i –o main.s 汇编，生成目标文件（.o文件）：gcc –c main.s –o main.o 链接，生成可执行文件（executable文件）：gcc main.o –o main 编译流程这里的编译是指将源文件（.c）生成可执行文件（executable）的这个完整的过程，而不是上面提到的四个步骤中的第二步，为了弄清楚编译过程究竟都做了哪些工作，接下来我们可以分步骤来看一下gcc编译.c文件的过程，了解了每一步的内容，也就明白了整个编译流程，先给出源文件 mian.c 的源代码。1234567891011121314151617#include &lt;stdio.h&gt;#define A 100// calc sumint sum(int a, int b)&#123; return a + b;&#125;int main()&#123; int b = 1; int c = sum(A, b); printf("sum = %d\n", c); return 0;&#125; 预处理预处理又叫预编译，是完整编译过程的第一个阶段，在正式的编译阶段之前进行。预处理阶段将根据已放置在文件中的预处理指令来修改源文件的内容，对于C语言来说预处理的可执行程序叫做 cpp，全称为C Pre-Processor（C预处理器），是一个与 C 编译器独立的小程序，预编译器并不理解 C 语言语法，它仅是在程序源文件被编译之前，实现文本替换的功能。简单来说，预处理就是将源代码中的预处理指令根据语义预先处理，并且进行一下清理、标记工作，然后将这些代码输出到一个 .i 文件中等待进一步操作。 一般地，C/C++ 程序的源代码中包含以 # 开头的各种编译指令，被称为预处理指令，其不属于 C/C++ 语言的语法，但在一定意义上可以说预处理扩展了 C/C++。根据ANSI C 定义，预处理指令主要包括：文件包含、宏定义、条件编译和特殊控制等4大类。 预处理阶段主要做以下几个方面的工作： 文件包含：#include 是 C 程序设计中最常用的预处理指令，格式有尖括号 #include &lt;xxx.h&gt; 和双引号 #include &quot;xxx.h&quot; 之分，分别表示从系统目录下查找和优先在当前目录查找，例如常用的 #include &lt;stdio.h&gt; 指令，就表示使用 stdio.h 文件中的全部内容，替换该行指令。 添加行号和文件名标识： 比如在文件main.i中就有类似 # 2 &quot;main.c&quot; 2 的内容，以便于编译时编译器产生调试用的行号信息及用于编译时产生编译错误或警告时能够显示行号。 宏定义展开及处理： 预处理阶段会将使用 #define A 100 定义的常量符号进行等价替换，文中所有的宏定义符号A都会被替换成100，还会将一些内置的宏展开，比如用于显示文件全路径的__FILE__，另外还可以使用 #undef 删除已经存在的宏，比如 #undef A 就是删除之前定义的宏符号A。 条件编译处理: 如 #ifdef，#ifndef，#else，#elif，#endif等，这些条件编译指令的引入使得程序员可以通过定义不同的宏来决定编译程序对哪些代码进行处理，将那些不必要的代码过滤掉，防止文件重复包含等。 清理注释内容： // xxx 和 /*xxx*/ 所产生的的注释内容在预处理阶段都会被删除，因为这些注释对于编写程序的人来说是用来记录和梳理逻辑代码的，但是对编译程序来说几乎没有任何用处，所以会被删除，观察 main.i 文件也会发现之前的注释都被删掉了。 特殊控制处理: 保留编译器需要使用 #pragma 编译器指令，另外还有用于输出指定的错误信息，通常来调试程序的 #error 指令。 查看main.i文件 编译编译过程是整个程序构建的核心部分，也是最复杂的部分之一，其工作就是把预处理完生成的 .i 文件进行一系列的词法分析、语法分析、语义分析以及优化后产生相应的汇编代码文件，也就是 .s 文件，这个过程调用的处理程序一般是 cc 或者 ccl。汇编语言是非常有用的，因为它给不同高级语言的不同编译器提供了可选择的通用的输出语言，比如 C 和 Fortran 编译产生的输出文件都是汇编语言。 词法分析： 主要是使用基于有线状态机的Scanner分析出token，可以通过一个叫做 lex 的可执行程序来完成词法扫描，按照描述好的词法规则将预处理后的源代码分割成一个个记号，同时完成将标识符存放到符号表中，将数字、字符串常量存放到文字表等工作，以备后面的步骤使用。 语法分析： 对有词法分析产生的token采用上下文无关文法进行分析，从而产生语法树，此过程可以通过一个叫做 yacc 的可执行程序完成，它可以根据用户给定的语法规则对输入的记号序列进行解析，从而构建一棵语法树，如果在解析过程中出现了表达式不合法，比如括号不匹配，表达式中缺少操作符、操作数等情况，编译器就会报出语法分析阶段的错误。 语义分析： 此过程由语义分析器完成，编译器 cc 所能分析的语义都是静态语义，是指在编译期间可以确定的语义，通常包括声明和类型的匹配，类型的转换等。比如将一个浮点型的表达式赋值给一个整型的表达式时，语义分析程序会发现这个类型不匹配，编译器将会报错。而动态语义一般指在运行期出现的语义相关问题，比如将0作为除数是一个运行期语义错误。语义分析过程会将所有表达式标注类型，对于需要隐式转换的语法添加转换节点，同时对符号表里的符号类型做相应的更新。 代码优化： 此过程会通过源代码优化器会在源代码级别进行优化，针对于编译期间就可以确定的表达式（例如：100+1）给出确定的值，以达到优化的目的，此外还包括根据机器硬件执行指令的特点对指令进行一些调整使目标代码比较短，执行效率更高等操作。 查看main.s文件 汇编汇编过程是整个程序构建中的第三步，是将编译产生的汇编代码文件转变成可执行的机器指令。相对来说比较简单，每个汇编语句都有相对应的机器指令，只需根据汇编代码语法和机器指令的对照表翻译过来就可以了，最终生成目标文件，也就是 .o 文件，完成此工作的可执行程序通常是 as。目标文件中所存放的也就是与源程序等效的目标的机器语言代码，通常至少包含代码段和数据段两个段，并且还要包含未解决符号表，导出符号表和地址重定向表等3个表。汇编过程会将extern声明的变量置入未解决符号表，将static声明的全局变量不置入未解决符号表，也不置入导出符号表，无法被其他目标文件使用，然后将普通变量及函数置入导出符号表，供其他目标文件使用。 代码段： 包含主要是程序的指令。该段一般是可读和可执行的，但一般却不可写。 数据段： 主要存放程序中要用到的各种全局变量或静态的数据，一般数据段都是可读，可写，可执行的。 未解决符号表： 列出了在本目标文件里有引用但不存在定义的符号及其出现的地址。 导出符号表： 列出了本目标文件里具有定义，并且可以提供给其他目标文件使用的符号及其在出现的地址。 地址重定向表： 列出了本目标文件里所有对自身地址的引用记录。 查看main.o文件 链接链接过程是程序构建过程的最后一步，通常调用可执行程序 ld 来完成，可以简单的理解为将目标文件和库文件打包组装成可执行文件的过程，其主要内容就是把各个模块之间相互引用的部分都处理好，将一个文件中引用的符号同该符号在另外一个文件中的定义连接起来，使得各个模块之间能够正确的衔接，成为一个能够被操作系统装入执行的统一整体。 虽然汇编之后得到的文件已经是机器指令文件，但是依然无法立即执行，其中可能还有尚未解决的问题，比如源代码 main.c 中的 printf 这个函数名就无法解析，需要链接过程与对应的库文件对接，完成的重定位，将函数符号对应的地址替换成正确的地址。前面提到的库文件其实就是一组目标文件的包，它们是一些最常用的代码编译成目标文件后打成的包。比如 printf的头文件是 stdio.h，而它的实现代码是放在动态库 libc.so.6 中的，链接的时候就要引用到这个库文件。 从原理上讲，连接的的工作就是把一些指令对其他符号地址的引用加以修正，主要包括了地址和空间分配、符号决议和重定位等步骤，根据开发人员指定的链接库函数的方式不同，链接过程可分为静态链接和动态链接两种，链接静态的库，需要拷贝到一起，链接动态的库需要登记一下库的信息。 静态链接： 函数的代码将从其所在地静态链接库中被拷贝到最终的可执行程序中。这样该程序在被执行时，代码将被装入到该进程的虚拟地址空间中，静态链接库实际上是一个目标文件的集合，其中的每个文件含有库中的一个或者一组相关函数的代码，最终生成的可执行文件较大。 动态链接： 函数的代码被放到动态链接库或共享对象的某个目标文件中。链接处理时只是在最终的可执行程序中记录下共享对象的名字以及其它少量的登记信息。在这样该程序在被执行时，动态链接库的全部内容将被映射到运行时相应进程的虚地址空间，根据可执行程序中记录的信息找到相应的函数代码。这种连接方法能节约一定的内存，也可以减小生成的可执行文件体积。 ​查看main可执行文件 总结 gcc编译器的工作过程：源文件 --&gt; 预处理 --&gt; 编译 --&gt; 汇编 --&gt; 链接 --&gt; 可执行文件 gcc编译过程文件变化：main.c –&gt; main.i –&gt; mian.s –&gt; main.o –&gt; main 通过上面分阶段的解释编译过程，我们也明白了gcc其实只是一个后台程序的包装，它会根据阶段要求来调用 cpp、cc、as、ld 等命令 源代码整个编译过程产生的中间文件及最终结果可以通过传送门—— gcc编译项目 来获得，其中还有gcc和g++分别调用的对比，查看生成的文件可以发现，同样的源代码使用gcc和g++生成的文件是不一样的，总的来说使用g++编译生成的可执行文件要大一些。]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>gcc</tag>
        <tag>预处理</tag>
        <tag>编译</tag>
        <tag>汇编</tag>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++版本更迭历程]]></title>
    <url>%2Fblog%2F2019%2F04%2F09%2FC-C-%E7%89%88%E6%9C%AC%E6%9B%B4%E8%BF%AD%E5%8E%86%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言使用 C/C++ 实现功能的时候经常需要上网搜索一些解决方案，但是当你把代码粘贴到自己项目中时偶尔会出现编译失败的问题，其中一个原因就是新加的代码所使用的特性在当前的编译环境中并不支持，就好像不久前我们还在使用VS2003写着C++98标准的代码（2015年），虽然对C++11的特性垂涎已久，但是无奈在项目中就是无法使用，只能是遥望着它发飞快地发展出了C++14和C++17。 涉及到C/C++版本和标准的最常见的地方就是编译选项了，比如常见的 -std=c++11 就是使用C++11的标准编译，关于 C/C++ 各个版本标准的差异我们可能无法全部记住，但是一些主要的版本更替，还是很有必要了解一下的。 C语言版本更迭 年份 C标准 通用名 别名 标准编译选项 GNU扩展选项 1972 Birth C - - - - 1978 K&amp;R C - - - - 1989-1990 X3.159-1989, ISO/IEC 9899:1990 C89 C90, ANSI C, ISO C -ansi, -std=c90, -std=iso9899:1990 -std=gnu90 1995 ISO/IEC 9899/AMD1:1995 AMD1 C94, C95 -std=iso9899:199409 - 1999 ISO/IEC 9899:1999 C99 - -std=c99, -std=iso9899:1999 -std=gnu99 2011 ISO/IEC 9899:2011 C11 - -std=c11, -std=iso9899:2011 -std=gnu11 2018 ISO/IEC 9899:2018 C18 - -std=c18, -std=iso9899:2018 -std=gnu18 C++版本更迭 年份 C++标准 通用名 别名 标准编译选项 GNU扩展选项 1978 C with Classes - - - - 1998 ISO/IEC 14882:1998 C++98 - -std=c++98 -std=gnu++98 2003 ISO/IEC 14882:2003 C++03 - -std=c++03 -std=gnu++03 2011 ISO/IEC 14882:2011 C++11 C++0x std=c++11, std=c++0x std=gnu++11, std=gnu++0x 2014 ISO/IEC 14882:2014 C++14 C++1y std=c++14, std=c++1y std=gnu++14, std=gnu++1y 2017 ISO/IEC 14882:2017 C++17 C++1z std=c++17, std=c++1z std=gnu++17, std=gnu++1z 2020 to be determined C++20 C++2a -std=c++2a std=gnu++2a 号外C/C++标准 看了C++的发展史才知道，原来从1978年Bjarne Stroustrup就开始了C++雏形的使用，直到20年后的1998年才确定了第一个C++标准 C++11之前被称为C++0x，据说C++0x是C++11的草案，所以有些编译器使用C++11的编译参数是：-std=c++0x，后来使用：-std=c++11，但是据说不完全相同 关于C++20，协程的加入应该是一大惊喜了，值得期待！官方还表示，C++20 应该会是一个像 C++11 那样的大版本 gcc/g++ gcc发展到今天已经不单单可以编译C语言了，还可以编译C++、Java、Object-C等多种其他语言 有一种说法是GCC的全名是GNU Compiler Collection(GUN 编译器集合)，而gcc是GCC中用于编译c语言的编译器 事实上，gcc看起来并不像是一个编译器，而像一个调度器，针对于不同的文件调用不同编程语言的编译器 对于后缀为*.c的文件，gcc把它当作是C语言程序源代码，而g++当作是C++程序源代码 对于后缀为*.cpp的文件，gcc和g++都会当作是C++程序源代码 使用g++编译文件时，g++会自动链接标准库STL，而gcc不会自动链接STL，所以再使用gcc编译C++程序是有时会报错 在用gcc编译C++文件时，为了能够使用STL，需要加参数 –lstdc++ ，但这并不代表 gcc –lstdc++ 和 g++等价 据说g++会调用gcc，对于C++代码，因为gcc命令不能自动和C++程序使用的库联接，所以通常用g++来完成链接 需要注意的是，虽说g++会调用gcc，对于*.c文件来说，编译出来的可执行文件也不一样，因为gcc会当成C语言程序编译，而g++调用的gcc会把它当做C++语言程序来编译，这或许就能解释为什么用g++就可以编译所有C/C++的程序，还要有gcc的存在（就我测试来看，同样的C语言代码，g++编译出来的程序体积要大一些）]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>历史</tag>
        <tag>标准</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql表连接：内连接、外连接、交叉连接、自然连接真的都不一样吗]]></title>
    <url>%2Fblog%2F2019%2F04%2F03%2FMysql%E8%A1%A8%E8%BF%9E%E6%8E%A5%EF%BC%9A%E5%86%85%E8%BF%9E%E6%8E%A5%E3%80%81%E5%A4%96%E8%BF%9E%E6%8E%A5%E3%80%81%E4%BA%A4%E5%8F%89%E8%BF%9E%E6%8E%A5%E3%80%81%E8%87%AA%E7%84%B6%E8%BF%9E%E6%8E%A5%E7%9C%9F%E7%9A%84%E9%83%BD%E4%B8%8D%E4%B8%80%E6%A0%B7%E5%90%97%2F</url>
    <content type="text"><![CDATA[前言提起这几种表连接方式就让人头大，想当初还因为这个面试被刷了，长得挺像，用法挺像，可就是有点不一样，其实的它们的差异不是固定的，要在一个具体的环境下才能进行对比，比如在Mysql环境下, JOIN, INNER JOIN, CROSS JOIN 三者在语法上是等价的，也就是作用相同，但是在标准的SQL下却又存在差异。 选一个自己熟悉的环境对比一下，那就是Mysql数据库的表连接了，测试的多了渐渐的发现了一些规律和神坑，貌似一切表连接都是以内连接为基础，然后再此基础上进行变换可以得到一种新的连接，接下来就采用这种对比的逻辑，看看这些连接类型都有什么区别和联系。 测试环境 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 8Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. 创建测试数据 新建第一个测试表格a，包含id和name两列 1create table a(id int, name varchar(64), primary key(id)); 插入测试数据 1234insert into a values(1, 'albert');insert into a values(2, 'bella');insert into a values(3, 'amy');insert into a values(4, 'forier'); 新建第二个测试表格b，包含id和age两列 1create table b(id int, age int, primary key(id)); 插入测试数据 1234insert into b values(1, 18);insert into b values(2, 19);insert into b values(3, 25);insert into b values(5, 70); 分别查看两表中的数据如下 123456789101112131415161718192021mysql&gt; select * from a;+----+--------+| id | name |+----+--------+| 1 | albert || 2 | bella || 3 | amy || 4 | forier |+----+--------+4 rows in set (0.04 sec)mysql&gt; select * from b;+----+-----+| id | age |+----+-----+| 1 | 18 || 2 | 19 || 3 | 25 || 5 | 70 |+----+-----+4 rows in set (0.05 sec) 对比测试这篇对比文章可能和以往你看到的不太一样，对比的基础是内连接，其他的连接基本可以看做是在内连接的基础上加了一些条件和扩展得到的，所以首先我们需要先来看一下内连接。 内连接内连接基础语法是a inner join b，不过其中的inner可以省略，也就是可以写成a join b，如果不添加条件就是a表中的每条记录分别与b表中的每条记录做匹配，形成笛卡尔积，查询结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445mysql&gt; select * from a inner join b;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 1 | 18 || 3 | amy | 1 | 18 || 4 | forier | 1 | 18 || 1 | albert | 2 | 19 || 2 | bella | 2 | 19 || 3 | amy | 2 | 19 || 4 | forier | 2 | 19 || 1 | albert | 3 | 25 || 2 | bella | 3 | 25 || 3 | amy | 3 | 25 || 4 | forier | 3 | 25 || 1 | albert | 5 | 70 || 2 | bella | 5 | 70 || 3 | amy | 5 | 70 || 4 | forier | 5 | 70 |+----+--------+----+-----+16 rows in set (0.03 sec)mysql&gt; select * from a join b;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 1 | 18 || 3 | amy | 1 | 18 || 4 | forier | 1 | 18 || 1 | albert | 2 | 19 || 2 | bella | 2 | 19 || 3 | amy | 2 | 19 || 4 | forier | 2 | 19 || 1 | albert | 3 | 25 || 2 | bella | 3 | 25 || 3 | amy | 3 | 25 || 4 | forier | 3 | 25 || 1 | albert | 5 | 70 || 2 | bella | 5 | 70 || 3 | amy | 5 | 70 || 4 | forier | 5 | 70 |+----+--------+----+-----+16 rows in set (0.04 sec) 需要注意的是内连接的连接条件是可选择，如果不加就是笛卡尔积，如果想加的话可以选择on子句或者using子句，比如需要得到a表与b表中id一致的数据记录就可以使用如下on子句的写法： 123456789mysql&gt; select * from a join b on a.id = b.id;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 |+----+--------+----+-----+3 rows in set (0.04 sec) 同时对于上述例子中这个on子句中是被连接的两表的同时存在的字段时，可以使用using子句简化，写成如下查询，需要注意下结果集的变化，记录的条数与on子句相同，但是共有的id列被优化掉了一个，这也是on和using子句的区别，使用时根据需要选择： 123456789mysql&gt; select * from a join b using(id);+----+--------+-----+| id | name | age |+----+--------+-----+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 |+----+--------+-----+3 rows in set (0.04 sec) 交叉连接交叉连接基础语法是a cross join b，在Mysql的语法环境中，内连接与交叉连接完全一致，这一点可以通过下面几条查询与内连接的查询做对比得知： 123456789101112131415161718192021222324252627282930313233343536373839404142mysql&gt; select * from a cross join b;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 1 | 18 || 3 | amy | 1 | 18 || 4 | forier | 1 | 18 || 1 | albert | 2 | 19 || 2 | bella | 2 | 19 || 3 | amy | 2 | 19 || 4 | forier | 2 | 19 || 1 | albert | 3 | 25 || 2 | bella | 3 | 25 || 3 | amy | 3 | 25 || 4 | forier | 3 | 25 || 1 | albert | 5 | 70 || 2 | bella | 5 | 70 || 3 | amy | 5 | 70 || 4 | forier | 5 | 70 |+----+--------+----+-----+16 rows in set (0.04 sec)mysql&gt; select * from a cross join b on a.id = b.id;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 |+----+--------+----+-----+3 rows in set (0.04 sec)mysql&gt; select * from a cross join b using(id);+----+--------+-----+| id | name | age |+----+--------+-----+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 |+----+--------+-----+3 rows in set (0.04 sec) 外连接在Mysql中外连接分为左外连接和右外连接，但不存在全外连接，这一点与Oracle有些不同，不过可以通过左外连接和右外连接合并出全外连接的结果集，需要注意的是外连接必须添加on子句或者using子句，否则会报语法错误，对于左、有外连接可以分别看一下： 左外连接左外连接基础语法是a left outer join b，其中的outer可以省略，与内连接相比就是在与内连接相同条件下，在内连接的结果集中添加a表在b表中找不到匹配的记录，换句话说就是，结果集中会包含a表中的所有记录，如果b表中有匹配的记录就出现在结果集，否则使用NULL代替，也就是把a表看成根本，不可缺失记录，查询结果如下: 123456789101112131415161718192021mysql&gt; select * from a left outer join b on a.id = b.id;+----+--------+------+------+| id | name | id | age |+----+--------+------+------+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 || 4 | forier | NULL | NULL |+----+--------+------+------+4 rows in set (0.04 sec)mysql&gt; select * from a left join b on a.id = b.id;+----+--------+------+------+| id | name | id | age |+----+--------+------+------+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 || 4 | forier | NULL | NULL |+----+--------+------+------+4 rows in set (0.03 sec) 这个左外连接查询同样可以使用using子句来化简，并且也会将共有的字段省略一个： 12345678910mysql&gt; select * from a left join b using(id);+----+--------+------+| id | name | age |+----+--------+------+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 || 4 | forier | NULL |+----+--------+------+4 rows in set (0.04 sec) 右外连接右外连接基础语法是a right outer join b，其中的outer可以省略，与内连接相比就是在与内连接相同条件下，在内连接的结果集中添加b表在a表中找不到匹配的记录，换句话说就是，结果集中会包含b表中的所有记录，如果a表中有匹配的记录就出现在结果集，否则使用NULL代替，也就是把b表看成根本，不可缺失记录，作用与左外连接恰好相反，查询结果如下: 1234567891011121314151617181920212223242526272829303132mysql&gt; select * from a right outer join b on a.id = b.id;+------+--------+----+-----+| id | name | id | age |+------+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 || NULL | NULL | 5 | 70 |+------+--------+----+-----+4 rows in set (0.03 sec)mysql&gt; select * from a right join b on a.id = b.id;+------+--------+----+-----+| id | name | id | age |+------+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 || NULL | NULL | 5 | 70 |+------+--------+----+-----+4 rows in set (0.04 sec)mysql&gt; select * from a right join b using(id);+----+-----+--------+| id | age | name |+----+-----+--------+| 1 | 18 | albert || 2 | 19 | bella || 3 | 25 | amy || 5 | 70 | NULL |+----+-----+--------+4 rows in set (0.04 sec) 自然连接自然连接从名字来看就是两个表很自然的就连接上了，这要求两个表需要有可以参照的数据，具体到表设计上就是要求两个表必须要有相同的列，需要注意的是自然连接不允许添加连接子句，否则会报语法错误。自然连接分为一般自然连接、左外连接和自然右外连接连接，还是以内连接为标准，看看自然连接有什么不同： 一般自然连接一般自然连接基础语法是a natural join b，它不能加连接条件，使用两个表共有的字段id来“自然”地链接，同时会省略共有的字段，其作用相同于内连接使用using子句来查询，通过下面的对比，你会发现他们的作用是一样的。 12345678910111213141516171819mysql&gt; select * from a natural join b;+----+--------+-----+| id | name | age |+----+--------+-----+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 |+----+--------+-----+3 rows in set (0.03 sec)mysql&gt; select * from a join b using(id);+----+--------+-----+| id | name | age |+----+--------+-----+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 |+----+--------+-----+3 rows in set (0.04 sec) 自然左外连接自然左外连接基础语法是a natural left outer join b，其中的outer可以省略，它也不能加连接条件，使用两个表共有的字段id来“自然”地链接，同时会省略共有的字段，其作用相同于内连接使用using子句同时包含a表中的所有记录，以a表作为根本，包含所有记录，并且显示b表中匹配记录，如没有与a表匹配的记录则以NULL代替，其实就是左外连接省略掉using子句： 1234567891011121314151617181920212223242526272829303132mysql&gt; select * from a natural left outer join b;+----+--------+------+| id | name | age |+----+--------+------+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 || 4 | forier | NULL |+----+--------+------+4 rows in set (0.04 sec)mysql&gt; select * from a natural left join b;+----+--------+------+| id | name | age |+----+--------+------+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 || 4 | forier | NULL |+----+--------+------+4 rows in set (0.03 sec)mysql&gt; select * from a left join b using(id);+----+--------+------+| id | name | age |+----+--------+------+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 || 4 | forier | NULL |+----+--------+------+4 rows in set (0.03 sec) 自然右外连接自然左外连接基础语法是a natural right outer join b，其中的outer可以省略，它也不能加连接条件，其作用与自然左外连接相反，其实就是右外连接省略掉using子句： 1234567891011121314151617181920212223242526272829303132mysql&gt; select * from a natural right outer join b;+----+-----+--------+| id | age | name |+----+-----+--------+| 1 | 18 | albert || 2 | 19 | bella || 3 | 25 | amy || 5 | 70 | NULL |+----+-----+--------+4 rows in set (0.04 sec)mysql&gt; select * from a natural right join b;+----+-----+--------+| id | age | name |+----+-----+--------+| 1 | 18 | albert || 2 | 19 | bella || 3 | 25 | amy || 5 | 70 | NULL |+----+-----+--------+4 rows in set (0.04 sec)mysql&gt; select * from a right join b using(id);+----+-----+--------+| id | age | name |+----+-----+--------+| 1 | 18 | albert || 2 | 19 | bella || 3 | 25 | amy || 5 | 70 | NULL |+----+-----+--------+4 rows in set (0.04 sec) STRAIGHT_JOINSTRAIGHT_JOIN的基础语法是a STRAIGHT_JOIN b，确实没有找到这种连接的中文说法，不过它与内连接几乎一样，只是它总是把左侧a表作为驱动表优先读入，它只能加on子句，无法使用using子句，在Sql优化的过程中常常使用，也就是拒绝了Mysql的语句优化，而使用自己指定的顺序来连接表格，不过使用时需慎重，你得比Mysql聪明才可以！ 123456789mysql&gt; select * from a straight_join b on a.id = b.id;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 |+----+--------+----+-----+3 rows in set (0.04 sec) 逗号分隔连接表在from之后用逗号分隔的两个表格像极了内连接，只不过用逗号分隔的表不能使用子句连接，只可以用where来做条件筛选，不过作用之后的结果是一致的，可以对比看一下： 12345678910111213141516171819mysql&gt; select * from a join b on a.id = b.id;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 |+----+--------+----+-----+3 rows in set (0.04 sec)mysql&gt; select * from a, b where a.id = b.id;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 |+----+--------+----+-----+3 rows in set (0.04 sec) 各种连接对比通过描述可能有些关系还是没理解太清楚，所以整理了下面的表格，对比的更清楚一点，其中[]中的内容在编写sql时可以省略： 连接类型 语法 不加条件 加ON子句 加USING子句 与内连接关系 内连接 a [INNER] JOIN b 两表中任意两条记录分别匹配，形成笛卡尔积 只按照条件匹配，所有列均显示 按照共有的列匹配，去除重复列 X 交叉连接 a [CROSS] JOIN b 两表中任意两条记录分别匹配，形成笛卡尔积 只按照条件匹配，所有列均显示 按照共有的列匹配，去除重复列 语法等价，完全相同 左外连接 a LEFT [OUTER] JOIN b 必须加条件，否则报语法错误 只按照条件匹配，并且包含a表中没有匹配上的记录 按照共有的列匹配，并且包含a表中没有匹配上的记录 额外包含a表中没有匹配上的记录 右外连接 a RIGHT [OUTER] JOIN b 必须加条件，否则报语法错误 只按照条件匹配，并且包含b表中没有匹配上的记录 按照共有的列匹配，并且包含b表中没有匹配上的记录 额外包含b表中没有匹配上的记录 一般自然连接 a NATURAL JOIN b 使用两表中共有的字段匹配 不能使用ON子句 不能使用USING子句 相当于内连接使用USING子句 自然左外连接 a NATURAL LEFT [OUTER] JOIN b 使用两表中共有的字段匹配，并且包含a表中没有匹配上的记录 不能使用ON子句 不能使用USING子句 相当于内连接使用USING子句，并且包含a表中没有匹配上的记录 自然右外连接 a NATURAL RIGHT [OUTER] JOIN b 使用两表中共有的字段匹配，并且包含b表中没有匹配上的记录 不能使用ON子句 不能使用USING子句 相当于内连接使用USING子句，并且包含b表中没有匹配上的记录 STRAIGHT_JOIN a STRAIGHT_JOIN b 两表中任意两条记录分别匹配，形成笛卡尔积 只按照条件匹配，所有列均显示 不能使用USING子句 在内连接基础上确定读表顺序 逗号分隔表 a, b 两表中任意两条记录分别匹配，形成笛卡尔积 不能使用ON子句 不能使用USING子句 不能使用连接子句，只能使用Where筛选 总结 总的来看外连接中的outer是最没有存在感的，凡是它出现的地方都可以省略 黑魔法：a inner join b与a cross join b是等价的，后来我偶然间拼写错误发现a across join b也是可以的，另外a love join b也行，开始还以为发现了bug，后来再理解应该是拼错的单词作了表a的别名，虚惊一场！ 通过上面的表格发现每种连接貌似都和内连接扯上了关系，那就以内连接为基础，通过扩展来记忆也是不错的 如果表格不够清晰，换成思维导图或许会更好一些]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>查询</tag>
        <tag>表连接</tag>
        <tag>内连接</tag>
        <tag>外连接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP地址常见分类：A类、B类、C类、D类、E类]]></title>
    <url>%2Fblog%2F2019%2F04%2F03%2FIP%E5%9C%B0%E5%9D%80%E5%B8%B8%E8%A7%81%E5%88%86%E7%B1%BB%EF%BC%9AA%E7%B1%BB%E3%80%81B%E7%B1%BB%E3%80%81C%E7%B1%BB%E3%80%81D%E7%B1%BB%E3%80%81E%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[前言虽然IPv6渐渐出现在了人们的视线之中，但是目前来看IPv4仍然占据着主导地位，在日常的编码过程中两者都会接触到，但实际上两者在使用范围、消息头结构等细节上有诸多不同，具体的那些细节对于应用层来说可能体会不到，所以我们先从两者的表示方式来看看，学会认出哪些是IPv4类型的地址，而哪些是IPv6类型的地址。 IPv4地址表示方法每个IPv4地址占用4个字节，长度为32位，由网络号和主机号部分组成，最常采用点分十进制表示法，格式为 ddd.ddd.ddd.ddd，其中 0 &lt;= ddd &lt;= 255，而每个 d 都是十进制数，可省略前导零，比如常见的192.168.1.1，理论上最多能表示的地址个数为$2^32$。 IPv6地址表示方法每个IPv6地址占用16个字节，长度为128位，占用空间是IPv4地址的4倍，但是这里要注意，IPv4所能表示的地址个数相比于IPv4来说可不是4倍的关系，IPv6理论上最多能表示的地址个数为$2^128$，是IPv4能力的$2^96$倍，换算成10进制也就是大约79228162514264337593543950336倍，在很长一段时间内不用再担心IP地址不够用的问题了。 而IPv6地址由于占用位数较多，所以采用更容易书写和理解的冒分十六进制表示法，格式为xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx，其中每个 x 表示一个十六进制的符号，也就是0-9A-F，比如一个普通IPv6地址23CD:0F01:0005:0789:ABED:EF01:2345:67D9，前导零也是可以省略的，例如前一个地址可以记作23CD:F01:5:789:ABED:EF01:2345:67D9。 在某些情况下，一个IPv6地址内可能包含很长的一段0，这时可以把连续的一段0压缩为::, 但要注意是，地址中::只能出现一次，这样才能保证地址解析的唯一性，比如地址FF20:A:0:0:0:0:0:1AC2，可以写成FF20:A::1AC2，而地址FF20:A:0:0:1:0:0:1AC2中间有两段0，为保证解析的唯一性，只能选择一段0来压缩，比如写成FF20:A::1:0:0:1AC2或者是FF20:A:0:0:1::1AC2。 为了实现IPv4地址和IPv6地址互相通信，在IPv6的环境下，IPv4地址会被扩展成IPv6地址，此时地址的格式常表示为：xxxx:xxxx:xxxx:xxxx:xxxx:FFFF:ddd.ddd.ddd.ddd，前面的96位采用IPv6冒分十六进制表示，而后面32位地址则使用IPv4的点分十进制表示，例如常用的IPv4地址192.168.1.1与表示成IPv6地址就是FFFF:192.168.1.1。 IPv4地址常见分类192.168.1.1这个IP地址随着路由器的普及逐渐为人们所熟知，有些人可能知道这是一个C类地址，究竟什么是C类地址？难道还有A类、B类地址？不是说IP地址是惟一表示一台主机的吗，为什么我家的路由器和邻居家的路由器地址都是192.168.1.1，关于这些问题就涉及到了IPv4地址的常见分类，其实IPv4地址一般被分为A、B、C、D、E五类，其中还包含一些保留地址和局域网地址，关于这些信息为了对比方便，我整理了下面这幅图，有关分类的疑惑可以看图了解一下： 书愤陆游早岁那知世事艰，中原北望气如山。楼船夜雪瓜洲渡，铁马秋风大散关。塞上长城空自许，镜中衰鬓已先斑。出师一表真名世，千载谁堪伯仲间。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Network</tag>
        <tag>网络</tag>
        <tag>IP</tag>
        <tag>IPv4</tag>
        <tag>Ipv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql开启、查看慢查询日志]]></title>
    <url>%2Fblog%2F2019%2F03%2F25%2FMysql%E5%BC%80%E5%90%AF%E3%80%81%E6%9F%A5%E7%9C%8B%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[前言想要优化现有的数据库结构或者查询语句，首先要找到需要的优化的地方，不然就会出现费了很大精力优化却不达目的的情况，这就和上学考试一样，想要取得好的成绩，先要分析自己差在哪里，重点学习才会有快速的提升。 关于查询Mysql的瓶颈，或者说查询Mysql出现操作缓慢的问题，我们可以使用Mysql自带的慢查询日志来分析，优化不是改正错误，那种错误在开发过程中叫做BUG，伴随着软件开发工程师的一生，而优化是指在逻辑正确的前提下，让程序运行的更快更稳定，一般来说就是优化比较耗时的操作，提升用户体验。比如一个信息系统，如果输入账号密码后需要10分钟才能登录成功，我想基本上也不会有人使用了。 慢查询日志就是一种特殊的记录，用于统计Mysql操作过程中一些耗时的语句，生成文件或者表格，为优化Mysql操作提供分析数据，从名字也很好理解，慢查询日志就是记录一些查询的比较慢的记录，帮助使用者定位具体的问题，接下来就简单地描述一下慢查询日志是如何开启和查看的。 测试环境 Windows 10Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 开启慢查询日志修改过Mysql配置的小伙伴应该知道，Mysql的一些环境配置可以通过命令行直接修改，也可以修改配置文件后重新启动Mysql服务来生效，我们这次选择修改配置文件的方法，首先找到配置文件my.ini（Mysql5.7Windows版本，Linux版本应该叫my.cnf吧），一般在安装目录所在的ProgramData目录下，比如我的是在 C:/ProgramData/MySQL/MySQL Server 5.7 ，如果找不到可以下载一个叫Everything的软件搜一下（顺便安利一下，真的挺好用）。 用记事本或者其他编辑软件打开，搜索 long_query_time找到配置区域，其中有一些其他的配置，与慢查询无关已经剔除：12345# General and Slow logging.log-output=FILEslow-query-log=1slow_query_log_file="0491NPORIURNUYO-slow.log"long_query_time=0.01 slow-query-log：慢查询日志的开关，1表示开启，0表示关闭。Mysql5.1之前貌似是默认关闭的，而我这个版本在安装完成后自动开启了，如果没有可以将其设置为1，重启服务后会自动开启 long_query_time：这个参数很关键，表示慢查询日志的阈值，花费时间超过这个值的sql语句才会被记录，单位是秒，这一点需要注意，网上有些文章说这个参数是毫秒，不知道是不是版本问题，使用时可以测试一下，经测试可以配置成小数 log-output：表示日志存储的方式。FILE 表示将日志存入文件，默认值是FILE，另外可以取值 TABLE ，表示将日志存入数据库表，当然也可以两者都选择，配成 FILE,TABLE 。需要注意的是将日志记录到数据库表中，需耗费更多的系统资源，建议优先记录到文件 log-slow_query_log_file：当配置将日志记录到文件中时，这个参数可以指定文件名，路径一般在配置文件的同级的Data目录下，比如我的是在C:/ProgramData/MySQL/MySQL Server 5.7/Data，当发现sql运行较慢时可以打开这个文件看一下 具体例子 首先我们将long_query_time设置为0.05，也就是记录查询时间超过50毫秒的sql操作，这是个很随意的值，具体的生产环境根据具体情况配置，重启Mysql服务使其生效 创建一张测试表格 slow_query_test 1create table slow_query_test(id int, num int, money int); 然后创建一个存储过程，用来给数据表填充数据，命名为fill_slow_query_test 123456789CREATE PROCEDURE `fill_slow_query_test`()BEGIN DECLARE i int default 1; WHILE i &lt;= 100000 do insert into slow_query_test values(i, i, i); set i = i + 1; END WHILE;END 调用存储过程插入测试数并查询，得到以下结果 12345678910mysql&gt; call fill_slow_query_test();Query OK, 1 row affected (24.45 sec)mysql&gt; select * from slow_query_test where id = 9990;+------+------+-------+| id | num | money |+------+------+-------+| 9990 | 9990 | 9990 |+------+------+-------+1 row in set (0.09 sec) 通过观察结果可以发现，两次操作的时间都超过了0.05s，所以都应该被记录到慢查询日志日志中，打开日志查看内容 12345678910111213C:\Program Files\MySQL\MySQL Server 5.7\bin\mysqld.exe, Version: 5.7.21-log (MySQL Community Server (GPL)). started with:TCP Port: 3306, Named Pipe: (null)Time Id Command Argument# Time: 2019-03-25T03:14:50.241968Z# User@Host: root[root] @ localhost [::1] Id: 2# Query_time: 24.447215 Lock_time: 0.000364 Rows_sent: 0 Rows_examined: 0SET timestamp=1553483690;call fill_slow_query_test();# Time: 2019-03-25T03:15:27.862107Z# User@Host: root[root] @ localhost [::1] Id: 2# Query_time: 0.050133 Lock_time: 0.000133 Rows_sent: 1 Rows_examined: 100000SET timestamp=1553483727;select * from slow_query_test where id = 9990; 日志中的内容与我们猜想的基本一致，但是还要多一些，首先前3行是Mysql服务启动的记录，接下来的是Mysql慢查询日志的正文，每组都通过3行注释分隔： Time：记录执行操作时的日期和时间，默认没有包含时区信息，是标准的UTC时间 User@Host 记录执行操作的主机和用户，以及Mysql连接id等信息 Query_time 记录了查询消耗的时间，以及其他的一些操作信息接下来未被注释的内容就是真正执行的操作，包含当时的时间戳和具体执行的语句 简单优化针对于上述的例子，我们可以运用上一篇文章《Mysql查询可通过给条件字段添加索引提高查询速度》 提到的方法，简单优化一下： 首先给id字段添加简单索引 123mysql&gt; ALTER TABLE slow_query_test ADD INDEX id_index(id);Query OK, 0 rows affected (0.14 sec)Records: 0 Duplicates: 0 Warnings: 0 然后使用相同的sql语句再次查询 1234567mysql&gt; select * from slow_query_test where id = 9990;+------+------+-------+| id | num | money |+------+------+-------+| 9990 | 9990 | 9990 |+------+------+-------+1 row in set (0.04 sec) 对比前后的查询我们发现，加了索引的表格查询耗时已经小于0.05s，所以该查询不会被记录到慢查询日志中了 慢查询日志格式化处理有时面对慢查询日志文件内众多的数据确实无从下手，这是可以考虑使用mysql自带的mysqldumpslow工具来分析慢查询日志，该工具一般与mysql可执行文件在同一目录，比如我的是在C:/Program Files/MySQL/ySQL Server 5.7/bin&gt;，直接运行发现会报错 12C:\Program Files\MySQL\MySQL Server 5.7\bin&gt;mysqldumpslow'mysqldumpslow' 不是内部或外部命令，也不是可运行的程序或批处理文件。 仔细观察会发现，这个工具不知何时已经从可执行文件变成了一个Perl脚本mysqldumpslow.pl（之前使用linux版本是可执行文件）了，不能直接运行，需要安装Perl运行环境，这里有官方的下载地址，如果下载太慢的话可以下载我的备份文件，版本是一样的。 安装完成之后查看帮助（注意文件路径）12345678910111213141516171819202122232425262728PS C:\Program Files\MySQL\MySQL Server 5.7\bin&gt; perl mysqldumpslow.pl --helpUsage: mysqldumpslow [ OPTS... ] [ LOGS... ]Parse and summarize the MySQL slow query log. Options are --verbose verbose --debug debug --help write this text to standard output -v verbose -d debug -s ORDER what to sort by (al, at, ar, c, l, r, t), 'at' is default al: average lock time ar: average rows sent at: average query time c: count l: lock time r: rows sent t: query time -r reverse the sort order (largest last instead of first) -t NUM just show the top n queries -a don't abstract all numbers to N and strings to 'S' -n NUM abstract numbers with at least n digits within names -g PATTERN grep: only consider stmts that include this string -h HOSTNAME hostname of db server for *-slow.log filename (can be wildcard), default is '*', i.e. match all -i NAME name of server instance (if using mysql.server startup script) -l don't subtract lock time from total time 看完使用方法，我们可以按照查询消耗的时间排序输出前两条日志（注意日志的路径，为方便可以拷贝到mysqldumpslow工具目录）: 12345678PS C:\Program Files\MySQL\MySQL Server 5.7\bin&gt; perl mysqldumpslow.pl -s t -v -t 2 0491NPORIURNUYO-slow.logReading mysql slow query log from 0491NPORIURNUYO-slow.logCount: 1 Time=24.45s (24s) Lock=0.00s (0s) Rows=0.0 (0), root[root]@localhost call fill_slow_query_test()Count: 1 Time=0.05s (0s) Lock=0.00s (0s) Rows=1.0 (1), root[root]@localhost select * from slow_query_test where id = N 可以发现还是很方便的，最耗时的操作已经排到了第一位，在实际的优化过程中，这或许就是我们需要拿来开刀的目标了。 总结 通过修改配置文件my.ini中的slow-query-log、long_query_time来调整慢查询日志的开关和具体阈值 通过mysqldumpshow工具可以格式化慢查询日志，方便定位问题和分析问题]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>慢查询</tag>
        <tag>日志</tag>
        <tag>分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql查询可通过给条件字段添加索引提高查询速度]]></title>
    <url>%2Fblog%2F2019%2F03%2F15%2FMysql%E6%9F%A5%E8%AF%A2%E5%8F%AF%E9%80%9A%E8%BF%87%E7%BB%99%E6%9D%A1%E4%BB%B6%E5%AD%97%E6%AE%B5%E6%B7%BB%E5%8A%A0%E7%B4%A2%E5%BC%95%E6%8F%90%E9%AB%98%E6%9F%A5%E8%AF%A2%E9%80%9F%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[前言当使用sql语句查询表数据时，会发现随着表中记录的增多，查询的速度也会也来越慢，特别是那种日志记录，少则几十万，多则上百万，甚至上千万数据，如果查询一次耗时太长，会严重影响业务逻辑，这时候可以考虑给经常作为条件的字段添加索引了，这样做会大大加快查询速度，这里所说的条件字段，就是指sql语句中放到where条件中用于筛选记录的字段，关于加索引提高查询速度的做法，我们可以做一下试验，对比一下看看是否真的有效。 测试环境 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 8Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. 测试过程 首先创建一个不带有索引的数据表 tb_without_index 1create table tb_without_index(id int, num int, money int); 然后创建一个存储过程，用来给无索引数据表填充数据，命名为fill_tb_without_index 123456789CREATE PROCEDURE `fill_tb_without_index`()BEGIN DECLARE i int default 1; WHILE i &lt;= 100000 do insert into tb_without_index values(i, i, i); set i = i + 1; END WHILE;END 接着创建一个带有索引用来做对比的数据表 tb_with_index 1create table tb_with_index(id int, num int, money int, key `id_index`(id)); 同样创建一个给带索引数据表填充数据的存储过程 fill_tb_with_index 123456789CREATE PROCEDURE `fill_tb_with_index`()BEGIN DECLARE i int default 1; WHILE i &lt;= 100000 do insert into tb_with_index values(i, i, i); set i = i + 1; END WHILE;END 分别调用存储过程来填充数据，每个表填充需要20多秒，还是挺费时间的 12345mysql&gt; call fill_tb_without_index();Query OK, 1 row affected (25.48 sec)mysql&gt; call fill_tb_with_index();Query OK, 1 row affected (25.64 sec) 查询对比 对于单条数据的查询对比 123456789101112131415mysql&gt; select * from tb_with_index where id = 67853;+-------+-------+-------+| id | num | money |+-------+-------+-------+| 67853 | 67853 | 67853 |+-------+-------+-------+1 row in set (0.05 sec)mysql&gt; select * from tb_without_index where id = 67853;+-------+-------+-------+| id | num | money |+-------+-------+-------+| 67853 | 67853 | 67853 |+-------+-------+-------+1 row in set (0.08 sec) 对于范围数据的查询对比 123456789101112131415mysql&gt; select count(id) from tb_without_index where id &gt; 87862;+-----------+| count(id) |+-----------+| 12138 |+-----------+1 row in set (0.09 sec)mysql&gt; select count(id) from tb_with_index where id &gt; 87862;+-----------+| count(id) |+-----------+| 12138 |+-----------+1 row in set (0.05 sec) 结果分析 通过上面两种情况的对比，我们可以发现虽然每组对比只差零点零几秒的时间，但是从耗时来看有索引的表格查询比没有索引的表格查询节省了大约40%的时间，由此可见，给待查字段添加上索引，确实可以加快查询速度。 既然加上索引的效率可以提升这么多，那么可不可以把所有字段都加上索引呢？答案是不可以，这一点可以从测试过程的第5步结果来分析，这一步中给表格 tb_without_index 添加10万条数据耗时25.48秒，给表格 tb_with_index 添加10万条数据耗时25.64秒，也就是给有索引的表添加数据时要多花0.16秒的时间，这不是偶然的，可以反复测试，每次的测试结果都是有索引表的数据插入过程更耗时一点。 通过上面的对比和分析，可以知道，虽然添加索引可以加快查找速度，但是会拖慢插入和更新的速度，因为在有索引的数据表上更新和插入需要多花费时间来维护索引，至于两者之间的平衡，就需要使用者自己把握了。 添加索引 像上面提到的那样，可以在建表的时候就定义好索引，查询表结构发现字段id所在行的Key列值为MUL，表示它的值是可以重复的索引，其他两个字段都没有 12345678910create table tb_with_index(id int, num int, money int, key `id_index`(id));mysql&gt; desc tb_with_index;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | MUL | NULL | || num | int(11) | YES | | NULL | || money | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+3 rows in set (0.05 sec) 在已有的表格上创建索引，比如可以在列num上创建一个索引，语法：CREATE INDEX index_name ON table_name(column_list) 12345678910111213mysql&gt; CREATE INDEX num_index ON tb_with_index(num);Query OK, 0 rows affected (0.23 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc tb_with_index;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | MUL | NULL | || num | int(11) | YES | MUL | NULL | || money | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+3 rows in set (0.05 sec) 修改表结构添加索引，比如可以给列num添加一个索引，语法：ALTER TABLE table_name ADD INDEX index_name(column_list) 12345678910111213mysql&gt; ALTER TABLE tb_with_index ADD INDEX money_index(money);Query OK, 0 rows affected (0.21 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc tb_with_index;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | MUL | NULL | || num | int(11) | YES | MUL | NULL | || money | int(11) | YES | MUL | NULL | |+-------+---------+------+-----+---------+-------+3 rows in set (0.06 sec) 查看索引可以查看一个表上的所有索引信息，语法为：show index from table_name，查询结果如下 123456789 mysql&gt; show index from tb_with_index; +---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+ ---------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | +---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+ ---------------+ | tb_with_index | 1 | id_index | 1 | id | A | 98715 | NULL | NULL | YES | BTREE | | | | tb_with_index | 1 | num_index | 1 | num | A | 100035 | NULL | NULL | YES | BTREE | | | | tb_with_index | 1 | money_index | 1 | money | A | 100035 | NULL | NULL | YES | BTREE | | | +---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+ ---------------+3 rows in set (0.06 sec) 总结 给条件字段添加索引可以大大加快数据的查询速度，提高系统的性能。 不要考虑在所有的字段上添加索引，创建索引和维护索引都要耗费时间，这种时间随着数据量的增加而增加。 适合添加索引的字段：总是作为条件查询的字段、常用来做连接的字段、作为主键或者强调唯一的列上。 不适合加索引的字段：块数据类型的字段、取值很少的字段。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>索引</tag>
        <tag>index</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下查找包含指定内容的文件及其所在行数]]></title>
    <url>%2Fblog%2F2019%2F03%2F13%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%9F%A5%E6%89%BE%E5%8C%85%E5%90%AB%E6%8C%87%E5%AE%9A%E5%86%85%E5%AE%B9%E7%9A%84%E6%96%87%E4%BB%B6%E5%8F%8A%E5%85%B6%E6%89%80%E5%9C%A8%E8%A1%8C%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言在linux系统下搜索文件一般情况下一个命令就搞定了，之前搜索文件的时候一直使用find，今天排查问题时想查一个函数的调用者在哪个文件中，发现不会写了，搜了一下发现使用grep命令就可以实现，改变了我对grep命令的理解，原来使用grep命令的情况通常是作为结果的过滤函数，比如ps aux | grep gameserver，这次发现他居然还可以直接用来搜索，其实也是过滤的一种。 使用方法这里直接给出命令的写法，简单替换搜索内容就可以使用，也方便自己后续查找使用(例如查找包含stream的文件)：1grep -rn 'stream' . --include='*.cpp' 命令解析上述命令是一种比较常用的写法，就是在当前目录下（一定要注意那个.）查找包含stream的文件，并显示其所在的行，搜索的文件类型是.cpp，其实--include=后面的内容是遵循glob语法的，详细的就不展开了，简单来说就是支持通配符，而查找选项-rn中的r表示递归查找，其中的n表示显示行号，此外还可以使用选项-i表示忽略大小写，下面简单展示一下3个选项的功能： -r：只递归查找不显示行号 1234567891011[albert@localhost#18:17:41#/home/albert/test]$grep -r 'stream' . --include='*.cpp'./testPtr.cpp:#include &lt;iostream&gt;./crab-server/code/main/crab.cpp:#include &lt;iostream&gt;./testConstructor.cpp:#include &lt;iostream&gt;./smartptr/auto_ptr.cpp:#include &lt;iostream&gt;./io.cpp:#include &lt;fstream&gt;./io.cpp: ofstream logfile("./logs/players_distribution.txt", ios::out);./ptr.cpp:#include &lt;iostream&gt;./gdbtest/main.cpp:#include &lt;iostream&gt;./test_t.cpp:#include &lt;iostream&gt;./testshareptr.cpp:#include &lt;iostream&gt; -rn：递归查找并显示行号 1234567891011[albert@localhost#18:17:48#/home/albert/test]$grep -rn 'stream' . --include='*.cpp'./testPtr.cpp:4:#include &lt;iostream&gt;./crab-server/code/main/crab.cpp:3:#include &lt;iostream&gt;./testConstructor.cpp:1:#include &lt;iostream&gt;./smartptr/auto_ptr.cpp:4:#include &lt;iostream&gt;./io.cpp:1:#include &lt;fstream&gt;./io.cpp:9: ofstream logfile("./logs/players_distribution.txt", ios::out);./ptr.cpp:4:#include &lt;iostream&gt;./gdbtest/main.cpp:1:#include &lt;iostream&gt;./test_t.cpp:1:#include &lt;iostream&gt;./testshareptr.cpp:4:#include &lt;iostream&gt; -rni：递归查找显示行号并且忽略大小写 12345678910111213141516171819202122[albert@localhost#18:17:53#/home/albert/test]$grep -rni 'stream' . --include='*.cpp'./testPtr.cpp:4:#include &lt;iostream&gt;./crab-server/code/main/crab.cpp:3:#include &lt;iostream&gt;./testConstructor.cpp:1:#include &lt;iostream&gt;./epoll_cs_demo/testfd.cpp:5: int listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/testfd.cpp:8: listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/testfd.cpp:11: listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/testfd.cpp:14: listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/testfd.cpp:21: listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/testfd.cpp:25: listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/client.cpp:18: int client_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/server.cpp:24: int listen_fd = socket(AF_INET, SOCK_STREAM, 0);./smartptr/auto_ptr.cpp:4:#include &lt;iostream&gt;./io.cpp:1:#include &lt;fstream&gt;./io.cpp:9: ofstream logfile("./logs/players_distribution.txt", ios::out);./network/zgetaddrinfo.cpp:37: hints.ai_socktype = SOCK_STREAM;/* Stream socket */./linux_version/client.cpp:15: int client_fd = socket(AF_INET, SOCK_STREAM, 0);./linux_version/server.cpp:15: int listen_fd = socket(AF_INET, SOCK_STREAM, 0);./ptr.cpp:4:#include &lt;iostream&gt;./gdbtest/main.cpp:1:#include &lt;iostream&gt;./test_t.cpp:1:#include &lt;iostream&gt;./testshareptr.cpp:4:#include &lt;iostream&gt; 总结 查找指定内容的简单命令：grep -rn &#39;stream&#39; . --include=&#39;*.cpp&#39; 这个grep有很多附加的参数，看了文档之后发现了一个点，原来用法：egrep即grep -E，fgrep即rep -F，但是 egrep 和 fgrep现在都不建议使用了，无论是man手册还是--help选项中都提到了这一点]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>find</tag>
        <tag>查找</tag>
        <tag>linux</tag>
        <tag>grep</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为目标打好基础的希尔排序]]></title>
    <url>%2Fblog%2F2019%2F03%2F09%2F%E4%B8%BA%E7%9B%AE%E6%A0%87%E6%89%93%E5%A5%BD%E5%9F%BA%E7%A1%80%E7%9A%84%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言刚刚分析过的插入排序通常被叫做简单插入排序或者直接插入排序，而这篇文章刚好以插入排序为基础来说说希尔排序，还是先从名字开始，结果发现完全没有头绪，说实话第一次听说这个排序时还以为是个特别神奇的高端算法，结果了解一番之后发现其实是一个被改造的插入排序，“希尔”居然是发明者的名字，所以从名字来判断算法思想在这里行不通，甚至说快速排序起码说明了这种方法排序快，而希尔排序等于什么都没说。 希尔排序的基础是插入排序，整个排序也是在新元素不断插入到有序序列适当位置的过程中完成的，唯一的不同的就是通过不同的步长将整个序列划分为不同的小序列不断插入，直到步长为1时就退化成了最基本的直接插入排序，但是此时整个序列已经“基本”有序了，需要交换的元素对比一开始直接插入的方法明显减少，从而可以加快排序的速度，因为最后步长为1的一次插入排序与简单插入排序完全相同，所以前面的几趟排序完全可以看做是最后的排序目标“打基础”，让最后一次的排序序列尽可能有序，下面描述一下希尔排序的过程，前提是你已经了解简单插入排序的过程，可以参考文章抓扑克牌风格的插入排序熟悉一下。 希尔排序希尔排序的有一个关键的元素是步长，关于步长的选择有很多种方法，比如只选奇数，选择互为质数等等，其目的就是为了减少重复比较的次数，我们现在只为了解希尔排序的过程，所以先选择一种简单的步长选定方法，以元素个数的一半为基础，每次减少一半直到步长降为1，比如10个元素的步长选择分别为5,2,1，本质思想就是分别以步长5,2,1对整个待排序列进行简单的插入排序，最后就完成了整个序列的排序。 我们用物品重量排序作为例子吧，原来插入排序的例子是将新得到的扑克牌不断插入到有序序列中得到最终排序，这次可以直接先给出物品质量序列的初始排列，假设为99, 34, 54, 65, 11, 1, 5, 12, 89, 42，一共10件物品摆在面前，目标为将物品重量从小到大排序，首先选取步长5开始排序过程： 最开始的排序序列如下:99, 34, 54, 65, 11, 1, 5, 12, 89, 42 以步长为5将整个序列分为5组，分组情况如下：99, _, _, _, _, 1, _, _, _, __, 34, _, _, _, _, 5, _, _, __, _, 54, _, _, _, _, 12, _, __, _, _, 65, _, _, _, _, 89, __, _, _, _, 11, _, _, _, _, 42 将这五组子序列分别使用简单插入排序，得到以下序列：1, _, _, _, _, 99, _, _, _, __, 5, _, _, _, _, 34, _, _, __, _, 12, _, _, _, _, 54, _, __, _, _, 65, _, _, _, _, 89, __, _, _, _, 11, _, _, _, _, 42 这五个子序列组成完整的中间临时序列为：1, 5, 12, 65, 11, 99, 34, 54, 89, 42 然后以步长为2将整个序列划分，得到以下分组情况：1, _, 12, _, 11, _, 34, _, 89, __, 5, _, 65, _, 99, _, 54, _, 42 将这两组子序列使用简单插入排序，得到以下序列：1, _, 11, _, 12, _, 34, _, 89, __, 5, _, 42, _, 54, _, 65, _, 99 将子序列整体来看得到中间临时序列：1, 5, 11, 42, 12, 54, 34, 65, 89, 99 最后再将整个待排序列进行一次简单插入排序，便可得到最终排好的序列，实际上最后一次插入排序只有中间几个元素需要移动了：1, 5, 11, 12, 34, 42, 54, 65, 89, 99 代码实现12345678910111213141516171819202122232425262728293031323334353637/*功能： 交换两个变量参数： element1--被交换的第一个元素的地址 element2--被交换的第二个元素的地址返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void swap_data(int* element1, int* element2)&#123; int middle_value = *element1; *element1 = *element2; *element2 = middle_value;&#125;/*功能： 希尔排序，实现数组元素从小到大排列参数： array--表示待排序的数组，此处会退化成指针 count--数组元素的个数返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void shell_sort(int array[], int count)&#123; int step = count / 2; while (step &gt; 0) &#123; for (int pos = step; pos &lt; count; ++pos) &#123; for (int insert_index = pos; insert_index &gt;= step; insert_index -= step) &#123; if (array[insert_index] &lt; array[insert_index - step]) swap_data(&amp;array[insert_index], &amp;array[insert_index - step]); &#125; &#125; step /= 2; &#125;&#125; 对比插入排序源代码，找找不同 1234567891011void insert_sort(int array[], int count)&#123; for (int pos = 1; pos &lt; count; ++pos) &#123; for (int insert_index = pos; insert_index &gt; 0; --insert_index) &#123; if (array[insert_index] &lt; array[insert_index - 1]) swap_data(&amp;array[insert_index], &amp;array[insert_index - 1]); &#125; &#125;&#125; 代码分析以上代码就是希尔排序的实现方式了，对比直接插入的源代码发现，如果将希尔排序的初始步长设置成1，那么整个希尔排序的代码就和简单插入排序完全一样了，这也符合我们之前分析的过程，其实希尔排序就是分多次，每次用不同的步长执行简单插入排序。 还有一点就是代码执行的过程与上面示例中的分组插入看起来有些不同，只是因为这个写起来更方便一些，分组只是为了人脑能更快的理解算法的思想，但是代码编写时还要考虑复杂性，将数据拆分成几组然后分别进行插入排序完全可以做到，但是实际上完全没有必要。 比如分成两组排序的那一步，直观上先排索引为0,2,4,6,8上的元素，依次做插入操作，然后排索引为1,3,5,7,9上的元素，在依次做插入操作，但是在实现的代码中就做了变通，反正都要做插入操作，并且步长都是2，所以可以直接对索引是0,1,2,3,4,5,6,7,8,9上的元素做插入排序，只要注意步长是2，就不会影响到其他组（实际上并不存在）的元素了，整个过程顺着代码，一步步执行就明白了。 运行测试希尔排序–源码 如果你想运行测试一下，可以复制或者下载源代码，在本机运行测试一下，当然也可以选择在线C++编译器，把源代码复制到网页中运行查看结果，建议不明白的可以在本地环境单步调试一下，这样有助于理解算法思路。]]></content>
      <categories>
        <category>Sort</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>算法</tag>
        <tag>概念</tag>
        <tag>Sort</tag>
        <tag>希尔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下运行程序常用的nohup和&的区别]]></title>
    <url>%2Fblog%2F2019%2F02%2F25%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F%E5%B8%B8%E7%94%A8%E7%9A%84nohup%E5%92%8C-%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言复杂问题简单记，先了解一下概念，对于一般的小程序而言这两种启动方法应该用不上，如果程序瞬间的就结束了，是否挂起与是否后台也就没有了意义，所以标题中提到的方式常用来启动需要一直运行的程序，比如游戏服务器。 假如我们直接通过命令行./game_server运行一个简单的游戏服务器，那么会发现这个运行程序霸占了整个命令窗口，此时，我们无法再运行其他的程序，所有的输入都变成了game_server的输入，而命令终端此时也只能输出game_server程序的输出信息了。 接着再来了解两个信号，针对于霸占了命令终端的game_server我们可以采用以下方式将其终止掉，使用Ctrl+C组合键，实际上是给程序发送了SIGINT信号，可以以直接关掉命令终端，这个进程也会死掉，实际上是给程序发送了SIGHUP信号，而标题中的所说的两种方式就是针对于这两种信号的。 两种方式的区别 nohupnohup是no hang up的缩写，就是不挂断的意思，忽略SIGHUP信号，在关闭命令终端后程序依旧运行 &amp;&amp;是只后台运行，即忽略SIGINT信号，也就是按Ctrl+C不会终止程序，但是关闭命令行终端程序终止 总结所以要想程序忽略SIGINT和SIGHUP两种信号需要两种表示方法一同使用，总结如下 命令 忽略信号 按Ctrl+C结果 关闭终端 标准输入 输出 ./game 无 程序终止 程序终止 只能给game输入 终端输出 nohup ./game SIGHUP 程序终止 依旧运行 输入被忽略 输出到nohup.out文件 ./game &amp; SIGINT 依旧运行 程序终止 输入正常，终端可用 无输出 nohup ./game &amp; SIGINT、SIGHUP 依旧运行 依旧运行 输入正常，终端可用 输出到nohup.out文件]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nohup</tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下服务器程序的查看与gdb调试]]></title>
    <url>%2Fblog%2F2019%2F01%2F11%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9F%A5%E7%9C%8B%E4%B8%8Egdb%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[前言这一篇主要是记录下调试服务器程序常用的命令，内容很简单，但是长时间不用很容易记混，因为游戏服务器也不是天天宕机，所以当有一天突然挂掉需要调试的时候，如果记不清调试命令很容易耽误时间，有好几次我就把gdb gameserver core记成了gdb core gameserver，所以干脆把这些内容统计到一起，查询的时候也方便。 查询程序的运行情况 ps aux命令是常用来查询程序进程运行情况的，基本上不会漏掉，但是显示的无关程序太多，看着不方便所以常配合grep过滤 ps aux | grep gameserver可以显示指定过滤内容的程序，但是这种显示方式没有标题，对于不熟悉的人来说看不太明白，就像下面这样 123$ps aux | grep initroot 1 0.0 0.0 19232 976 ? Ss 2018 0:01 /sbin/init510 2042 0.0 0.0 105492 932 pts/2 S+ 10:04 0:00 grep init 所以这里给出ps aux默认的输出格式：USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND其中STAT: 该行程的状态，linux的进程常见状态：D 不可中断 uninterruptible sleep (usually IO)R 运行 runnable (on run queue)S 中断 sleepingT 停止 traced or stoppedZ 僵死 a defunct or zombie process注: 其它状态还包括W(无驻留页), &lt;(高优先级进程), N(低优先级进程), L(内存锁页). ps -eo pid,lstart,etime,command | grep gameserver有时需要查询特定进程的指定信息，比如运行时间，那么可以通过-o选项来指定，显示信息很明确 1215499 Thu Jan 10 23:22:53 2019 11:24:12 ./gameserver -d18097 Fri Jan 11 10:47:04 2019 00:01 grep gameserver 杀死指定进程 killall -10 gameserver: 按照进程名杀死进程，-10为自定义杀死信号 kill -10 gameserver_pid: 按照进程ID杀死进程，-10为自定义杀死信号 kill -9 gameserver_pid: -9为强制杀死进程的信号，无法被捕捉 kill -6 gameserver_pid: -6可以杀死进程并产生core文件 gdb调试通常要想使用gdb调试需要在编译程序时加上-g选项，之后才能用gdb进行调试：gcc -g main.c -o gameserver，如果想在程序崩溃时产生core文件，还需要设置系统命令ulimit -c unlimited才可以，调试程序又分为直接启动调试、调试core文件和附加到正在运行的进程调试，每种方式的参数略有不同： 直接启动调试，gdb gameserver这种方式相当于直接通过gdb启动了程序，并开启了调试模式，所以是拉取了新的进程 调试core文件，gdb gameserver core.xxx这种方式相当于展示程序崩溃前的堆栈情况，并进行调试，所以也算是拉取了新的进程 附加进程调试，gdb attach gameserver_pid/gdb gameserver gameserver_pid这种方式是将gdb调试工具附加到程序运行的当前进程上，并没有拉取新的进程，操作上也可以先敲gdb回车，然后再attach gameserver_pid，不过这种情况对于其他用户启动的程序，通常会提示“ptrace: 不允许的操作.”，所以需要使用sudo运行gdb gdb常用命令以下命令为调试linux程序常用的gdb命令，都是在调试服务器程序core文件过程中不断积累的，还有一些高级命令一般很少用到，掌握下面这些基本上就可以应付很多场景了，其中打印信息的命令print在打印map、vector等显示不友好，可以参考gdb调试脚本中的内容。 run/r：重新开始运行文件 break/b: 设置断点（I. b filename:linenum, II. b functioname, 条件断点: b position if condition） info/i: 查看信息（I. i b:查看断点信息，i locals: 查看当前帧局部变量值，i threads: 查看线程） delete/d: 删除断点（delete 3：删除通过info breakpoints查到的第3个断点，其实还可以删除别的） list/l: 查看原代码（list -n：显示第n行前后的源代码。list 函数名：查看具体函数） next/n: 逐过程调试（类似于VS的F10） step/s: 逐语句调试（类似于VS的F11） frame/f：切换函数的栈帧（可以调试输出指定函数内的情况） print/p：打印值及地址（用来显示变量值） thread/t: 切换线程（调试指定线程，用来处理多线程程序） continue/c：继续运行（常用调试完断点之后） backtrace/bt：显示堆栈（可以查看函数的调用的栈帧和层级关系） source: 加载脚本（可以在调试过程中使用脚本完成复杂逻辑调试）]]></content>
      <categories>
        <category>gdb</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>linux</tag>
        <tag>gdb</tag>
        <tag>ps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[抓扑克牌风格的插入排序]]></title>
    <url>%2Fblog%2F2018%2F12%2F04%2F%E6%8A%93%E6%89%91%E5%85%8B%E7%89%8C%E9%A3%8E%E6%A0%BC%E7%9A%84%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言上次聊到了快速排序，我们说到快排这个名字是非常抽象的，究竟什么是快排，从名字上我们无从得知，或许叫二分排序都比快速排序要形象的多，可是这又和归并排序重复了，所以我们还是不要在意快排的名字了，接下来看一下今天的插入排序，这里指的是简单的插入排序。 插入排序相比于快速排序要形象很多，整个排序过程就是在不断的插入操作中完成的，如果你打过扑克基本上很容易理解这种排序方法，排序的过程几乎与抓扑克牌的过程一模一样，假设三个人斗地主，每人一张牌依次抓取，其实一旦开始抓一张牌，那么牌堆里哪些牌是你的就已经确定了，只不过是隔两张之后的那张就是你的，所有这些归属于你的牌在牌堆里的顺序就是这些牌的初始顺序，而你抓牌摆牌的过程就是给这些牌从小到大（当然可以从大到小）排序的过程。 插入排序整个排序过程可以使用抓牌来模拟，抓第一张牌的时候无所谓顺序，放在手里就好，抓第二张牌的时候和第一张比较，按从小到大排好顺序，抓第三张牌的时候，和前面两张比较，“插入”适当的位置，后面的牌依次类推插入正确位置，最后手里的牌也就排好了顺序，还有一点需要注意，抓牌时可以真的将一张牌插入到另外两张牌之间的（实际上也是占用了原来牌的位置），但是在内存中，比如连续下标的一个数组中，要想在元素2和元素3中间插入一个数字是做不到的，如果确实要放到这两个数中间，那就需要将元素3往后移动，给需要插入的这个数字腾出一个地方，元素3后面如果也有其他元素呢？那就也需要向后移动，一直到后面没有需要移动的元素为止。 想象一下完整的抓牌过程，其中的关键点就在于拿到一张新牌（元素）后，和之前有序的手牌进行比较，找到合适的插入位置，依次移动手牌位置（为了仿照内存中移动，我们把牌向后移动，也就是从后向前比较找插入位置），为新来的牌腾出一个位置，把新抓到的牌放入空位，一直到完成最后一张牌的插入，我们也就同时完成了手牌的排序。其中的关键词有之前有序、移动、插入。 接下来可以举个例子操作一下，假设我开了天眼，可以看到牌堆里所有的牌，那么确定了抓牌顺序之后，我也就知道我会抓到哪些牌了，他们分别是6, 2, 7, 3, 8, 9，下面来模拟一下这个牌堆中的牌到了我的手里时候怎么就有序了，还有一个情况就是我用右手摸牌，左手拿牌，但是左手比较小，只能放的下6张牌，这时候可以看看实际的抓牌流程了。 起初情况是左手没有牌，右手抓了一张6:L=_, _, _, _, _, _，R=6 这时候没有什么犹豫的，直接放到左手第一个位置就好了：L=6, _, _, _, _, _ ，R=_ 然后又抓到一张2，移动左手的牌，拿2和左手有序的牌进行比较，这是左手就1张6，将其向后移动得到：L=_, 6, _, _, _, _ ，R=2 接下来需要把右手的2放到左手腾出的位置即可：L=2, 6, _, _, _, _ ，R=_ 紧接着又抓到一张7，发现放到后面就可以，不用移动元素了：L=2, 6, 7, _, _, _ ，R=_ 然后又抓到一张3，其实找插入位置还有另一种形式，就是放到最后，然后不断的换到合适的位置，用这张3来试一下：L=2, 6, 7, _, _, _ ，R=3 先放到左手最后：L=2, 6, 7, 3, _, _ ，R=_ 然后和前面比3大的换一下位置：L=2, 6, 3, 7, _, _ ，R=_ 再换一次找到了真正插入的位置：L=2, 3, 6, 7, _, _ ，R=_ 后面的8，9两张都不需要交换位置，直接放到最后就得到了最终的结果：L=2, 3, 6, 7, 8, 9 ，R=_ 代码实现1234567891011121314151617181920212223242526272829303132/*功能： 交换两个变量参数： element1--被交换的第一个元素的地址 element2--被交换的第二个元素的地址返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void swap_data(int* element1, int* element2)&#123; int middle_value = *element1; *element1 = *element2; *element2 = middle_value;&#125;/*功能： 插入排序，实现数组元素从小到大排列参数： array--表示待排序的数组，此处会退化成指针 count--数组元素的个数返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void insert_sort(int array[], int count)&#123; for (int pos = 1; pos &lt; count; ++pos) &#123; for (int insert_index = pos; insert_index &gt; 0; --insert_index) &#123; if (array[insert_index] &lt; array[insert_index - 1]) swap_data(&amp;array[insert_index], &amp;array[insert_index - 1]); &#125; &#125;&#125; 代码分析以上代码就是模拟的抓牌过程，新加入的牌放到手牌最后，然后不断的和前面的手牌交换位置，“插入”到有序的手牌序列中，最后得到整体有序，配合前面具体的例子，可以把具体的那些数字带入到这段代码中，头脑中或者在纸上“运行”一下，你就会了解插入排序的原理了。 运行测试快速排序–源码 如果你想运行测试一下，可以复制或者下载源代码，在本机运行测试一下，当然也可以选择在线C++编译器，把源代码复制到网页中运行查看结果，建议不明白的可以在本地环境单步调试一下，这样有助于理解算法思路。]]></content>
      <categories>
        <category>Sort</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>算法</tag>
        <tag>概念</tag>
        <tag>Sort</tag>
        <tag>插入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中使用select into语句给变量赋值没有匹配记录时的结果]]></title>
    <url>%2Fblog%2F2018%2F11%2F17%2FMysql%E4%B8%AD%E4%BD%BF%E7%94%A8select-into%E8%AF%AD%E5%8F%A5%E7%BB%99%E5%8F%98%E9%87%8F%E8%B5%8B%E5%80%BC%E6%B2%A1%E6%9C%89%E5%8C%B9%E9%85%8D%E8%AE%B0%E5%BD%95%E6%97%B6%E7%9A%84%E7%BB%93%E6%9E%9C%2F</url>
    <content type="text"><![CDATA[前言对select into语句感兴趣是因为看了项目中的一个存储过程引起的，在程序运行之前看了存储过程的逻辑，本以为没有数据时会报错，结果程序却正常运行，这说明我对select into语句理解的问题，同时也暴露了一个知识盲点，所以写了个小例子测试一下，并把测试的过程记录方便日后查找。 创建测试表格为了更清楚的表明问题，我们创建的表格尽可能的简单，同时为了测试空值的情况，数据列我们不设置默认值，表格命名为’intotest’，创建语句如下： 12345CREATE TABLE `intotest` ( `id` int(4) NOT NULL AUTO_INCREMENT, `number` int(4), PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=binary ROW_FORMAT=DYNAMIC; 插入测试数据表格建立完成可以使用可视化工具或者insert语句插入测试数据，插入测试数据后查询结果如下： 123456789mysql&gt; select * from intotest;+----+--------+| id | number |+----+--------+| 1 | 1 || 2 | 2 || 3 | NULL |+----+--------+3 rows in set (0.00 sec) 建立一个存储过程我们建立一个用于测试的存储过程，主要的逻辑就是看看当select into语句找不到匹配记录时，被赋值的变量会怎么样，建立存储过程的代码如下： 1234567CREATE PROCEDURE `select_into_value2`()BEGIN DECLARE _value INT DEFAULT 0; SELECT number FROM intotest WHERE id=1 INTO _value; SELECT _value;END 这个存储过程运行正常，配合刚才我们插入表格的记录可以知道，运行后的结果为1: 123456789mysql&gt; call select_into_value();+--------+| _value |+--------+| 1 |+--------+1 row in set (0.00 sec)Query OK, 0 rows affected (0.00 sec) 测试过程 当查询结果中不存在符合条件的记录时会怎样，修改存储过程定义，然后查看运行结果： 1234567CREATE PROCEDURE `select_into_value2`()BEGIN DECLARE _value INT DEFAULT 0; SELECT number FROM intotest WHERE id=5 INTO _value; SELECT _value;END 123456789mysql&gt; call select_into_value();+--------+| _value |+--------+| 0 |+--------+1 row in set (0.00 sec)Query OK, 0 rows affected (0.00 sec) 结果为0，也就是说当查不到匹配结果时，不会执行select into的赋值效果。 当匹配到查询结果但是查询出来的数值为null会怎样，修改存储过程定义，然后查看运行结果： 1234567CREATE PROCEDURE `select_into_value2`()BEGIN DECLARE _value INT DEFAULT 0; SELECT number FROM intotest WHERE id=3 INTO _value; SELECT _value;END 123456789mysql&gt; call select_into_value();+--------+| _value |+--------+| NULL |+--------+1 row in set (0.00 sec)Query OK, 0 rows affected (0.00 sec) 结果为NULL，也就是说当查到匹配结果时，不管结果时什么都会赋值到指定的变量中（类型不匹配的sql错误除外）。 当连续查询赋值中间出现不匹配会怎样，修改存储过程定义，然后查看运行结果： 12345678CREATE PROCEDURE `select_into_value2`()BEGIN DECLARE _value INT DEFAULT 0; SELECT number FROM intotest WHERE id=2 INTO _value; SELECT number FROM intotest WHERE id=5 INTO _value; SELECT _value;END 123456789mysql&gt; call select_into_value();+--------+| _value |+--------+| 2 |+--------+1 row in set (0.00 sec)Query OK, 0 rows affected (0.00 sec) 想必明白了前两种情况，这第三种也应该明白了，两条语句顺序执行，找到匹配的就赋值，找不到就放弃操作，结果就保留了上一次成功赋值的结果。 总结 关于select into语句赋值的规则就一句话，找到了符合条件的记录就赋值，找不到就算了。 在找到记录的前提下，如果类型不匹配会导致赋值失败并报错，比如查询到字符串赋值给整型变量。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>查询赋值</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua中关于table对象引用传递的注意事项]]></title>
    <url>%2Fblog%2F2018%2F09%2F18%2FLua%E4%B8%AD%E5%85%B3%E4%BA%8Etable%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E4%BC%A0%E9%80%92%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[前言最近写了挺长一段时间的Lua，发现Lua这个语言真的是很随意，产生这种感觉的根本原因应该是它把“函数” 作为了“第一类值”，也就是说函数也可以作为变量的“值”，这使得Lua可以随处定义函数，进而改变逻辑的走向，整个流程任你摆布。 虽说把一个函数来回设置方便了许多，但是同样带来了一些不容易发现的问题，如果搞不清定义域和引用关系，常常会导致程序错误，比如最近用Lua写按钮的触发事件时，使用公有函数创建了对应的闭包，一开始感觉table的引用有问题，写了很多中转的代码，最后发现直接就可以使用，浪费了不少时间，最后仔细分析就是闭包最根本的形式，只不过被业务逻辑给干扰了视线，接下来我们一起看看，table和闭包究竟会发生什么关系！ 代码测试 table作为函数参数时的操作 123456789101112131415print("\nexample 1:");data_table = &#123;a = 1, b = 2, 3, 4, 5, 6&#125;;function filter(data_tb) for k,v in pairs(data_tb) do if v % 2 == 0 then data_tb[k] = nil; end endend-- 过滤掉偶数filter(data_table);for k,v in pairs(data_table) do print(k,v)end 1234example 1:1 33 5a 1 以上为去掉table中的偶数的代码，直接操作参数data_tb就可以对传入的data_table进行改变，这样的逻辑一般不会出错，接着我们看下接下来需求，直接将表中数据清空。 1234567891011print("\nexample 2:");data_table = &#123;a = 1, b = 2, 3, 4, 5, 6&#125;;function destroy(data_tb) data_tb = &#123;&#125;;end-- 销毁整个表destroy(data_table);for k,v in pairs(data_table) do print(k,v)end 1234567example 2:1 32 43 54 6b 2a 1 看到这次的输出可能有些人就感到奇怪了，怎么上个例子改变元素可以，而这里直接给变量data_tb赋值，变成空表怎么不行了？这是因为data_tb是对变量data_table的整体引用，所以可以通过data_tb来改变变量data_table内部的值，但是当执行data_tb = {};代码时表示data_tb不再引用data_table，而去引用{}了，也就是data_tb和data_table脱离了关系，这一点可以类比C++代码： 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;void change_string(char* pStr)&#123; pStr[0] = '5'; pStr[1] = '0'; pStr = "only test\n";&#125;int main()&#123; char szContent[32] = "help"; change_string(szContent); cout &lt;&lt; szContent &lt;&lt; endl; return 0;&#125; 分析一下这段代码的输出结果，如果你能知道结果为50lp，那说明你的C++水平已经超过了入门级别，理解了这段代码有助于清楚的理解前两段Lua代码。 看一个标准闭包实现的计数器 12345678910111213print("\nexample 3:");function counter() local count = 0; return function() count = count + 1; return count; endendfunc = counter();print(func());print(func());print(func()); 1234example 3:123 这段代码的不同之处就在于变量count，这是一个标准的计数器，也是一个标准的闭包，也就是说Lua支持这样的语法，闭包中可以在定义之后一直引用外部的变量，并且在返回函数的整个使用生命周期内都可以引用这个变量，加入外部修改了这个变量，闭包中引用的值也会改变，换句话来说就是闭包这种引用是引用的变量，而不是仅仅保存了一个值。 lua中常见的table引用 12345print("\nexample 4:");local t1 = &#123;i = 1&#125;;local t2 = t1;t1.i = 666;print(t2.i) 12example 4:666 这个例子类似于前面“过滤掉偶数”的代码，首先定义了表t1，然后定义了变量t2引用了变量t1，实际上这里t2不是定义了变量t1本身，而是引用了t1的值，也就是引用的是{i=1}，这里通过t1.i = 666也可以影响到变量t2，其实这个例子看不出引用的究竟是变量t1还是t1的值，可以接着看下面的例子。 12345print("\nexample 5:");local t1 = &#123;i = 1&#125;;local t2 = t1;t1 = &#123;i = 11&#125;;print(t2.i) 12example 5:1 通过这个例子就很清楚了，前面的部分和上个例子一致，但是后面直接给变量t1赋值时并没有改变t2的值，由此可以看出t1和t2已经“分离”了。 table引用和闭包结合的例子 12345678910111213print("\nexample 6:");local tb = &#123;i= 1&#125;;function outer() return function() local t = tb; print(t.i); endendlocal show = outer();tb = &#123;i = 6&#125;;show(); 12example 6:6 这个例子应该会有猜错结果的人，我自己就是在类似的代码中搞糊涂的，一种想法是函数outer定义的时候变量t的值已经定义了，还有一种就是认为在返回函数show的时候变量t的值会定义，但是这两种想法都是错误的，实际上是调用函数show的时候才给t赋值，这时变量t引用的是拥有最新值的tb，所以t.i的值是6，如果你猜对了这个例子的结果，接下来看看下面的代码。 12345678910111213print("\nexample 7:");local tb = &#123;i= 1&#125;;function outer() local t = tb; return function() print(t.i); endendlocal show = outer();tb = &#123;i = 7&#125;;show(); 12example 7:1 如果清楚了上个例子的运行过程，就应该很容易知道这个例子的结果，其中变量t的值是在调用函数outer时确定的，所以后面的赋值tb = {i = 7};对变量t的值没有影响。 总结 lua中操作变量注意值和引用，其实很多语言都有这种区分。 注意闭包可以访问外部变量的特性，程序中使用起来非常方便。 实际使用过程中往往还夹杂着业务逻辑，要学会挖掘本质问题，这样往往可以看到真正的运行逻辑。 测试源码示例传送门：lua中table引用]]></content>
      <categories>
        <category>Lua</category>
      </categories>
      <tags>
        <tag>C++</tag>
        <tag>Lua</tag>
        <tag>table</tag>
        <tag>引用传递</tag>
        <tag>闭包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unique_ptr浅析]]></title>
    <url>%2Fblog%2F2018%2F09%2F12%2Funique-ptr%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言unique_ptr这个指针是C++11标准时被引入标准库的，有一种说法称它是boost::scoped_ptr的一个分身，并且它在C++11的时候“转正”了，但是scoped_ptr还被留在boost库中，看来没有转正的机会了，不过unique_ptr与scoped_ptr确实很像，unique_ptr只比scoped_ptr多了一个移动语义，可以通过std::move()函数来转移内部对象的所有权。 其实在我看来，unique_ptr与auto_ptr是最像的，他设计之初就是为了替代auto_ptr，其实两者基本上没有区别，如果把auto_ptr限制一下，使其不能通过拷贝构造和赋值获得所有权，但是可以通过std::move()函数获得所有权，那基本上就变成了unique_pr，这一点通过下面的函数分析也可以看出，两者的函数基本一致。 unique_pr作为一个模板类，可以直接用它来定义一个智能指针的对象，例如std::unique_pr&lt;Test&gt; pa(new Test);，查看unique_pr的代码时发现，它主要有get、release、reset、operator*、operator-&gt;、operator=、swap、operator bool、get_deleter几个函数，相比于auto_ptr常用函数来说，只多了swap、operator bool、get_deleter这三个函数，基本上没什么变化，不过get_deleter这个函数值的详细解释一下，下面通过一些例子来了解一下unique_pr的具体用法。 使用环境 VS2015 + Windows7（应该是C++11标准） 头文件#include &lt;memory&gt; 命名空间using namespace std; 测试过程首先我们先编写一个测试类，用来测试智能指针各个函数的作用，以及可能出现的问题，测试类的代码如下：123456789101112131415161718class Example&#123;public: Example(int param = 0) &#123; number = param; cout &lt;&lt; "Example: " &lt;&lt; number &lt;&lt; endl; &#125; ~Example() &#123; cout &lt;&lt; "~Example: " &lt;&lt; number &lt;&lt; endl; &#125; void test_print() &#123; cout &lt;&lt; "in test print: number = " &lt;&lt; number &lt;&lt; endl; &#125; void set_number(int num) &#123; number = num; &#125;private: int number;&#125;; 测试函数get、release、reset、operator*、operator-&gt;、swap、operator bool这些函数在解释auto_ptr的时候基本都提到过，swap、operator bool作为两个新的函数在解释shared_ptr的时候也演示过，所以此处就不花过多的篇幅举例了，这里写到一个测试函数中，体会一下用法就好： 123456789101112131415161718192021222324252627282930void test1()&#123; unique_ptr&lt;Example&gt; ptr1(new Example(1)); // Example: 1(输出内容) if (ptr1.get()) // 调用get函数，判断内部指针的有效性 &#123; ptr1.get()-&gt;test_print(); // in test print: number = 1(输出内容) ptr1-&gt;set_number(2); // 调用了operator-&gt; (*ptr1).test_print(); // in test print: number = 2(输出内容) &#125; if (ptr1) // 调用operator bool 检测内部对象的有效性 cout &lt;&lt; "ptr1 is valid\n"; // ptr1 is valid(输出内容) Example *p = ptr1.release(); // 调用release函数，取出内部对象 if (!ptr1) // 调用operator bool 检测内部对象的有效性 cout &lt;&lt; "ptr1 is invalid\n"; // ptr1 is invalid(输出内容) ptr1.reset(p); // 调用reset函数，重新设置内部对象 if (ptr1) // 调用operator bool 检测内部对象的有效性 cout &lt;&lt; "ptr1 is valid\n"; // ptr1 is valid(输出内容) ptr1-&gt;test_print(); // in test print: number = 2(输出内容) unique_ptr&lt;Example&gt; ptr2(new Example(20)); // Example: 20(输出内容) ptr1.swap(ptr2); // 调用swap函数，重新设置内部对象 ptr1-&gt;test_print(); // in test print: number = 20(输出内容) ptr2-&gt;test_print(); // in test print: number = 2(输出内容) ptr1.reset(); // ~Example: 20(输出内容)// 重置内部对象被销毁&#125; // ~Example: 2(输出内容) // 出作用域被析构 测试函数operator=operator=这个函数是unique_ptr与auto_ptr最大的区别，因为在auto_ptr中，这个操作函数往往是导致问题出现的罪魁祸首，赋值之后所有权转移，原智能指针对象无效，这样往往会导致程序崩溃，所以在unique_ptr中operator=被禁止使用了，取而代之的是具有移动语义的std::move()函数，如果unique_ptr的对象直接赋值的话，会在编译期间就提示错误： 12345678910void test2()&#123; //unique_ptr&lt;Example&gt; ptr2 = new Example(2);// 编译错误，不支持原始指针到智能指针的隐式转换 unique_ptr&lt;Example&gt; ptr2(new Example(2)); // Example: 2(输出内容) //unique_ptr&lt;Example&gt; ptr3 = ptr2; // 编译错误，...: 尝试引用已删除的函数 //unique_ptr&lt;Example&gt; ptr4(ptr2); // 编译错误，...: 尝试引用已删除的函数 unique_ptr&lt;Example&gt; ptr5(std::move(ptr2)); // 正常编译，使用move移动语义，符合预期效果 ptr5-&gt;test_print(); // in test print: number = 2(输出内容)&#125; // ~Example: 2(输出内容) // 出作用域被析构 测试unique_ptr作为参数和返回值unique_ptr是可以作为参数和返回值的，不过因为operator=不允许使用，所以在作为参数的时候需要使用函数std::move()，但是作为返回值却不需要，这里留个疑问，最后分析一下： 1234567891011121314151617181920212223242526void test3_inner1(unique_ptr&lt;Example&gt; ptr3_1)&#123; ptr3_1-&gt;test_print(); // in test print: number = 3（输出内容）&#125; // ~Example: 3(输出内容) // 出作用域被析构unique_ptr&lt;Example&gt; test3_inner2()&#123; unique_ptr&lt;Example&gt; ptr3_2(new Example(32));// Example:32（输出内容） ptr3_2-&gt;test_print(); // in test print: number = 32（输出内容） return ptr3_2;&#125;void test3()&#123; unique_ptr&lt;Example&gt; ptr3(new Example(3)); // Example:3（输出内容） ptr3-&gt;test_print(); // in test print: number = 3（输出内容） //test3_inner1(ptr3); // 直接作为参数传递会报编译错误,不存在拷贝构造 test3_inner1(std::move(ptr3)); // 但是可以使用std::move的移动语义来实现 if (!ptr3) cout &lt;&lt; "ptr3 is invalid\n"; // ptr1 is valid(输出内容),移动之后ptr3无效 ptr3 = test3_inner2(); // 由于不允许调用构造或者赋值，此处使用了移动语义move ptr3-&gt;test_print(); // in test print: number = 32（输出内容）&#125; // ~Example: 32（输出内容）,出定义域ptr3释放内部对象 测试unique_ptr类型的指针或者引用作为参数这一点没有什么问题，因为不会发生所有权的转移和引用计数的增加，所有的智能指针，包括auto_ptr在内在这种用法的情况下都不会发生问题： 123456789101112131415161718void test4_inner1(unique_ptr&lt;Example&gt;* ptr4_1)&#123; (*ptr4_1)-&gt;test_print(); // in test print: number = 4（输出内容） &#125; // 指针传递没有析构void test4_inner2(unique_ptr&lt;Example&gt;&amp; ptr4_2)&#123; ptr4_2-&gt;test_print(); // in test print: number = 4（输出内容）&#125; // 引用传递没有析构void test4()&#123; unique_ptr&lt;Example&gt; ptr4(new Example(4)); // Example:4（输出内容） ptr4-&gt;test_print(); // in test print: number = 4（输出内容） test4_inner1(&amp;ptr4); // 取地址作为参数 test4_inner2(ptr4); // 引用作为参数&#125; // ~Example: 4（输出内容）,出定义域ptr4释放内部对象 测试unique_ptr作为容器元素前面分析auto_ptr的时候已经说过，auto_ptr在作为容器元素时，是不具有跨平台性质的，因为在有的平台表现很正常，有的环境下直接编译报错，原因就是使用auto_ptr很容易出错，不是说一定会出错，而是可能出问题，所以个别平台直接在编译期报错，防止后续的错误。而unique_ptr作为容器元素时，表现很统一，没有任何问题，但是我感觉这里就有点牵强，后续再说，注意v[6] = unique_ptr&lt;Example&gt;(new Example(56));这一句，是不是感觉很神奇，居然不报编译错误，我感觉和作为返回值时是相同的处理。 12345678910111213141516171819202122232425262728void test5()&#123; vector&lt;unique_ptr&lt;Example&gt;&gt; v(7); for (int i = 0; i &lt; 6; i++) &#123; v[i] = unique_ptr&lt;Example&gt;(new Example(50 + i)); // 依次输出Example:70,...Example:75 &#125; // 直接赋值，迷之成功，不是不能operator=吗,这里实际上调用的还是std::move类似的移动语义？ v[6] = unique_ptr&lt;Example&gt;(new Example(56));// Example:56（输出内容） // 直接将unique_ptr对象push_back v.push_back(unique_ptr&lt;Example&gt;(new Example(57))); // Example:57（输出内容） // 利用移动语义push_back v.push_back(std::move(unique_ptr&lt;Example&gt;(new Example(58)))); // Example:58（输出内容） // 利用make_unique创建unique_ptr,C++14才支持 v.push_back(make_unique&lt;Example&gt;(59)); // Example:59（输出内容） // 循环调用 for (int i = 0; i &lt; 10; i++) &#123; v[i]-&gt;test_print(); &#125;// 依次输出in test print: number = 50....in test print: number = 59&#125;// 依次输出~Example: 50,~Example: 51...~Example: 59 测试函数get_deleter这个函数还是第一次提到，作用就是获得unique_ptr对象的“删除器”，如果不手动指定就会获得默认的删除器，否则就返回你指定的，举个例子一看就明白了，代码如下： 123456789101112131415161718192021222324252627// a custom deleterclass custom_deleter &#123; int flag;public: custom_deleter(int val) : flag(val) &#123;&#125; template &lt;class T&gt; void operator()(T* p) &#123; std::cout &lt;&lt; "use custom deleter, flag=" &lt;&lt; flag ; delete p; &#125;&#125;;void test6()&#123; custom_deleter dlter(666); unique_ptr&lt;Example, custom_deleter&gt; ptr6(new Example(6), dlter); // Example:6（输出内容） ptr6-&gt;test_print(); // in test print: number = 6（输出内容） unique_ptr&lt;Example, custom_deleter&gt; ptr7(new Example(7), ptr6.get_deleter()); // 调用get_deleter // 重置智能指针，内部对象使用自定义删除器删除 ptr6.reset(); // 输出：use custom deleter, flag = 666~Example: 6 ptr7-&gt;test_print(); // in test print: number = 7（输出内容）&#125; // 输出：use custom deleter, flag = 666~Example: 7 现象分析上面的几个例子都很简单，基本上看一遍就知道怎么用了，但是有一点让人很迷惑，就是operator=的使用，最开始已经说过了，unique_ptr中的operator=已经被禁止使用了，但是例子中有两处很有争议，就是unique_ptr作为函数返回值和直接把unique_ptr赋值给vector元素，一开始我也不是太清楚，后来找资料时发现了一些线索，和大家分享一下: 当函数返回一个对象时，理论上会产生临时变量，那必然是会导致新对象的构造和旧对象的析构，这对效率是有影响的。C++编译针对这种情况允许进行优化，哪怕是构造函数有副作用，这叫做返回值优化（RVO)，返回有名字的对象叫做具名返回值优化(NRVO)，就那RVO来说吧，本来是在返回时要生成临时对象的，现在构造返回对象时直接在接受返回对象的空间中构造了。假设不进行返回值优化，那么上面返回unique_ptr会不会有问题呢？也不会。因为标准允许编译器这么做：1.如果支持move构造，那么调用move构造。2.如果不支持move，那就调用copy构造。3.如果不支持copy，那就报错吧。 很显然，unique_ptr本身是支持move构造的，所以unique_ptr对象可以被函数返回，另外我推测将unique_ptr直接赋值给vector元素也利用了相似的操作，这里不太确定，希望了解的小伙伴能告知一下其中的原因。 说到这里，我们对unique_ptr也有了整体的认识，说unique_ptr是auto_ptr的替代品，可是unique_ptr真的优秀了吗？我看未必，它并非不会再犯错，只是犯错的成本大了一些，如果使用std::move()转移了所有权之后，再直接使用原来的智能指针对象，同样会使得程序崩溃。 其实auto_ptr和unique_ptr给我的感觉就是就好比租房子，租房时有些人喜欢看一下房东的房产证，有的人则无所谓，来个人说是房东他就敢跟人签合同，房屋所有权是通过房产证来转移的，使用auto_ptr就好像两个人可以私下交易，把钱和房产证直接交换，房产证的转移很随便，使用unique_ptr就好比在转移房产的时候需要放鞭炮、然后在全世界广播一下，比较麻烦，并且有可能被租房的人看到，但是本质是一样的，都是拿钱来转移房的所有权，关键还是看租房的人，如果租房先看房产证，即使是房产证的转移很随便（也就是使用auto_ptr），也不会出问题，如果租房根本不看房产证，即使房产证交易通知了世界上所有人（即使用unique_ptr），也会租到没证的房子（程序崩溃）。 所以说unique_ptr并没有消除错误，仅仅是提高了犯错的成本。 总结 对比auto_ptr和unique_ptr后发现，unique_ptr几乎只是将auto_ptr的operator=改为std::move()函数。 现在标准库中只剩下了shared_ptr、weak_ptr和unique_ptr三个智能指针，weak_ptr是为了解决shared_ptr的循环引用问题而存在的，有其特定的使用情况，所以只剩下了shared_ptr和unique_ptr的选择，选择的标准就是看是否需要对原对象共享所有权，如果需要使用shared_ptr，如果不需要是独占所有权的使用unique_ptr。 unique_ptr并没有从根本上消除可能错误，仅仅是提高了犯错的成本，并且给出移动所有权的提示，但是在容器vector元素赋值时依然很隐晦，可能造成auto_ptr相同的错误。 测试源码示例传送门：unique_ptr用法]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>智能指针</tag>
        <tag>unique_ptr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[weak_ptr浅析]]></title>
    <url>%2Fblog%2F2018%2F09%2F01%2Fweak-ptr%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言weak_ptr这个指针天生一副“小弟”的模样，也是在C++11的时候引入的标准库，它的出现完全是为了弥补它老大shared_ptr天生有缺陷的问题，其实相比于上一代的智能指针auto_ptr来说，新进老大shared_ptr可以说近乎完美，但是通过引用计数实现的它，虽然解决了指针独占的问题，但也引来了引用成环的问题，这种问题靠它自己是没办法解决的，所以在C++11的时候将shared_ptr和weak_ptr一起引入了标准库，用来解决循环引用的问题。 weak_ptr本身也是一个模板类，但是不能直接用它来定义一个智能指针的对象，只能配合shared_ptr来使用，可以将shared_ptr的对象赋值给weak_ptr，并且这样并不会改变引用计数的值。查看weak_ptr的代码时发现，它主要有lock、swap、reset、expired、operator=、use_count几个函数，与shared_ptr相比多了lock、expired函数，但是却少了get函数，甚至连operator* 和 operator-&gt;都没有，可用的函数数量少的可怜，下面通过一些例子来了解一下weak_ptr的具体用法。 使用环境 VS2015 + Windows7（应该是C++11标准） 头文件#include &lt;memory&gt; 命名空间using namespace std; 测试过程 weak_ptr解决shared_ptr循环引用的问题定义两个类，每个类中又包含一个指向对方类型的智能指针作为成员变量，然后创建对象，设置完成后查看引用计数后退出，看一下测试结果： 123456789101112131415161718192021222324252627282930313233343536373839class CB;class CA&#123;public: CA() &#123; cout &lt;&lt; "CA() called! " &lt;&lt; endl; &#125; ~CA() &#123; cout &lt;&lt; "~CA() called! " &lt;&lt; endl; &#125; void set_ptr(shared_ptr&lt;CB&gt;&amp; ptr) &#123; m_ptr_b = ptr; &#125; void b_use_count() &#123; cout &lt;&lt; "b use count : " &lt;&lt; m_ptr_b.use_count() &lt;&lt; endl; &#125; void show() &#123; cout &lt;&lt; "this is class CA!" &lt;&lt; endl; &#125;private: shared_ptr&lt;CB&gt; m_ptr_b;&#125;;class CB&#123;public: CB() &#123; cout &lt;&lt; "CB() called! " &lt;&lt; endl; &#125; ~CB() &#123; cout &lt;&lt; "~CB() called! " &lt;&lt; endl; &#125; void set_ptr(shared_ptr&lt;CA&gt;&amp; ptr) &#123; m_ptr_a = ptr; &#125; void a_use_count() &#123; cout &lt;&lt; "a use count : " &lt;&lt; m_ptr_a.use_count() &lt;&lt; endl; &#125; void show() &#123; cout &lt;&lt; "this is class CB!" &lt;&lt; endl; &#125;private: shared_ptr&lt;CA&gt; m_ptr_a;&#125;;void test_refer_to_each_other()&#123; shared_ptr&lt;CA&gt; ptr_a(new CA()); shared_ptr&lt;CB&gt; ptr_b(new CB()); cout &lt;&lt; "a use count : " &lt;&lt; ptr_a.use_count() &lt;&lt; endl; cout &lt;&lt; "b use count : " &lt;&lt; ptr_b.use_count() &lt;&lt; endl; ptr_a-&gt;set_ptr(ptr_b); ptr_b-&gt;set_ptr(ptr_a); cout &lt;&lt; "a use count : " &lt;&lt; ptr_a.use_count() &lt;&lt; endl; cout &lt;&lt; "b use count : " &lt;&lt; ptr_b.use_count() &lt;&lt; endl;&#125; 测试结果如下： 123456CA() called!CB() called!a use count : 1b use count : 1a use count : 2b use count : 2 通过结果可以看到，最后CA和CB的对象并没有被析构，其中的引用效果如下图所示，起初定义完ptr_a和ptr_b时，只有①③两条引用，然后调用函数set_ptr后又增加了②④两条引用，当test_refer_to_each_other这个函数返回时，对象ptr_a和ptr_b被销毁，也就是①③两条引用会被断开，但是②④两条引用依然存在，每一个的引用计数都不为0，结果就导致其指向的内部对象无法析构，造成内存泄漏。 解决这种状况的办法就是将两个类中的一个成员变量改为weak_ptr对象，因为weak_ptr不会增加引用计数，使得引用形不成环，最后就可以正常的释放内部的对象，不会造成内存泄漏，比如将CB中的成员变量改为weak_ptr对象，代码如下：1234567891011class CB&#123;public: CB() &#123; cout &lt;&lt; "CB() called! " &lt;&lt; endl; &#125; ~CB() &#123; cout &lt;&lt; "~CB() called! " &lt;&lt; endl; &#125; void set_ptr(shared_ptr&lt;CA&gt;&amp; ptr) &#123; m_ptr_a = ptr; &#125; void a_use_count() &#123; cout &lt;&lt; "a use count : " &lt;&lt; m_ptr_a.use_count() &lt;&lt; endl; &#125; void show() &#123; cout &lt;&lt; "this is class CB!" &lt;&lt; endl; &#125;private: weak_ptr&lt;CA&gt; m_ptr_a;&#125;;测试结果如下：12345678CA() called!CB() called!a use count : 1b use count : 1a use count : 1b use count : 2~CA() called!~CB() called!通过这次结果可以看到，CA和CB的对象都被正常的析构了，引用关系如下图所示，流程与上一例子相似，但是不同的是④这条引用是通过weak_ptr建立的，并不会增加引用计数，也就是说CA的对象只有一个引用计数，而CB的对象只有2个引用计数，当test_refer_to_each_other这个函数返回时，对象ptr_a和ptr_b被销毁，也就是①③两条引用会被断开，此时CA对象的引用计数会减为0，对象被销毁，其内部的m_ptr_b成员变量也会被析构，导致CB对象的引用计数会减为0，对象被销毁，进而解决了引用成环的问题。 测试weak_ptr对引用计数的影响其实weak_ptr本身设计的很简单，就是为了辅助shared_ptr的，它本身不能直接定义指向原始指针的对象，只能指向shared_ptr对象，同时也不能将weak_ptr对象直接赋值给shared_ptr类型的变量，最重要的一点是赋值给它不会增加引用计数： 1234567891011121314151617181920212223void test1()&#123; // 编译错误 // error C2665: “std::weak_ptr&lt;CA&gt;::weak_ptr”: 3 个重载中没有一个可以转换所有参数类型 // weak_ptr&lt;CA&gt; ptr_1(new CA()); shared_ptr&lt;CA&gt; ptr_1(new CA()); cout &lt;&lt; "ptr_1 use count : " &lt;&lt; ptr_1.use_count() &lt;&lt; endl; // 输出：ptr_1 use count : 1 shared_ptr&lt;CA&gt; ptr_2 = ptr_1; cout &lt;&lt; "ptr_1 use count : " &lt;&lt; ptr_1.use_count() &lt;&lt; endl; // 输出：ptr_1 use count : 2 cout &lt;&lt; "ptr_2 use count : " &lt;&lt; ptr_2.use_count() &lt;&lt; endl; // 输出：ptr_1 use count : 2 weak_ptr&lt;CA&gt; wk_ptr = ptr_1; cout &lt;&lt; "ptr_1 use count : " &lt;&lt; ptr_1.use_count() &lt;&lt; endl; // 输出：ptr_1 use count : 2 cout &lt;&lt; "ptr_2 use count : " &lt;&lt; ptr_2.use_count() &lt;&lt; endl; // 输出：ptr_1 use count : 2 // 编译错误 // error C2440 : “初始化”: 无法从“std::weak_ptr&lt;CA&gt;”转换为“std::shared_ptr&lt;CA&gt;” // shared_ptr&lt;CA&gt; ptr_3 = wk_ptr;&#125; 测试weak_ptr常用函数的用法weak_ptr中只有函数lock和expired两个函数比较重要，因为它本身不会增加引用计数，所以它指向的对象可能在它用的时候已经被释放了，所以在用之前需要使用expired函数来检测是否过期，然后使用lock函数来获取其对应的shared_ptr对象，然后进行后续操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546void test2()&#123; shared_ptr&lt;CA&gt; ptr_a(new CA()); // 输出：CA() called! shared_ptr&lt;CB&gt; ptr_b(new CB()); // 输出：CB() called! cout &lt;&lt; "ptr_a use count : " &lt;&lt; ptr_a.use_count() &lt;&lt; endl; // 输出：ptr_a use count : 1 cout &lt;&lt; "ptr_b use count : " &lt;&lt; ptr_b.use_count() &lt;&lt; endl; // 输出：ptr_b use count : 1 weak_ptr&lt;CA&gt; wk_ptr_a = ptr_a; weak_ptr&lt;CB&gt; wk_ptr_b = ptr_b; if (!wk_ptr_a.expired()) &#123; wk_ptr_a.lock()-&gt;show(); // 输出：this is class CA! &#125; if (!wk_ptr_b.expired()) &#123; wk_ptr_b.lock()-&gt;show(); // 输出：this is class CB! &#125; // 编译错误 // 编译必须作用于相同的指针类型之间 // wk_ptr_a.swap(wk_ptr_b); // 调用交换函数 wk_ptr_b.reset(); // 将wk_ptr_b的指向清空 if (wk_ptr_b.expired()) &#123; cout &lt;&lt; "wk_ptr_b is invalid" &lt;&lt; endl; // 输出：wk_ptr_b is invalid 说明改指针已经无效 &#125; wk_ptr_b = ptr_b; if (!wk_ptr_b.expired()) &#123; wk_ptr_b.lock()-&gt;show(); // 输出：this is class CB! 调用赋值操作后，wk_ptr_b恢复有效 &#125; // 编译错误 // 编译必须作用于相同的指针类型之间 // wk_ptr_b = wk_ptr_a; // 最后输出的引用计数还是1，说明之前使用weak_ptr类型赋值，不会影响引用计数 cout &lt;&lt; "ptr_a use count : " &lt;&lt; ptr_a.use_count() &lt;&lt; endl; // 输出：ptr_a use count : 1 cout &lt;&lt; "ptr_b use count : " &lt;&lt; ptr_b.use_count() &lt;&lt; endl; // 输出：ptr_b use count : 1&#125; 现象分析引用计数的出现，解决了对象独占的问题，但是也带来了循环引用的困扰，使用weak_ptr可以打破这种循环，当你理不清引用关系的时候，不妨采用文中画图的方式来理一理头绪，或许就会有眼前一亮的感觉。 总结 weak_ptr虽然是一个模板类，但是不能用来直接定义指向原始指针的对象。 weak_ptr接受shared_ptr类型的变量赋值，但是反过来是行不通的，需要使用lock函数。 weak_ptr设计之初就是为了服务于shared_ptr的，所以不增加引用计数就是它的核心功能。 由于不知道什么之后weak_ptr所指向的对象就会被析构掉，所以使用之前请先使用expired函数检测一下。 测试源码示例传送门：weak_ptr用法]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>智能指针</tag>
        <tag>weak_ptr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shared_ptr浅析]]></title>
    <url>%2Fblog%2F2018%2F08%2F15%2Fshared-ptr%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言这个指针近乎完美，原来出现在boost库中，C++11时引入了标准库，解决了auto_ptr对内部对象独占的机制，转而采用引用计数的方式，每增加一次赋值，则引用计数加1，每析构一个智能指针对象，则引用计数减1，当引用计数为1时销毁智能指针对象的同时，也析构内部对象。这种采用引用计数方式避免了对象所有权转移，所以作为函数返回值，函数参数，容器的元素都不会有问题，但是因为引用计数的加入，相应的会带来对引用计数维护的开销。 与auto_ptr一样，shared_ptr本身也是一个模板类，那么一般情况下直接用它来定义一个智能指针的对象，例如std::shared_ptr&lt;Test&gt; pa(new Test);需要注意的是pa虽然叫智能指针，但是它是一个对象，在它的内部保存着一个原始的对象的指针。查看shared_ptr的代码时发现，它主要有get、swap、reset、unique、use_count、operator bool、operator*、operator-&gt;、operator=几个函数，与auto_ptr相比少了release函数，但是多了swap、unique、use_count、operator bool四个函数,下面通过一些例子来了解一下shared_ptr的具体用法。 使用环境 VS2015 + Windows7（应该是C++11标准） 头文件#include &lt;memory&gt; 命名空间using namespace std; 测试过程首先我们先编写一些测试类，用来测试智能指针各个函数的作用，以及可能出现的问题，测试类的代码如下：1234567891011121314151617181920class Example&#123;public: Example(int param = 0) &#123; number = param; cout &lt;&lt; "Example: " &lt;&lt; number &lt;&lt; endl; &#125; ~Example() &#123; cout &lt;&lt; "~Example: " &lt;&lt; number &lt;&lt; endl; &#125; void test_print() &#123; cout &lt;&lt; "in test print: number = " &lt;&lt; number &lt;&lt; endl; &#125; void set_number(int num) &#123; number = num; &#125; int get_number() &#123; return number; &#125;private: int number;&#125;; 测试函数get reset operator* operator-&gt;这几个函数与auto_ptr智能指针的用法一样，可以参考auto_ptr用法，get函数可以获得智能指针包装的原始指针，可以用来判断被包装对象的有效性，也可以用来访问被包装对象，operator*可以直接对智能指针包装的原始指针解引用，获得被包装的对象，operator-&gt;用来取得原始对象的指针，引用成员时与get函数作用相同，reset函数用于重新设置内部对象，若参数为空，则表示取消对内部对象的引用，此时若引用计数大于1则进行减1操作，否则直接析构内部对象。需要注意的是普通的对象指针是无法隐式转换成shared_ptr的，需要利用构造函数实现，示例代码如下： 123456789101112131415161718void test1()&#123; //error C2440: “初始化”: 无法从“Example *”转换为“std::shared_ptr&lt;Example&gt;” //shared_ptr&lt;Example&gt; ptr1 = new Example(1); shared_ptr&lt;Example&gt; ptr1(new Example(1)); // Example: 1（输出内容） if (ptr1.get()) // 调用函数get，获取原始指针，判断有效性 &#123; cout &lt;&lt; "ptr1 is valid" &lt;&lt; endl; // 原始指针有效 &#125; ptr1-&gt;test_print(); // in test print: number = 1（输出内容），调用operator-&gt; ptr1.reset(); // ~Example: 1（输出内容）,调用函数reset，设置为空，释放原内部对象 ptr1.reset(new Example(2)); // Example: 2（输出内容）,重新申请对象并设置 (*ptr1).test_print(); // in test print: number = 1（输出内容），调用operator*&#125; // ~Example: 1（输出内容）,出定义域，释放内部对象 测试函数operator bool用法operator bool函数其实就是用来判断内部对象是否有效的，若内部对象不为空则返回true，否则返回false，大概的实现就是return this-&gt;get() != nullptr;，测试代码如下： 1234567891011void test2()&#123; shared_ptr&lt;Example&gt; ptr2(new Example(2)); // Example: 2（输出内容） if (ptr2) // 调用operator bool cout &lt;&lt; "ptr2 is valid" &lt;&lt; endl; // ptr2 is valid（输出内容），说明ptr2是有效的 ptr2.reset(); // ~Example: 2（输出内容），设置内部对象为空 if (ptr2) // 调用operator bool cout &lt;&lt; "ptr2 is valid" &lt;&lt; endl; // 没有输出，说明ptr2已经无效&#125; 测试函数swap用法从这个名字就可以看出，这个函数用于交换，那么是用来交换什么的呢？实际上是用来交换内部对象的，看下面的例子一试便知，代码运行过后，通过打印可以发现智能指针对象ptr3和ptr4的内部对象进行了交换： 12345678910111213void test3()&#123; shared_ptr&lt;Example&gt; ptr3(new Example(3)); // Example: 3（输出内容） shared_ptr&lt;Example&gt; ptr4(new Example(4)); // Example: 4（输出内容） ptr3-&gt;test_print(); // in test print: number = 3（输出内容） ptr4-&gt;test_print(); // in test print: number = 4（输出内容） ptr3.swap(ptr4); // 调用函数swap ptr3-&gt;test_print(); // in test print: number = 4（输出内容） ptr4-&gt;test_print(); // in test print: number = 3（输出内容）&#125; // ~Example: 3（输出内容）,出定义域，释放内部对象 // ~Example: 4（输出内容）,出定义域，释放内部对象 测试函数unique use_count operator=用法为什么把这几个函数放到一起来说，因为他们是息息相关的，首先函数operator=是用来处理赋值操作的，而赋值操作就会影响引用计数的变化，也就是赋值操作后，use_count函数查询到的引用计数会发生变化，而当use_count返回引用计数是1时，用来表明是否独自引用内部对象的函数unique也会返回true，换句话说unique函数的实现基本就是return this-&gt;use_count() == 1，测试代码如下： 12345678910111213141516171819202122void test4()&#123; shared_ptr&lt;Example&gt; ptr4(new Example(4)); // Example: 4（输出内容） if (ptr4.unique()) &#123; cout &lt;&lt; "ptr4 is unique" &lt;&lt; endl; // ptr4 is unique（输出内容） cout &lt;&lt; "ptr4 use count : " &lt;&lt; ptr4.use_count() &lt;&lt; endl;// ptr4 use count : 1（输出内容） &#125; shared_ptr&lt;Example&gt; ptr5 = ptr4; if (ptr4) cout &lt;&lt; "ptr4 is valid" &lt;&lt; endl;// ptr4 is valid(输出内容）说明赋值之后两个智能指针对象都有效 if (ptr5) cout &lt;&lt; "ptr5 is valid" &lt;&lt; endl;// ptr5 is valid(输出内容）说明赋值之后两个智能指针对象都有效 if (ptr4.unique()) cout &lt;&lt; "ptr4 is unique" &lt;&lt; endl; // 没有输出，说明ptr4不是唯一管理内部对象的智能指针了 cout &lt;&lt; "ptr4 use count : " &lt;&lt; ptr4.use_count() &lt;&lt; endl; // ptr4 use count : 2（输出内容） cout &lt;&lt; "ptr5 use count : " &lt;&lt; ptr5.use_count() &lt;&lt; endl; // ptr4 use count : 2（输出内容）&#125; // ~Example: 4（输出内容）,出定义域，释放内部对象 测试用同一个对象指针生成两个shared_ptr对象与auto_ptr一样，我测试的结果是崩溃，官方标准网站上说是结果未定义，基本上就是说不靠谱，别这样干，仔细想想也能理解，虽说shared_ptr是通过引用计数方式实现，但也不是无所不能，比如这种情况，两个对象都是通过构造生成的，对内部对象的指针p都是“唯一”引用的，也就是两个对象的内部引用计数都是1，当第一个智能指针对象销毁时，会析构内部对象，当第二个智能指针对象销毁时，同样会析构内部对象，这样就造成了崩溃，测试如下： 12345678910void test5()&#123; Example *p = new Example(5); // Example: 5（输出内容） shared_ptr&lt;Example&gt; ptr5(p); shared_ptr&lt;Example&gt; ptr6(p); cout &lt;&lt; "ptr4 use count : " &lt;&lt; ptr5.use_count() &lt;&lt; endl;// ptr4 use count : 1（输出内容） cout &lt;&lt; "ptr5 use count : " &lt;&lt; ptr6.use_count() &lt;&lt; endl;// ptr5 use count : 1（输出内容）&#125; // ~Example: 3（输出内容）,出定义域，ptr5释放内部对象 // ~Example : -572662307（输出内容）,出定义域，ptr6释放内部对象，程序崩溃 测试shared_ptr作为函数参数和返回值因为shared_ptr内部是引用计数，而不是独占所有权，所以在赋值的时候只改变引用计数，不会发生所有权转移，所以这两种用法基本没有问题，发生在auto_ptr上的崩溃惨剧也不会在这里上演，测试代码如下： 12345678910111213141516171819202122232425void test6_inner1(shared_ptr&lt;Example&gt; ptr6_1)&#123; ptr6_1-&gt;test_print(); // in test print: number = 6（输出内容） cout &lt;&lt; "ptr6_1 use count : " &lt;&lt; ptr6_1.use_count() &lt;&lt; endl;// ptr6 use count : 2（输出内容）&#125;shared_ptr&lt;Example&gt; test6_inner2()&#123; shared_ptr&lt;Example&gt; ptr6_2(new Example(62)); // Example:62（输出内容） ptr6_2-&gt;test_print(); // in test print: number = 62（输出内容） cout &lt;&lt; "ptr6_2 use count : " &lt;&lt; ptr6_2.use_count() &lt;&lt; endl;// ptr6_2 use count : 1（输出内容） return ptr6_2;&#125;void test6()&#123; shared_ptr&lt;Example&gt; ptr6(new Example(6)); // Example:6（输出内容） ptr6-&gt;test_print(); // in test print: number = 6（输出内容） cout &lt;&lt; "ptr6 use count : " &lt;&lt; ptr6.use_count() &lt;&lt; endl;// ptr6 use count : 1（输出内容） test6_inner1(ptr6); cout &lt;&lt; "ptr6 use count : " &lt;&lt; ptr6.use_count() &lt;&lt; endl;// ptr6 use count : 1（输出内容） ptr6 = test6_inner2(); // ~Example: 6（输出内容）,ptr6接管新的对象，原来对象被析构 cout &lt;&lt; "ptr6 use count : " &lt;&lt; ptr6.use_count() &lt;&lt; endl;// ptr6 use count : 1（输出内容）&#125; // ~Example: 62（输出内容）,出定义域，ptr6释放内部对象 测试shared_ptr作为容器元素在这里也不存在auto_ptr作为容器元素时的争议，同样是引用计数的机制发挥了作用，使得他满足的容器的要求——其元素对象的拷贝与原对象相同或者等价，所以这里也不会出现问题，同时那些针对于容器的算法在shared_ptr上也可以大显身手，比如下面这个排序的例子： 12345678910111213141516171819202122232425262728// 一般会写成只读引用类型，这里为了说明问题才这样定义bool comp(shared_ptr&lt;Example&gt; a, shared_ptr&lt;Example&gt; b)&#123; return a-&gt;get_number() &gt; b-&gt;get_number();&#125;void test7()&#123; vector&lt;shared_ptr&lt;Example&gt;&gt; v(10); for (int i = 0; i &lt; 10; i++) &#123; v[i] = shared_ptr&lt;Example&gt;(new Example(70+i)); &#125;// 依次输出Example:70,Example:71,Example:72...Example:79 // 循环调用 for (int i = 0; i &lt; 10; i++) &#123; v[i]-&gt;test_print(); &#125;// 依次输出in test print: number = 70....in test print: number = 79 sort(v.begin(), v.end(), comp); // 这可以正常运行，但是使用auto_ptr会死的很难看 // 循环调用 for (int i = 0; i &lt; 10; i++) &#123; v[i]-&gt;test_print(); &#125;// 依次输出in test print: number = 79....in test print: number = 70&#125;// 依次输出~Example: 79,~Example: 78...~Example: 70 测试使用指针或者引用作为参数虽然shared_ptr作为参数、返回值、容器元素貌似没有丝毫问题了，但是有时还是使用shared_ptr对象的指针或者引用比较好，因为这样可以减少对对象的拷贝，毕竟对象的拷贝是需要消耗时间的，用更好的方式为什么不用呢，参考下面的用法，没有任何问题： 12345678910111213141516171819202122void test8_inner1(shared_ptr&lt;Example&gt;* ptr8_1)&#123; (*ptr8_1)-&gt;test_print(); // in test print: number = 8（输出内容） cout &lt;&lt; "ptr8_1 use count : " &lt;&lt; (*ptr8_1).use_count() &lt;&lt; endl;// ptr8_1 use count : 1（输出内容）&#125;void test8_inner2(shared_ptr&lt;Example&gt;&amp; ptr8_2)&#123; ptr8_2-&gt;test_print(); // in test print: number = 8（输出内容） cout &lt;&lt; "ptr8_2 use count : " &lt;&lt; ptr8_2.use_count() &lt;&lt; endl;// ptr8_2 use count : 1（输出内容）&#125;void test8()&#123; shared_ptr&lt;Example&gt; ptr8(new Example(8)); // Example:8（输出内容） ptr8-&gt;test_print(); // in test print: number = 8（输出内容） cout &lt;&lt; "ptr8 use count : " &lt;&lt; ptr8.use_count() &lt;&lt; endl;// ptr8 use count : 1（输出内容) test8_inner1(&amp;ptr8); cout &lt;&lt; "ptr8 use count : " &lt;&lt; ptr8.use_count() &lt;&lt; endl;// ptr8 use count : 1（输出内容) test8_inner2(ptr8); cout &lt;&lt; "ptr8 use count : " &lt;&lt; ptr8.use_count() &lt;&lt; endl;// ptr8 use count : 1（输出内容)&#125; // ~Example: 8（输出内容）,出定义域，ptr8释放内部对像 现象分析shared_ptr与auto_ptr相比要优秀的多，这得益于其内部引用计数的实现，正是这种非独占所有权的方式，使其摆脱了auto_ptr的种种限制，并将其踢出了C++标准（auto_ptr在C++17中被移除），但是shared_ptr也不是完美无缺的，引用计数不能解决所的问题，并且可能会带来一些问题，比如“循环引用问题”，这个得靠后面我们即将说到的weak_ptr来解决，所以说没有什么结构是完美的，选择合适的就是最好的，综合前面多个测试的例子，可以得到一些经验。 总结 shared_ptr作为目前最优秀的指针，取代auto_ptr是必然的，所以能使用shared_ptr的地方还是尽量使用shared_ptr。 不要使用同一个原始对象的指针生成多个shared_ptr对象，这样使用会导致未定义的行为，比如test5这个函数就导致了崩溃和错误的输出。 shared_ptr不是万能的，如果不加思考的把原始指针都替换成shared_ptr，虽然大部分能防止内存泄露，但是还会造成其他的问题，比如循环引用，这种情况需要使用weak_ptr来解决问题，如果不解决就会造成另一种形式的内存泄漏。 不要使用get返回的指针来初始化一个shared_ptr对象，这种的做法的本质与第2点一样，会造成未定义的行为。 尽量不要保存get函数返回的指针，因为你不知道什么时候这个指针对应的对象就被析构掉了，所以请“随用随取”。 测试源码示例传送门：shared_ptr用法]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>智能指针</tag>
        <tag>shared_ptr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[auto_ptr浅析]]></title>
    <url>%2Fblog%2F2018%2F08%2F08%2Fauto-ptr%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言之前简单的列举了一下各种智能指针的特点，其中提到了这个历经沧桑的指针，C++98中引入，C++11中弃用，C++17中被移除，弃用的原因主要是使用不当容易造成内存崩溃，不能够作为函数的返回值和函数的参数，也不能在容器中保存auto_ptr。其实说这个指针“不能够作为函数的返回值和函数的参数，也不能在容器中保存”，这个结论过于武断了，经过一系列的测试后发现，原来真正的结论不应该说“不能”，准确来说是“不建议”。 auto_ptr本身是一个模板类，那么一般情况下直接用它来定义一个智能指针的对象，例如std::auto_ptr&lt;Test&gt; pa(new Test);需要注意的是pa虽然叫智能指针，但是它是一个对象，在它的内部保存着一个原始的对象的指针，其原理就是 RAII(Resource Acquisition Is Initialization) ，在智能指针构造的时候获取资源，在析构的时候释放资源，并进行相关指针操作的重载，使其使用起来就像普通的指针一样方便。 查看auto_ptr的代码时发现，它主要有get、release、reset、operator*、operator-&gt;、operator=几个函数，下面通过一些例子来了解一下auto_ptr的具体用法。 使用环境 VS2015 + Windows7（应该是C++11标准） 头文件#include &lt;memory&gt; 命名空间using namespace std; 测试过程首先我们先编写一些测试类，用来测试智能指针各个函数的作用，以及可能出现的问题，测试类的代码如下：123456789101112131415161718class Example&#123;public: Example(int param = 0) &#123; number = param; cout &lt;&lt; "Example: " &lt;&lt; number &lt;&lt; endl; &#125; ~Example() &#123; cout &lt;&lt; "~Example: " &lt;&lt; number &lt;&lt; endl; &#125; void test_print() &#123; cout &lt;&lt; "in test print: number = " &lt;&lt; number &lt;&lt; endl; &#125; void set_number(int num) &#123; number = num; &#125;private: int number;&#125;; 测试函数get、operator*、operator-&gt;get函数可以获得智能指针包装的原始指针，可以用来判断被包装对象的有效性，也可以用来访问被包装对象，operator*可以直接对智能指针包装的原始指针解引用，获得被包装的对象，operator-&gt;用来取得原始对象的指针，引用成员时与get函数作用相同，示例代码如下： 1234567891011void test1()&#123; auto_ptr&lt;Example&gt; ptr1(new Example(6)); // Example: 6(输出内容) if (ptr1.get()) // 判断内部指针的有效性 &#123; // 以下为访问成员的3种方法 ptr1.get()-&gt;test_print(); // in test print: number = 6(输出内容) ptr1-&gt;set_number(8); (*ptr1).test_print(); // in test print: number = 8(输出内容) &#125;&#125; // ~Example: 8(输出内容) // 出作用域被析构 测试函数release错误用法release函数是很容易让人误解的函数，一般看到release会想起释放、回收的含义，函数的作用通常就是回收掉申请的资源，但是这里就要注意了，auto_ptr对象的release函数只有释放的意思，指的是释放指针的所有权，说简单点就是auto_ptr的对象与原始的指针脱离关系，但是并不回收原始指针申请的内存，如果不主动释放就会造成内存泄露，就像下面这样： 12345678910111213void test2()&#123; //auto_ptr&lt;Example&gt; ptr2 = new Example(6); // 编译错误，不支持不同指针到智能指针的隐式转换 auto_ptr&lt;Example&gt; ptr2(new Example(6)); // Example: 6(输出内容) if (ptr2.get()) // 判断内部指针的有效性 &#123; ptr2.release(); // 调用release之后会释放内存所有权，但是不会析构，造成内存泄漏 if (!ptr2.get()) cout &lt;&lt; "ptr2 is invalid" &lt;&lt; endl; // ptr2 is invalid(输出内容) ptr2.release(); // 多写一遍没有任何作用 &#125;&#125; 测试函数release正确用法知道了relsease函数的错误用法，那么正确用法也就应该清楚了，需要自己调用delete，话说如果自己调用了delete那还用智能指针干什么，下面展示正常的用法： 123456789101112void test3()&#123; auto_ptr&lt;Example&gt; ptr3(new Example(3)); // Example: 3(输出内容) if (ptr3.get()) // 判断内部指针的有效性 &#123; Example *p = ptr3.release(); // release函数调用之后会释放内存的所有权，并且返回原始指针 if (!ptr3.get()) cout &lt;&lt; "ptr3 is invalid" &lt;&lt; endl; // ptr3 is invalid(输出内容) delete p; // ~Example: 3(输出内容) // 主动析构Example对象 &#125;&#125; 测试函数reset用法reset函数取其字面含义，就是重新设置的意思，也就是给一个指着对象设置一个新的内存对象让其管理，如果设置之前智能指针的已经管理了一个对象，那么在设置之后原来的对象会被析构掉，具体看测试结果： 12345678void test4()&#123; auto_ptr&lt;Example&gt; ptr4(new Example(4)); // Example: 4(输出内容) cout &lt;&lt; "after declare ptr4" &lt;&lt; endl; // after declare ptr4 ptr4.reset(new Example(5)); // Example: 5 // ~Example: 4 cout &lt;&lt; "after function reset" &lt;&lt; endl; // after function reset&#125; 测试函数operator=用法operator=也就是赋值运算符，是智能指针auto_ptr最具争议的一个方法，或者说一种特性，它的种种限制完全来自于这个赋值操作，作为面向的对象中的一部分，如果把一个对象赋值给另一个对象，那么两个对象就是完全一样的，但是这一点却在auto_ptr上打破了，智能指针auto_ptr的赋值，只是移交了所有权，将内部对象的控制所有权从等号的右侧转移到左侧，等号右侧的智能指针丧失对原有内部对象的控制，如果右侧的对象不检测内部对象的有效性，就会造成程序崩溃，测试如下： 1234567891011121314void test5()&#123; auto_ptr&lt;Example&gt; ptr5(new Example(5)); // Example: 5(输出内容) auto_ptr&lt;Example&gt; ptr6 = ptr5; // 没有输出 if (ptr5.get()) cout &lt;&lt; "ptr5 is valid" &lt;&lt; endl; // 没有输出，说明ptr5已经无效，如果再调用就会崩溃 if (ptr6.get()) cout &lt;&lt; "ptr6 is valid" &lt;&lt; endl; // ptr6 is valid(输出内容) ptr6-&gt;test_print(); // in test print: number = 5(输出内容) //ptr5-&gt;test_print(); // 直接崩溃 &#125; 测试auto_ptr类型返回一些文章中指出，auto_ptr不能作为函数的返回值，但是在我的测试环境下，可以正常执行，并且结果正确，但是还是不建议这样做，原因就是operator=，后面统一总结，先看下这个正常的例子： 1234567891011auto_ptr&lt;Example&gt; test6_inner()&#123; auto_ptr&lt;Example&gt; ptr6(new Example(6)); // Example: 6(输出内容) return ptr6;&#125;void test6()&#123; auto_ptr&lt;Example&gt; ptr6 = test6_inner(); // 测试auto_ptr类型返回值 ptr6-&gt;test_print(); // in test print: number = 6(输出内容)&#125; // ~Example: 6(输出内容) // 主动析构Example对 测试auto_ptr作为参数这是常常容易出错的情况，原因还是operator=的操作引起的，因为auto_ptr的赋值会转移控制权，所以你把auto_ptr的对象作为参数传递给一个函数的时候，后面再使用这个对象就会直接崩溃： 1234567891011void test7_inner(auto_ptr&lt;Example&gt; ptr7)&#123; ptr7-&gt;test_print(); // in test print: number = 6(输出内容)&#125; // ~Example: 7(输出内容) // 主动析构Example对象void test7()&#123; auto_ptr&lt;Example&gt; ptr7(new Example(7)); // Example: 7(输出内容) test7_inner(ptr7); // 传递参数 //ptr7-&gt;test_print(); // 直接崩溃&#125; 两个auto_ptr管理一个指针这种错误稍微出现的明显一点，因为智能指针的对象在析构时会回收内部对象的内存，如果两个智能指针同时管理一个内部对象，那么两个auto_ptr对象析构时都会试图释放内部对象的资源，造成崩溃问题： 1234567void test8()&#123; Example *p = new Example(8); // Example: 7(输出内容) auto_ptr&lt;Example&gt; ptr8(p); auto_ptr&lt;Example&gt; ptr9(p);&#125; //~Example: 8(输出内容) // 主动析构Example对象 //~Example: -572662307(输出内容) // 第二次析构崩溃 测试auto_ptr作为容器元素这是一个被广泛讨论的问题，可能你已经猜到了，一般说auto_ptr不能作为容器的元素也是因为operator=操作，但是我在Windows平台上成功运行了下面的代码，并且输出了正常的对象构造信息和析构信息，但是在Linux平台根本就编译不过去，出现大段的编译错误，其中重要的一句就是.../bits/stl_construct.h:73: 错误：对‘std::auto_ptr&lt;Example&gt;::auto_ptr(const std::auto_ptr&lt;Example&gt;&amp;)’的调用没有匹配的函数，其实可以说是operator=的锅，也可以说是拷贝构造函数的锅，但最根本的问题还是赋值时控制权转移导致的，测试代码如下： 123456789void test9()&#123; vector&lt;auto_ptr&lt;Example&gt;&gt; v(10); int i = 0; for (; i &lt; 10; i++) &#123; v[i] = auto_ptr&lt;Example&gt;(new Example(i));// windows下正常构造、析构，linux下无法通过编译 &#125;&#125; 测试auto_ptr的引用作为参数传递这个例子比较正常，就是将auto_ptr的对象进行引用传递，这种方式不会造成控制权转移，所以不会出现问题： 1234567891011void test10_inner(auto_ptr&lt;Example&gt;&amp; ptr10)&#123; ptr10-&gt;test_print(); // in test print: number = 6(输出内容)&#125; // 这里没有析构void test10()&#123; auto_ptr&lt;Example&gt; ptr10(new Example(10)); // Example: 10(输出内容) test10_inner(ptr10); // 传递引用参数 ptr10-&gt;test_print(); // in test print: number = 10(输出内容)&#125; //~Example: 10(输出内容) // 主动析构Example对象 测试auto_ptr的指针作为参数传递这个例子本质上同上个例子一样，就是将auto_ptr的对象的地址传递，这种指针的方式不会造成控制权转移，所以也不会出现问题： 1234567891011void test11_inner(auto_ptr&lt;Example&gt;* ptr11)&#123; (*ptr11)-&gt;test_print(); // in test print: number = 11(输出内容)&#125; // 这里没有析构void test11()&#123; auto_ptr&lt;Example&gt; ptr11(new Example(11)); // Example:11(输出内容) test11_inner(&amp;ptr11); // 传递地址参数 ptr11-&gt;test_print(); // in test print: number = 11(输出内容)&#125; // ~Example: 11(输出内容) // 主动析构Example对象 现象分析上述这些例子比较简单，主要是说明auto_ptr的用法，其中比较有争议的也就是6,7,9三个例子，也就是我们前文所说的“不建议”将auto_ptr作为函数返回值、函数参数、容器内的元素，这三个例子中只有作为函数参数的那个例子崩溃了，但是如果我们调用完函数test7_inner之后，不在使用智能指针ptr7也就不会崩溃了，那么是不是说只要我们注意到可能发生的问题，就可以使用auto_ptr在这些情况呢，目前来看是这样的。 但是为什么在Windows上成功运行的test9在Linux上却编译不过呢？简单点说就是为了怕你犯错，而对你采取管制措施，实际上你可以把auto_ptr作为容器的元素，但是因为这样太容易出错了，所以压根就不允许你这样做。 那么Linux是怎样在编译时期就提示auto_ptr这种错误，而Windows又是怎样绕过这种错误的呢？其实从应用的方便性和安全角度出发，容器应该要求其元素对象的拷贝与原对象相同或者等价，但是很明显auto_ptr做不到这一点，因为它的赋值是实质上是控制权的转移，而不是等价的复制，所以拷贝之后原对象必然被改变，linux版本的auto_ptr就是利用了这一点，使其违反C++的静态类型安全规则，这个版本的auto_ptr只实现构造函数auto_ptr(auto_ptr&amp; other)和赋值函数auto_ptr&amp; operator=(auto_ptr&amp; other)，因为参数都是非const，在构造或者赋值的时候原对象可能会发生变化，所以与容器对元素要求的不符合，这样在编译阶段就会检查出错误，也就是我们上面test9函数中提示的错误.../bits/stl_construct.h:73: 错误：对‘std::auto_ptr&lt;Example&gt;::auto_ptr(const std::auto_ptr&lt;Example&gt;&amp;)’的调用没有匹配的函数，这样就避免了把auto_ptr作为容器的元素。 关于Windows平台上正常运行test9函数的疑惑，实际上可以从两个方面来考虑，一种方式就是放宽容器对元素的要求，也就是说允许容器中的元素赋值之后，原对象被改变；另一种方式就是auto_ptr只提供构造函数auto_ptr(const auto_ptr&amp; other)和赋值函数auto_ptr&amp; operator=(const auto_ptr&amp; other)，这样就就可以通过容器的检测了，但是还有一个问题需要解决，那就是auto_ptr肯定要改变原对象，const类型就没法改变了，其实还有一种神奇的操作叫强制类型转换，使用const_cast就可以改变const对象，这样就达到了使用auto_ptr作为容器元素的目的，具体细节参考: auto_ptr到底能不能作为容器的元素? 前面提到把auto_ptr作为容器元素时很容易出错，这是为什么各个版本的auto_ptr实现的差异会这么大的原因，出错的根本原因就是auto_ptr构造和赋值时控制权的转移，试想一下，对一个容器进行排序，然后提供一个排序函数，然后排序时把容器中的元素传入比较函数，结果容器中元素的内部对象全都被清空了，这显然不是我们想要的，但是如果你不使用类似操作，那么把auto_ptr作为容器元素也没有什么不可。 总结 既然auto_ptr在C++17中已经被移除，那么我们也应该顺应潮流，尽量不使用auto_ptr了。 虽然不建议使用auto_ptr了，但是他的用法和注意事项我们还是应该了解，毕竟存在了这么多年，还有很多老代码中在用着。 由于各平台差异很大，目前auto_ptr作为容器元素不可移植，无论你使用的STL平台是否允许auto_ptr容器，你都不应该这样做。 通过分析发现auto_ptr能不能作为容器的元素并非绝对的，不仅与STL的实现有关，而且与STL容器的需求和安全性以及容器的语义有关。]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>智能指针</tag>
        <tag>auto_ptr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能指针分类及简单特性]]></title>
    <url>%2Fblog%2F2018%2F08%2F06%2F%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E5%88%86%E7%B1%BB%E5%8F%8A%E7%AE%80%E5%8D%95%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[前言智能指针的种类繁多，我听说过的就有这些：auto_ptr、shared_ptr、weak_ptr、unique_ptr、scoped_ptr、scoped_array、shared_array、intrusive_ptr，这些智能指针看起来种类繁多，但实际上常用的就只有两三种，他们是shared_ptr、weak_ptr和unique_ptr，先简单了解一下这几个指针，后续再列出具体的例子和选择标准。 分类及特性 auto_ptr 这个指针历经沧桑，C++98中引入，C++11中弃用，C++17中被移除，弃用的原因主要是使用不当容易造成内存崩溃，不能够作为函数的返回值和函数的参数，也不能在容器中保存auto_ptr。 shared_ptr 据说是最好用的智能指针，使用引用计数实现，每使用它一次，内部的引用计数加1，每析构一次，内部的引用计数减1，减为0时，自动删除所指向的堆内存。shared_ptr内部的引用计数是线程安全的，但是对象的读取需要加锁。 weak_ptr 没有什么存在感，基本只在解除 shared_ptr循环引用时使用，weak_ptr没有共享资源，它的构造不会引起指针引用计数的增加，使用weak_ptr的成员函数use_count()可以观测资源的引用计数，使用成员函数lock()从被观测的shared_ptr获得一个可用的shared_ptr对象。 unique_ptr 一种比auto_ptr更加优秀的指针，可以唯一的拥有一个对象，auto_ptr通过等号赋值改变所有权后，再次引用原对象会造成内存崩溃，但是unique_ptr可以用过std::move改变所有权，并且引用原对象会在编译时期就指出错误，同时在容器算法中也可以使用，另有一种说法是说unique_ptr是scoped_ptr在标准库中的一个分身。 scoped_ptr 存在于boost库而非标准库中，要把资源限制在作用域里的，并且永远不能被复制，是一种轻量级的智能指针，和const auto_ptr很像，但是可以被reset，并可以更加清楚地表明意图。 scoped_array 跟scoped_ptr一样，也是独享所有权的，用于管理动态数组，不支持复制，并且初始化的时候需要使用动态数组，没有重载operator*，需要使用get()函数。 shared_array 跟 shared_ptr 一样，内部使用了引用计数，可以复制，通过参数来传递等，需要使用动态数组来初始化。 intrusive_ptr 这是一种侵入式的智能指针，内部不含有引用计数，要求被存储的对象自己实现引用计数功能，不然编译不过，还要提供intrusive_ptr_add_ref和intrusive_ptr_release函数接口供intrusive_ptr调用。 总结 智能指针的种类很多，但是只要掌握shared_ptr、weak_ptr、unique_ptr这三种指针的用法，就可以处理绝大多数问题。 智能指针的选择就根据特性来选，但是auto_ptr尽量不要用了，虽然历史悠久，但是毕竟由于各种诟病被抛弃了。 以上只给出了分类和简单特性，后续有时间会依次给出示例，指出用法和需要注意的点。]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>智能指针</tag>
        <tag>shared_ptr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简述TCP三次握手和四次挥手流程]]></title>
    <url>%2Fblog%2F2018%2F07%2F11%2F%E7%AE%80%E8%BF%B0TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言关于TCP的连接过程，很多从事程序开发的小伙伴应该都听过三次握手，可这三次握手的细节还是有很多人不太清楚的，特别是有些参数记不清楚，我也经常弄错，所以我根据自己的理解画了两张图，将TCP连接和断开的流程简单记录一下，以方便后续查找复习之用。 三次握手 初始状态：客户端A和服务器B均处于CLOSED状态，然后服务器B创建socket，调用监听接口使得服务器处于LISTEN状态，等待客户端连接。（后续内容用A，B简称代替） A首先向B发起连接，这时TCP头部中的SYN标识位值为1，然后选定一个初始序号seq=x（一般是随机的），消息发送后，A进入SYN_SENT状态，SYN=1的报文段不能携带数据，但要消耗一个序号。 B收到A的连接请求后，同意建立连接，向A发送确认数据，这时TCP头部中的SYN和ACK标识位值均为1，确认序号为ack=x+1，然后选定自己的初始序号seq=y（一般是随机的），确认消息发送后，B进入SYN_RCVD状态，与连接消息一样，这条消息也不能携带数据，同时消耗一个序号。 A收到B的确认消息后，需要给B回复确认数据，这时TCP头部中的ACK标识位值为1，确认序号是ack=y+1，自己的序号在连接请求的序号上加1，也就是seq=x+1，此时A进入ESTABLISHED状态，当B收到A的确认回复后，B也进入ESTABLISHED状态，至此TCP成功建立连接，A和B之间就可以通过这个连接互相发送数据了。 四次挥手 初始状态：客户端A和服务器B之间已经建立了TCP连接，并且数据发送完成，打算断开连接，此时客户端A和服务器B是等价的，双方都可以发送断开请求，下面以客户端A主动发起断开请求为例。（后续内容用A，B简称代替） A首先向B发送断开连接消息，这时TCP头部中的FIN标识位值为1，序号是seq=m，m为A前面正常发送数据最后一个字节序号加1得到的，消息发送后A进入FNI_WAIT_1状态，FIN=1的报文段不能携带数据，但要消耗一个序号。 B收到A的断开连接请求需要发出确认消息，这时TCP头部中的ACK标识位值为1，确认号为ack=m+1，而自己的序号为seq=n,n为B前面正常发送数据最后一个字节序号加1得到的，然后B进入CLOSE_WAIT状态，此时就关闭了A到B的连接，A无法再给B发数据，但是B仍然可以给A发数据（此处存疑），同时B端通知上方应用层，处理完成后被动关闭连接。然后A收到B的确认信息后，就进入了FIN_WAIT_2状态。 B端应用层处理完数据后，通知关闭连接，B向A发送关闭连接的消息，这时TCP头部中的FIN和ACK标识位值均为1，确认号ack=m+1，自己的序号为seq=k，（B发出确认消息后有发送了一段数据，此处存疑），消息发送后B进入LACK_ACK状态。 A收到B的断开连接的消息后，需要发送确认消息，这是这时TCP头部中的ACK标识位值为1，确认号ack=k+1，序号为m+1（因为A向B发送断开连接的消息时消耗了一个消息号），然后A进入TIME_WAIT状态，若等待时间经过2MSL后，没有收到B的重传请求，则表明B收到了自己的确认，A进入CLOSED状态，B收到A的确认消息后则直接进入CLOSED状态。至此TCP成功断开连接。 总结 关于三次握手，参考了很多资料说服务器是被动打开连接，对此有些不解，希望知道的朋友给出提示和建议。 关于四次挥手，在我的叙述中有两处存疑，就是B收到的A的主动断开请求后，进入CLOSE_WAIT状态，是否还能发送数据到A，参考了一些资料说A不能发数据给B，但是B能发数据给A，并且A也可以接收，但是无论我在Windows环境测试还是Linux环境下测试这种状态A都无法收到B的数据，不知道我是不是理解错了，希望明白原理的小伙伴能解答一下。 在四次挥手的最后阶段，有一个等待时间2MSL，这个不是一个时间单位，而是一个表明时间段的名词，这段等待时间就是为了在B没收到确认消息时，接收B的重传请求的，如果不等待这一段时间直接进入CLOSED状态，那么B未收到A的确认消息就会发送重传请求，而此时A已经关闭，就不会再给B重传了，其中MSL的是Maximum Segment Lifetime英文的缩写，可简单译为“报文最大生存时间”，也就是说如果B没有收到确认信息，那么在2MSL这段时间内很大概率就会发送重传请求，并且被A收到，RFC 793中规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。 在连接和断开的过程都有提到ACK和ack，这一点要注意区分，大写的ACK代表TCP头部中6个标识位之一，是表明这是个确认报文，而小写的ack拜师确认序号，表明对方发来的数据到ack这个序号前的都已经收到了。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Network</tag>
        <tag>Socket</tag>
        <tag>网络连接</tag>
        <tag>网络断开</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结构体sockaddr、sockaddr_in、sockaddr_in6之间的区别和联系]]></title>
    <url>%2Fblog%2F2018%2F07%2F10%2F%E7%BB%93%E6%9E%84%E4%BD%93sockaddr%E3%80%81sockaddr-in%E3%80%81sockaddr-in6%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[前言最近在学习网络相关的知识，虽然之前代码写了不少，但是长时间不写难免会忘记，简单地复习了一下IO多路复用的方式，对比了解了一下epoll模式和select模式的异同，不过写代码的时候发现，这个socket连接中有几个结构还是挺让人头大的，用着用着突然就强转成其他的类型了，加上年前改了半天IPv6的连接，这几个结构体更加混乱，所以今天角色放到一起，从源码的角度看一下sockaddr、sockaddr_in、sockaddr_in6这三个结构体之间的联系，以及为什么有些情况可以直接强转。 代码分析 看一下这三个结构的定义，先说明一下版本，操作系统为CentOS，头文件版本应该挺古老了，在’/usr/include/netinet/in.h’ 中发现版权信息：Copyright (C) 1991, 1992, 1994-2001, 2004, 2006, 2007, 2008, 2009, 2010，看着很古老，但之后的版本应该没有改动很大吧，反正不太清楚，我们就分析当前这一个版本吧。 1234567891011121314151617181920212223242526272829303132333435/* /usr/include/bits/socket.h *//* Structure describing a generic socket address. */struct sockaddr&#123; __SOCKADDR_COMMON (sa_); /* Common data: address family and length. */ char sa_data[14]; /* Address data. */&#125;;/* /usr/include/netinet/in.h *//* Structure describing an Internet socket address. */struct sockaddr_in&#123; __SOCKADDR_COMMON (sin_); in_port_t sin_port; /* Port number. */ struct in_addr sin_addr; /* Internet address. */ /* Pad to size of `struct sockaddr'. */ unsigned char sin_zero[sizeof (struct sockaddr) - __SOCKADDR_COMMON_SIZE - sizeof (in_port_t) - sizeof (struct in_addr)];&#125;;/* /usr/include/netinet/in.h */#ifndef __USE_KERNEL_IPV6_DEFS/* Ditto, for IPv6. */struct sockaddr_in6&#123; __SOCKADDR_COMMON (sin6_); in_port_t sin6_port; /* Transport layer port # */ uint32_t sin6_flowinfo; /* IPv6 flow information */ struct in6_addr sin6_addr; /* IPv6 address */ uint32_t sin6_scope_id; /* IPv6 scope-id */&#125;;#endif /* !__USE_KERNEL_IPV6_DEFS */ 看到3个结构的定义想到了什么？只是看着有点像吧，真正的区别我们往下看，其中3个结构里都包含了 __SOCKADDR_COMMON 这个宏，我们先把它的定义找到，最后在’usr/inlcue/bits/sockaddr.h’中找到如下代码， 1234567891011/* POSIX.1g specifies this type name for the `sa_family' member. */typedef unsigned short int sa_family_t;/* This macro is used to declare the initial common members of the data types used for socket addresses, `struct sockaddr', `struct sockaddr_in', `struct sockaddr_un', etc. */#define __SOCKADDR_COMMON(sa_prefix) \ sa_family_t sa_prefix##family#define __SOCKADDR_COMMON_SIZE (sizeof (unsigned short int)) 由此我们知道，这三个结构的第一个字段都是一个unsigned short int 类型，只不过用宏来定义了三个不同的名字，至此第一个结构就清楚了，在一般环境下（short一般为2个字节），整个结构占用16个字节，变量sa_family占用2个字节，变量sa_data 保留14个字节用于保存IP地址信息。 接着我们发现第二个结构中还有in_port_t和struct in_addr两个类型没有定义，继续找下去吧，在文件‘/usr/include/netinet/in.h’发现以下定义 123456789/* Type to represent a port. */typedef uint16_t in_port_t;/* Internet address. */typedef uint32_t in_addr_t;struct in_addr&#123; in_addr_t s_addr;&#125;; 这么看来sockaddr_in这个结构也不复杂，除了一开始的2个字节表示sin_family，然后是2个字节的变量sin_port表示端口，接着是4个字节的变量sin_addr表示IP地址，最后是8个字节变量sin_zero填充尾部，用来与结构sockaddr对齐 现在我们该分析结构sockaddr_in6了，这里边只有一个未知的结构in6_addr，经过寻找发现其定义也在’/usr/include/netinet/in.h’中 12345678910111213141516171819#ifndef __USE_KERNEL_IPV6_DEFS/* IPv6 address */struct in6_addr&#123; union &#123; uint8_t __u6_addr8[16];#if defined __USE_MISC || defined __USE_GNU uint16_t __u6_addr16[8]; uint32_t __u6_addr32[4];#endif &#125; __in6_u;#define s6_addr __in6_u.__u6_addr8#if defined __USE_MISC || defined __USE_GNU# define s6_addr16 __in6_u.__u6_addr16# define s6_addr32 __in6_u.__u6_addr32#endif&#125;;#endif /* !__USE_KERNEL_IPV6_DEFS */ 这个结构看起来有点乱，但是如果抛开其中的预编译选项，其实就是8个字节，用来表示IPV6版本的IP地址，一共128位，只不过划分字节的段数有些不同，每段字节多一点那么段数就少一点，反义亦然。 那接下来我们整理一下，为了看的清楚，部分结构使用伪代码，不能通过编译，主要是方便对比，整理如下 12345678910111213141516171819202122232425/* Structure describing a generic socket address. */struct sockaddr&#123; uint16 sa_family; /* Common data: address family and length. */ char sa_data[14]; /* Address data. */&#125;;/* Structure describing an Internet socket address. */struct sockaddr_in&#123; uint16 sin_family; /* Address family AF_INET */ uint16 sin_port; /* Port number. */ uint32 sin_addr.s_addr; /* Internet address. */ unsigned char sin_zero[8]; /* Pad to size of `struct sockaddr'. */&#125;;/* Ditto, for IPv6. */struct sockaddr_in6&#123; uint16 sin6_family; /* Address family AF_INET6 */ uint16 sin6_port; /* Transport layer port # */ uint32 sin6_flowinfo; /* IPv6 flow information */ uint8 sin6_addr[16]; /* IPv6 address */ uint32 sin6_scope_id; /* IPv6 scope-id */&#125;; 这么来看是不是就清晰多了，由此我们发现结构 sockaddr 和 sockaddr_in 字节数完全相同，都是16个字节，所以可以直接强转，但是结构 sockaddr_in6 有28个字节，为什么在使用的时候也是直接将地址强制转化成(sockaddr*)类型呢？ 强转的可能性其实sockaddr 和 sockaddr_in 之间的转化很容易理解，因为他们开头一样，内存大小也一样，但是sockaddr和sockaddr_in6之间的转换就有点让人搞不懂了，其实你有可能被结构所占的内存迷惑了，这几个结构在作为参数时基本上都是以指针的形式传入的，我们拿函数bind()为例，这个函数一共接收三个参数，第一个为监听的文件描述符，第二个参数是sockaddr*类型，第三个参数是传入指针原结构的内存大小，所以有了后两个信息，无所谓原结构怎么变化，因为他们的头都是一样的，也就是uint16 sa_family，那么我们也能根据这个头做处理，原本我没有看过bind()函数的源代码，但是可以猜一下: 1234567891011121314151617int bind(int socket_fd, sockaddr* p_addr, int add_size)&#123; if (p_addr-&gt;sa_family == AF_INET) &#123; sockaddr_in* p_addr_in = (sockaddr_in*)p_addr; //... &#125; else if (p_addr-&gt;sa_family == AF_INET6) &#123; sockaddr_in6* p_addr_in = (sockaddr_in6*)p_addr; //... &#125; else &#123; //... &#125;&#125; 由以上代码完全可以实现IPv4和IPv6的版本区分，所以不需要纠结内存大小的不同 总结 通过等价替换的方式我们可以更好的了解sockaddr、sockaddr_in、sockaddr_in6之间的异同。 网路接口函数针对于IPv4和IPv6虽然有不同的结构，但是接口基本相同，主要是为了用户（开发者）使用方便吧。 有时间可以看一下bind()、accept()等函数，看看其中对于结构的使用到底是怎样的。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Network</tag>
        <tag>Socket</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VS2015调试dump文件时提示未找到xxx.exe或xxx.dll]]></title>
    <url>%2Fblog%2F2018%2F06%2F23%2FVS%E8%B0%83%E8%AF%95dump%E6%96%87%E4%BB%B6%E6%97%B6%E6%8F%90%E7%A4%BA%E6%9C%AA%E6%89%BE%E5%88%B0Xxxx-exe%E6%88%96xxx-dlll%2F</url>
    <content type="text"><![CDATA[前言游戏开发的过程中，经常会出现客户端宕机的问题，这时候一个小小的dump文件可以记录当时的内存及堆栈情况，对于解决崩溃的问题有巨大的帮助，之前用VS2008的时候调试过dump文件，但是最近客户端升级为VS2015以后，调试dump文件时经常会出现未找到xxx.exe或xxx.dll的情况，之前一直好使的方法现在却行不通了，于是决定找找解决的办法。 问题原因起初尝试过新建dump文件所显示的路径，复制exe或dll到指定路径下，复制dump文件到exe所在路径下都提示找不到，甚至是手动指定dll或者exe文件都无法打开，这就很奇怪了，原来只要把dump文件放在exe所在目录就可以啊，怎么这次不行了呢？终于，经过多次试验之后发现，原来在VS2015上调试dump文件，要求dump文件的版本与产生dump文件的exe或者dll必须一致，也就是说你要调试一个dump文件，就必须找到找到对应版本dll和exe，否则就会提示无法找到xxx.exe或xxx.dll，下面我们来试验一下。 产生dump文件产生dump文件的方法网上很容易找到，如果想测试的话可以自己找一找，也可以使用下面的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include "stdafx.h"#include "Windows.h"#include "DbgHelp.h"int GenerateMiniDump(PEXCEPTION_POINTERS pExceptionPointers)&#123; // 定义函数指针 typedef BOOL(WINAPI * MiniDumpWriteDumpT)( HANDLE, DWORD, HANDLE, MINIDUMP_TYPE, PMINIDUMP_EXCEPTION_INFORMATION, PMINIDUMP_USER_STREAM_INFORMATION, PMINIDUMP_CALLBACK_INFORMATION ); // 从 "DbgHelp.dll" 库中获取 "MiniDumpWriteDump" 函数 MiniDumpWriteDumpT pfnMiniDumpWriteDump = NULL; HMODULE hDbgHelp = LoadLibrary(_T("DbgHelp.dll")); if (NULL == hDbgHelp) &#123; return EXCEPTION_CONTINUE_EXECUTION; &#125; pfnMiniDumpWriteDump = (MiniDumpWriteDumpT)GetProcAddress(hDbgHelp, "MiniDumpWriteDump"); if (NULL == pfnMiniDumpWriteDump) &#123; FreeLibrary(hDbgHelp); return EXCEPTION_CONTINUE_EXECUTION; &#125; // 创建 dmp 文件件 TCHAR szFileName[MAX_PATH] = &#123; 0 &#125;; TCHAR* szVersion = _T("dump_file_v1.0"); SYSTEMTIME stLocalTime; GetLocalTime(&amp;stLocalTime); wsprintf(szFileName, L"%s-%04d%02d%02d-%02d%02d%02d.dmp", szVersion, stLocalTime.wYear, stLocalTime.wMonth, stLocalTime.wDay, stLocalTime.wHour, stLocalTime.wMinute, stLocalTime.wSecond); HANDLE hDumpFile = CreateFile(szFileName, GENERIC_READ | GENERIC_WRITE, FILE_SHARE_WRITE | FILE_SHARE_READ, 0, CREATE_ALWAYS, 0, 0); if (INVALID_HANDLE_VALUE == hDumpFile) &#123; FreeLibrary(hDbgHelp); return EXCEPTION_CONTINUE_EXECUTION; &#125; // 写入 dmp 文件 MINIDUMP_EXCEPTION_INFORMATION expParam; expParam.ThreadId = GetCurrentThreadId(); expParam.ExceptionPointers = pExceptionPointers; expParam.ClientPointers = FALSE; pfnMiniDumpWriteDump(GetCurrentProcess(), GetCurrentProcessId(), hDumpFile, MiniDumpWithDataSegs, (pExceptionPointers ? &amp;expParam : NULL), NULL, NULL); // 释放文件 CloseHandle(hDumpFile); FreeLibrary(hDbgHelp); return EXCEPTION_EXECUTE_HANDLER;&#125;LONG WINAPI ExceptionFilter(LPEXCEPTION_POINTERS lpExceptionInfo)&#123; // 这里做一些异常的过滤或提示 if (IsDebuggerPresent()) &#123; return EXCEPTION_CONTINUE_SEARCH; &#125; return GenerateMiniDump(lpExceptionInfo);&#125;void create_dump()&#123; // 给空指针赋值，使程序崩溃产生 Dump 文件 int *ptr = NULL; *ptr = 101;&#125;int main()&#123; // 加入崩溃dump文件功能 SetUnhandledExceptionFilter(ExceptionFilter); create_dump();&#125; 将上述代码编译成exe文件，然后点击运行就会在exe所在目录产生一个dump文件，例如我产生的dump文件为dump_file_v1.0-20180623-123940.dmp 调试dump文件双击打开刚刚生成的dump文件，会出现如下界面： 点击右侧 “使用 仅限本机 进行调试” 按钮，就会显示出程序崩溃时的堆栈信息和内存情况以及崩溃位置的代码，如下图： 以上是正常的调试情况，接下来不需要改变代码，重新编译一下程序，得到新版本的exe文件，然后双击刚刚的dump文件dump_file_v1.0-20180623-123940.dmp，点击右侧 “使用 仅限本机 进行调试” 按钮，情况就会发生变化，显示结果如下图： 点击 “中断” 按钮，就会出现标题所说的未找到vsDump.exe。在小型转储中未找到 vsDump.exe。 您需要加载二进制文件才能查找当前堆栈帧的源代码。 看到了吧，只要是dump文件不是这个exe产生的，不管源代码是不是一样，结果都会提示找不到exe，至此我们就找到了“VS2015调试dump文件时提示未找到xxx.exe或xxx.dll”的原因。 总结 VS2015调试dump文件时需要保证dump文件和exe、dll版本一致 遇到奇怪的问题可以手动模拟一下，往往可以重现，然后找到具体的原因]]></content>
      <categories>
        <category>VS</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>VS</tag>
        <tag>dump文件调试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作指向类成员的指针需要了解的两个操作符->*和.*]]></title>
    <url>%2Fblog%2F2018%2F05%2F12%2F%E6%93%8D%E4%BD%9C%E6%8C%87%E5%90%91%E7%B1%BB%E6%88%90%E5%91%98%E7%9A%84%E6%8C%87%E9%92%88%E9%9C%80%E8%A6%81%E4%BA%86%E8%A7%A3%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%93%8D%E4%BD%9C%E7%AC%A6-%E5%92%8C%2F</url>
    <content type="text"><![CDATA[前言关于 -&gt;* 这种写法在很早就在项目代码里见过了，并且还写过，不过当时并没有正确的理解这样写的含义，一直到最近发现这样写很奇怪，于是根据自己的理解，开始改代码，发现无论怎么改都无法通过编译，仔细搜索后才发现这是一种固定的写法，也就是说 -&gt;* 是一个操作符，无法拆分，同时还有一个 .* 也是相同的作用，只不过是用于对象上，而 -&gt;* 是用于对象的指针上。 那么这两个操作符究竟有什么作用呢？实际上它们主要用于操作指向类成员的指针，可能你会说指向类成员的指针直接定义就好了，为什么这么麻烦，还要是用这两个操作符呢？接下来我们举几个例子就明白了。 指向类数据成员的指针12345678910111213141516#include &lt;iostream&gt;class C&#123;public: int m;&#125;;int main()&#123; int C::* p = &amp;C::m; // pointer to data member m of class C C c = &#123;7&#125;; std::cout &lt;&lt; c.*p &lt;&lt; '\n'; // prints 7 C* cp = &amp;c; cp-&gt;m = 10; std::cout &lt;&lt; cp-&gt;*p &lt;&lt; '\n'; // prints 10&#125; 看到上述代码中的p指针有什么不同了吧，这是一个指向类成员变量的指针，如果我们不这样定义p也想操作c对象的成员变量m要怎么办呢？我们可以这样写： 123456789101112131415#include &lt;iostream&gt;class C&#123;public: int m;&#125;;int main()&#123; C c = &#123;7&#125;; int *p = &amp;c.m; std::cout &lt;&lt; *p &lt;&lt; '\n'; // prints 7 *p = 10; std::cout &lt;&lt; *p &lt;&lt; '\n'; // prints 10&#125; 这样代码中的变量p就变成了一个简单的指向整型数据的指针，我们也可以通过它访问c对象的m变量，并且给它赋值，但是你有没有发现区别，前一种指针p只依赖于类C的定义，可以在类C创建对象之前就给指针p定义赋值，但是后一种数据指针p就只能在类C创建对象之后才能给它赋值，还有一点，前一种指针p可以根据调用它的对象不同而访问不同类C对象的值，而后一种指针p就只能访问它所指向的那个对象的m值，如果要访问其他对象，需要重新给p赋值。 注意指向类成员指针的定义和赋值方法，是int C::* p = &amp;C::m;，取变量m的地址还有两种写法，&amp;(C::m) 或者 &amp;m这两种写法只能写在类C的成员函数中，所表示的也就是一个简单的指向整型变量的指针，即int*，与 &amp;C::m的含义是大不相同的。 而操作符-&gt;* 和.*在代码中起什么作用呢，我们只看这一句std::cout &lt;&lt; cp-&gt;*p &lt;&lt; &#39;\n&#39;;，其中表达式cp-&gt;*p用到了操作符-&gt;*，根据我的理解这个操作符的作用就是将后面的指针解引用，然后再被前面的对象调用，首先我们看cp是一个指向c对象的指针，如果想访问m变量，可以直接使用cp-&gt;m，假设现在不想这么写，我们有一个指向类C中m变量的指针p，那么直接写成cp-&gt;p肯定是不行的，因为p并不是类C的成员，它只是一个指向类C成员的指针，所以需要将其解引用，转换成真正的成员才能被cp指针引用到，那么*cp其实就是类C中的m，组合到一起就是cp-&gt; *p，这只是理解，其实-&gt;*是一个不可分割的操作符，需要紧挨着写成cp-&gt;*p才能编译通过。 另外关于指向类成员指针，在操作对象是父类对象和子类对象时有什么不同呢?答案是：指向可访问的非虚拟基类的数据成员的指针可以隐式地转换为指向派生类的同一数据成员的指针，反过来结果就是未定义的了，可以参考代码： 1234567891011121314151617#include &lt;iostream&gt;class Base&#123;public: int m;&#125;;class Derived : public Base &#123;&#125;;int main()&#123; int Base::* bp = &amp;Base::m; int Derived::* dp = bp; Derived d; d.m = 1; std::cout &lt;&lt; d.*dp &lt;&lt; '\n'; // prints 1 std::cout &lt;&lt; d.*bp &lt;&lt; '\n'; // prints 1&#125; 指向类成员函数的指针其实前面的例子我在工作中还真没遇到过，但是指向类数据成员的指针确实经常用，熟悉函数指针的工程师都知道，类似于void (*func)(); 就是定义了指向一个无返回值无参数函数的指针，调用时只要写成(*func)();就行，但是如果定义指向类成员函数的指针可就麻烦一点了，接下来看一个例子： 1234567891011121314class C&#123;public: void f(int n) &#123; std::cout &lt;&lt; n &lt;&lt; '\n'; &#125;&#125;;int main()&#123; void (C::* p)(int) = &amp;C::f; // pointer to member function f of class C C c; (c.*p)(1); // prints 1 C* cp = &amp;c; (cp-&gt;*p)(2); // prints 2&#125; 这个例子中的函数指针p是有作用域的，也就是只能指向类C中的无返回值并且有一个整型参数的函数，代码中赋值为&amp;C::f，这个形式与数据成员指针的赋值一样，其实函数f就是类C的一个成员而已。 那么它是怎么通过p指针调用到函数f的呢？我们看一句代码(cp-&gt;*p)(2);其实-&gt;*在这里还是起到了解引用并访问的作用，如果要访问f函数，只要cp-&gt;f(2)即可，但是这里没有f只有一个指向f的指针p，所以将f替换成*p编程cp-&gt;*p(2);但是这样无法通过编译，它无法区分那一部分是函数体，那一部分是参数，所以加个括号指明一下变成(cp-&gt;*p)(2);就可以正常访问f函数了。 实际上对面向对象编程了解的深入一点就会知道，调用对象的成员函数，实际上就是把对象的指针this作为函数第一个参数传进去，比如cp-&gt;f(2)，假如函数f的函数指针是func，那么cp-&gt;f(2)就是调用func(cp, 2)，这样在函数f中就可以调用对象的成员变量或者其他的成员函数了，但是如果你的成员函数中没有访问成员内容，那么这个this指针传什么都可以，也就是说func(cp, 2)和func(0, 2)、func(0x1234567890, 2)都是等价的，在这个例子中就是这样，所有你可以这样来写一段代码：(((C*)0)-&gt;*p)(2)，也是可以打印出数字2的。 另外关于指向类成员函数指针，在操作对象是父类对象和子类对象时与成员变量的规则一致：指向可访问的非虚拟基类的成员函数的指针可以隐式地转换为指向派生类的同一成员函数的指针，反过来也是未定义，可以参考代码： 12345678910111213141516#include &lt;iostream&gt;class Base&#123;public: void f(int n) &#123; std::cout &lt;&lt; n &lt;&lt; '\n'; &#125;&#125;;class Derived : public Base &#123;&#125;;int main()&#123; void (Base::* bp)(int) = &amp;Base::f; void (Derived::* dp)(int) = bp; Derived d; (d.*dp)(1); (d.*bp)(2);&#125; 具体使用前面提到过指向类数据成员的指针我之前真的没用到过，但是指向成员函数的指针，我却用了不少，一般都是放在函数数组中使用，比如有这样一个场景，游戏npc根据状态执行对应的状态函数，这些状态函数是成员函数，为此我们需要将npc所有的状态函数添加到一个函数数组中，假设有idle、run、walk、jump四种状态，下面是实现代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;iostream&gt;class CNpc&#123; typedef void (CNpc::*StateFunction)();public: int state; // 0,1,2,3 对应 idle、run、walk、jump StateFunction state_function_array[4];public: CNpc() &#123; state = 0; state_function_array [0] = &amp;CNpc::idle; state_function_array [1] = &amp;CNpc::run; state_function_array [2] = &amp;CNpc::walk; state_function_array [3] = &amp;CNpc::jump; &#125; void change_state(int new_state) &#123; state = new_state; &#125; void process_state() &#123; if (state_function_array[state]) &#123; (this-&gt;*state_function_array[state])(); // 调用函数指针的地方 &#125; &#125;private: void idle() &#123; std::cout &lt;&lt; "state = idle" &lt;&lt; std::endl; &#125; void run() &#123; std::cout &lt;&lt; "state = run" &lt;&lt; std::endl; &#125; void walk() &#123; std::cout &lt;&lt; "state = walk" &lt;&lt; std::endl; &#125; void jump() &#123; std::cout &lt;&lt; "state = jump" &lt;&lt; std::endl; &#125;&#125;;int main()&#123; CNpc npc; npc.process_state(); npc.process_state(); npc.change_state(1); npc.process_state(); npc.change_state(3); npc.process_state(); npc.process_state(); npc.process_state(); npc.change_state(2); npc.process_state(); npc.change_state(0); npc.process_state(); npc.process_state(); return 0;&#125; 运行结果 123456789state = idlestate = idlestate = runstate = jumpstate = jumpstate = jumpstate = walkstate = idlestate = idle 总结 牢记-&gt;*和.*也是一种操作符，使用的时候不要拆开 理解操作符中的*符号的解引用的作用 如果有理解不正确的地方欢迎大家批评指正]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>类成员访问</tag>
        <tag>成员指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bat批处理替换字符串中匹配的子串]]></title>
    <url>%2Fblog%2F2018%2F04%2F12%2Fbat%E6%89%B9%E5%A4%84%E7%90%86%E6%9B%BF%E6%8D%A2%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E5%8C%B9%E9%85%8D%E7%9A%84%E5%AD%90%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[前言关于字符串的操作通常是编程生涯中不可避免的，在各种竞赛中、工作中常常能使用到，许多语言中都有专门负责处理字符串的模块或者类，对于字符串的替换一般也有专门的函数，比如Lua中的string.gsub()、Python中的replece()等，那么批处理在进行字符串操作的时候，有没有好用的替换函数呢？ 前两天在使用批处理更新资源文件的时候发现，批处理中也有专门处理字符串替换的方法，并且这是我见到的最有意思的字符串替换方式，就是利用A:B=C的方式来替换字符串，具体含义就是在字符串变量A中查找所有的子串B并且替换成子串C，看起来很有意思吧？下面举一个具体的示例看一下。 代码示例12345678910111213141516171819202122@echo offSET INPUT_PARAM=%1rem 替换输入变量中的world为Chinaecho source string is %INPUT_PARAM%echo === China replace world ===echo replace result is %INPUT_PARAM:world=China%echo.rem 将路径中的反斜杠替换成斜杠SET IMAGE_PATH=C:\NVIDIA\AndroidWorks\001echo source string is %IMAGE_PATH%echo === \ replace / ===echo replace result is %IMAGE_PATH:\=/%echo.echo ABCD:A=apause 代码中举了两个例子，将变量中的world为China、将路径中的反斜杠替换成斜杠都成功地替换了子串的内容，但是我们发现这个的作用对象只能是变量，对于最后一句echo ABCD:A=a并没有发生替换，下面可以看一下运行结果。 运行结果1234567891011E:\batTool&gt;Replace.bat &quot;Hello wolrd, All over the world!&quot;source string is &quot;Hello wolrd, All over the world!&quot;=== China replace world ===replace result is &quot;Hello wolrd, All over the China!&quot;source string is C:\NVIDIA\AndroidWorks\001=== \ replace / ===replace result is C:/NVIDIA/AndroidWorks/001ABCD:A=a请按任意键继续. . . 总结 bat处理字符串替换的方式比较有意思，需要知道A:B=C形式的替换方法 字符串替换只能是针对变量，对于文本貌似不起作用。]]></content>
      <categories>
        <category>bat</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[略显神秘的快速排序]]></title>
    <url>%2Fblog%2F2018%2F04%2F08%2F%E7%95%A5%E6%98%BE%E7%A5%9E%E7%A7%98%E7%9A%84%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言继续我的填坑旅程，上次说到《排序算法系列之（二）——冒泡排序名字最为形象的一个》2017-09-16 10:42:07，又过了半年多，终于再一次鼓起勇气决定聊一聊快速排序的思路，不过与冒泡排序不同的是，这个快速排序的名字似乎和算法的思路没有什么关系，这个名字太抽象了，起这个名字可能当初仅仅是因为它比别的排序快一点。咳咳！ 抽象的名字不利于我们对于算法思路的理解，或许这就是我为什么当初认为快速排序是最难理解的排序算法，也可能是当初还没接触过堆排序、希尔排序等这些另类的排序吧！毕竟工作5年之后再来看这个快速排序，思路也是很清晰的，忽然发现它当初那份神秘的气息消散了许多。 快速排序我们今天同样略过各种复杂度，直奔主题——快速排序，既然它的名字不是说算法思路，那就是说性质了，通俗点说就是在一般情况下它比选择排序、冒泡排序要快，先不用关心它为什么快，我们先来模拟一个最简单的快速排序。 快速排序的核心思想是分治、递归，将原本问题的规模不断缩小，递归求解，这类算法往往代码很简单，但是理解起来难度大一点，说一下总体思路，我们先来举个例子。假设将N个数从小到大排序，首先是在等待排序的数组N中随便选一个数M，为了简单我们选择第一个，然后遍历待排数组，把比M小的数放到M的左边，把比M大的数放到M的右边，一次遍历结束M左边有m1个数，右边有m2个数(m1+m2+1=N)，然后就形成了两个待排数组N1和N2，对于每个待排数组重复上述操作，直到待排数组缩小到一个数字，则待排数据排序完毕，整个数组变为有序。 因为这个排序比较抽象，所以前面的橘子、苹果的例子很难解释清楚，但是我们可以用标了号的橙子来理解，是不是感觉橙子伟大了一点，为什么橙子可以，因为早上刚刚吃过橙子，嗯！就是这么任性！假设桌上摆着一排橙子，他们的重量分别是6, 2, 7, 3, 8, 9，什么？你问我重量单位是什么，那就是斤吧，谁叫这些橙子变异了呢，大的大，小的小，好了，能帮助我们理解算法就好了，自从有了转基因，今后多重的橙子都可能遇到。 事先解释一下，我们这些橙子在桌上排成了一排，并且每一个橙子都放在了盘子里，盘子不移动，我们只移动盘子里的橙子，空盘子用*表示，手里的橙子用M表示，为了省点力气，我们尽可能的少移动橙子。 起初桌子上盘子里的橙子情况是这样的:6, 2, 7, 3, 8, 9，M=* 用手拿起第一个盘子里的橙子后：*, 2, 7, 3, 8, 9 ，M=6 从后往前找到第一个比M小的橙子放到前面，9、8、3，发现3是第一个符合条件的，把它拿到前面的盘子，变成了这样：3, 2, 7, *, 8, 9 ，M=6 然后第一个不算从前往后找到第一个比M大的橙子放到后面，2、7，发现7是第一个符合条件的，把它放在后面的空盘子：3, 2, *, 7, 8, 9 ，M=6 到此为止，我们已经把所有位置都遍历一遍了，这就是所谓的一趟排序，如果中间还有位置没有比较，重复步骤3和步骤4，直到所有的位置的橙子都被遍历到，把M=6放到最后的空盘子中就变成了：3, 2, 6, 7, 8, 9 ，M=* 执行到这个步骤，原来的这些橙子就被分成了两部分，比M=6小的放到了它的前面，比M=6大的放到了它的后面，现在就变成了两个规模较小的数组排序，我们以前面的待排数组N1为例，重复步骤2，先取出第一个橙子，拿在手里：*, 2 ，M=3 重复步骤3，从后往前找到第一个比M小的橙子放到前面，发现2这个橙子，然后把它放到前面的空盘子，现在的情况如下：2, * ，M=3 本来应该重复步骤4，但是此时发现所有的位置已经遍历过了，所以步骤4省略，直接步骤5，把M=3放在空盘子中：2, 3 ，M=* 此时被M=3分割的就过只有一部分，并且不大于一个橙子，所以左半部分排序结果，总体来看顺序为：2, 3, 6, 7, 8, 9 ，M=* 接着就要对步骤5后面的右半部分排序了，也就算是对7, 8, 9，虽然现在数据少我们一眼就能看出这结果数是有序的，但是如果在程序代码中，还是会对这部分橙子重复步骤3、4、5来达到有序，这里就不再逐步解释了，最后的结果就是：2, 3, 6, 7, 8, 9 ，M=* 代码实现1234567891011121314151617181920212223242526272829/*功能： 快速排序，实现数组元素从小到大排列参数： array--表示待排序的数组，此处会退化成指针 low --待排序区间的起始索引 high --待排序区间的结束索引返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void quick_sort(int array[], int low, int high)&#123; if (low &gt;= high) return; int front = low, back = high, key = array[low]; // 选取第一个元素作为中轴 while (front &lt; back) &#123; while (front &lt; back &amp;&amp; array[back] &gt;= key) --back; array[front] = array[back]; // 从后面找到第一个比中轴小的交换 while (front &lt; back &amp;&amp; array[front] &lt;= key) ++front; array[back] = array[front]; // 从前面找到第一个比中轴大的交换 &#125; array[front] = key; quick_sort(array, low, front - 1); // 递归快排前半段 quick_sort(array, low, front + 1); // 递归快排后半段&#125; 代码分析上述代码与橙子排序的示例思路完全一致，key = array[low]是步骤2，选取第一个元素作为中轴；最外层的while循环是反复重复步骤3和步骤4，保证遍历所有位置的橙子；内部的第一个while循环是步骤3，从后面找到第一个比中轴小的；内部的第二个while循环是步骤4，从前面找到第一个比中轴大的；array[front] = key;就是步骤5，把手里的橙子放回到空盘子中；接下来的两个函数调用都是调用自己，也就是递归调用，分别处理小于M的一段和大于M的一段，怎么样？代码是不是好理解多了？如果觉得我理解的有问题或者代码有错，也欢迎大家批评指正。 运行测试快速排序–源码 如果你想运行测试一下，可以复制或者下载源代码，在本机运行测试一下，当然也可以选择在线编辑器，这是我新发现的在线编译器，样子还挺好看的，把源代码复制到网页中运行查看结果。]]></content>
      <categories>
        <category>Sort</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>算法</tag>
        <tag>概念</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神秘莫测的时间复杂度]]></title>
    <url>%2Fblog%2F2018%2F03%2F29%2F%E7%A5%9E%E7%A7%98%E8%8E%AB%E6%B5%8B%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[前言说到时间复杂度，作为程序员或多或少都会有所接触，特别是算法工程师肯定是天天和这个概念打交道，其实前几篇总结排序的文章我一直没有提时间复杂度，因为网上太多的文章讲这个概念了，所以我只总结了一下我对几种排序算法的理解，以及简单的实现代码，而当我今天准备总结一下快速排序的时候，我发现各个关于快速排序的文章都有讲到时间复杂度，有的甚至直接就给出 O(N*log(N))，这个对数是以2为底的，还是以10为底的都没有说清楚，这简直让人感到莫名其妙，所以我决定还是简单说一下我对时间复杂度这个概念的理解。 其实时间复杂的作用很简单，就是用来表示算法运行时间与数据规模的关系，其中的数据规模常常用字母N或者n表示，将算法的运行时间表示为n的函数表达式应该为 t=f(n) ，而时间复杂度就是表达式中幂最高的那一项，然后去掉常数系数，比如当算法运行时间表达式为 t = f(n) = 3 * n^2 + n 时，那么这个算法的时间复杂度就是O(n^2)，字母O用来表示时间复杂度，也就是该算法与数据规模成平方阶的关系，为什么要去掉一次项n，因为在数据规模扩大时，它相对于平方阶来说基本可以忽略不计。 时间复杂度计算方法虽然很多编程工作者都接触过时间复杂度，但是真正要想把时间复杂度算明白可不是件容易的事，特别是遇到时间复杂度中包含对数项的，那就更让人糊涂了，很多人搞不明白为什么会有对数次的运算，实际上二分法常常是导致时间复杂度中出现对数项的一种算法，要算出时间复杂度，本质上就是算出执行完算法算所需要的操作次数，这种操作通常是比较、赋值、交换等等，而时间复杂度与数据规模相关，通常把一个算法执行完所需的操作次数，表示成和数据规模n相关的函数，这就是我们所说的时间复杂度。时间复杂度是用来衡量算法所需时间资源的，所以只保留最高次幂的项就可以，不用纠结于是O(n^2+n)还是O(n^2)，在大规模的数据面前，这两种时间复杂度几乎相等，总之一句话，看一个算法的时间复杂度，就是数这个算法执行完所需要的操作次数，并且把这个次数表示成与n相关的简单函数。 时间复杂度示例接下来我们举几个简单的例子，来理解一下什么是时间复杂度，并且了解一下“计算时间复杂度就是数算法执行操作的次数”这句话的意思，接下来我们一起数一下： 常规方法计算区间[1,n]中所有整数的和 12345int sum = 0, n = 10000;for (int i = 1; i &lt;= n; i++)&#123; sum += i;&#125; 上述代码就是一个很简单的计算方法，具体操作就是遍历区间[1,n]内的所有整，然后依次相加，执行次数很好数吧？就是n次，因为每遍历一个数，就会执行一次累加操作，一共有n个数字，所以执行完这段代码需要进行n次累加运算，随着数据规模的扩大，也就是数字n的扩大，计算次数也在扩大，但是还是n次，所以可以用n来表示这段代码的时间复杂度，也就是O(n)。 利用等差数列公式计算区间[1,n]中所有整数的和 12int n = 10000;int sum = (1 + n) * n / 2; 等差数列的求和公式相信很多人都是知道的，那么这种计算方法对于遍历来说快了太多，因为它是直接计算出来的，也就是1次就能计算出结果，计算次数不会随着数据规模的扩大而扩大，那么这个算法的时间复杂度就是O(1)，也许有的人会纠结这里有加法、乘法、除法，不应该是3次运算吗？实际上就是3次运算，但是常数级的时间复杂度都会用O(1)来表示，它是一个衡量的指标，不需要精确到具体的次数，即使这个常数次数是1000也写成O(1)即可，所以通过这点可以看出，时间复杂度是O(1)的算法未必就比时间复杂度是O(n)的算法计算次数少，比如这个例子中，当n小于3时，第一种算法反而计算的次数少，但是时间复杂度通常是用来衡量数据规模很大的时候，算法所需时间的情况，所以通常情况下O(1)的算法在时间上还是优于O(n)的算法。 利用冒泡排序对所给数组进行排序 12345678910111213void bubble_sort(int array[], int n)&#123; for (int bubble_count = 0; bubble_count &lt; n - 1; ++bubble_count) &#123; for (int bubble_pos = 0; bubble_pos &lt; n - 1 - bubble_count; ++bubble_pos) &#123; if (array[bubble_pos] &gt; array[bubble_pos + 1]) &#123; swap_data(&amp;array[bubble_pos], &amp;array[bubble_pos + 1]); // 交换数据 &#125; &#125; &#125;&#125; 冒泡排序算是排序算法中规则比较简单的了，那么它的时间复杂度怎样来计算呢，或者说怎样来数它的执行次数呢，本例的执行操作次数指的是比较和交换，随着数据规模的扩大，也就只有这些操作次数是跟着变的，那么我们来数一数执行这些操作的次数，首先这是个双重循环，外层循环会遍历n-1次，随着外层循环增多内层循环次数会逐渐减少，听起来很麻烦的，外层和内层都在变化，怎么计算呢？其实可以回归本质，我们看看一共执行了多少次比较运算就可以，第一遍冒泡，内层循环执行了n-1次比较，第二遍冒泡，内层循环执行了n-2次比较，依次类推最后肯定是执行了1次比较，一共比较了多少次是不是就很好计算了，这些次数就是一个等差数列，求和就是这个算法的执行次数，f(n) = (1 + n - 1) * (n - 1) / 2 = n * (n - 1) / 2 = n^2 / 2 - n /2，根据时间复杂度定义，取最高次幂的项去掉系数就得到冒泡排序的时间复杂度O(n^2)。 计算一个十进制数的所有位上（个位、十位、百位…）上1的个数，例如12341这个数中包含2个1 123456789101112int count_one(int n)&#123; int count = 0; while(n &gt; 0) &#123; if ((n % 10) == 1) ++count; n /= 10; &#125; return count;&#125; 这也是一个很简单的算法，我们只要取出每一位上的数字，看看是不是1就可以，如果是1的话统计的变量count就加1就可以，那么这个算法的操作次数与数据规模n有什么关系呢，实际上这次数我们很清楚，就是n一共有几位数，就需要执行几次操作，当数字是34时，我们需要执行两次操作，当数字是24353的时候我们需要执行5次操作，那么怎么把这个次数表示成n的函数呢，仔细想想者原来就是对数，在本例中f(n) = (int)lg(n) + 1，也就是对n取10的对数，然后取整后加1，那么这个算法的时间复杂度就出来了，就是去掉常数项和修饰符变为O(lg(n))。 总结写这篇总结的初衷就是网上太多的算法直接给出了时间复杂度，而缺乏必要的说明，其实时间复杂度的计算并不算太复杂，只要你回归定义的本质，仔细的算算究竟需要多少次操作就可以得到大概的时间复杂度，并且一个算法的时间复杂度也不是固定的，比如快速排序，一般大家都喜欢说它是N乘以对数级的，但是当它的最坏情况发生时，它会退化成平方级的。]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>概念</tag>
        <tag>O(n)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bat批处理遍历指定目录下文件并更新]]></title>
    <url>%2Fblog%2F2018%2F03%2F21%2Fbat%E6%89%B9%E5%A4%84%E7%90%86%E9%81%8D%E5%8E%86%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%E4%B8%8B%E6%96%87%E4%BB%B6%E5%B9%B6%E6%9B%B4%E6%96%B0%2F</url>
    <content type="text"><![CDATA[前言先来看这样一个需求，假设有A，B两个目录，其中A目录是资源目录，B目录是工作目录，其中资源目录不定期更新，资源文件都在A目录下，并且没有子目录层级关系，但是资源要被使用时需要更新到B工作目录，B目录根据工程需要建立了一个包含众多子目录的层级体系，这样当A目录中的一个资源文件更新后，需要手动复制A目录中更新的资源文件，然后在B目录中找到对应的位置，然后进行粘贴替换，这样的操作如果很久一次、或者每次只有1、2个文件还好，如果资源文件大范围更新，那么要一个个找到更新文件在B目录中的位置然后替换就成了一件令人苦恼的事情，所以根据这个需求，才有了下面的探索过程。 思路的转变一开始想把A目录作为出发点，毕竟A目录中包含了修改后的资源文件，但是A目录更新后怎样才能准确的修改对应的B目录呢？我想到了配表，每次新增资源后，都会修改配置表，将A目录中的各个文件资源与B目录中的位置建立对应关系，这样A目录下的资源更新后就可以根据配置文件统一更新B目录了。 但这样的做法就是，需要经常维护配置文件，特别是增加或者删除资源的时候，然后我就想到了现在的这个做法，从B目录出发，注意本文主要解决的是资源文件的更新，而不是新增，更新就说明是原有的文件，只是内容发生了变化，比如一些UI文件，这些文件经常会做布局格式的调整，控件的增加和删除等等，调整结束后需要更新到工作目录。 实现过程实现的过程并没有想象的那么顺利，期间遇到了诸多问题和一些新的概念，比如for循环的语法，for循环中的变量定义，if条件的语法，字符串变量的替换，文件目录的处理，延迟环境变量扩展等等，这些问题每一项都可以作为一个单独的知识点，后续我会抽时间慢慢总结到一起，总之最后终于可以用了，前后大约花了1个半小时的时间，想想也是醉了，下面是一个具体的示例及对应的实现代码。 A资源目录对应实际的”E:/dirZ”，结构如下： 12345678910root:[E:/dirZ]+--aaa.txt+--bbb.txt+--ccc.txt+--ddd.txt+--eee.txt+--extra.c+--extra.h+--fff.txt+--ggg.txt B工作目录对应实际的”E:/dirA”，结构如下： 123456789101112131415root:[E:/dirA]+--aaa.txt+--bbb.txt+--dirB| +--ccc.txt| +--extra.c| +--extra.h+--dirC| +--ddd.txt| +--dirD| | +--eee.txt+--dirE| +--dirF| | +--fff.txt| | +--ggg.txt 现在需要把E:/dirZ目录中的txt文件，按照E:/dirA目录的层级结构，更新到对应位置，并且不更新ggg.txt文件，以下是实现的代码: 1234567891011121314151617181920212223242526272829303132333435@echo offrem 启用延迟环境变量扩展setlocal enabledelayedexpansionrem 定义不需要更新的文件SET EXCEPT_FILE=ggg.txtrem 定义工作目录和资源目录SET WORK_PATH=E:\dirA\SET RESO_PATH=E:\dirZ\rem 简单输出查看一下echo WORK_PATH is %WORK_PATH%echo RESO_PATH is %RESO_PATH%echo ------------------------rem for循环递归遍历WORK_PATH目录中的.txt文件，文件的全路径放在变量f中for /R %WORK_PATH% %%f in (*.txt) do ( rem 使用TARGET_FILE变量记录绝对文件名，注意延迟变量的使用 SET TARGET_FILE=%%f echo !TARGET_FILE! rem 去掉路径，只保留文件名及扩展名 SET "FILE_PATH_NO_EXT=%%~nxf" rem 利用资源路径和文件名，拼接出资源的绝对全路径 SET SOURCE_FILE=%RESO_PATH%!FILE_PATH_NO_EXT! echo !SOURCE_FILE! rem 条件判断是否是不需要更新的文件 if NOT !FILE_PATH_NO_EXT!==%EXCEPT_FILE% ( copy !SOURCE_FILE! !TARGET_FILE! ))pause 运行结果 123456789101112131415161718192021222324WORK_PATH is E:\dirA\RESO_PATH is E:\dirZ\------------------------E:\dirA\aaa.txtE:\dirZ\aaa.txt已复制 1 个文件。E:\dirA\bbb.txtE:\dirZ\bbb.txt已复制 1 个文件。E:\dirA\dirB\ccc.txtE:\dirZ\ccc.txt已复制 1 个文件。E:\dirA\dirC\ddd.txtE:\dirZ\ddd.txt已复制 1 个文件。E:\dirA\dirC\dirD\eee.txtE:\dirZ\eee.txt已复制 1 个文件。E:\dirA\dirE\dirF\fff.txtE:\dirZ\fff.txt已复制 1 个文件。E:\dirA\dirE\dirF\ggg.txtE:\dirZ\ggg.txt请按任意键继续. . . 总结到此为止我们就解决了这个资源更新的实际问题，每次资源更新后只要运行这个批处理文件就可以更新工作目录中对应的资源文件了，在这个例子中关于目录的截取，一开始走了很多弯路，其实有很多现成的方式，所以需要在此记录一下，方便以后查找使用，具体查看示例代码： 12345678910111213141516171819202122232425ECHO offSETlOCAL enabledelayedexpansion SET FIND_DIR=E:\dirA\dirC\dirDfor /R %FIND_DIR% %%f in (*.txt) do ( SET FULL_PATH=%%f ECHO 完整的路径: !FULL_PATH! SET FILE_DIR=%%~dpf ECHO 所在的目录: !FILE_DIR! SET FILE_NAME=%%~nf ECHO 无后缀文件: !FILE_NAME! SET FILE_EXT=%%~xf ECHO 文件名后缀: !FILE_EXT! SET "FILE_NAME_NOT_PATH=%%~nxf" ECHO 无路径文件: !FILE_NAME_NOT_PATH! SET "FULL_PATH_NOT_EXT=%%~dpnf" ECHO 无后缀全名: !FULL_PATH_NOT_EXT!)pause 运行结果： 123456完整的路径: E:\dirA\dirC\dirD\eee.txt所在的目录: E:\dirA\dirC\dirD\无后缀文件: eee文件名后缀: .txt无路径文件: eee.txt无后缀全名: E:\dirA\dirC\dirD\eee]]></content>
      <categories>
        <category>bat</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于游戏中仓库类的设计]]></title>
    <url>%2Fblog%2F2018%2F02%2F25%2F%E5%85%B3%E4%BA%8E%E6%B8%B8%E6%88%8F%E4%B8%AD%E4%BB%93%E5%BA%93%E7%B1%BB%E7%9A%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[前言这个游戏中的仓库类设计开始于春节前，和大家一样，我也是期盼着放假而无心工作，所以在放假前一天虽然蹦出了思维的火花，我却没有使用文字记录下来，但是大致的思路我已经记录到脑子中了，这一次的突然感悟，与上次突然明白什么是选择排序，什么是冒泡排序很类似，都是一瞬间突然明白，是一个从量变到质变的过程，接下来简单记录下我关于仓库的理解。 初觉不妥游戏中的仓库是用来存放道具的，这是我在接触这套游戏代码时形成的稳固的印象，结果就是代码中充斥着道具属性的判断，因为是很古老的代码，一开始我并没有产生疑问，同时也是修修补补的解决了许多BUG，可是渐渐的问题暴露了出来，设计上仓库里存储的是道具的索引，通过索引可以找到唯一的一个道具，这个思想根深蒂固，导致在写代码时自然而然的就在仓库的类里直接判断了道具属性，仔细想想这是不正确的。 起初感觉有问题时，大概是工作两年后，第一次重构道具系统的时候，当时在写放入道具和取出道具的时候总感觉怪怪的，但是又说不出问题出在哪里，其实就是在放入和取出的逻辑中，操作了道具的属性，修改了道具的坐标。也就是在仓库类的代码中设置了道具的属性，但是他们两个类不是依赖关系，硬生生的产生了依赖关系。 新的任务道具系统的第一次重构，我并没有找到为什么代码怪怪的，也就没有修改，但是新的任务在工作4年之后给了我一个新的机会，再写一遍道具系统，这时候那段奇怪的代码给我的感觉更强烈了，绝对有问题，也就是那么一瞬，我似乎明白了，仓库这个类被我们强加了太多的东西，谁说仓库中就一定要放道具了，我们在游戏中也没有直接把道具的对象保存在仓库中，而是把道具的索引存在了仓库中，也就是仓库中存储了道具的身份证，同理如果我们把人的身份中存在仓库中，那么仓库就是管理人的，如果我们把车牌号存储在仓库中，那么仓库就是管理车辆的。 因为起初游戏中的仓库只保存了道具的索引，所以我们想当然的认为仓库中只能保存道具，所以把一大堆的道具操作代码写到了仓库类中，是时候把代码提出来了，仓库就是仓库，它只根据坐标存储对应数据的ID，而这个ID对应的数据，应该在仓库以外的类中操作，这个ID可能对应道具、可能对应人、也可能对应车辆，干干净净的仓库管理了一组数据的ID，至于对ID对应数据的操作，一概不应该放在仓库类中进行。 重构的结果仓库类简简单单，保存着道具ID，只提供按位置放入ID，按位置取出ID，能够给出仓库的使用情况，能够初始化仓库的状态，仓库类有以上这些操作足以，仓库本身并不应该知道自己存的是道具还是车辆，真正要修改道具的属性，或者要查找指定属性的道具，放到道具管理类中来编写逻辑即可。]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>游戏</tag>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim、Xshell、远程终端莫名卡死的原因]]></title>
    <url>%2Fblog%2F2018%2F02%2F03%2FVim%E3%80%81Xshell%E3%80%81%E8%BF%9C%E7%A8%8B%E7%BB%88%E7%AB%AF%E8%8E%AB%E5%90%8D%E5%8D%A1%E6%AD%BB%E7%9A%84%E5%8E%9F%E5%9B%A0%2F</url>
    <content type="text"><![CDATA[前言最近通过Xshell连接远程服务器，然后使用Vim修改文件时会莫名其妙的卡死，一开始我还没注意，因为近期的网络一直不太好，经常出现按下一个字母半天才反应过来的情况，所以我没有太在意，直接关闭终端重新打开就好。直到有一天我开着两个终端的时候，Vim又卡着不动了，而另一个终端还以流畅的处理我敲击的命令，我就断定这肯定不是网络原因了。 原因既然是Vim卡住了那就查查Vim本身有什么BUG吧，结果上网搜了一圈发现原来是远程终端的问题，根本就不关Vim的事，它只是躺着中枪了而已(*^▽^*)，实际上就是不小心按下了快捷键 Ctrl+S 导致的，为什么常常是Vim卡住呢？那是因为很多人习惯了在 Windows上 的保存快捷键，写写文档总是习惯性按下快捷键 Ctrl+S 保存一下，来避免程序突然崩溃导致文档丢失，这就解释了为什么出问题的总是Vim，因为使用Vim编辑文本有时会习惯性的按下 Ctrl+S 保存，而在执行Shell命令是很小的概率会按 Ctrl+S，所以大多数人卡住往往是在使用Vim的时候。 可是快捷键 Ctrl+S 为什么会导致终端卡死呢？实际上这个快捷键的含义是“阻断向终端输出内容”，很多人说这个快捷键的作用是暂停终端，我个人感觉这种说法并不准确，实际是上终端并没有暂停，按下 Ctrl+S快捷键后，你依然可以像终端发送命令，终端也会正常执行，只是不会将反馈内容和结果显示在终端上而已，这个特性可以用来暂停显示快速滚动输出的内容，比如在编译大型项目的时候。 解决办法解除这种状态的方法很简单，按下快捷键 Ctrl+Q 就可以“恢复向终端输出内容”，只是很多时候我们并不知道，以为是终端卡死了然后错杀了程序！ 附注关于这个问题，Vim文档中“SECTION 32 - VIM ON UNIX”一节也给出了回答，有兴趣的小伙伴可以自己看一下： 32.1. I am running Vim in a xterm. When I press the CTRL-S key, Vim freezes. What should I do now? vimdoc.sourceforge.net]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
        <tag>Xshell</tag>
        <tag>终端卡死</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim中简单格式化代码]]></title>
    <url>%2Fblog%2F2018%2F02%2F02%2FVim%E4%B8%AD%E7%AE%80%E5%8D%95%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[前言写这个总结的起因是我在把Windows上VS中的代码粘贴在Linux服务器的Vim中时，代码格式惨不忍睹，我就搞不明白为什么它每一行都要向后缩进，搞得我的代码最后像倒立的楼梯似的，就像这样： 123456789int main(int argc, char *argv[])&#123; int i=0,j=0; if (i != 0) &#123;i++; &#125; else &#123;i--; &#125; for(i=0;i&lt;5;i++)j++; printf("i=%d,j=%d\n",i,j); return 0;&#125; 往常我一般就是切换到插入模式，然后使用删除键删除掉前面多余的空格，可是这一次我决定不再忍受了，我要找到快速格式化的方法，还别说，方法其实很简单，各种格式化方法的核心就是符号=。 何谓“简单”其实一开始我想标题的时候并没有加上“简单”二字，直到我发现了一个求知者看似“无理”的要求，他要求在Vim中把上面格式的代码格式化成下面这样： 123456789101112131415161718int main(int argc, char *argv[])&#123; int i=0,j=0; if (i != 0) &#123; i++; &#125; else &#123; i--; &#125; for(i=0;i&lt;5;i++) j++; printf("i=%d,j=%d\n",i,j); return 0;&#125; 如果你也是这样想的，很抱歉，你可以关掉这个页面了，本文提供的方法无法满足你的要求，这就是我的标题中为什么加上了“简单”二字，而Vim中的简单格式化只能是格式化成下面这样，以行为单位，保证每行的缩进都是正确的： 123456789int main(int argc, char *argv[])&#123; int i=0,j=0; if (i != 0) &#123;i++; &#125; else &#123;i--; &#125; for(i=0;i&lt;5;i++)j++; printf("i=%d,j=%d\n",i,j); return 0;&#125; 如果你确实要把大括号的换行也显示正确，那么只能通过安装插件、编写脚本、或者把源代码中对应的位置敲如回车，变成下面这样格式的代码，然后再使用本文后面叙述的方法来格式化就可以了。 1234567891011121314151617int main(int argc, char *argv[])&#123; int i=0,j=0; if (i != 0) &#123; i++; &#125; else &#123; i--; &#125; for(i=0;i&lt;5;i++) j++; printf("i=%d,j=%d\n",i,j); return 0;&#125; 神奇的=其实格式化的核心内容就是这个 =，其中绝大部分的方法都是 = 的变种，只是让人不容易发觉，甚至有些方法例如 gg=G 包装的让人都无法注意到真正起作用的就是那个 =，格式化的前提是处于命令模式，也就是按完 ESC 时的模式，而格式化时 = 真正起作用的只有两种情况： 先按=，再选区域 先说应用最广泛的全文格式化的方法gg=G，就是这种情况的变种，分析一下命令的含义，先是gg表示回到文档最开始，= 表示要格式化，G 表示到文档末尾，也就是说 gg=G 的含义就是： 跳到文档开头-&gt;开始格式化-&gt;一直格式化到文档末尾 既然明白了原理，假如此时光标就在文档开始处，那么使用命令 =G 也是可以格式化全文的，同理命令 G=gg也可以达到格式化全文的效果，而命令 =100j 就是从文档当前位置向下格式化100行。 先选区域，再按= 这种方式我反正用不习惯，不过也说一下，就是先按 v (可视化编辑)或 shift+v (可视化编辑行模式)或 ctrl+v (可视化编辑块模式)，然后利用方向键 h,j,k,l 选择区域，最后按 = 完成格式化，简单操作例如 vjjj= 就是从当前位置向下格式化3行代码。 直接输入== 不是说两种情况吗，为什么会有第3条呢？其实在命令模式下输入 == ，也就是连着输入两个等号，就是格式化当前行的方法，我感觉它和上两种情况一样，可能是又不知道归入哪一种情况比较好，所以就单列出来咯。 总结 本文中所提到的格式化代码只是很简单的格式化，以行为单位保证缩进正常，无法处理大括号换行等情况。 如果要挑起“大括号换行”的战争，麻烦装一个格式化插件吧，Vim只和Emacs打架，不想参与“大括号换行”战争。 如果要部分格式化，首先保证要格式化的代码之前的内容是格式化好的，否则格式化无效，请选择全文格式化吧！]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>Vim</tag>
        <tag>代码格式化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql查询时case when语句的使用]]></title>
    <url>%2Fblog%2F2018%2F02%2F01%2FMysql%E6%9F%A5%E8%AF%A2%E6%97%B6case-when%E8%AF%AD%E5%8F%A5%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言前几天在技术论坛论坛上发现一个求助帖，大体意思就是要把一个表中的数据按条件分成两类，每一类排序方式不同，然后整体作为查询的结果集，乍一看这问题不是很难，很多人给出的答案是分别查询排序后再 union合并到一起，但是后来楼主明确指出不想使用 union 操作，这时有一位高人巧用 case when 语句解决了问题，其实这是我第一次接触 case when 语句，于是查询了一下具体用法，在此做个小结，方便日后查询使用。 创建示例表格数据库表格结构很简单，马上要期末了，就以学习成绩为数据来建立一张数据表，表中包含唯一ID、学号、姓名、性别、分数等列，其中性别这一列用整数代表，0表示男，1表示女，建立表格的sql语句如下： 123456789CREATE TABLE `grade` ( `id` int(4) NOT NULL AUTO_INCREMENT, `number` int(4) NOT NULL DEFAULT '0', `name` varbinary(32) NOT NULL DEFAULT '', `sex` int(4) NOT NULL DEFAULT '0', `score` int(4) NOT NULL DEFAULT '0', PRIMARY KEY (`id`), KEY `find_index` (`number`,`name`)) ENGINE=InnoDB DEFAULT CHARSET=binary ROW_FORMAT=DYNAMIC; 插入测试数据表格建立完成可以使用可视化工具或者insert语句插入测试数据，插入测试数据后查询结果如下： 123456789101112131415161718mysql&gt; select number,name,sex,score from grade;+----------+----------+-----+-------+| number | name | sex | score |+----------+----------+-----+-------+| 20180001 | xiaoming | 0 | 68 || 20180002 | xiaohong | 1 | 98 || 20180003 | xiaobing | 0 | 78 || 20180004 | xiaoli | 0 | 88 || 20180005 | zhangsan | 0 | 32 || 20180006 | zhaosi | 0 | 58 || 20180007 | marry | 1 | 78 || 20180008 | tom | 0 | 100 || 20180009 | feifei | 1 | 90 || 20180010 | lili | 1 | 92 || 20180011 | xiaozhao | 0 | 52 || 20180012 | xiaowang | 0 | 62 |+----------+----------+-----+-------+12 rows in set (0.00 sec) 获取平均成绩班主任们坐在一起做喜欢做的事就是比一下自己的学生和别人班的差距，谁让他们每个人带的学生都是一届不如一届呢！（你们是我带过的学生中最差的一届！！！）说到比成绩一般都是比较并均分，sql语句可能会写成下面这样： 1234567mysql&gt; select avg(score) as 平均分 from grade;+-----------+| 平均分 |+-----------+| 74.6667 |+-----------+1 row in set (0.02 sec) 是的，很简单就能获得班级的平均分，如果要分组呢？比如分别查一下男生和女生的平均分，因为我们知道表中的sex表示性别，所以直接按照sex分组就可以实现，可以将语句简单写成这样： 12345678mysql&gt; select sex as 性别, avg(score) as 平均分 from grade group by sex;+--------+-----------+| 性别 | 平均分 |+--------+-----------+| 0 | 67.2500 || 1 | 89.5000 |+--------+-----------+2 rows in set (0.00 sec) 是不是很简单？可是性别显示成0和1确实不利于阅读，但是表中又没有保存0、1与男、女的对应关系，应该怎么办呢？这就要用到我们今天所要用到的case when语句了，语法上共有两种写法，看着具体例子体会一下吧。 case when 语句的使用 第一种用法：case后面跟列名，when后面跟对应值 12345CASE case_value WHEN when_value THEN statement_list [WHEN when_value THEN statement_list] ... [ELSE statement_list]END 这种用法正好解决我们刚刚提出的问题，当sex值为0时当前列显示“男”，否则显示“女”，sql写法如下： 123456789mysql&gt; select (case sex when 0 then '男' else '女' end) as 性别, avg(score) as 平均分 -&gt; from grade group by sex;+--------+-----------+| 性别 | 平均分 |+--------+-----------+| 男 | 67.2500 || 女 | 89.5000 |+--------+-----------+2 rows in set (0.00 sec) 第二种用法：case后面空白，when后面跟着判断条件 12345CASE WHEN search_condition THEN statement_list [WHEN search_condition THEN statement_list] ... [ELSE statement_list]END 针对于这种写法，我们考虑这样一种需求，学生成绩是有评分的，大于等于90分的学生是A，小于90分大于等于60分的学生是B， 其余的学生是C，现在要查询评分为A、B、C的学生成绩的平均分分别是多少，因为成绩评分并不是单独的一列，所以不能简单的 使用 group by 来分组实现了，但是可以利用 case when 语句实现，写起来也很简单，看看下面的sql语句就知道了！ 12345678910mysql&gt; select (case when score &gt;= 90 then 'A' when score &lt; 60 then 'C' else 'B' end) as 等级, -&gt; avg(score) as 平均分 from grade group by 等级;+--------+-----------+| 等级 | 平均分 |+--------+-----------+| A | 95.0000 || B | 74.8000 || C | 47.3333 |+--------+-----------+3 rows in set (0.00 sec) 总结 case when 语句共有两种写法，使用时要区别两种用法的差异。 使用 case when 语句可以实现修改数值的对应关系，还可以按照复杂的条件进行分组。 关于 case when 语句的详细用法，有兴趣的同学可以参考一下官方文档：13.6.5.1 CASE Syntax]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>分组查询</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql验证联合索引的最左原则]]></title>
    <url>%2Fblog%2F2018%2F01%2F29%2FMysql%E9%AA%8C%E8%AF%81%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95%E7%9A%84%E6%9C%80%E5%B7%A6%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[前言如果你接触过数据库，应该听说过在数据库表的某些列上建立索引能够加快查找速度，如果研究更深入一点的人，可能还听说过联合索引，那么索引为什么能够加快查找速度呢？联合索引究竟又是什么呢？下面说说我的简单理解。 索引试想一下，把1~10000这1万个数字打乱顺序存储在数组中，如果要找到5000这个数字在哪，那就得从数组第0个元素开始，依次遍历找到5000这个数字所在的位置，运气好了1次就能找到，运气不好需要查询1万个数，可是如果把这1万个数作为map的key，每个数存在数组中的位置作为value，存储在map结构中很快就能找到，通常情况下要比直接遍历快的多。 其实这里的map充当的是一个索引的作用，我们知道map存储数据时使用树形结构，会根据要查找的值和当前节点比较，来确定继续查找左分支还是右分支，而数据库中的索引充当的也是这样的作用，mysql中的索引是BTree结构（多路搜索树），就是利用建立索引的列中的所有值建立了一棵树，通过有序的树形查找一般要比全局搜索快多了吧！ 联合索引简单了解了一下索引的含义，那么什么是联合索引呢？其实mysql数据库中的索引不止可以建立在一个列上，它可以将一个索引同时建立在说多个列上，也就是我们所说的联合索引，联合索引的作用特别大，有时会超过单列索引，至于什么时候建立单列索引，什么时候建立联合索引同样是个很复杂的问题，在此不做描述。有兴趣的读者可以自行搜索一下。 最左原则当你在多个列上建立一个索引时，怎样的查找才能利用索引加快速度呢？说到这我们先建立一个带有索引的表格，具体的分析一下什么叫做索引的最左原则。 123456789CREATE TABLE IF NOT EXISTS `test_index`( `id` int(4) NOT NULL AUTO_INCREMENT, `a` int(4) NOT NULL DEFAULT '0', `b` int(4) NOT NULL DEFAULT '0', `c` int(4) NOT NULL DEFAULT '0', `data` int(4) NOT NULL DEFAULT '0', PRIMARY KEY (`id`), KEY `union_index` (`a`,`b`,`c`))ENGINE=InnoDB ROW_FORMAT=DYNAMIC DEFAULT CHARSET=binary; 分析上述建表语句，创建了一个名为test_index 的数据库表格，然后在a、b、c三列上建立了联合索引，索引名字为union_index，而最左原则指的就是当你建立了这样一个索引的时候，等于建立了(a)、 (a,b)、 (a,b,c)三个索引，通过条件 (a), (a,b), (a,b,c) 这三种条件查询的时候都可以利用索引加快速度，所以在建立索引的时候要把最常用的条件列放到联合索引的最左边，接下来我们来验证一下，工具就是mysql自带的explain命令。 测试版本 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 13Server version: 5.7.21-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners. 验证过程 首先以列a作为条件查询数据，我们看到 type: ref 表示引用查找， key_len: 4 表示索引长度为4，也就说明利用了索引来进行查找 123456789101112131415mysql&gt; explain select data from test_index where a = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 4 ref: const rows: 70 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.01 sec) 然后以列b作为条件查询数据，可以看到type: ALL表示全表查找， key_len: NULL 表示没有索引，也就说明如果只使用b作为查询条件，不能利用索引来加快查找速度 123456789101112131415mysql&gt; explain select data from test_index where b = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 716173 filtered: 10.00 Extra: Using where1 row in set, 1 warning (0.00 sec) 接着以列c作为条件查询数据，可以看到type: ALL表示全表查找， key_len: NULL 表示没有索引，情况与用b作为条件一样，只使用c作为查询条件也不能利用索引来加快查找速度 123456789101112131415mysql&gt; explain select data from test_index where c = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 716173 filtered: 10.00 Extra: Using where1 row in set, 1 warning (0.00 sec) 现在来测一下使用a、b作为条件的情况，我们看到 type: ref 表示引用查找， key_len: 8 表示索引长度为8，也就是说我们利用上了a、b联合索引来进行查找 123456789101112131415mysql&gt; explain select data from test_index where a = 1 and b = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 8 ref: const,const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 紧接着来测一下使用a、c作为条件的情况，我们看到 type: ref 表示引用查找， key_len: 4 表示索引长度为4，这就奇怪了，按照最左原则来说，a、c上是不会建立索引的，为什么会有索引长度呢？其实与a、b上的索引一比较我们就能发现，a、c上的索引长度只有4，而且单独的c上是没有索引的，所以4字节长度的索引只能是a上的，也就是说这种情况我们只使用了a列上的索引来进行查找 123456789101112131415mysql&gt; explain select data from test_index where a = 1 and c = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 4 ref: const rows: 70 filtered: 10.00 Extra: Using index condition1 row in set, 1 warning (0.00 sec) 为了进一步验证上面的想法，这一次测一下使用b、c作为条件的情况，我们看到 type: ALL 表示全表查找， key_len: NULL 表示没有索引可以使用，按照最左原则来说，b列上没有索引，c列上也没有索引，同时b、c的上也不存在联合索引，所以使用b、c作为查询条件时无法利用联合索引 123456789101112131415mysql&gt; explain select data from test_index where b = 1 and c = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 716173 filtered: 1.00 Extra: Using where1 row in set, 1 warning (0.00 sec) 测试完两个条件的情况，接下来测试一下使用a、b、c作为条件的情况，我们看到 type: ref 表示引用查找， key_len: 12 表示索引长度为12，这完全符合联合索引的最左原则，同时使用3个条件查询可以利用联合索引 123456789101112131415mysql&gt; explain select data from test_index where a = 1 and b = 1 and c = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 12 ref: const,const,const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 测试进行到现在，我测试了所有的情况吗？不是的！还可以颠倒顺序啊，我原来一直以为联合索引是有顺序的，结果测试后才发现，利用索引的条件符合“交换律”，也就是下面这种情况也能利用a、b上的联合索引，索引长度为8 123456789101112131415mysql&gt; explain select data from test_index where b = 1 and a = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 8 ref: const,const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 再来试试这种情况，按照最左原则，c上没有建立索引，a上有索引，c、a没有建立联合索引，所以只能使用a上的索引进行查找，结果索引长度只有4，验证了我们的想法，联合查询条件使用索引时满足“交换律” 123456789101112131415mysql&gt; explain select data from test_index where c = 1 and a = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 4 ref: const rows: 70 filtered: 10.00 Extra: Using index condition1 row in set, 1 warning (0.00 sec) 接下来几种交换顺序的情况(c,b)、(a,c,b)、(c,b,a)等，大家可以自己进行验证，到此为止，mysql联合索引的最左原则也就验证结束了！ 总结 联合索引的最左原则就是建立索引KEY union_index (a,b,c)时，等于建立了(a)、(a,b)、(a,b,c)三个索引，从形式上看就是索引向左侧聚集，所以叫做最左原则，因此最常用的条件应该放到联合索引的组左侧。 利用联合索引加速查询时，联合查询条件符合“交换律”，也就是where a = 1 and b = 1 等价于 where b = 1 and a = 1，这两种写法都能利用索引KEY union_index (a,b,c)。 遇到这种不确定的问题还是需要实际测试一下，简单的调整一下索引顺序可能会极大的提升效率哦！]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>实用工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python统计指定号码的历史中奖情况]]></title>
    <url>%2Fblog%2F2018%2F01%2F11%2FPython%E7%BB%9F%E8%AE%A1%E6%8C%87%E5%AE%9A%E5%8F%B7%E7%A0%81%E7%9A%84%E5%8E%86%E5%8F%B2%E4%B8%AD%E5%A5%96%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[前言生活在寸土寸金的帝都，买房变成了一件可遇而不可求的事情，作为一个朝九晚九挣工资的人来说，买房或许只是出现在梦里，但是梦想总是要有的，万一实现了呢？其实真正赚钱的方式都明明白白地写在了刑法里，可是咱可是本分人，不能做哪些违法的事情，想要赚钱买房，还有一种比较随意的方式——买彩票，如今这帝都的房价，不是你中一张500万彩票就能买得起的，如果要买的起，那就需要中两张！ 经历中两张500万的彩票，想想就知道这种概率有多大了，跟你被天上掉下的陨石砸中脑袋差不多，是不是感觉没有希望了，不过不要灰心嘛，万一你要被砸中了呢？ 对于预测彩票号码这件事情，很抱歉，我不是神仙，没有方法可以办到，不过有件事你需要知道一下：那就是双色球自从问世以来，十几年间从未出现过一次号码完全相同的情况，也就是说你买个和历史号码一样的，基本中不了大奖了，但是也不一定，万一就有两颗陨石同时砸中你呢! 对于买彩票这件事，有的人喜欢买一个号，坚持多年从不动摇，一心做着发财梦；而有的人却是很随意，每天机选，靠天吃饭；还有一部分大神就比较高端了，每天窝在彩票投注站里，写写画画，仿佛可以窥探天机一样，每期少则几十，多则几百的砸着自己的血汗钱，我劝你们还是醒醒吧。 而我呢，就属于半个第一种人，坚持着一个号，做着发财梦，偶然间看到彩票投注站就买一张，遇不到就算了，典型的佛系彩票购买者，这样买了一段时间，忽然有个想法，我买的这个号到底在历史上中没中过大奖呢？于是作为程序猿的我决定写个程序查一下不就好了，所以才有了下面这段代码。 代码 引入库函数，其实需要的函数特别简单，就是要处理csv格式的双色球历史开奖数据。 1import csv 定义奖项，也就是中奖号码情况与奖项的对应关系，注意中一个篮球是6等奖哟！ 1234567891011121314151617# list award classifyaward_classify = &#123; (6,1): 1, (6,0): 2, (5,1): 3, (5,0): 4, (4,1): 4, (4,0): 5, (3,1): 5, (3,0): 0, (2,1): 6, (2,0): 0, (1,1): 6, (1,0): 0, (0,1): 6, (0,0): 0&#125; 定义比对函数，这个函数要能判断出我的号码跟一个历史号码相比，中了几个红球和蓝球。 123456789101112131415161718# count red balls and blue ballsdef count_red_blue_balls(my_number, history_number): red_count, blue_count = 0, 0 my_index, history_index = 0, 0 while my_index &lt; 6 and history_index &lt; 6: if my_number[my_index] == history_number[history_index]: my_index += 1 history_index += 1 red_count += 1 elif my_number[my_index] &lt; history_number[history_index]: my_index += 1 else: history_index += 1 if my_number[6] == history_number[6]: blue_count = 1 return red_count, blue_count 查询历史中奖情况，使用我选择的号码和历史开奖情况逐一比对，得到每个奖项中奖次数。 123456789# count award situation of my numberdef count_award_situation(my_number): local_award_statistics = [0,0,0,0,0,0,0] with open('lottery_history_data.csv', 'r') as file: data_content = csv.reader(file) for row_data in data_content: local_award_statistics[award_classify[count_red_blue_balls(my_number, list(map(int, row_data[1:8])))]] += 1 return local_award_statistics 展示查询结果，将统计结果以友好的方式呈现。 1234567# show award statictics for a numberdef show_award_result(my_number, award_statistics): print("my number is %s\n" % my_number) print("history award record list:") for index in range(0,7): print("award %d: %4d times" % (index, award_statistics[index])) 启动函数，读取自己定义的号码，然后进行统计 123456789# main functionif __name__ == '__main__': #my_number = [5,6,10,11,25,30,11] #my_number = [5,8,10,15,26,30,6] print("请输入6个红球和1个蓝球号码，空格分隔：") my_number = list(map(int, input().split())) award_statistics = count_award_situation(my_number) show_award_result(my_number, award_statistics) 运行结果 总结 这段代码只是一时好奇的产物，所以说好奇心带来了生产力。 统计代码只是做简单使用，所以一些特殊情况并未判断，比如输入字母或者未排序的数字。 看到我的号码连个4等奖都没有中过，不知道是该高兴还是难过，是不是这个大奖在等着我啊！ 说到这也该结束了，不好意思上周六(20180113)买的双色球又中了6等奖，明天(20180121)要去领奖喽！ 源码代码传送门(附双色球历史数据)：一触即达]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python查找文件中包含中文的行]]></title>
    <url>%2Fblog%2F2018%2F01%2F06%2FPython%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6%E4%B8%AD%E5%8C%85%E5%90%AB%E4%B8%AD%E6%96%87%E7%9A%84%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[前言近几天在做多语言版本的时候再次发现，区分各种语言真的是一件比较困难的事情，上一次做中文提取工具的就花了不少时间，这次决定用python试一试，结果写起来发现真是方便不少，自己整理了一下方便以后查找使用。 代码123456789101112131415161718192021222324#!/usr/bin/env python3# -*- coding: utf-8 -*-# find the line of containing chinese in files__author__ = 'AlbertS'import redef start_find_chinese(): find_count = 0; with open('ko_untranslated.txt', 'wb') as outfile: with open('source_ko.txt', 'rb') as infile: while True: content = infile.readline() if re.match(r'(.*[\u4E00-\u9FA5]+)|([\u4E00-\u9FA5]+.*)', content.decode('utf-8')): outfile.write(content) find_count += 1; if not content: return find_count# start to findif __name__ == '__main__': count = start_find_chinese() print("find complete! count =", count) 文件 输入：source_ko.txt 3 캐릭터 Lv.50 달성8 캐릭터 Lv.80 달성10 캐릭터 Lv.90 달성……2840 飞黄腾达4841 同归于尽8848 캐릭터 Lv.50 달 输出：ko_untranslated.txt 2840 飞黄腾达4841 同归于尽 总结 其实这段小小的代码中包含了两个常用的功能，那就是读写文件和正则表达式。 这也是两个重要的知识点，其中with操作可能防止资源泄漏，操作起来更加方便。 正则表达式可是一个文字处理的利器，代码中的正则可能还不太完善，后续我会继续补充更新。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fblog%2F2018%2F01%2F05%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy Picture Watermark1?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9hbGJlcnRnaXRodWJob21lLmdpdGh1Yi5pby9ibG9nL2Fib3V0,size_18,color_FFFFFF,t_70#pic_center) Fans aticlehttps://blog.csdn.net/albertsh/article/details/100594143https://blog.csdn.net/albertsh/article/details/100540338!-- https://blog.csdn.net/albertsh/article/details/52788106 https://blog.csdn.net/albertsh/article/details/52797519 --https://blog.csdn.net/albertsh/article/details/82286999https://blog.csdn.net/albertsh/article/details/90736859 Blog Record博客记录QQ：347070901微信公众号：写代码的苏东坡===============================我的Github：AlbertGithubHome===============================刚刚起步 2013-10-05 08:39 写了第一篇转载博文 2015-11-19 11:20 收到第一条博客评论 2016-12-27 20:18 翻译第一篇英文资料 2017-03-27 09:55 访问第一次突破三万 2017-05-21 09:25 积分第一回到达一仟 2017-05-21 09:25 等级第一次满足四级 2017-09-14 21:00 版式第一次不让更改 2017-11-14 11:59 排名第一次有了数字 2018-07-16 19:39 访问第一次达二十万2018-12-08 10:41 访问第一回破三十万2019-06-22 18:30 访问第一次破四十万2019-09-24 17:04 博客嗖一下到了六级2020-01-02 15:55 访问第一回达五十万2020-02-17 20:17 粉丝第一回超过千人2020-06-20 12:09 评论第一次跨越千次2020-06-25 16:31 等级飞一般来到七级2020-07-31 11:05 点赞第一次达到千人2020-08-09 20:48 积分第一回突破一万 imgroot More info: Deployment]]></content>
  </entry>
</search>
