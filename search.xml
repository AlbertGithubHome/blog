<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[git branch常用分支操作]]></title>
    <url>%2Fblog%2F2020%2F02%2F25%2Fgit-branch%E5%B8%B8%E7%94%A8%E5%88%86%E6%94%AF%E6%93%8D%E4%BD%9C%2F</url>
    <content type="text"><![CDATA[前言最近代码的版本控制工具由SVN换成了Git，只用管理个人项目常用的灵魂三步git add、git commit、git push看来是行不通了，之前虽然也一直在用 git，但是用法很有限，主要集中在前面提到的三步，所以为了更好的工作，我决定还是好好总结一下。 分支在Git的操作里有着很重要的地位，代表了不同的开发线路，创建一个分支，也就多了一个索引文件，相比于SVN分支拷贝全部文件来说来方便的多，所以Git使得按功能分支的开发模式变得非常简单，在开发过程中常常需要对分支进行操作。 远程仓库本来就几个分支，操作上也没有太麻烦，但是加入了远程仓库以后，事情变得复杂起来。有了远程仓库一般意味着代码开发需要多人合作了，这时候常常会产生冲突，分支合并时也变得不那么容易了。 远程仓库其实也很好理解，就是放在远处用来保存代码资源的一个仓库，其实和本地的代码库没有什么区别，这个远程仓库主要是为了把大家修改的代码都合并到一起，给大家提供一个统一的目标点。 远程仓库究竟有多远，常见的代码托管平台：github、gitlab、码云都可以提供远程仓库，如果你在月球上放置一台可以联网的代码仓库服务器，那么距离就是38.4万千米，但是远程仓库也可以很近，你也可以把本机电脑的D盘里的代码仓库作为E盘的代码仓库的远程仓库，或许远程仓库可能只和你隔了一个文件夹。 由于网络的原因，github 和 gitlab 访问常常很慢，所以为了做练习测试推送，我在码云创建了一个仓库 gitstart，它的地址大概是这个样子：git@gitee.com:myname/gitstart.git，创建的方法一搜一大把，上面提到的几个托管平台，在哪创建都可以，一定要记住地址，因为后面还要用到。 建立联系本地创建文件夹并进入12345678albert@homepc MINGW64 /d$ mkdir gitstartalbert@homepc MINGW64 /d$ cd gitstart/albert@homepc MINGW64 /d/gitstart$ 这里的文件夹名字可以和远程仓库不同，但是为了看起来方便对应，还是取相同的名字好一点。 初始化仓库123456albert@homepc MINGW64 /d/gitstart$ git initInitialized empty Git repository in D:/gitstart/.git/albert@homepc MINGW64 /d/gitstart (master)$ 临时插播好奇心（不在流程中）目前这个状态有点意思，初始化完之后，(master) 这个字符串表示当前是在 master分支，查一下日志看看： 123456albert@homepc MINGW64 /d/gitstart (master)$ git logfatal: your current branch 'master' does not have any commits yetalbert@homepc MINGW64 /d/gitstart (master)$ 提示也是正确的，说 master分支没有任何提交，但是我们查询一下分支看看： 12345albert@homepc MINGW64 /d/gitstart (master)$ git branch -aalbert@homepc MINGW64 /d/gitstart (master)$ 居然是空的，没有分支，查询 .git\HEAD 文件发现里面有一行 ref: refs/heads/master，说明当前分支时 master，但是为什么查询分支没有结果呢？ 打开 .git\refs\heads 目录，发现这个文件夹下根本没有 master文件，其实想想也对，Git 中的分支其实对应着 commit id，现在什么都没有提交，master 也就找不到 commit id，所以就是有 master 文件，里面也不知道写什么。 查询远程仓库12345albert@homepc MINGW64 /d/gitstart (master)$ git remote -valbert@homepc MINGW64 /d/gitstart (master)$ 依旧什么内容都没有，说明还没有和远程仓库建立联系。 与远程仓库建立对应关系12345678910albert@homepc MINGW64 /d/gitstart (master)$ git remote add origin git@gitee.com:myname/gitstart.gitalbert@homepc MINGW64 /d/gitstart (master)$ git remote -vorigin git@gitee.com:myname/gitstart.git (fetch)origin git@gitee.com:myname/gitstart.git (push)albert@homepc MINGW64 /d/gitstart (master)$ 这一步需要注意，origin看起来就是一个远程仓库的别名，代表着 git@gitee.com:myname/gitstart.git 这个代码仓库，刚刚提到过，这个远程仓库也可以是本地的，所以你添加git remote add origin d:/test 也是可以的，就表明 gitstart 的远程仓库是本地的 test 仓库。 第一个分支刚刚说过，现在本地库的状态有些特殊，实际上刚刚在码云上创建的 git@gitee.com:myname/gitstart.git 库也很特殊，他们都没有真正的分支，这时只要我们成功提交一次，创建一个commit id，就相当于初始化了master分支。 添加README文件12345678910111213albert@homepc MINGW64 /d/gitstart (master)$ echo "learn git branch command"&gt;README.mdalbert@homepc MINGW64 /d/gitstart (master)$ git add README.mdwarning: LF will be replaced by CRLF in README.md.The file will have its original line endings in your working directoryalbert@homepc MINGW64 /d/gitstart (master)$ git commit -m"add readme file"[master (root-commit) 3226b63] add readme file 1 file changed, 1 insertion(+) create mode 100644 README.md 查询当前分支123albert@homepc MINGW64 /d/gitstart (master)$ git branch -a* master 这次可以是出现了，分支为 master，前面的 * 表示为当前分支。 将分支推送到远程仓库12345678910albert@homepc MINGW64 /d/gitstart (master)$ git push -u origin masterEnumerating objects: 3, done.Counting objects: 100% (3/3), done.Writing objects: 100% (3/3), 248 bytes | 248.00 KiB/s, done.Total 3 (delta 0), reused 0 (delta 0)remote: Powered by GITEE.COM [GNK-3.8]To gitee.com:myname/gitstart.git * [new branch] master -&gt; masterBranch 'master' set up to track remote branch 'master' from 'origin'. 至此，本地仓库和远程仓库就建立了联系，下面可以开始学习 Git 分支命令了。 分支操作新建分支新建分支可以使用 git branch branch_name 命令，以下就是一个创建名为 release 分支的命令： 12albert@homepc MINGW64 /d/gitstart (master)$ git branch release 也可以使用 git checkout -b branch_name 来创建一个新分支，创建完会自动切换到新分支： 123456albert@homepc MINGW64 /d/gitstart (master)$ git checkout -b devSwitched to a new branch 'dev'albert@homepc MINGW64 /d/gitstart (dev)$ 切换分支这是一个很奇怪的命令，命令格式为 git checkout branch_name，总感觉 checkout 子命令包揽了不属于自己的工作，如果在git branch的基础上加一个参数会更合理的一点，但这和切换分支的实际含义可能还有关系，切换分支其实就是修改HEAD文件中的 commit id，而没有真正的发生切换。 12345678910albert@homepc MINGW64 /d/gitstart (dev)$ git checkout releaseSwitched to branch 'release'albert@homepc MINGW64 /d/gitstart (release)$ git checkout devSwitched to branch 'dev'albert@homepc MINGW64 /d/gitstart (dev)$ 查看本地分支像刚才我们创建的 release 分支和 dev 分支都是在本地创建的，这样的分支通过 git branch 命令就可以查看 12345albert@homepc MINGW64 /d/gitstart (dev)$ git branch* dev master release 这样就列举了本地的所有分支，在当前分支名字 dev 前面哈还有一个 * 作为标记 查看远程分支只要在上面的命令基础上加上 -r 参数就行了 123albert@homepc MINGW64 /d/gitstart (dev)$ git branch -r origin/master 查询到的分支只有 origin/master 一个，这个分支是一开始我们进行第一次提交产生 master 分支之后，通过 git push -u origin master 推送到远程仓库的，所以现在只有一个。 查看所有分支所有分支包括本地分支和远程分支，将 -r 参数换成 -a 参数就可以了 123456albert@homepc MINGW64 /d/gitstart (dev)$ git branch -a* dev master release remotes/origin/master 将本地分支推送到远程仓库其实之前已经操作过了，可以试着复习一下，git push -u origin branch_name，其实这是一个简写，-u 可以写成 --set-upstream 表示设置上游分支，其实就是和远程仓库的分支建立联系。 branch_name 也是 local_branch_name:remote_branch_name的一种简写，冒号前表示本地分支，冒号后面表示远程分支，如果只写一个就表示两个分支名相同，远程仓库中如果没有这个分支就会新建一个。 也就是说 git push -u origin dev 和 git push--set-upstream origin dev:dev 是一样的，下面来试一下，然后查看一下分支： 1234567891011121314151617albert@homepc MINGW64 /d/gitstart (dev)$ git push -u origin devTotal 0 (delta 0), reused 0 (delta 0)remote: Powered by GITEE.COM [GNK-3.8]remote: Create a pull request for 'dev' on Gitee by visiting:remote: https://gitee.com/myname/gitstart/pull/new/myname:dev...myname:masterTo gitee.com:myname/gitstart.git * [new branch] dev -&gt; devBranch 'dev' set up to track remote branch 'dev' from 'origin'.albert@homepc MINGW64 /d/gitstart (dev)$ git branch -a* dev master release remotes/origin/dev remotes/origin/master 冒号前后的米名字是不是一定相同呢？完全没有必要，我们可以让本地的 release 分支对应远程的 master 分支，只不过这样怪怪的，但是操作上完全可以的。 12345678albert@homepc MINGW64 /d/gitstart (dev)$ git checkout releaseSwitched to branch 'release'albert@homepc MINGW64 /d/gitstart (release)$ git push -u origin release:masterEverything up-to-dateBranch 'release' set up to track remote branch 'master' from 'origin'. 查看本地分支与远程分支对应关系这个也是刚刚知道的，可以使用 git branch -vv 命令，注意是两个 v: 12345albert@homepc MINGW64 /d/gitstart (release)$ git branch -vv dev 3226b63 [origin/dev] add readme file master 3226b63 [origin/master] add readme file* release 3226b63 [origin/master] add readme file 执行这个命令之后可以看出，本地的 master 和 release 分支都对应着远程的 master 分支 删除本地分支我们先复习一下新建分支，然后把它推送到远程仓库，再使用 git branch -d branch_name 命令进行删除 12345678910111213141516171819202122albert@homepc MINGW64 /d/gitstart (release)$ git checkout -b feature_testSwitched to a new branch 'feature_test'albert@homepc MINGW64 /d/gitstart (feature_test)$ git push origin feature_testTotal 0 (delta 0), reused 0 (delta 0) remote: Powered by GITEE.COM [GNK-3.8]remote: Create a pull request for 'feature_test' on Gitee by visiting:remote: https://gitee.com/myname/gitstart/pull/new/myname:feature_test...myname:masterTo gitee.com:myname/gitstart.git * [new branch] feature_test -&gt; feature_testalbert@homepc MINGW64 /d/gitstart (feature_test)$ git branch -a dev* feature_test master release remotes/origin/dev remotes/origin/feature_test remotes/origin/master 开始删除分支，删除之前记得切换到别的分支，否则删除不成功 1234567891011121314151617albert@homepc MINGW64 /d/gitstart (feature_test)$ git checkout devSwitched to branch 'dev'Your branch is up to date with 'origin/dev'.albert@homepc MINGW64 /d/gitstart (dev)$ git branch -d feature_testDeleted branch feature_test (was 3226b63).albert@homepc MINGW64 /d/gitstart (dev)$ git branch -a* dev master release remotes/origin/dev remotes/origin/feature_test remotes/origin/master 删除远程分支通过上面的操作我们发现只删除了本地的分支，远程的分支还在，要想删除远程分支，需要使用 git push origin --delete branch_name 命令 12345678910111213albert@homepc MINGW64 /d/gitstart (dev)$ git push origin --delete feature_testremote: Powered by GITEE.COM [GNK-3.8]To gitee.com:myname/gitstart.git - [deleted] feature_testalbert@homepc MINGW64 /d/gitstart (dev)$ git branch -a* dev master release remotes/origin/dev remotes/origin/master 这次再查看时发现远程分支也被删掉了。 获取远程主分支到本地其实 Git 的克隆命令默认就是把远程仓库的主分支下载到本地，我们可以使用 git clone 远程地址 本地文件夹 命令来克隆一个仓库，如果本地文件夹省略，则默认新建一个与仓库名相同的文件夹： 1234567891011121314151617albert@homepc MINGW64 /d$ git clone https://gitee.com/myname/gitstart.git gitstartcopyCloning into 'gitstartcopy'...remote: Enumerating objects: 3, done.remote: Counting objects: 100% (3/3), done.remote: Total 3 (delta 0), reused 0 (delta 0)Unpacking objects: 100% (3/3), done.albert@homepc MINGW64 /d$ cd gitstartcopy/albert@homepc MINGW64 /d/gitstartcopy (master)$ git branch -a* master remotes/origin/HEAD -&gt; origin/master remotes/origin/dev remotes/origin/master 获取远程其他分支到本地从上面命令执行后的结果来看，当前本地仓库中只有 master 分支，其他的分支都是在远程仓库上，这时可以用 git checkout branch_name 命令来下载远程分支： 1234567891011121314151617albert@homepc MINGW64 /d/gitstartcopy (master)$ git checkout devSwitched to a new branch 'dev'Branch 'dev' set up to track remote branch 'dev' from 'origin'.albert@homepc MINGW64 /d/gitstartcopy (dev)$ git branch -a* dev master remotes/origin/HEAD -&gt; origin/master remotes/origin/dev remotes/origin/masteralbert@homepc MINGW64 /d/gitstartcopy (dev)$ git branch -vv* dev 3226b63 [origin/dev] add readme file master 3226b63 [origin/master] add readme file 看到这里可能会疑惑了，git checkout branch_name 不是切换分支的命令吗？实际上当 branch_name 分支在本地不存在而远程仓库存在时，这个命令与 git checkout -b &lt;branch&gt; --track &lt;remote&gt;/&lt;branch&gt; 含义相同，会在本地新建一个分支，并与远程分支建立联系。 常用集合 新建分支：git checkout -b branch_name 切换分支：git checkout branch_name 查看分支：git branch -a 删除分支：git branch -d branch_name 推送分支到远程：git push origin branch_name 删除远程的分支：git push origin --delete branch_name 拉取远程分支到本地：git checkout branch_name 查询分支的对应关系：git branch -vv 总结 以上这些命令都是在本地测试过的，可能考虑的不太全面，不过没关系，以后的分支操作还会补充到这里。 这些命令在有些特殊的情况下使用可能会遇到问题，如果大家发现了问题请及时指出，我会尽快修改的。]]></content>
      <categories>
        <category>Git</category>
      </categories>
      <tags>
        <tag>git</tag>
        <tag>branch</tag>
        <tag>checkout</tag>
        <tag>push</tag>
        <tag>remote</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[挥一挥衣袖，开始一段新的旅程]]></title>
    <url>%2Fblog%2F2020%2F02%2F16%2F%E6%8C%A5%E4%B8%80%E6%8C%A5%E8%A1%A3%E8%A2%96%EF%BC%8C%E5%BC%80%E5%A7%8B%E4%B8%80%E6%AE%B5%E6%96%B0%E7%9A%84%E6%97%85%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[悄悄的我走了，正如我悄悄的来；我挥一挥衣袖，不带走一片云彩。 前言钱钟书老先生在《围城》中说道:“天下只有两种人。比如一串葡萄到手，一种人挑最好的先吃，另一种人把最好的留到最后吃。照例第一种人应该乐观，因为他每吃一颗都是吃剩的葡萄里最好的；第二种人应该悲观，因为他每吃一颗都是吃剩的葡萄里最坏的。不过事实却适得其反，缘故是第二种人还有希望，第一种人只有回忆”。 而我在反思自己时却发现，无法将自身完全归于这两种人的一类，如果非要选一种，我更像是老先生提到的第二种人，总喜欢把最好的留到最后。按理说这样的人应该总是向前充满希望的，但是我却热衷于收集回忆，记录生活中的点点滴滴，认真记下生活中的每一笔支出，写下人生中一次次感动… 其实一开始我并没有这方面的爱好，不知从何时起，儿时的记忆渐渐和梦境中的画面杂糅在了一起，有些事情已经分不清是之前确实发生的，还是曾经在梦境中悄悄的来到过，所以慢慢地我养成了这样的习惯，记录生活中一切想要被回忆的事情，期待着有一天能与对此感兴趣的人一起分享这些点点滴滴。 缘由技术博客中很少写自己的生活，这一次其实也和技术有关，在一个工作岗位上勤勤恳恳工作六年之后，今年终于鼓足勇气决定出来找找新的机会，确定了新的目标之后回头看看这六年收获了很多，同时在这段找工作的经历中也学会了不少东西，新的工作基本定下来了，现在总结一下工作以来的经历以及面试中遇到的问题，方便后续复盘时能有个参照。 懵懵懂懂的6年前走出校门从大四学期便开始走出校门，一切按照教学大纲进行着，大四这年是企业实训，我们被安排到一家机构进行学习，学习结束已经13年的深冬，我们一群小伙伴作为花朵开始走出曾经的温室。 其实从实训的后半段我们已经开始在北京各大高校“流窜”，参加了很多不请自来的校招，进行了一轮轮的笔试，但很少有人从中得到满意的工作机会，我也尝试过几次，但是感觉自己真的很渺小，经过努力得到了一个大厂的面试邀请，我怀着激动的心情前去面试，走的时候还换上了自己都觉得怪异的正装，好在面试官并不在意我的这份不自然，完全投入身心开始进行面试。 很幸运我通过了一面，但是在去参加二面的路上我才发现后背已经被汗水浸湿了，之前也参加过几次面试，但是这一次确实是让我身心俱疲，从中也渐渐体会到了不同公司之间的技术差距，我一心想加入这个团体，但是二面的结果又把我拉回了现实，二面的过程很糟糕，有一道题我至今还记得，那就是关于数据库的连接，但是回答的很模糊，由于自己的知识储备不足，我怀疑自己当时连题目都没有弄懂。 走进社会大厂失利后，开始寻找其他的机会，毕竟工作是现在的第一要务，放弃了保研机会一心想着早点参加工作，如果连工作都找不到岂不是让人笑话了，时间不久便通过了几家面试，其中有意向可以试试的有两家，一家是做偏硬件的软件，另一家就是做游戏开发的，工资待遇差不多，相比较而言第一家要高一些，但是当时沉迷于Dota的我经过“深思熟虑”之后，委婉的谢绝了第一家的邀请，进入了这家游戏公司，也就是后来我工作了6年的公司。 开始工作我的人生很幸运，我一直这样觉得，在这里我碰到了我工作的中的第一位导师，都说师傅领进门，修行在个人，那么他就是我进入社会环境的那个师傅，但是他比我也大不了几岁，我更愿意称呼他为兄长。 时光荏苒，岁月如梭，即便转眼已经过去了6年多，但是工作第一天他让我修改的第一个BUG我至今还记得，那是一把“罪恶坑的钥匙”，BUG具体的细节并不重要，而是他处理的方式让我记忆犹新。 开发环境配置好之后，兄长便指给我一个BUG，让我尝试修改，便是那个“罪恶坑的钥匙”，第二天他就过来询问BUG的修改情况，我告诉他我的修改思路A，他说可以这样改，但是这种修改方式可能会给后面带来一些不利于扩展的问题，然后在他的电脑上给我看了他建议的修改思路B，然后让我按照这个思路去修改，我比较之后确实思路B更好一些。问题的关键是这个BUG他已经想好了修改方案，并且尝试修改过，他指定让我修改完全是为了帮我熟悉问题的处理方式而非完成工作。 之后也和一些其他领导沟通过工作，但是能这样带我入门的兄长就只此一个，其他人大多是就是完成工作即可，很少有人再想教我的什么东西了。我是幸运的，在我懵懂的年纪碰上了这样一位领路人，之后我们在项目组之间分分合合，但始终工作在同一个屋檐下。 勤勤恳恳的6年初入职场刚刚参见工作，一切都显得那么新鲜，经常会有这样的感叹：原来游戏中的这个功能是这样实现的！开始的时候对于工作的状态还是有点不适应，印象最深的就是下午的时候总是昏昏沉沉的，当时可以用“熬”这个字来形容，但是随着后面工作内容的铺开，大脑在紧张的处理这些问题时，犯困的毛病就改掉了。 工作之前写的项目很多是个人完成的，就是几个人合伙做一个项目，基本上也不太大，所有的代码也都很了解，但是刚接触这个游戏项目时感觉它太大了，所有的代码只能不断的搜索才能找到，仿照已有的功能开发了两个新功能之后，渐渐的找到了感觉。 很长一段时间之后再回过头来看自己的代码时会发出这样的感叹：这段代码是我写的吗？现在整个流程我已经清楚了，但是当时写这段代码的时候是怎么找到这里的。其实一开始写代码完全是照葫芦画瓢，很多语句不知道什么意思，但是功能类似，这样写完就可以用了。 当时还有一个情况就是开发环境是没有网络的，有问题不能上网去查，好在分配给我的没有太复杂的功能，依照原来的系统都可以完成，并且我喜欢做笔记，常用的那些代码实现都让我记在了本子里，有些还记了不止一遍，这些笔记我至今还留着，现在看起来显得过于幼稚，但却是我工作以来的痕迹。 渐入佳境工作一年以后，对整个游戏已经比较熟悉了，可以独自完成很多功能，稳定下来的游戏也逐渐对接多个平台开始蓬勃发展，那时的我真的是干劲十足，每天像打了鸡血一样，作为服务器开发的我开始偶尔“插手”客户端的开发工作。 期间还养成了每天读书的习惯，其实这个习惯的养成是被动的，原因是分配给我的电脑比较卡，我提过几次但是一直没有换的机会，每天早上开机至少得10分钟左右才能正常顺畅的工作，所以后来我一般会早来一会，开机这期间我就会把旁边同事的书拿过来看看，后来同事的书看完了，我就买一些相同类型的技术书籍来看，再后来开始扩展知识面，买一些流行技术的书，这个习惯就一直保留了下来，一直到现在每年都会看几本技术书籍，有些是不朽的经典，有些是新进的技术。 其实很多书的内容我只是有大概的印象，具体的内容早就忘记了，偶有几本书感觉有意思会回过头来再次翻看，每次看都会有不同的感受，我喜欢在纸质书上做笔记，想到什么就写什么，有些章节会被我划的很乱。在我看书的时候总有同事问我，你看那么多书都记得吗？都学会了吗？这时我常常会自嘲一般的回答：“看着玩而已，早都不记得了”。 实际上记不记得重要吗？今天吃了有营养的东西，明天依旧会饿，你会因为明天还会吃饭就放弃今天的美食吗？我想不会的吧，我感觉看书也是一样，我今天看了明白了一些事情，或者读到一个故事感动了很久，明天忘了就忘了，毕竟我曾经学会过，曾经也感动过。这些东西会消失的无影无踪吗？我想也不会的吧，吃过的美食总会有一部分营养进入了我们的细胞，成为了肉体的一部分，而曾经读过的书会忘得一干二净吗？当然不会，那些使我们印象深刻的文字总会在未来的某个深刻，在我们的脑子中再次迸发出来。 再入蛮荒天下没有不散的筵席，参加工作时就参与开发的这个项目终于到了最后的维护阶段，这个阶段距离我刚进公司时已经过去了2年半的时间，此时原项目不再进行新的开发只进行必要的维护，原项目组的人也被分成了两部分，现在的有两个新项目，一个是相同技术栈不同玩法的端游项目，一个是紧追潮流的手游项目。我当时想去做手游，最终也确实分到了手游组，就是从这时起，我与之前的兄长分到了不同的项目。 事实证明这个公司向手游进军的项目确实是一条蛮荒的道路，整个技术链遇到了前所未有的挑战，我们一步步探索着前进的道路，试图越过一个个技术的深坑，而真实情况却是多少次我都陷在了里面。 在这个项目组我遇到了很多新的伙伴，有的乐观、有的开放、有的乐于奉献、有的精益求精，在这我看到了相同而又不同的服务器程序，之前的程序被改的面目全非，我又得重新适应，面对全新的客户端也有太多的新知识需要学习，每天必须打起十二分精神来应对工作。 一次次的否定自我，一次次的推到重建，在项目的紧要关头，升级引擎、重建UI、优化逻辑，最终还是把这款游戏送上了线，但事实却如昙花一般，一闪而过，失败了，我们没有做出成功的产品，仅仅是做了一次失败的尝试，此时距离进入这个项目组过了1年半的时间。 并入源头手游组的失败尝试使我有了到外面大世界看看的想法，就在这时，和我们一同开始的另一个项目组已经完成了一次轮回，很明显他们成功了，作为同时开始的两个项目，一成一败的比较对于我们的打击很大，而那个成功的项目组也进入维护阶段，领导决定合并两个项目组继续完成手游的开发，这使我又打消了出门找工作的念头。 两个项目虽然一成一败，但是各有优势，因为最终做的是手游，所以原来的手游组有技术优势，而另一个成功的项目有成功的游戏内容，两者一合并应该很快就能出一个产品，更重要的是，这两拨人有很多都是曾经的好友，好友联手打造一个游戏也是很有意思的事情。 可是理想很丰满，现实很骨感，事实证明做出一款游戏是多么的不容易，虽然两部分好友合并到一起没有什么磨合的问题，但是游戏内容的一次次修改不断冲击着之前制定的开发计划，整个开发计划不断修改，时间节点在不断修改的需求面前显得那么渺小，常常被无情的践踏。 终于看到胜利的曙光了，在不断调整了2年之后，游戏迎来了上线的的一天，之后开始根据线上反馈进行调整，在我看来游戏开发到这已经基本完成，虽然达不到爆款的要求，但终究是一款中规中矩的游戏，没有大的问题，也没有太闪光的点，我在这的修行也要告一段落了。 离开这里的一个导火索是游戏内容一次大的调整，本来现阶段不可能大面积修改功能了，可是在计划中还是出现了太多看不懂的修改内容，因为之前有了完成游戏就离开的想法，看到这里仿佛又要开启一个新游戏了，我也就没有再留下的必要了，是时候到外面的世界去看看了。 信心满满的6年后外出求索19年底，在第一家也是唯一一家公司呆了6年之后，我开始外出面试了，从一开始的信心满满到后面的发奋图强，我逐渐认识到了，我必须出来闯闯了，我在一个安逸的地方待了太久，虽然每天都在学习，但事实上优秀的人比你还要努力，以下简单介绍下面试过程，对于需要掌握的知识进行一个梳理，便于日常复习警醒自己，大概面了几家，以下按一面时间先后排列以下T、D、Y、W、Z、H：，全部以字母代替就不列出公司名了，有兴趣的可以进一步交流下。 T公司 很抱歉一开始把公司名看错了，当时还在想一家旅游公司怎么还做游戏，但是毕竟是第一家在招聘APP上给我发面试邀请的公司，怎么也要去看看，后来了解了一下这是一家主营棋牌类的公司，面试当天早早就来到了这家公司，顺便再楼下吃个了饭，面试开始先填个表格，内容跟查户口一样，我只填了其中的必要信息，接着做笔试题，包括后面几家面试，这是我唯一做的一套笔试题，内容不难，可能就是一个简单了解。 我还没写完面试官就来了，我看他特别像我初中的化学老师，整个过程很轻松，聊聊笔试题、曾经的项目，面试官还介绍了他们公司的情况，他表示了对我的肯定，问我有没有兴趣转Golang语言，我内心是拒绝的，其实嘴上也拒绝了，因为我一直使用C++，之后又是其他一个组的负责人来面试，他们使用的Python，整个过程依旧轻松加愉悦，还向他请教了分布式服务器的知识，最终因为我不想放弃C++而结束，他问原因是什么？我开玩笑说：可能是情怀吧！ 涉及到笔试面试部分内容，列举在此主要为了重温复盘，如果你想做游戏开发也可以看看这些知识： 不同类型数据内存占用大小 估算PC机上1秒钟可能执行的空的for循环次数 linux下常用搜索文件命令 常用的设计模式 字符串翻转 扑克牌中挑最长顺子 回旋排列矩阵 分布式服务器设计 linux中的lvs 服务器横向扩展 从头实现一个服务期 websocket 玩家背包怎样设计 D公司 这个公司完全是抱着学习的心态去的，因为公司本身很大并且不是做游戏的，来这家公司完全是因为他们的技术总监在招聘APP给我发了面试邀请，我本来觉得不合适，人家说可以来试试，抱着学习的态度我就去了，为了这次面试还看了好几个调度算法，最终也没用上。 本来10点半的面试，7点多我就出发了，期间地铁还坐反了，还好出门早，来到西二旗发现手机都没有信号，出门都骑不了自行车，走了很久才找到一辆，开锁出发一气呵成，9点多就到公司楼下了，旁边便利店买了个菜团子，对于干吃的我来说太大了，10点左右进入公司，大公司就是不一样，进门登记后还要贴一个签，这是怕我乱跑啊。 面试不久后进行，来了一个小哥哥，年纪应该不大，很沉稳的样子，带了一台笔记本电脑，这个好像是标配，提倡无纸化办公吧，我的一切反馈他都会记录在上面，整个过程对于他来说应该是轻松的，但是对于我来说有些窘迫，整个过程对我的评价就是，很多东西用的很熟，但是对于原理掌握的还不够，算是没有达到他们的要求，这也在我的意料之中，毕竟就是来学习的。涉及到的面试内容大概有如下问题： 开源项目源码的阅读情况 动态库加载路径 编译的过程 线程崩溃为什么会导致进程挂掉？一定会挂掉吗？ 加权最短路径 打印过程中出现中断 中断信号怎么处理 怎么理解多态 编译时多态和运行时多态 模板和基础类型的效率比较 gdb调试 为什么先构造基类 析构函数的调用顺序 非阻塞的write什么时候返回 如果连不上服务器会有那些情况 注意wireshark的使用 listen的backlog参数 Y公司 这个公司有自己成熟的产品线，涉及到卡牌、MMORPG等等，同样是在招聘APP上收到面试邀请，但这次招人的是一个SLG游戏组，整个给人的感觉无论是公司的氛围还是项目的情况与我当前公司很像，一共来公司面了两次，第一次两个技术Leader分别进行面试，然后又和HR聊了一下，技术面主要围绕曾经的项目，后来第二次面试跟游戏制作人聊了一下，感觉和之前的公司更像了，当时就打了退堂鼓，最终婉言谢绝了这家公司的Offer，面试主要技术内容： 技能设计 redis缓存 指针用法 二分法思想 项目熟练度 W公司 这个公司是游戏开发中的大厂了，首先是在招聘APP上，HR和我沟通之后要去了简历想要看看，后来收到了面试电话确定了面试时间，面试当天也是早早的来到了公司，这天在周围没有找到吃饭的地方，要饿着肚子了，等待了一会被HR小姐姐带去二楼等了半小时，后来她跑过来告诉我位置错了，确实有点尴尬。 之后我被带去了正确的位置，然后开始了面试过程，面试官是一个小哥哥，整个面试的过程感觉表现的不是很好，有些问题回答的不太完整，但是却从中学习到了很多东西，临走时问了几个面试问题的正解，并且冒昧的问了小哥哥的工作年限，得知才比我大两岁就已经在游戏大厂当主程之后，深感我们之间的差距还很大，同时也激起了我努力学习的意志。 面试后好几天也没有消息，本来我感觉这次面试可能失败了，但是几天后我又收到了该公司的二面邀请，收到邀请时挺高兴的，当时还有另外几家面试，之前已经约好了时间，所以这次二面不得不向后推了几天，因为是第二次去，路线熟悉了很多，又是早早来到公司，本来以为还是技术面，但是交流几个问题之后发现问的都是之前的项目，和人员之间的沟通的问题，后来对方主动说明他是项目负责人，整个聊天过程比较轻松，谈过之后让回去等消息。 第二天收到HR视频面试的邀请，本来想约晚一点回家好好面试，但是因为HR小姐姐还有其他安排，我只得将面试时间提前，在公司旁边找了个安静的地方进行视频面试，主要聊了一下目前的薪资待遇以及项目情况，能够入职的时间等等，整个过程很愉快，并且得知其实是一个工作室在招聘，我问了一些相关的问题，面试结束回到家我仔细考虑了这个机会，第二天又找该项目的负责人了解了项目的详细情况，觉得这是一个很好的学习机会，与目前的工作内容有很强的互补性，可以试一试。 Gitflow使用方法 gcc编译过程 extern和static的作用 多态、虚函数、多继承虚函数 大根堆创建和插入 排序找出接近当前数的较大数 迭代器的理解、迭代器都是指针吗？ 字符编码、unicode、utf8 指针数组、数组指针、函数指针 引用和指针的区别 网络4次挥手、为什么要4次？ 函数阻塞是否占用资源–挂起不占用 Z公司 这个公司不是游戏公司，近两年异常火爆，有专门的游戏部门，但是我面试的职位不是游戏岗位，而是时下非常火的中台岗位，其实是在尝试新的领域。起初是猎头在招聘APP上要了我的简历，然后接到了公司HR小姐姐的电话，约定了面试时间，相互加了微信，面试之前和HR小姐姐交流了不少，知道公司技术面大概有3面，因为心里没底，抱着学习的态度考虑能过两面就行，如果实在太难能过一面也行，作为一个求知者，知道各个公司都需要哪些知识也就有了学习的目标。 可现实总是太残酷，这个面试我算通过了半面，什么叫半面，由于我的“出色”表现，我感觉正常的一轮面试并没有结束就被礼貌的请出来了，因为几个问题之后我也感觉出来了，我之前学的技术和他们开发思想差的有点多，所以出于礼貌，面试官也没说什么，还给出了一些建议，人真的不错，大公司的涵养还是有的。 你开发的最满意的系统 –道具系统 map和hashmap的区别 stl的使用 vector的扩容，是不是线程安全的？ 遍历删除vector元素，迭代器失效 有没有用过redis的有序集合 redis中hash插入的时间复杂度 设计一个红包系统 –评价为原始的面向对象方式，有些过时 给出建议这个红包系统必须要考虑redis、分布式、容灾、备份 建议如果想转向互联网需要准备的很多，可以先看下现有的解决方案 H公司 这个公司的面试机会是猎头推荐的，主要做战争题材的游戏比较多，现在也有卡牌和休闲，本来约的面试时间比较早，但是由于个人原因回了次老家，结果这个面试不得不向后推了，面试当天来到公司，前台居然一个人都没有，之后电话联系到面试官，首先表达了之前改约的歉意开始了面试过程。 面试主要围绕之前的项目进行，对具体的系统实现问的很详细，通过对细节的了解，对我之前的工作内容有很多不理解，感觉有很多内容不符合他的认知，整个过程倒还轻松，没有太多的技术问题，总体感觉不是一路人，很可能走不到一起。 聊了大概一小时，换HR继续聊，还是问了之前项目、期望薪资以及入职时间等等，确定了是卡牌组再招人，问了一些当前公司情况之后，按照流程回去等消息，但个人觉得可能不太合适。 面向对象要求比较高，C+Class的方式不被认可 着重问了一个游戏系统的实现方式（押镖） 面相对象设计技能系统 强调游戏充值实现的重要性，以及可能出现的多种情况 认为只有DBA才有权利修改数据库结构 准备离开出去面试一圈基本确定了新的工作，是时候离开了，先跟带自己入门的兄长道个别，我们两个聊了很久，对于我离开去学习新知识，兄长表示支持，他不仅是我工作上的领路人，同时脾气特别好，平时处理问题也很妥当，一直是我学习的榜样。 紧接着便向老大提出了离职，准备年前离职后去新公司入职，而老大的意思是再等等，年前太仓促了，先看看现在公司的情况，年后回来如果还想走再办离职吧，考虑到还有一段时间的就要放假了，为了更好的完成了交接工作，我答应了老大的请求。 即将离开过年期间考虑了好久，还是准备出去闯一闯，今年春节的新型冠状病毒疫情非常严重，很多公司都推迟了上班时间，虽然2号之后就回来上班了，但是很多同事由于封路的原因都还没回来，离职手续也一直没有办成，年后又找老大聊了一次，毕竟工作了6年，虽然不舍，但是确实该离开了，期待下周的情况能好一些，能顺利办完手续开始新的旅程。 挥挥手再出发 更新于2020年2月15日22:45:51 挥手告别事情办得比较顺利，经过前期的准备，周一便完成了工作交接，上传了交接文档，周二开始办理离职手续，由于新型冠状病毒疫情的原因，公司依旧没有什么人，好在办理离职的人员都在，签字、签字、再签字，成功在下午拿到离职证明，不过唯一遗憾的是，工牌和门禁卡同时上交了，不能给我留个纪念了，毕竟是在身上装了6年的工牌，6年了几乎没有离开过…… 因为很多同事也没来，加之疫情的严重性，散伙饭并没有吃成，前一天下班的时候专门去旁边的簋街转了一圈，发现除了几家仅有的外卖之外，都是黑着灯的，这可是簋街啊，是让人们可以排队等到凌晨2点的簋街，现在居然这样冷冷清清的，找不到吃饭的地方，散伙饭只能作罢。 下班前跟仅有的几个来上班的好友道了别，当然其中还有我那位可敬的兄长，当所有人都在关心你飞的高不高时，只有朋友关心你累不累，兄长就是这样的朋友，临走了还关心地问我社保能不能接上，只因为我之前和他提过一次担心社保断缴的问题。因为很多人还没来上班，剩下的关系好的小伙伴，在我晚上回家后，通过微信开始了与他们的远程云分别。 还看今朝告别了过去的工作，自然要步入新的旅程，为尽量避免人员接触，新的公司在周五为我在线办理了入职手续，两位帮忙办理入职的新同事真的非常友好，整个流程遇到不懂的都会及时解答，这让我非常期待下周一正式工作后的生活，新的旅程即将开始，又要在一个地方生根发芽了~]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>工作</tag>
        <tag>学习</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[利用__declspec(dllexport)和__declspec(dllimport)在Windows平台编写和使用DLL的小例子]]></title>
    <url>%2Fblog%2F2020%2F02%2F05%2F%E5%88%A9%E7%94%A8-declspec-dllexport-%E5%92%8C-declspec-dllimport-%E5%9C%A8Windows%E5%B9%B3%E5%8F%B0%E7%BC%96%E5%86%99%E5%92%8C%E4%BD%BF%E7%94%A8DLL%E7%9A%84%E5%B0%8F%E4%BE%8B%E5%AD%90%2F</url>
    <content type="text"><![CDATA[前言关于 __declspec(dllexport) 和 __declspec(dllimport) 这两个关键字在上大学期间就没见过几次面，直到毕业后在公司项目的代码中又遇到过几次，每次也是绕着走，生怕和它产生什么联系，只知道它和动态链接库 DLL 有关，但是当前这个项目中几乎没有用到自己写的动态链接库，所以我也就心安理得的躲了它这么久。 最近看一些开源项目的源码时又发现了这两个关键字，此时凭借自己掌握的知识和学习方法再来看这两个关键字，发现也没有什么值得害怕的地方，其实简单来说就是 __declspec(dllexport) 是用来说明指定类和函数需要从 DLL 中导出的，而 __declspec(dllimport) 是用来说明指定的类和函数是从DLL中导入的。 说明 __declspec(dllexport) 和 __declspec(dllimport) 只在 Windows 平台才有，用来说明类或函数的导出和导入。 在 Linux 平台上源文件中的所有函数都有一个的visibility属性，默认导出。如果要隐藏所有函数导出，则需要在GCC编译指令中加入 -fvisibility=hidden 参数。 生成 dll 的同时还会生成对应的 lib 文件，一般是一些索引信息，记录了 dll 中函数的入口和位置，这在之前还真的不知道，原来一直以为 lib 只是静态库文件呢。 疑问 为什么要导入导出，直接把代码拿过来一起编译不好吗？ 想要一起编译前提是你得有源代码，如果人家就给你一个动态库或者静态库，你想把源代码放到一起编译的愿望根本实现不了。 为什么要分为静态库和动态库？搞这么麻烦，还要导入导出。 这具体的就要查查他们两者的优缺点了，每种事务的产生必要有其产生的原因，比如静态库，很可能就是一个程序员今天在A工程写了一个读取文件的类，过一段时间又在B工程写了一个读取文件的类，代码都差不多，不久又在C工程中直接把代码复制过来改一改又写了一份，这时想到干脆了写个“静态库”这种东西吧，相同的代码直接封装到库中，哪个工程需要就直接拿过来编译，也不需要再复制代码了。 又比如动态库，前面的静态库解决了代码重复开发和维护的问题，但是读取文件的静态库中的代码在A、B、C三个工程中都存在一份，导致每个可执行程序都很大，可不可以共用一份呢？结果又发明了动态库，在编译时只指定函数的入口地址，运行时才加载动态库，这样就使得可执行程序体积大大缩小。 以上内容纯粹我个人想像的，真正发明静态库和动态库是由于什么原因，大家可以自行去了解… 动态库要比静态库好吗？ 个人感觉合适的才是最好的，不存在动态库要比静态库好的说法，最起码不是全都好，动态库的代码是在可执行程序运行时才载入内存的，在编译过程中仅简单的引用，因此代码体积较小，但是运行时要去加载库会花费一定的时间，执行速度相对会慢一些，总的来说静态库是牺牲了空间换时间，而动态库是牺牲了时间换空间。 .h（头文件） .lib（库文件） .dll（动态链接库文件） 之间的联系和区别 .h 文件是编译时需要的， .lib 是链接时需要的， .dll 是运行时需要的。如果有 .dll 文件，那么 .lib 一般是一些索引信息，记录了 .dll 中函数的入口和位置，.dll 中是函数的具体的执行内容。如果只有 .lib 文件，那么这个 .lib 文件是静态编译出来的，索引和实现都在文件中。 DLL的编写与使用前面说了这么多，其实就是想带大家先了解一下动态链接库 DLL ，接下来开始编写一个DLL并在另一个工程中使用它，前提是你已经会使用开发工具VS，如果不会先查查教程。 测试环境 VS2013随意版（个人感觉这个版本启动能快一点） Win10畅想版（我也不知道啥版本） 编写DLL编写 DLL 的方法不知一种，这里只简单介绍一种，对于直接写 .def 文件的方法这里不会展开，尽量依靠开发工具一步步向下执行就好，其实当你理解了开发工具的是怎样工作的，一切就没有那么神秘了，有些步骤直接修改配置文件也是可以实现的，只不过开发工具给我们提供了界面，操作起来更加方便了而已，下面我们开始编写： 打开VS新建项目，选择Win32项目，项目名称GenDLL，解决方案名称DLLExample，点击确定： 直接下一步，应用程序类型选择DLL，点击完成： 项目会自动创建一个GenDLL.cpp文件，我们在手动创建一个GenDLL.h文件，两个文件中编写如下代码： 123456789// GenDLL.h#ifdef GENDLL_EXPORTS#define TEST_API __declspec(dllexport)#else#define TEST_API __declspec(dllimport)#endifTEST_API int add(int a, int b); 123456789// GenDLL.cpp : 定义 DLL 应用程序的导出函数。#include "stdafx.h"#include "GenDLL.h"TEST_API int add(int a, int b)&#123; return a + b;&#125; 这段代码中有一个 TEST_API 是我在头文件中自定义的，当存在GENDLL_EXPORTS宏时， TEST_API 代表 __declspec(dllexport) 也就是导出函数，当不存在GENDLL_EXPORTS宏时， TEST_API 代表 __declspec(dllimport) 表示导入函数，而 GENDLL_EXPORTS 这个宏是与项目名相关的，自动生成的宏，在 DLL 项目中存在格式为 “大写项目名_EXPORTS”。 也就是说同一个头文件中计算加法的函数 add 在 GenDLL 这个生成 DLL 的项目中表示导出函数，在其他使用这个 DLL 的项目中表示导入函数。 编译看输出发现有GenDLL.lib和GenDLL.dll两个文件： 123456781&gt;------ 已启动生成: 项目: GenDLL, 配置: Debug Win32 ------1&gt; stdafx.cpp1&gt; dllmain.cpp1&gt; GenDLL.cpp1&gt; 正在创建库 c:\users\administrator\documents\visual studio 2013\Projects\DLLExample\Debug\GenDLL.lib 和对象 c:\users\administrator\documents\visual studio 2013\Projects\DLLExample\Debug\GenDLL.exp1&gt; GenDLL.vcxproj -&gt; c:\users\administrator\documents\visual studio 2013\Projects\DLLExample\Debug\GenDLL.dll========== 生成: 成功 1 个，失败 0 个，最新 0 个，跳过 0 个 ========== 使用DLL 在DLLExample这个解决方案下添加一个新项目，命名为UseDLL，然后点击确定： 直接下一步，应用程序类型选择“控制台应用程序”，点击完成： 在文件UseDLL.cpp文件中引用之前GenDLL项目的头文件，编写使用 add 函数的代码： 123456789101112// UseDLL.cpp : 定义控制台应用程序的入口点。#include "stdafx.h"#include &lt;iostream&gt;#include "../GenDLL/GenDLL.h"int _tmain(int argc, _TCHAR* argv[])&#123; std::cout &lt;&lt; "100+1=" &lt;&lt; add(100, 1) &lt;&lt; std::endl; system("pause"); return 0;&#125; 编译代码发现报错，提示有一个无法解析的外部命令： 1234567891&gt;------ 已启动生成: 项目: UseDLL, 配置: Debug Win32 ------1&gt; UseDLL.cpp1&gt; stdafx.cpp1&gt; 正在生成代码...1&gt;UseDLL.obj : error LNK2019: 无法解析的外部符号 &quot;__declspec(dllimport) int __cdecl add(int,int)&quot; (__imp_?add@@YAHHH@Z)，该符号在函数 _wmain 中被引用1&gt;c:\users\administrator\documents\visual studio 2013\Projects\DLLExample\Debug\UseDLL.exe : fatal error LNK1120: 1 个无法解析的外部命令========== 生成: 成功 0 个，失败 1 个，最新 0 个，跳过 0 个 ========== 提示这个错误本意就是说链接没有找到函数实现，链接需要什么文件，前面提到需要lib文件，那么我们设置一下，让UseDLL工程能够找到GenDLL.lib文件。 打开UseDLL工程的属性，在“配置属性-&gt;链接器-&gt;输入-&gt;附加依赖项”中添加GenDLL.lib: 然后在“配置属性-&gt;链接器-&gt;常规-&gt;附加库目录”中添加GenDLL.lib所在路径“../Debug”即可成功编译： 直接运行就可以看到调用DLL的结果，因为这两个工程在同一解决方案下，所以最终UseDLL.exe和GenDLL.dll在同一目录下，这样不会报找不到DLL的错误 如果是不同的目录就会像下图那样，提示找不到GenDLL.dll，只要把GenDLL.dll复制到和UseDLL.exe相同目录即可： 加载DLL上面提到当运行程序找不到 DLL时可以把 DLL 放到可执行程序程序的目录，有时运行大型软件找不到 DLL 时，我们也会下载一个放到System32目录，其实程序在加载 DLL 的时候是会按照一定顺序的，这些目录包括：包含exe文件的目录、进程的当前工作目录、Windows系统目录、Windows目录、Path环境变量中的一系列目录等等，这些目录的搜索顺序还会受到安全 DLL 搜索模式是否启用的影响。 所以说如果不是对DLL 放置的位置有特殊要求，那么直接放在exe文件所在的目录就好了，一般也是会优先搜索的。 总结 Windows上才有 __declspec(dllexport) 和 __declspec(dllimport) .h 文件是编译时需要的， .lib 是链接时需要的， .dll 是运行时需要的 程序运行时加载 DLL 一般优先从exe文件的所在目录优先加载]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>dllexport</tag>
        <tag>dllimport</tag>
        <tag>DLL</tag>
        <tag>Windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2020年的春节，我们一起抗击新型冠状病毒]]></title>
    <url>%2Fblog%2F2020%2F01%2F29%2F2020%E5%B9%B4%E7%9A%84%E6%98%A5%E8%8A%82%EF%BC%8C%E6%88%91%E4%BB%AC%E4%B8%80%E8%B5%B7%E6%8A%97%E5%87%BB%E6%96%B0%E5%9E%8B%E5%86%A0%E7%8A%B6%E7%97%85%E6%AF%92%2F</url>
    <content type="text"><![CDATA[终于到了什么都不用做，在家躺着就能为国家做贡献的时候了！ 前言新型冠状病毒，一个看起来陌生的词语，使得原本最热闹的春季变得异常冷清，随着疫情范围的扩大，这个本来陌生的词语一次次冲击着人们的认知。这个病毒到底是什么，为什么扩散起来这么凶猛？ 2019-nCoV新型冠状病毒，在各种媒体上还会以“2019-nCoV”的名字出现，人感染了冠状病毒后常见体征有呼吸道症状、发热、咳嗽、气促和呼吸困难等。在较严重病例中，感染可导致肺炎、严重急性呼吸综合征、肾衰竭，甚至死亡。 引用百度百科中文字，对其描述为： 2019新型冠状病毒，即“2019-nCoV”，因2019年武汉病毒性肺炎病例而被发现，2020年1月12日被世界卫生组织命名。冠状病毒是一个大型病毒家族，已知可引起感冒以及中东呼吸综合征（MERS）和严重急性呼吸综合征（SARS）等较严重疾病。新型冠状病毒是以前从未在人体中发现的冠状病毒新毒株。 目前掌握的情况： 传染源: 野生动物，可能为中华菊头蝠 传播途径: 经呼吸道飞沫传播，亦可通过接触传播 易感人群: 人群普遍易感。老年人及有基础疾病者感染后病情较重，儿童及婴幼儿也有发病 潜伏期: 1 ~ 14 天，平均 10 天，潜伏期内存在传染性 2019-nCoV与SARS这个新型冠状病毒导致的肺炎传播速度如此之快，很多人拿它和03年的非典（SARS）相比，确实这两个病毒有很多相似的地方，同样都是新型冠状病毒，同样都会引起肺炎，甚至连发生的时间都非常相似，非典是02年11月出现病例，而2019-nCoV出现的时间大概是12月。 那它们两个这么像，能不能用相同的方法和药物治疗呢？目前来看是办不到的，两者虽然很相似，但是毕竟都是新型病毒，我们知道一种病毒变异后原来的药物很可能就起不到作用了，更何况这是两种不同的病毒，但是也有好的一面，毕竟在抗击非典时我们积累了宝贵的经验，对于防控类似的疾病能够提供很大的帮助。 比如当年非典时期,北京市在小汤山就建立起了一座封闭式的医院,就是小汤山医院，而武汉参照北京“小汤山模式” 神速建造了“火神山医院”，从开工到投入使用预计会花费10天左右，这个速度也是令人惊叹了，没有之前的经验积累是很难办到的。 为什么传播的这么快其实一开始我们都没有重视这场战斗，导致这个新型冠状病毒钻了空子，传播速度之快达到了让人心惊的地步，感觉主要有下面几方面的原因吧： 华南海鲜市场存在大量新型冠状病毒，源头上就很广 起初没有得到足够重视，认为不存在人传人的可能，导致接触者甚至医务人员被感染 病毒在潜伏期也有可能传播，这是与非典不同的，导致一些携带病毒的人在无意识的情况下成了传染源 正好赶上春节返乡高峰，而武汉作为九省通衢的枢纽，反倒为病毒散播提供了便捷的条件，扩散范围很快就达到了全国 目前的形式新型冠状病毒疫情已经开始进入初期扩散阶段，并呈上升趋势，但是应对措施也已经铺开，延长假期，控制人员流动，积极研制疫苗，组织医疗救援队赶赴武汉等等，相信不久疫情就能够控制住。 本来春节是一年中最忙碌的日子，今年却异常的冷清了，为了大家的健康，今年周围的人都取消了拜年聚会活动，村口也安排了人专门劝返探亲人员，因为这样我们反而多了一些陪伴家人的时间，而我居然有时间来码字了，往年不是在这喝酒就是在那聚会的，现在这样安安静静的待在家里感觉也不错。 引用网上一段顺口溜，写的不错与大家分享： 国家有难，咱不添乱。坐在家里，就是贡献。亲戚不走，来年还有。朋友不聚，回头再叙。利人利己，互不传染。吃好睡好，悠闲过年。坚持几天，你我平安。 新型冠状病毒最新消息目前新型冠状病毒处于蔓延的趋势，各种消息满天飞，真真假假难以辨认，所以我单独建了一个项目用来收集最新的消息，尽可能保证消息的准确，其中包含最新的疫情地图、最新疫情新闻、以及正规的捐助渠道等等，有兴趣的小伙伴可以一起舔砖加瓦。 抗击2019-nCoV最新情报-ChineseVictory 更新于2020年1月29日21:25:30 今天看到一个同类型的记录武汉抗击新型冠状病毒的项目，已经有3000多的star了，我们两个项目创建的时间很接近，再看看我的项目情况有点惨淡啊！贴个图，大家感兴趣可以来逛逛，不过人家那个项目确实很规范，我还有很多东西可以学习。 从star数为0来看确实惨淡，再放一遍项目地址-ChineseVictory，感兴趣可以来看看;)]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>生活</tag>
        <tag>病毒</tag>
        <tag>武汉</tag>
        <tag>春节</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[2019！一份迟到的年终总结]]></title>
    <url>%2Fblog%2F2020%2F01%2F03%2F2019%EF%BC%81%E4%B8%80%E4%BB%BD%E8%BF%9F%E5%88%B0%E7%9A%84%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93%2F</url>
    <content type="text"><![CDATA[长大了就要为小时候吹过的牛而奋斗~ 前言2019即将过去，瞅一眼桌面右下角的时间，距离2020年还有63分51秒，这是我第一次这么强烈地想在一年结束之际写下点什么。本身是一个喜欢收集和总结知识的性格，但对自己的人生却少有总结，一方面感觉没什么可写，一方面也确实对自己太过宽容。 每年年初总是在朋友圈和各大平台浏览着一个个新年展望，而每年年末总是在相同的位置看着他们把年初展望的日期向后推一年，这是个段子，同样也是事实，很多人的生活过得平平淡淡，我们都是人群中的大多数，平庸而碌碌无为。 迟到之所以在年终总结前冠以“迟到”二字，是因为我突然意识到这份总结早就应该做了，对于参加工作已经6年的我来说，刚刚意识到需要做年终总结确实有些不应该。作为普通人的我来说记忆能力有限，小时候吹过的牛早就忘了，如果能及时的做年终总结，或许我还可以为了去年吹过的牛奋斗一把，可是我没有，我连去年的想法也忘得差不多了，此时此刻才刚刚意识到曾经的失误。 得与失既然是总结就要回想一下在过去的一年中我得到了什么，失去了什么，而在新的一年中我想获得什么，回想即将过去的2019年发现，今年确实发生了很多往年没有发生过的事情，这可能也是我突然非常想写点东西，记录下来的原因。 回顾2019这一年发生的事情太多，相互之间纠葛不断，不过还是从最简单的分类：工作、学习、生活这三个方面来聊聊吧，虽然很多事情不能完全归为某一类，但是贴一个标签总能清楚一点。 工作上依旧是踏踏实实，勤勤恳恳的一年，做了整整一年的游戏开发几乎颗粒无收，这已经不是第一年没有收成了，有时候真的有点后悔为了工作侵占了陪家人的时间，特别是看不到回报的时候。 从年初就开始做收尾工作，几次上线几次调整，不知不觉我们又过了一个年，在我心中这款游戏的开发工作已经接近尾声，这样的状态不应该再持续下去了。 学习上作为一个好学的程序猿，深知“学如逆水行舟，不进则退”的道理，今年在CSDN上写了42篇原创博客，算是高产的一年了，也终于迈进了总排名前一万名的大关，截个图记录一下： 有点小遗憾，访问量差几百才到50万，不过新年第一天应该差不多啦，不仅仅是知识的总结，由于加了CSDN的博客群，今年还认识了许多有意思的小伙伴，比如：铁柱同学（一个冒充小白的大佬）、第三女神（粉丝炸裂式增长）、TRHX（网站做的特漂亮），还有很多小伙伴就不一一列举啦。 关于读书，我只喜欢读纸质的书籍，喜欢那种在书上乱画，随便记笔记的方式，当然有一点不好，就是想查一个知识点，知道是哪一本书，不得不翻一翻才能找到，好希望纸质书能有个搜索按钮，不过这个问题找个电子版就能解决了。 今年一共读了7本关于编程技术的书籍： Redis入门指南(第2版) 图解HTTP 自动化平台测试开发 ——Python测试开发实践 图解密码技术 图解TCP/IP 漫画算法 ——小灰的算法之旅 MySQL必知必会 推荐这本《小灰的算法之旅》，可以把学知识当做一种乐趣，绝对能达到事半功倍的效果。 附上 我的完整书单 生活上今年在生活上发生的事情好像比之前几年加起来都要多，年中得到了一个特别可爱的宝宝，为了解决宝宝上学问题，之前从没考虑买房的我到了售楼处就买了一套，几乎都没挑就定下了，当然这么冲动的行为必须要付出代价，因此背上了近百万的债务，从此变成了一个给银行打工按月还款的房奴。 说实话宝宝刚出生时并不好看，可是越长越可爱，现在已经7个月大了，开始会爬了，真想不去上班一直陪她玩，有时候确实有一种为了她放弃全世界的冲动，宝宝今天有点发烧，凌晨一点了还没有睡，陪我一起跨年总结了，好在这会儿烧退了一些，快点好起来吧！ 2019年生活上发生的另外一件很重要的事情就是投资，入市有风险，投资需谨慎，这不是一句玩笑话，今年年初股市行情一片大好，正当我们陶醉其中的时候，贸易大棒直接挥下，给准备一飞冲天的行情当头一棒，还好跑得快，不然年初那波行情的盈利在贸易战初期就会飞烟灭了。 年初的基金行情也异常火爆，在支付宝买了点指数基金，贸易战开始之后就抛掉了，并没有多少盈利： 说完赚钱的接下来就是赔钱的，P2P暴雷给我炸的遍体鳞伤，从5月份出事到现在毫无音信，真应了那句话，你看上了人家的高息，而人家看上的是你的本金，P2P今年可谓损失惨重。 因为赚钱心切，今年还投资了一点数字货币，结果因爆仓而结束，每次都是到了爆仓点位迅速反弹，好像在提示我压根就不是我应该玩的，不过从这次投资来看，我才明白为什么有钱的人越来越有钱，而穷人一辈子很难翻身。 一句话，穷人没有东山再起的资本和承担风险的能力，举个例子：我和一个富有的人同时买一只数字货币，而我们都只花了500块来买相同的点位，不同的是富有的人保证金更多一些，这样当行情来到我的爆仓点位时，我和富有的人损失相同的钱，但是我爆仓了，而他没有，待到行情迅速反弹，他却赚的盆满钵满。 或者换一种情况，我们两个同时爆仓，他立马在低位投入2倍的钱，迅速赚回损失，而我只能眼睁睁的看着行情反弹却没有投资的砝码，忽然觉得T+1好像真的是帮助我们这些散户的。 展望20202019已经过去，面对着已经到来的2020年，我们需要踏上新的征程，我还没有适应给自己定出量化的目标，不过可以暂时写下大致的方向，也算是给自己一个时刻的提醒。 对工作新的一年不能再碌碌无为，真的需要去闯一闯了，最近和一些互联网公司的员工沟通过，仿佛我们不是生活在一个地球，外面的世界真的很大，外面的机会真的很多，是时候出去看看了，浏览一下世界的另一面，当然，脚踏实地的工作风格不能丢弃。 对学习经过一段时间的与大牛们的沟通，我渐渐的明白了自己的差距，也大致了解了需要重点学习哪些知识，所以简单列举如下： 巩固基础知识，对于一些函数不仅要会用，还应该花时间探究实现的方式，往深处挖掘，比如listen函数backlog参数意义。 阅读 redis 源码，这是很多人都提到的一点，适当可以看一下 STL 源码 看两本有关分布式知识的图书 对生活 尽最大可能陪陪家人 投资达到2019的水平（只看赚的，不看赔的） 总结接触了一些大牛之后备受打击，可是以往的岁月已经无法改变，只要认清了自己从现在开始就不晚，2019悄然离开，2020已经隆重登场！加油~]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>总结</tag>
        <tag>工作</tag>
        <tag>学习</tag>
        <tag>生活</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[单继承、多继承、菱形继承的虚函数表]]></title>
    <url>%2Fblog%2F2020%2F01%2F03%2F%E5%8D%95%E7%BB%A7%E6%89%BF%E3%80%81%E5%A4%9A%E7%BB%A7%E6%89%BF%E3%80%81%E8%8F%B1%E5%BD%A2%E7%BB%A7%E6%89%BF%E7%9A%84%E8%99%9A%E5%87%BD%E6%95%B0%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[前言最近被问到一个关于多继承虚函数表的问题，当时回答是可能存在多个虚函数表，应该是顺序排列的，但具体怎么排列还是有些疑惑的，回答的时候到有点儿心虚。之后查了资料，做了简单的实验，可以确定的是对于继承了多个含有虚函数基类的子类来说，指向虚函数表的指针应该不止一个。 问题虚函数表的问题是从C++多态的概念引出的，要想实现多态有3个条件： 存在继承：没有继承就没有多态（运行时），在多态中必须存在有继承关系的父类和子类。 重写函数：父类中需要定义带有 virtual 关键字的函数，而在子类中重写一个名字和参数与父类中定义完全相同的函数。 向上转型：将父类的指针和引用指向子类的对象。 满足以上三个条件，当使用父类的指针调用带有 virtual 关键字的函数时，就会产生多态行为。 实现这种多态表现的核心内容就是虚函数表，对于带有 virtual 关键字的函数地址会被放入一个表格，而在类中会有一个指向虚函数表的指针指向这个表格，表明这个表格属于类的一部分。 对于父类来说，这个表格中都是自己类的虚函数，而对于子类来说，首先这个虚函数表包含父类中所有的虚函数，当子类重写某个虚函数时就会用子类重写后的函数地址替换原来父类中定义的函数地址，同时在子类的虚函数表中还会包含子类独有的虚函数。 由此可见虚函数表的不同和复杂性还是体现在子类上，所以之后会分别测试单继承、多继承、菱形继承三种情况下虚函数表的不同，主要看一下虚函数表的个数和内存布局情况。 测试环境首先来说明一下测试环境，测试工具是VS2013，对于int *p; sizeof(p)的结果是4，说明编译环境是32位的，这个对后面查看内存结构非常关键。 开始测试使用VS2013查看类的内存布局非常方便，因为类的大小在编译期间就已经确定了，不用运行就可以通过添加编译选项知道类的大小和布局，而指向虚函数表的指针也会占用类的大小，如果说编译的时候确定了类的大小，那从侧面也说明了在编译期间虚函数表实际上也确定了。 使用VS2013查看类的布局时，可以在项目的属性页：“配置属性”–&gt;“C/C++”–&gt;“命令行”中输入以下任意一个命令， /d1reportAllClassLayout ：这个选项可以在VS的输出窗口显示所有相关联的类结构，因为一些外部类也会显示，最终的内容会非常多，需要自己辨别有用的信息。 /d1reportSingleClassLayoutXXX ：这个选项只会在输出窗口显示指定的类结构，只需要将XXX替换成想显示的类的名字即可，缺点就是无法同时显示多个想查看的类。 无虚函数简单类结构在查看虚函数表的结构之前，先使用之前的编译参数来查看一下简单的类结构，排除虚函数的干扰，能更清楚的了解类成员在类中的布局情况，有一点需要提一下，成员变量会占用类的大小，但是成员函数不会，如果有虚函数，所有的虚函数会被放入一个表格，而在类中放置一个指向虚函数表的指针，来看一下简单代码： 123456789101112131415class CBase&#123;public: void func() &#123;&#125;public: int m_var1;&#125;;class CDerived : public CBase&#123;public: void func() &#123;&#125;public: int m_var2;&#125;; 编译输出的类的内存布局为： 1234567891011121&gt; class CBase size(4):1&gt; +---1&gt; 0 | m_var11&gt; +---1&gt;1&gt; class CDerived size(8):1&gt; +---1&gt; | +--- (base class CBase)1&gt; 0 | | m_var11&gt; | +---1&gt; 4 | m_var21&gt; +--- 从上面的输出内容来看，很清楚的可以看到基类 CBase 的大小 size(4) 占用4个字节，只有一个成员变量 m_var1，在类中偏移量为0的位置，而派生类 CDerived 占用8个字节大小，第一个成员继承自基类 CBase 的 m_var1，在类中偏移量为0的位置，还有一个子类独有的成员变量 m_var2，在类中偏移量为4的位置。 掌握着这种简单类的查看类结构的方法，接下来开始看一下包含虚函数的类的内存布局。 包含虚函数的类结构查看包含虚函数的类结构相对来说麻烦一点，先来说两个符号，免得一会看见结构发懵，vfptr 表示类中指向虚函数表的指针，通常放在类的起始位置，比成员变量的位置都要靠前， vftable 表示类中引用的虚函数表，在具体分析是还有有一些修饰符，用来表明是谁的虚函数表。 单继承这种情况的下的子类的虚函数表很简单，在该子类的内存布局上，最开始的位置保存了一个指向虚函数表的指针，虚函数表中包含了从父类继承的虚函数，当子类中重写父类虚函数时会将虚函数表中对应的函数地址替换，最后添加上自己独有的虚函数地址，下面上代码分析一下： 12345678910111213141516171819class CBase&#123;public: void func0() &#123;&#125; virtual void func1() &#123;&#125; virtual void func2() &#123;&#125;public: int m_var1;&#125;;class CDerived : public CBase&#123;public: virtual void func2() &#123;&#125; virtual void func3() &#123;&#125; void func4() &#123;&#125;public: int m_var2;&#125;; 上面这两个类的内存布局情况如下： 123456789101112131415161718192021222324252627282930313233341&gt; class CBase size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | m_var11&gt; +---1&gt;1&gt; CBase::$vftable@:1&gt; | &amp;CBase_meta1&gt; | 01&gt; 0 | &amp;CBase::func11&gt; 1 | &amp;CBase::func21&gt;1&gt; CBase::func1 this adjustor: 01&gt; CBase::func2 this adjustor: 01&gt;1&gt;1&gt; class CDerived size(12):1&gt; +---1&gt; | +--- (base class CBase)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | m_var11&gt; | +---1&gt; 8 | m_var21&gt; +---1&gt;1&gt; CDerived::$vftable@:1&gt; | &amp;CDerived_meta1&gt; | 01&gt; 0 | &amp;CBase::func11&gt; 1 | &amp;CDerived::func21&gt; 2 | &amp;CDerived::func31&gt;1&gt; CDerived::func2 this adjustor: 01&gt; CDerived::func3 this adjustor: 0 看起来是不是比没有虚函数时复杂多了，不过不要着急，从上到下慢慢分析就好了，这次的基类 CBase 大小是8个字节，首先是{vfptr}这个指向虚函数表的指针，在类中的偏移量是0，接下来是成员变量 m_var1，在类中偏移量是4。 然后是 CBase::$vftable@ 表示基类 CBase 的虚函数表，其中第一行 &amp;CBase_meta 看起来怪怪的，这里我们不展开（因为我也没弄太懂），应该是和虚函数表相关的元数据，第二行是一个0，看起来是一个偏移量，这里没有偏移，当出现偏移时我们再试着分析（相信我，马上就会出现），第三行内容 &amp;CBase::func1 是自己类的虚函数，前面有一个0，应该是指该虚函数在虚函数表中索引，第四行也是相同的情况。 接下来出现了两行非常相似的内容，看一下CBase::func1 this adjustor: 0，这句代码中的关键是 adjustor，其实有是一个偏移量，据说涉及到thunk技术，据说“thunk其实就是一条汇编指令，操作码是0xe9，就是jmp，后面紧跟操作数”，这里我们就不展开了，如果后面弄明白了可以单独写一篇总结，到此为止基类的内存结构就分析完了。 继续看派生类 CDerived，它的大小是12个字节，内部结构首先是 {vfptr} 一个指向虚函数表的指针，偏移量为0，m_var1 是从父类继承的成员变量，偏移量为4，而 m_var2 是自己类独有的成员变量，偏移量是8。 然后看派生类对应的虚函数表 CDerived::$vftable@，跳过前两行直接看一下后面几个函数，发现只有 func1 是基类的，而函数 func2 和 func3 都是派生类的，出现这种情况的原因是子类重写了函数 func2 和 func3 ，所以用重写后的函数地址替换了从基类继承的虚函数，造成了目前看到的状况。 最后又出现了两行 adjustor，很奇怪为什么 func1 函数没有 adjustor，貌似这个 adjustor 只对当前类有效，先留个疑问，接下来看一下多继承。 多继承当多个父类中都包含虚函数的时候，和子类关联的虚函数表就不止一个了，这个情况是可以通过使用sizeof(子类)来简单验证的： 这一部分是在没有VS的情况下预先写下的，本来考虑使用VS展开布局后，这一段就没有什么必要了，但是后来想想还是留着吧，因为这一段使用的g++编译器，64位环境，每个指针占用8个字节，通过不同的环境调试，更加可以证明，多继承下的多个虚函数表的存在性： 1234567class W&#123;public: long n;public: void func()&#123;&#125;&#125;; 对于这样的一个简单类，sizeof(W) = 8，类的大小等于成员变量的大小。 123456789101112131415class W1&#123;public: long n1;public: virtual void func1()&#123;&#125;&#125;;class W2&#123;public: long n2;public: virtual void func2()&#123;&#125;&#125;; 对于上面这两个简单的包含虚函数的类，sizeof(W1) = 16，sizeof(W2) = 16，因为每个类都除了一个 long 类型的成员变量以外，还包含了指向虚函数的一个指针，所以类的大小是16个字节。 1234567class WW : public W1, public W2&#123;public: long nn;public: virtual void func()&#123;&#125;&#125;; 而继承了 W1 和 W2 这两个父类的子类 WW 在继承了两个成员变量 n1 和 n2 之外，还有自己的成员变量 nn，三个变量占用字节24个，而计算类 WW 的的大小 sizeof(W1) = 40，也就是说除了成员变量24个字节，还剩余了16个字节的空间没有着落，我们知道它至少包含一个指向虚函数表的指针，占用8个字节的大小，还剩8个字节没有找到用处，从此处分析应该还有一个指向虚函数表的指针，具体的情况可以看一下内存分布。 接下来和单继承的分析方法一样，写代码编译查看布局： 123456789101112131415161718192021222324252627282930313233class CBase0&#123;public: void func0() &#123;&#125; virtual void func1() &#123;&#125; virtual void func2() &#123;&#125; virtual void func3() &#123;&#125;public: int m_var0;&#125;;class CBase1&#123;public: void func0() &#123;&#125; virtual void func2() &#123;&#125; virtual void func3() &#123;&#125; virtual void func4() &#123;&#125;public: int m_var1;&#125;;class CDerived : public CBase0, public CBase1&#123;public: virtual void func1() &#123;&#125; virtual void func2() &#123;&#125; virtual void func4() &#123;&#125; virtual void func5() &#123;&#125; void func6() &#123;&#125;public: int m_var2;&#125;; 上面3个类描述了一个简单的多继承的情况，之所以写这么多函数就是构建一种，既有虚函数覆盖，又有单独不被覆盖的情况，下面展示了这段代码的内存布局。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566671&gt; class CBase0 size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | m_var01&gt; +---1&gt;1&gt; CBase0::$vftable@:1&gt; | &amp;CBase0_meta1&gt; | 01&gt; 0 | &amp;CBase0::func11&gt; 1 | &amp;CBase0::func21&gt; 2 | &amp;CBase0::func31&gt;1&gt; CBase0::func1 this adjustor: 01&gt; CBase0::func2 this adjustor: 01&gt; CBase0::func3 this adjustor: 01&gt;1&gt;1&gt; class CBase1 size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | m_var11&gt; +---1&gt;1&gt; CBase1::$vftable@:1&gt; | &amp;CBase1_meta1&gt; | 01&gt; 0 | &amp;CBase1::func21&gt; 1 | &amp;CBase1::func31&gt; 2 | &amp;CBase1::func41&gt;1&gt; CBase1::func2 this adjustor: 01&gt; CBase1::func3 this adjustor: 01&gt; CBase1::func4 this adjustor: 01&gt;1&gt;1&gt; class CDerived size(20):1&gt; +---1&gt; | +--- (base class CBase0)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | m_var01&gt; | +---1&gt; | +--- (base class CBase1)1&gt; 8 | | &#123;vfptr&#125;1&gt; 12 | | m_var11&gt; | +---1&gt; 16 | m_var21&gt; +---1&gt;1&gt; CDerived::$vftable@CBase0@:1&gt; | &amp;CDerived_meta1&gt; | 01&gt; 0 | &amp;CDerived::func11&gt; 1 | &amp;CDerived::func21&gt; 2 | &amp;CBase0::func31&gt; 3 | &amp;CDerived::func51&gt;1&gt; CDerived::$vftable@CBase1@:1&gt; | -81&gt; 0 | &amp;thunk: this-=8; goto CDerived::func21&gt; 1 | &amp;CBase1::func31&gt; 2 | &amp;CDerived::func41&gt;1&gt; CDerived::func1 this adjustor: 01&gt; CDerived::func2 this adjustor: 01&gt; CDerived::func4 this adjustor: 81&gt; CDerived::func5 this adjustor: 0 内容很多，前面两个基类 CBase0 和 CBase1 的布局很简单，参照之前的分析很容易看懂，直接从派生类看起吧。 我们发现派生类 CDerived 中确实有两个指向虚函数表的指针，接下来看一下这两个虚函数表，这个虚函数表和前面遇到的格式一样，除了第一行的元数据，第二行的诡异偏移量0，剩下的虚函数指针有的是从基类继承来的，有的是被当前派生类覆盖的，还有派生类自己独有的。 而第二个虚函数表就有点意思了，首先是少了 &amp;CDerived_meta 这一行，然后偏移量终于不是0了，而是-8，从派生类 CDerived 的内存布局上来看，以下开始大胆假设，至于小心求证的部分放到以后来做（看自己的进步状态了）。 第二个指向虚函数表的指针是不是距离类的起始偏移量是8，我猜这个-8的意思就是指的这个偏移量，这个值有可能被后面使用，第二行出现了 &amp;thunk: this-=8; goto CDerived::func2，其中包含 thunk 字样，表示这个 func2 不归我管，你去-8偏移量的那个虚函数表里找一找。 还有一点你有没有发现 func5 这个函数只在第一个虚函数表中出现，而没有出现在第二个虚函数表中，这也是一个规则，自己独有的虚函数放到第一个虚函数表中，这可能也是为什么只有第一个虚函数表包含元数据行。 最后一点，我们发现对于函数 func4 来说 adjustor 终于不是0了，而值变成了8，仿佛在说这个虚函数只在偏移量的为8的位置。 菱形继承对于这一部分，并没有太多新的内容，只是简单的菱形继承中，最初的基类在最终的子类中会包含两份，而虚函数的样子并没有太大的不同，接下来简单看一下代码和对应的内存布局即可，因为菱形继承并不被提倡，所以也不用花太多时间来分析这个问题。 123456789101112131415161718192021222324252627282930313233343536class CSuper&#123;public: virtual void func0() &#123;&#125; virtual void func1() &#123;&#125;public: int m_var;&#125;;class CBase0 : public CSuper&#123;public: virtual void func1() &#123;&#125; virtual void func2() &#123;&#125;public: int m_var0;&#125;;class CBase1 : public CSuper&#123;public: virtual void func1() &#123;&#125; virtual void func3() &#123;&#125;public: int m_var1;&#125;;class CDerived : public CBase0, public CBase1&#123;public: virtual void func1() &#123;&#125; virtual void func3() &#123;&#125; virtual void func4() &#123;&#125;public: int m_var2;&#125;; 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091921&gt; class CSuper size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | m_var1&gt; +---1&gt;1&gt; CSuper::$vftable@:1&gt; | &amp;CSuper_meta1&gt; | 01&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CSuper::func11&gt;1&gt; CSuper::func0 this adjustor: 01&gt; CSuper::func1 this adjustor: 01&gt;1&gt;1&gt; class CBase0 size(12):1&gt; +---1&gt; | +--- (base class CSuper)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | m_var1&gt; | +---1&gt; 8 | m_var01&gt; +---1&gt;1&gt; CBase0::$vftable@:1&gt; | &amp;CBase0_meta1&gt; | 01&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CBase0::func11&gt; 2 | &amp;CBase0::func21&gt;1&gt; CBase0::func1 this adjustor: 01&gt; CBase0::func2 this adjustor: 01&gt;1&gt;1&gt; class CBase1 size(12):1&gt; +---1&gt; | +--- (base class CSuper)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | m_var1&gt; | +---1&gt; 8 | m_var11&gt; +---1&gt;1&gt; CBase1::$vftable@:1&gt; | &amp;CBase1_meta1&gt; | 01&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CBase1::func11&gt; 2 | &amp;CBase1::func31&gt;1&gt; CBase1::func1 this adjustor: 01&gt; CBase1::func3 this adjustor: 01&gt;1&gt;1&gt; class CDerived size(28):1&gt; +---1&gt; | +--- (base class CBase0)1&gt; | | +--- (base class CSuper)1&gt; 0 | | | &#123;vfptr&#125;1&gt; 4 | | | m_var1&gt; | | +---1&gt; 8 | | m_var01&gt; | +---1&gt; | +--- (base class CBase1)1&gt; | | +--- (base class CSuper)1&gt; 12 | | | &#123;vfptr&#125;1&gt; 16 | | | m_var1&gt; | | +---1&gt; 20 | | m_var11&gt; | +---1&gt; 24 | m_var21&gt; +---1&gt;1&gt; CDerived::$vftable@CBase0@:1&gt; | &amp;CDerived_meta1&gt; | 01&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CDerived::func11&gt; 2 | &amp;CBase0::func21&gt; 3 | &amp;CDerived::func41&gt;1&gt; CDerived::$vftable@CBase1@:1&gt; | -121&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;thunk: this-=12; goto CDerived::func11&gt; 2 | &amp;CDerived::func31&gt;1&gt; CDerived::func1 this adjustor: 01&gt; CDerived::func3 this adjustor: 121&gt; CDerived::func4 this adjustor: 0 虚继承解决菱形继承的一个常用的办法就是改为虚继承，实际上虚继承中就是将从最基类中继承的公共部分提取出来放在最子类的末尾，然后在提取之前的位置用一个叫做vbptr的指针指向这里。 之前看到过一种说法： 虚继承内部实现也相当复杂，似乎破坏了OO的纯洁性 至于复杂不复杂，看看后面的内存布局就很清楚了，那是相当复杂，其中出现了各种偏移，简单了解下就行了，如果不是维护老代码，谁现在还写这样的结构。 123456789101112131415161718192021222324252627282930313233343536class CSuper&#123;public: virtual void func0() &#123;&#125; virtual void func1() &#123;&#125;public: int m_var;&#125;;class CBase0 : virtual public CSuper&#123;public: virtual void func1() &#123;&#125; virtual void func2() &#123;&#125;public: int m_var0;&#125;;class CBase1 : virtual public CSuper&#123;public: virtual void func1() &#123;&#125; virtual void func3() &#123;&#125;public: int m_var1;&#125;;class CDerived : public CBase0, public CBase1&#123;public: virtual void func1() &#123;&#125; virtual void func3() &#123;&#125; virtual void func4() &#123;&#125;public: int m_var2;&#125;; 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281&gt; class CSuper size(8):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | m_var1&gt; +---1&gt;1&gt; CSuper::$vftable@:1&gt; | &amp;CSuper_meta1&gt; | 01&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CSuper::func11&gt;1&gt; CSuper::func0 this adjustor: 01&gt; CSuper::func1 this adjustor: 01&gt;1&gt;1&gt; class CBase0 size(20):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | &#123;vbptr&#125;1&gt; 8 | m_var01&gt; +---1&gt; +--- (virtual base CSuper)1&gt; 12 | &#123;vfptr&#125;1&gt; 16 | m_var1&gt; +---1&gt;1&gt; CBase0::$vftable@CBase0@:1&gt; | &amp;CBase0_meta1&gt; | 01&gt; 0 | &amp;CBase0::func21&gt;1&gt; CBase0::$vbtable@:1&gt; 0 | -41&gt; 1 | 8 (CBase0d(CBase0+4)CSuper)1&gt;1&gt; CBase0::$vftable@CSuper@:1&gt; | -121&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CBase0::func11&gt;1&gt; CBase0::func1 this adjustor: 121&gt; CBase0::func2 this adjustor: 01&gt;1&gt; vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; CSuper 12 4 4 01&gt;1&gt;1&gt; class CBase1 size(20):1&gt; +---1&gt; 0 | &#123;vfptr&#125;1&gt; 4 | &#123;vbptr&#125;1&gt; 8 | m_var11&gt; +---1&gt; +--- (virtual base CSuper)1&gt; 12 | &#123;vfptr&#125;1&gt; 16 | m_var1&gt; +---1&gt;1&gt; CBase1::$vftable@CBase1@:1&gt; | &amp;CBase1_meta1&gt; | 01&gt; 0 | &amp;CBase1::func31&gt;1&gt; CBase1::$vbtable@:1&gt; 0 | -41&gt; 1 | 8 (CBase1d(CBase1+4)CSuper)1&gt;1&gt; CBase1::$vftable@CSuper@:1&gt; | -121&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CBase1::func11&gt;1&gt; CBase1::func1 this adjustor: 121&gt; CBase1::func3 this adjustor: 01&gt;1&gt; vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; CSuper 12 4 4 01&gt;1&gt;1&gt; class CDerived size(36):1&gt; +---1&gt; | +--- (base class CBase0)1&gt; 0 | | &#123;vfptr&#125;1&gt; 4 | | &#123;vbptr&#125;1&gt; 8 | | m_var01&gt; | +---1&gt; | +--- (base class CBase1)1&gt; 12 | | &#123;vfptr&#125;1&gt; 16 | | &#123;vbptr&#125;1&gt; 20 | | m_var11&gt; | +---1&gt; 24 | m_var21&gt; +---1&gt; +--- (virtual base CSuper)1&gt; 28 | &#123;vfptr&#125;1&gt; 32 | m_var1&gt; +---1&gt;1&gt; CDerived::$vftable@CBase0@:1&gt; | &amp;CDerived_meta1&gt; | 01&gt; 0 | &amp;CBase0::func21&gt; 1 | &amp;CDerived::func41&gt;1&gt; CDerived::$vftable@CBase1@:1&gt; | -121&gt; 0 | &amp;CDerived::func31&gt;1&gt; CDerived::$vbtable@CBase0@:1&gt; 0 | -41&gt; 1 | 24 (CDerivedd(CBase0+4)CSuper)1&gt;1&gt; CDerived::$vbtable@CBase1@:1&gt; 0 | -41&gt; 1 | 12 (CDerivedd(CBase1+4)CSuper)1&gt;1&gt; CDerived::$vftable@CSuper@:1&gt; | -281&gt; 0 | &amp;CSuper::func01&gt; 1 | &amp;CDerived::func11&gt;1&gt; CDerived::func1 this adjustor: 281&gt; CDerived::func3 this adjustor: 121&gt; CDerived::func4 this adjustor: 01&gt;1&gt; vbi: class offset o.vbptr o.vbte fVtorDisp1&gt; CSuper 28 4 4 0 总结 虚函数表是用来实现多态的核心内容。 多继承很强大但是不要滥用，当多个基类都含有虚函数时，派生类会有多个指向虚函数表的指针。 忘记菱形继承吧，为了取消二义性引入虚继承，结果造成内存分布复杂而又难以理解，大道至简，回归本质吧！]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>继承</tag>
        <tag>多态</tag>
        <tag>虚函数表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++ STL中map的[]操作符使用时的一个坑]]></title>
    <url>%2Fblog%2F2019%2F12%2F14%2FC-STL%E4%B8%ADmap%E7%9A%84-%E6%93%8D%E4%BD%9C%E7%AC%A6%E4%BD%BF%E7%94%A8%E6%97%B6%E7%9A%84%E4%B8%80%E4%B8%AA%E5%9D%91%2F</url>
    <content type="text"><![CDATA[前言学习C++，自从发现了map这个结构以后，就深深的被这种键值对的方式吸引了，写代码时也渐渐离不开这种结构了，一次偶然的机会发现这个map还有个 [] 运算符，仿佛又发现了新大陆一样，写代码更加方便了，殊不知一个深深的大坑正在前面等着我。 问题一开始学到map的时候还是中规中矩的使用函数插入删除，比如定义一个map，先引入头文件和命名空间： 1234#include &lt;map&gt;using namespace std;map&lt;int, int&gt; mapTest; 上面就轻松定义了一个map结构对象，是一个整数到另一个整数的映射，这种映射有什么用呢？举个简单的例子，这个映射可以作为学生的学号和成绩的对应关系，这样只要知道学号，就可以从map中直接获得对应的成绩很方便。 最开始学习插入时通常有以下两种方式： 12mapTest.insert(map&lt;int, int&gt;::value_type(1001, 100));mapTest.insert(make_pair(1002, 98)); 但是学了 map 的 [] 操作符以后，上述代码可以写成： 12mapTest[1001] = 100;mapTest[1002] = 98; 查找一个元素的时候需要用到find()函数，一般写成 123map&lt;int, int&gt;::const_iterator itor = mapTest.find(1001);if (itor != mapTest.end()) return itor-&gt;second; 但是学了 map 的 [] 操作符以后，上述代码就可以简写成： 1return mapTest[1001]; 特别的在插入一个元素的时候，比如用来计数，每次给一个键对应的值加1时，可以直接写成： 1mapTest[1001] += 1; 根本不用检查 1001 这个键是否存在，使用 [] 操作符，在使用前会先默认成0，然后执行+1操作，这个比先使用find()查找，然后+1操作后再插入方便多了。 其实这只是使用map结构的一种语法糖，但是这语法糖简直太好使了，太甜了，让人欲罢不能，所以我就含着这块糖掉进了坑里，因为调用 map 的有时会产生副作用，如果查找一个键不在 map 中，则会在map中对应的这个键的位置插入默认值，接下来看一下例子就明白了。 测试过程测试代码在VS2015中编译运行，C++11标准，如果编译不正确可以看一下环境是否不同，尝试修改代码实现即可，测试的例子也是上面提到的，使用 map 来存储学生学号和成绩的对应关系，下面来简单实现一个类，描述这种关系： 编写测试类1234567891011121314151617181920212223242526272829303132333435363738394041#include &lt;map&gt;#include &lt;iostream&gt;#include &lt;algorithm&gt;using namespace std;class CReportCard&#123;public: CReportCard() &#123; m_mapStuNo2Score.clear(); &#125; ~CReportCard() &#123; m_mapStuNo2Score.clear(); &#125;public: void LoadScores(); // 模拟录入成绩 int GetScoreByStudentNo(const int nStudentNo); // 根据学号查询成绩 void PrintReportCard(); // 打印成绩单private: map&lt;int, int&gt; m_mapStuNo2Score;&#125;;void CReportCard::LoadScores()&#123; m_mapStuNo2Score[1001] = 99; m_mapStuNo2Score[1002] = 94; m_mapStuNo2Score[1004] = 89; m_mapStuNo2Score[1005] = 92; m_mapStuNo2Score[1007] = 80;&#125;int CReportCard::GetScoreByStudentNo(const int nStudentNo)&#123; return m_mapStuNo2Score[nStudentNo];&#125;void CReportCard::PrintReportCard()&#123; cout &lt;&lt; "show report card start-----&gt;" &lt;&lt; endl; std::for_each(m_mapStuNo2Score.begin(), m_mapStuNo2Score.end(), [](std::map&lt;int, int&gt;::reference socrepair) &#123; std::cout &lt;&lt; socrepair.first &lt;&lt; "'s score = " &lt;&lt; socrepair.second &lt;&lt; "\n"; &#125;); cout &lt;&lt; "show report card end&lt;------" &lt;&lt; endl;&#125; 这个类的内容很简单，使用 map 类型的对象 m_mapStuNo2Score 来存储学号和成绩的对应关系，LoadScores()函数中使用 [] 操作符向 map 中插入元素，模拟成绩录入过程；GetScoreByStudentNo()函数同样使用了 [] 操作符模拟成绩查询过程；PrintReportCard()函数遍历 map 打印成绩单信息。 看似正常的调用接下来编写一个函数来使用这个类，测试如下： 123456789101112int main(int argc, char* argv[])&#123; CReportCard obj; obj.LoadScores(); cout &lt;&lt; "student no = 1001, score = " &lt;&lt; obj.GetScoreByStudentNo(1001) &lt;&lt; endl; cout &lt;&lt; "student no = 1004, score = " &lt;&lt; obj.GetScoreByStudentNo(1004) &lt;&lt; endl; obj.PrintReportCard(); return 0;&#125; 首先调用 LoadScores()函数来加载数据，然后通过 GetScoreByStudentNo() 函数来查找学号为 1001 和 1004 的两个学生的成绩，最后打印一下成绩单，接下来看一下运行结果： student no = 1001, score = 99student no = 1004, score = 89show report card start—–&gt;1001’s score = 991002’s score = 941004’s score = 891005’s score = 921007’s score = 80show report card end&lt;—— 以上结果正常的打印出了查询的分数和成绩单，一切看起来毫无问题，如果查询的学号不存在又会怎么样呢？ 出现问题的调用修改上面的测试函数，将学生学号改成不存在的数值，修改如下： 12345678910111213int main(int argc, char* argv[])&#123; CReportCard obj; obj.LoadScores(); cout &lt;&lt; endl; cout &lt;&lt; "student no = 1011, score = " &lt;&lt; obj.GetScoreByStudentNo(1011) &lt;&lt; endl; cout &lt;&lt; "student no = 1014, score = " &lt;&lt; obj.GetScoreByStudentNo(1014) &lt;&lt; endl; obj.PrintReportCard(); return 0;&#125; 大部分的内容并没有发生变化，只将学号改成了不存在的情况，测试结果如下： student no = 1011, score = 0student no = 1014, score = 0show report card start—–&gt;1001’s score = 991002’s score = 941004’s score = 891005’s score = 921007’s score = 801011’s score = 01014’s score = 0show report card end&lt;—— 不存在的学号对应的分数是0，这应该也说的过去，因为键不存在，所以对 map 使用 [] 操作符查找时，寻找的键不存在则返回了整型的默认值0，但是在打印成绩单的时候居然多了两项，这充分暴露了 [] 操作符可能产生的副作用。 在查找返回时，[] 操作符并不是找不到返回对应类型默认值就完了，还会把查找的键和默认值作为一对，插入到待查的 map，这种操作一般是我们不需要的，所以在你明确不需要这个副作用时，查找 map 元素不要使用 [] 操作符。 亡羊补牢上面说到，[] 操作符查找不到就插入的副作用一般我们不使用，所以在查找时还是使用 find() 函数更规范一些，修改 GetScoreByStudentNo() 函数如下： 123456int CReportCard::GetScoreByStudentNo(const int nStudentNo)&#123; //return m_mapStuNo2Score[nStudentNo]; map&lt;int, int&gt;::const_iterator itor = m_mapStuNo2Score.find(nStudentNo); return itor != m_mapStuNo2Score.end() ? itor-&gt;second : 0;&#125; 此时再运行上面的例子就正常了，成绩单中也不会插入无效值了。 总结 map 的 [] 操作符会有副作用，当查找的键不存在时，会在对应键位置插入默认值 时刻保持清醒的头脑，过分的方便或许会给你自己埋下深深的坑 敬畏自然、敬畏生命、敬畏你写下的每一行代码]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>find</tag>
        <tag>中括号</tag>
        <tag>insert</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL中全局变量、会话变量、用户变量和局部变量的区别]]></title>
    <url>%2Fblog%2F2019%2F12%2F03%2FMySQL%E4%B8%AD%E5%85%A8%E5%B1%80%E5%8F%98%E9%87%8F%E3%80%81%E4%BC%9A%E8%AF%9D%E5%8F%98%E9%87%8F%E3%80%81%E7%94%A8%E6%88%B7%E5%8F%98%E9%87%8F%E5%92%8C%E5%B1%80%E9%83%A8%E5%8F%98%E9%87%8F%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言之前在项目的存储过程中发现有通过 DECLARE 关键字定义的变量如DECLARE cnt INT DEFAULT 0;，还有形如 @count 这样的变量，存储过程中拿过来直接就进行设置，像这样set @count=1;，这两种类型的变量究竟有什么区别却弄不清楚，赶紧上网查询资料，发现还有@@sql_mode这样的变量，这一个圈俩圈的到底是什么啊？会不会出现三个圈的情况？ 变量分类与关系经过一段时间学习和测试，再配合官方的文档，现在大致弄清楚了这些变量的区别，一般可以将MySQL中的变量分为全局变量、会话变量、用户变量和局部变量，这是很常见的分类方法，这些变量的作用是什么呢？可以从前往后依次看一下。 首先我们知道MySQL服务器维护了许多系统变量来控制其运行的行为，这些变量有些是默认编译到软件中的，有些是可以通过外部配置文件来配置覆盖的，如果想查询自编译的内置变量和从文件中可以读取覆盖的变量可以通过以下命令来查询: 1mysqld --verbose --help 如果想只看自编译的内置变量可以使用命令： 1mysqld --no-defaults --verbose --help 接下来简单了解一下这几类变量的应用范围，首先MySQL服务器启动时会使用其软件内置的变量（俗称写死在代码中的）和配置文件中的变量（如果允许，是可以覆盖源代码中的默认值的）来初始化整个MySQL服务器的运行环境，这些变量通常就是我们所说的全局变量，这些在内存中的全局变量有些是可以修改的。 当有客户端连接到MySQL服务器的时候，MySQL服务器会将这些全局变量的大部分复制一份作为这个连接客户端的会话变量，这些会话变量与客户端连接绑定，连接的客户端可以修改其中允许修改的变量，但是当连接断开时这些会话变量全部消失，重新连接时会从全局变量中重新复制一份。 其实与连接相关的变量不只有会话变量一种，用户变量也是这样的，用户变量其实就是用户自定义变量，当客户端连接上MySQL服务器之后就可以自己定义一些变量，这些变量在整个连接过程中有效，当连接断开时，这些用户变量消失。 局部变量实际上最好理解，通常由DECLARE 关键字来定义，经常出现在存储过程中，非常类似于C和C++函数中的局部变量，而存储过程的参数也和这种变量非常相似，基本上可以作为同一种变量来对待。 变量的修改先说全局变量有很多是可以动态调整的，也就是说可以在MySQL服务器运行期间通过 SET 命令修改全局变量，而不需要重新启动 MySQL 服务，但是这种方法在修改大部分变量的时候都需要超级权限，比如root账户。 相比之下会话对变量修改的要求要低的多，因为修改会话变量通常只会影响当前连接，但是有个别一些变量是例外的，修改它们也需要较高的权限，比如 binlog_format 和 sql_log_bin，因为设置这些变量的值将影响当前会话的二进制日志记录，也有可能对服务器复制和备份的完整性产生更广泛的影响。 至于用户变量和局部变量，听名字就知道，这些变量的生杀大权完全掌握在自己手中，想改就改，完全不需要理会什么权限，它的定义和使用全都由用户自己掌握。 测试环境以下给出MySQL的版本，同时使用root用户测试，这样可以避免一些权限问题。 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 变量查询与设置全局变量这些变量来源于软件自编译、配置文件中、以及启动参数中指定的变量，其中大部分是可以由root用户通过 SET 命令直接在运行时来修改的，一旦 MySQL 服务器重新启动，所有修改都被还原。如果修改了配置文件，想恢复最初的设置，只需要将配置文件还原，重新启动 MySQL 服务器，一切都可以恢复原来的样子。 查询查询所有的全局变量： 1show global variables; 一般不会这么用，这样查简直太多了，大概有500多个，通常会加个like控制过滤条件： 12345678910111213141516171819mysql&gt; show global variables like 'sql%';+------------------------+----------------------------------------------------------------+| Variable_name | Value |+------------------------+----------------------------------------------------------------+| sql_auto_is_null | OFF || sql_big_selects | ON || sql_buffer_result | OFF || sql_log_off | OFF || sql_mode | STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION || sql_notes | ON || sql_quote_show_create | ON || sql_safe_updates | OFF || sql_select_limit | 18446744073709551615 || sql_slave_skip_counter | 0 || sql_warnings | OFF |+------------------------+----------------------------------------------------------------+11 rows in set, 1 warning (0.00 sec)mysql&gt; 还有一种查询方法就是通过select语句： 1select @@global.sql_mode; 当一个全局变量不存在会话变量副本时也可以这样 1select @@max_connections; 设置设置全局变量也有两种方式： 1set global sql_mode=''; 或者 1set @@global.sql_mode=''; 会话变量这些变量基本来自于全局变量的复制，与客户端连接有关，无论怎样修改，当连接断开后，一切都会还原，下次连接时又是一次新的开始。 查询类比全局变量，会话变量也有类似的查询方式，查询所有会话变量 1show session variables; 添加查询匹配，只查一部分会话变量： 1show session variables like 'sql%'; 查询特定的会话变量，以下三种都可以： 123select @@session.sql_mode;select @@local.sql_mode;select @@sql_mode; 设置会话变量的设置方法是最多的，以下的方式都可以： 123456set session sql_mode = '';set local sql_mode = '';set @@session.sql_mode = '';set @@local.sql_mode = '';set @@sql_mode = '';set sql_mode = ''; 用户变量用户变量就是用户自己定义的变量，也是在连接断开时失效，定义和使用相比会话变量来说简单许多。 查询直接一个select语句就可以了： 1select @count; 设置设置也相对简单，可以直接使用set命令： 12set @count=1;set @sum:=0; 也可以使用select into语句来设置值，比如： 1select count(id) into @count from items where price &lt; 99; 局部变量局部变量通常出现在存储过程中，用于中间计算结果，交换数据等等，当存储过程执行完，变量的生命周期也就结束了。 查询也是使用select语句： 12declare count int(4);select count; 设置与用户变量非常类似： 1234declare count int(4);declare sum int(4);set count=1;set sum:=0; 也可以使用select into语句来设置值，比如： 12declare count int(4);select count(id) into count from items where price &lt; 99; 其实还有一种存储过程参数，也就是C/C++中常说的形参，使用方法与局部变量基本一致，就当成局部变量来用就可以了 几种变量的对比使用 操作类型 全局变量 会话变量 用户变量 局部变量（参数） 文档常用名 global variables session variables user-defined variables local variables 出现的位置 命令行、函数、存储过程 命令行、函数、存储过程 命令行、函数、存储过程 函数、存储过程 定义的方式 只能查看修改，不能定义 只能查看修改，不能定义 直接使用，@var形式 declare count int(4); 有效生命周期 服务器重启时恢复默认值 断开连接时，变量消失 断开连接时，变量消失 出了函数或存储过程的作用域，变量无效 查看所有变量 show global variables; show session variables; - - 查看部分变量 show global variables like &#39;sql%&#39;; show session variables like &#39;sql%&#39;; - - 查看指定变量 select @@global.sql_mode、select @@max_connections; select @@session.sql_mode;、 select @@local.sql_mode;、 select @@sql_mode; select @var; select count; 设置指定变量 set global sql_mode=&#39;&#39;;、 set @@global.sql_mode=&#39;&#39;; set session sql_mode = &#39;&#39;;、 set local sql_mode = &#39;&#39;;、 set @@session.sql_mode = &#39;&#39;;、 set @@local.sql_mode = &#39;&#39;;、 set @@sql_mode = &#39;&#39;;、 set sql_mode = &#39;&#39;; set @var=1;、 set @var:=101;、 select 100 into @var; set count=1;、 set count:=101;、 select 100 into count; 相信看了这个对比的表格，之前的很多疑惑就应该清楚了，如果发现其中有什么疑惑的地方可以给我留言，或者发现有什么错误也可以一针见血的指出来，我会尽快改正的。 总结 MySQL 中的变量通常分为：全局变量、 会话变量、 用户变量、 局部变量 其实还有一个存储过程和函数的参数，这种类型和局部变量基本一致，当成局部变量来使用就行了 在表格中有一个容易疑惑的点就是无论是全局变量还是会话变量都有select@@变量名的形式。 select@@变量名这种形式默认取的是会话变量，如果查询的会话变量不存在就会获取全局变量，比如@@max_connections 但是SET操作的时候，set @@变量名=xxx 总是操作的会话变量，如果会话变量不存在就会报错]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>全局变量</tag>
        <tag>会话变量</tag>
        <tag>用户变量</tag>
        <tag>局部变量</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据库导入、导出、复制表、重命名表]]></title>
    <url>%2Fblog%2F2019%2F11%2F30%2FMySQL%E6%95%B0%E6%8D%AE%E5%BA%93%E5%AF%BC%E5%85%A5%E3%80%81%E5%AF%BC%E5%87%BA%E3%80%81%E5%A4%8D%E5%88%B6%E8%A1%A8%E3%80%81%E9%87%8D%E5%91%BD%E5%90%8D%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[前言提前说明这是一篇小白总结，高手勿喷请绕行，写这篇总结的原因是发觉自己有时候确实眼高手低了，大道至简，花了很多时间去看索引、缓存、主从等等，等到出现实际问题的时候却发现自己磨磨蹭蹭写出的SQL语句居然有语法错误，看来还得稳扎稳打从基础入手，因为实际工作的用到的SQL并不多，现在把常用的几条总结一下，即使下次不能立马写出来，也能在这篇文章中的快速找到想要的。 正如标题中的提到的这些，数据库的导入和导出在紧急处理线上数据时很常用，而复制表基本上也是为了不影响原数据的情况下进行问题排查，重命名表是为了导入多份备份数据时原数据不被覆盖，比如想对比两天的A表数据，可以先把第一天的数据导入，然后将A表名修改成Aold，接着直接再导入第二天的数据库数据，这样就可以将数据库中表Aold和A进行对比了，可以避免两个数据库中的同一个表进行对比时写很长的SQL。 测试环境 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 11Server version: 5.7.28-log MySQL Community Server (GPL)Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 测试过程为了说明实现这些要求的具体SQL，我们先建立一个测试数据库，然后创建测试表格，插入测试数据，最后在这个数据库上依次实现这些要求。 创建测试数据创建测试数据库和表格1234567891011121314151617181920mysql&gt; create database dbtest;Query OK, 1 row affected (0.00 sec)mysql&gt; use dbtestDatabase changedmysql&gt; create table a(id int, num int);Query OK, 0 rows affected (0.02 sec)mysql&gt; create table b(id int, name varchar(32));Query OK, 0 rows affected (0.01 sec)mysql&gt; show tables;+--------------+| Tables_in_zz |+--------------+| a || b |+--------------+2 rows in set (0.00 sec) 插入测试数据1234567891011121314151617181920212223242526272829mysql&gt; insert into a values(1, 100);Query OK, 1 row affected (0.02 sec)mysql&gt; insert into a values(2, 200);Query OK, 1 row affected (0.01 sec)mysql&gt; select * from a;+------+------+| id | num |+------+------+| 1 | 100 || 2 | 200 |+------+------+2 rows in set (0.01 sec)mysql&gt; insert into b values(1, 'albert');Query OK, 1 row affected (0.01 sec)mysql&gt; insert into b values(2, 'tom');Query OK, 1 row affected (0.01 sec)mysql&gt; select * from b;+------+--------+| id | name |+------+--------+| 1 | albert || 2 | tom |+------+--------+2 rows in set (0.00 sec) 数据库导出数据库导出时使用的最基础的工具叫mysqldump，这是单独的工具不是mysql命令，刚学MySQL的时候居然在MySQL的命令行中使用mysqldump，现在只能当笑话看了。 导出指定数据库中所有表结构和数据在系统的命令行工具下输入以下命令，敲入回车输入密码，再回车就可以将数据库dbtest的结构和数据导出到dbtest.sql文件中： 1&gt;mysqldump -uroot -h192.168.1.101 -p dbtest &gt; dbtest.sql 打开dbtest.sql文件，显示如下：文件内容比较长，里面包含了数据库的表结构和其中的数据信息： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273-- MySQL dump 10.13 Distrib 5.7.21, for Win64 (x86_64)---- Host: localhost Database: dbtest-- -------------------------------------------------------- Server version 5.7.21-log/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;/*!40101 SET NAMES utf8 */;/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;/*!40103 SET TIME_ZONE='+00:00' */;/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;---- Table structure for table `a`--DROP TABLE IF EXISTS `a`;/*!40101 SET @saved_cs_client = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `a` ( `id` int(11) DEFAULT NULL, `num` int(11) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8;/*!40101 SET character_set_client = @saved_cs_client */;---- Dumping data for table `a`--LOCK TABLES `a` WRITE;/*!40000 ALTER TABLE `a` DISABLE KEYS */;INSERT INTO `a` VALUES (1,100),(2,200);/*!40000 ALTER TABLE `a` ENABLE KEYS */;UNLOCK TABLES;---- Table structure for table `b`--DROP TABLE IF EXISTS `b`;/*!40101 SET @saved_cs_client = @@character_set_client */;/*!40101 SET character_set_client = utf8 */;CREATE TABLE `b` ( `id` int(11) DEFAULT NULL, `name` varchar(32) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8;/*!40101 SET character_set_client = @saved_cs_client */;---- Dumping data for table `b`--LOCK TABLES `b` WRITE;/*!40000 ALTER TABLE `b` DISABLE KEYS */;INSERT INTO `b` VALUES (1,'albert'),(2,'tom');/*!40000 ALTER TABLE `b` ENABLE KEYS */;UNLOCK TABLES;/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;-- Dump completed on 2019-11-30 11:32:23 只导出指定数据库中所有表的结构只导出表结构的方法和上面是一样的，只是加上 -d 选项就可以了，运行下面命令就可以将dbtest数据库中的所有表结构导出到 dbteststructure.sql 中，因为和上面类似，文件中的内容就不贴了，只比 dbtest.sql 文件少了插入数据的内容： 1&gt;mysqldump -uroot -h192.168.1.101 -p -d dbtest &gt; dbteststructure.sql 只导出指定数据库中的一个表只导出数据库中指定表，可以是一个也可以是多个，在数据库名字后面跟表的名字就可以了，比如导出表a： 1&gt;mysqldump -uroot -h192.168.1.101 -p dbtest a &gt; dbtest_a.sql 导出多个数据库数据出多个数据库数据需要加上 --databases 选项，然后在后面依次跟上数据库名字就行： 1&gt;mysqldump -uroot -h192.168.1.101 -p --databases dbtest dbtest2 &gt; db_more.sql 导出所有数据库数据导出所有的数据库时不需要加数据库的名字，加上 --all-databases 选项就可以了 1&gt;mysqldump -uroot -h192.168.1.101 -p --all-databases &gt; db_all.sql 数据库导入数据库的导入比较简单，实际上就是把sql文件在MySQL中执行一下，可以使用以下两种方式： 系统命令行导入一般需要指定导入的数据库dbtest和sql文件的路径，在Linux上举例： 1&gt;mysql -uroot -h192.168.1.101 -p dbtest &lt; /home/albert/dbtest.sql --default-character-set=utf8 在Windows上举例，主要是路径需要注意，Windows上使用正斜杠/和反斜杠\都可以，默认是反斜杠，如果路径中包含空格可以用双引号将整个路径包起来： 1&gt;mysql -uroot -h192.168.1.101 -p dbtest &lt; D:\albert\dbtest.sql --default-character-set=utf8 注意--default-character-set=utf8是指定默认的字符集，主要是防止导入时出现编码错误，之前总结过，在此复习一下。 MySQL命令行导入首先连接MySQL服务器进行登陆： 1&gt;mysql -uroot -h192.168.1.101 -p --default-character-set=utf8 输入密码登陆后再使用source命令直接导入sql文件就可以： 1mysql&gt; source D:\albert\dbtest.sql 数据表复制数据表的复制可以分为结构复制和完全复制，其中完全复制时可以先复制结构，再将数据复制到新表中： 只复制表结构 使用LIKE语句，只不过5.0版本之后才支持，之前的版本无法使用 1CREATE TABLE new_table LIKE old_table; 1234567891011121314151617181920212223mysql&gt; select * from a;+------+------+| id | num |+------+------+| 1 | 100 || 2 | 200 |+------+------+2 rows in set (0.01 sec)mysql&gt; create table a2 like a;Query OK, 0 rows affected (0.04 sec)mysql&gt; desc a2;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.02 sec)mysql&gt; select * from a2;Empty set (0.00 sec) 使用 SELECT 语句加不成立的条件实现 1CREATE TABLE new_table SELECT * FROM old_table WHERE FALSE; 123456789101112131415mysql&gt; create table a3 select * from a where false;Query OK, 0 rows affected (0.07 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc a3;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.01 sec)mysql&gt; select * from a3;Empty set (0.01 sec) 复制表结构和数据 可以先按照上面的语句复制结构，然后再讲数据复制过去： 12CREATE TABLE new_table SELECT * FROM old_table WHERE FALSE;INSERT INTO new_table SELECT * FROM old_table; 123456789101112mysql&gt; insert into a2 select * from a;Query OK, 2 rows affected (0.07 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; select * from a2;+------+------+| id | num |+------+------+| 1 | 100 || 2 | 200 |+------+------+2 rows in set (0.00 sec) 直接将结构和数据全部复制 1CREATE TABLE new_table SELECT * FROM old_table; 123456789101112131415161718192021mysql&gt; create table a4 select * from a;Query OK, 2 rows affected (0.06 sec)Records: 2 Duplicates: 0 Warnings: 0mysql&gt; desc a4;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.01 sec)mysql&gt; select * from a4;+------+------+| id | num |+------+------+| 1 | 100 || 2 | 200 |+------+------+2 rows in set (0.00 sec) 数据表重命名使用 ALTER 命令实现1ALTER TABLE old_table RENAME [TO|AS] new_table; 这个语句中的TO和AS是可选的，加不加都行，也可以选择其中一个，效果是一样的，测试如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344mysql&gt; show tables;+------------------+| Tables_in_dbtest |+------------------+| a || b |+------------------+5 rows in set (0.02 sec)mysql&gt; alter table b rename c;Query OK, 0 rows affected (0.04 sec)mysql&gt; show tables;+------------------+| Tables_in_dbtest |+------------------+| a || c |+------------------+5 rows in set (0.00 sec)mysql&gt; alter table c rename to d;Query OK, 0 rows affected (0.02 sec)mysql&gt; show tables;+------------------+| Tables_in_dbtest |+------------------+| a || d |+------------------+5 rows in set (0.00 sec)mysql&gt; alter table d rename as e;Query OK, 0 rows affected (0.02 sec)mysql&gt; show tables;+------------------+| Tables_in_dbtest |+------------------+| a || e |+------------------+5 rows in set (0.00 sec) 使用RENAME命令1RENAME TABLE old_table TO new_table; 这个语句中TO就不能省略了，否则会报语法错误，测试如下： 123456789101112131415161718192021mysql&gt; show tables -&gt; ;+------------------+| Tables_in_dbtest |+------------------+| a || e |+------------------+5 rows in set (0.00 sec)mysql&gt; rename table e to f;Query OK, 0 rows affected (0.11 sec)mysql&gt; show tables;+------------------+| Tables_in_dbtest |+------------------+| a || f |+------------------+5 rows in set (0.01 sec) 总结 数据库的导出、导入、数据表的复制、重命名都是MySQL操作的基础，需要熟练掌握 数据库导出：mysqldump -uroot -h192.168.1.101 -p dbtest &gt; dbtest.sql 数据库导入：mysql -uroot -h192.168.1.101 -p dbtest &lt; /tmp/dbtest.sql --default-character-set=utf8 数据表复制：CREATE TABLE new_table SELECT * FROM old_table; 表格重命名：RENAME TABLE old_table TO new_table;]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>导入</tag>
        <tag>导出</tag>
        <tag>复制表</tag>
        <tag>重命名</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql导入数据库时报错ERROR: Unknown command ' ']]></title>
    <url>%2Fblog%2F2019%2F11%2F20%2FMysql%E5%AF%BC%E5%85%A5%E6%95%B0%E6%8D%AE%E5%BA%93%E6%97%B6%E6%8A%A5%E9%94%99ERROR-Unknown-command-0%2F</url>
    <content type="text"><![CDATA[前言之前查询数据问题时多次使用过数据库导出导入命令，从来没发生过这种错误，那是一个风和日丽的上午，忽然来了一个紧急的任务，线上数据出问题了，需要马上处理一下，连上数据库备份服务器，找到备份数据直接下载下来，优雅（cong mang）地处理着这一切，本打算在Windows上直接导入查询处理一下算了，结果忙中添乱，导入数据库时居然报了一大堆错误，其中最扎眼的就是一连串的ERROR: Unknown command ‘\0’，没办法了，先找一台Linux服务器，上传导入数据分析处理一气呵成，处理完线上问题终于有时间回头来看看这个问题了。 测试环境数据库版本 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 9Server version: 5.7.28-log MySQL Community Server (GPL)Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 系统版本 Win10马马虎虎版本来打算用来快速处理的，结果添了不少乱 问题出现过程直接使用cmd命令行输入mysql -uroot -h192.168.1.101 -p，然后输入密码后成功登录，接着选择数据库use dbtest，导入数据库文件source E:\onlinedb.sql，结果意外发生了，出现了一大堆的如下错误： …………ERROR:Unknown command ‘\0’.ERROR:Unknown command ‘\0’.ERROR:Unknown command ‘\0’.ERROR:Unknown command ‘\0’.ERROR 1064 (42000): You have an error in your SQL syntax; check the manual … 命令行界面中出现了多次错误提醒ERROR: Unknown command &#39;\0&#39;.，最后有一个常见的语法错误提醒，看到这个&#39;\0&#39;，这个字节中的0，程序中nullptr，我猜到可能是编码问题，而最后的语法错误也是由于编码不同而部分解析导致的，于是查了一些资料发现果然是编码问题，只要在客户端连接Mysql服务器时指定UTF8编码就可以了。 问题结果过程导入的流程不变，只要在客户端连接Mysql服务器时指定编码就可以避免前面遇到的错误，连接时的命令修改为mysql -uroot -h192.168.1.101 -p --default-character-set=utf8就没问题了，上面提到的语法错误也不存在了。 其实这种跨平台的坑有很多，因为平台之间的哲学思想不同，导致对一些默认值的处理不太一样，同样的文件在Windows平台上导入报错，但是我换到Linux服务器上就没有任何问题，接触多了自然就释然了。 总结 导入sql文件时报错ERROR: Unknown command &#39;\0&#39;需在Mysql命令行客户端连接服务器时指定编码 连接时指定编码的格式为mysql -uroot -h192.168.1.101 -p --default-character-set=utf8]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>ERROR</tag>
        <tag>source</tag>
        <tag>sql</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中Blob类型字段的插入、查看、截取和拼接]]></title>
    <url>%2Fblog%2F2019%2F11%2F20%2FMysql%E4%B8%ADBlob%E7%B1%BB%E5%9E%8B%E5%AD%97%E6%AE%B5%E7%9A%84%E6%8F%92%E5%85%A5%E3%80%81%E6%9F%A5%E7%9C%8B%E3%80%81%E6%88%AA%E5%8F%96%E5%92%8C%E6%8B%BC%E6%8E%A5%2F</url>
    <content type="text"><![CDATA[前言本来并没有太注意到Blob这个类型，在游戏的开发中存储数据常常使用这个类型，这里的使用其实是“机械”的使用，因为应用程序和Mysql数据库之间的逻辑已经封装好了，我只要把对应的数据扔到接口里就行了，可是最近发生了点问题，所以决定深入研究一下Blob类型的操作方法。 问题是这样的，由于应用程序的一个逻辑错误，导致Mysql数据库中有一个Blob类型的字段的前几个字节被写入了错误的值，当然这个问题，我们可以通过应用程序处理，在逻辑中读出Blob字段的值，修改为正确值以后再写回到数据库中，可是这样有些麻烦，并且这些处理逻辑与业务无关。 为了更方便的解决问题，决定使用SQL语句直接修改数据库，将错误的数据恢复正常，因为之前没有直接用SQL修改过Blob类型的字段，所以多花了一点时间用来测试，现在把整个过程记录一下，方便下次直接操作。 在整个处理的过程中用到了查看、截取和拼接三种操作，为了让例子看起来更加精炼，我们把插入也测一下，然后创造出我们想要的精简后的数据，首先还是来看一下数据库版本。 数据库版本 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.28-log MySQL Community Server (GPL)Copyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 创建测试表测试的表格结构很简单，只需要带有一个Blob类型的字段就尅可以了，为了操作方便再添加一个id，操作的SQL语句如下： 1234567891011mysql&gt; create table bloboperation(id int, data blob);Query OK, 0 rows affected (0.36 sec)mysql&gt; desc bloboperation;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || data | blob | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.07 sec) 插入数据因为知道Blob是二进制数据，所以首先插入两条用十六进制表示的字节串试一下，提示成功插入，插入两条一样的数据是为了之后修改的时候对比方便： 12345mysql&gt; insert into bloboperation values(1, 0x01020304FFFFFFFF0000000CAACB0000);Query OK, 1 row affected (0.06 sec)mysql&gt; insert into bloboperation values(2, 0x01020304FFFFFFFF0000000CAACB0000);Query OK, 1 row affected (0.04 sec) 插入字节串没有问题，那插入字符串和数字看看会有什么结果，测试语句如下，最后发现均可以正常插入： 12345mysql&gt; insert into bloboperation values(3, 'hellworld');Query OK, 1 row affected (0.04 sec)mysql&gt; insert into bloboperation values(4, 0);Query OK, 1 row affected (0.03 sec) 查看数据上面插入了4条不同类型的数据都成功了，我们简单来查一下看看数据和我们插入的是否一样： 12345678910mysql&gt; select * from bloboperation;+------+------------------+| id | data |+------+------------------+| 1 | ÿÿÿÿ ? || 2 | ÿÿÿÿ ? || 3 | hellworld || 4 | 0 |+------+------------------+4 rows in set (0.00 sec) 这究竟是什么鬼，除了第3、4条和我们插入的数据一样，前两条数据看起来和我们之前插入数据时完全不一样，其实这时候需要用到一个hex()函数来看Blob类型的数据，查询结果如下： 12345678910mysql&gt; select id,hex(data),length(data) from bloboperation;+------+----------------------------------+--------------+| id | hex(data) | length(data) |+------+----------------------------------+--------------+| 1 | 01020304FFFFFFFF0000000CAACB0000 | 16 || 2 | 01020304FFFFFFFF0000000CAACB0000 | 16 || 3 | 68656C6C776F726C64 | 9 || 4 | 30 | 1 |+------+----------------------------------+--------------+4 rows in set (0.02 sec) 这回前两条数据正常了，可是后两条数据为什么又看起来不一样了呢，如果你产生了这样的疑问，就需要好好理解一下内存值和表现值的对应关系了，第4条插入语句的中数据0，实际上是被当做字符串存储的，而字符’0’的ASCII码是十进制的48，表示成十六进制就是0x30，也就是上面查到的这样，同理这个打错了的字符串’hellworld’也是这样存储的。 截取数据本来以为截取数据需要一个特别的函数，没想到用的是字符串截取函数substring(str,startpos,length)，第一个参数是需要截取的字符串或字节串，第二个参数起始位置从1开始，第三个参数就是截取的长度。 以第一条数据为例，截取第4到第8个一共5个字节，测试如下： 1234567mysql&gt; select id,hex(substring(data,4,5)) from bloboperation where id=1;+------+--------------------------+| id | hex(substring(data,4,5)) |+------+--------------------------+| 1 | 04FFFFFFFF |+------+--------------------------+1 row in set (0.00 sec) 拼接数据看到上一个函数之后，你应该有所察觉，这个Blob类型的数据处理起来并不麻烦，那么拼接函数会不会用的是concat()这个处理字符串的函数呢？恭喜你，答对了，就是使用这个函数，我们来把前四个字节和最后四个字节拼接到一起，测试如下： 1234567mysql&gt; select id,hex(concat(substring(data,1,4),substring(data,13,4))) from bloboperation where id=1;+------+-------------------------------------------------------+| id | hex(concat(substring(data,1,4),substring(data,13,4))) |+------+-------------------------------------------------------+| 1 | 01020304AACB0000 |+------+-------------------------------------------------------+1 row in set (0.00 sec) 进制转换我们看到id为1的数据有16个字节，实际上在应用程序的内存中对应了4个int类型，每个int类型占用四个字节，为了修改数据，我们需要知道原数据在程序中代表的数字是多少，这就用到进制转换函数conv，可以先进行一个简单转换，16进制转10进制的例子： 1234567mysql&gt; select conv('FF',16,10);+------------------+| conv('FF',16,10) |+------------------+| 255 |+------------------+1 row in set (0.00 sec) 通过上面的转换十六进制的FF被转换成了十进制的255，应用到Blob字段也是一样，我们看下id为1的数据第一个int保存的数据是多少: 12345678mysql&gt; select id,conv(hex(concat(substring(data,4,1),substring(data,3,1),substring(data,2,1),substring(data,1,1))),16,10) as firstint from bloboperation where id=1;+------+----------+| id | firstint |+------+----------+| 1 | 67305985 |+------+----------+1 row in set (0.01 sec) 现在我们就得到了第一个int类型的值是67305985，可能有的同学会有疑惑，为什么不直接截取前4个字节，而要一个一个的拼接呢？这就涉及到大端数据和小端数据知识了，我们使用的PC机通常是小端的，数据的地位存储在低内存，数据的高位存储在高内存，所以需要把四个字节反过来拼接在一起再进行转换。 实际处理理解了上面的知识，就可以处理之前遇到的问题了，假设这16个字节代表的4个int类型分别是A，B，C，D，需要处理的问题是当变量D的值是52138的时候把变量B清0。 通过分析判断D变量的值之前有类似的，按照刚才第一个变量那样处理，把B变量清零可以通过A变量拼接0，然后再拼接C变量和D变量得到，具体的执行语句如下： 12345678910111213141516171819mysql&gt; update bloboperation set data=concat(substring(data,1,4), 0x00000000, substring(data,9,8))whereconv( hex(concat(substring(data,16,1),substring(data,15,1),substring(data,14,1),substring(data,13,1))), 16,10)=52138and id=1;Query OK, 1 row affected (0.06 sec)Rows matched: 1 Changed: 1 Warnings: 0mysql&gt; select id,hex(data),length(data) from bloboperation;+------+----------------------------------+--------------+| id | hex(data) | length(data) |+------+----------------------------------+--------------+| 1 | 01020304000000000000000CAACB0000 | 16 || 2 | 01020304FFFFFFFF0000000CAACB0000 | 16 || 3 | 68656C6C776F726C64 | 9 || 4 | 30 | 1 |+------+----------------------------------+--------------+4 rows in set (0.00 sec) 执行更新后查询发现，第5到8个字节对应的变量B确实被清0了，也就是我们的目标达到了。 总结 Blob类型字段的处理常用到的函数hex()、substring()、concat()、conv() 注意conv()函数的第一个参数需要是十六进制表示的字符串，不需要带0x]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>Blob substring</tag>
        <tag>hex</tag>
        <tag>concat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[.bat批处理（八）：各种形式的变量%0、%i、%%i、var、%var%、!var!的含义和区别]]></title>
    <url>%2Fblog%2F2019%2F11%2F08%2Fbat%E6%89%B9%E5%A4%84%E7%90%86%EF%BC%88%E5%85%AB%EF%BC%89%EF%BC%9A%E5%90%84%E7%A7%8D%E5%BD%A2%E5%BC%8F%E7%9A%84%E5%8F%98%E9%87%8F-0%E3%80%81-i%E3%80%81-i%E3%80%81var%E3%80%81-var-%E7%9A%84%E5%90%AB%E4%B9%89%E5%92%8C%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言最近使用批处理程序处理文件的时候，发现这 bat中的变量形式真是“变化多端”，有时候加1个百分号%，有时候加2个百分号%%，还有的时候加感叹号!，真是让初学者一头雾水，于是查询资料做了一些小测试，终于大致弄清楚了这些变量的含义，接下来一一列举出来。 变量对比下面通过一些具体的例子来看下标题中提到的这些变量什么时候使用，使用的时候有哪些注意事项。 %0这个是批处理程序中的固定用法，类似于C++程序main函数中argv变量数组，类比可以知道，argv[0]表示exe程序的文件名，argv[1]表示启动程序的第1个参数，后面依次类推。而在批处理程序中%0表示这个批处理程序的文件名，%1表示调用这个批处理时传入的第1个参数，%2表示调用这个批处理时传入的第2个参数，最大可以到%9，具体用法可以参考之前的总结《.bat批处理（二）：%0 %1——给批处理脚本传递参数》，简单测试如下： 12345@echo offecho param0=%0echo param0=%1echo param0=%2 将上述代码保存在文件testparams.bat中，从cmd命令行运行批处理文件，只传入一个参数，运行结果如下： C:\Users\Administrator\Downloads&gt;testparams.bat “hello world”param0=testparams.batparam1=”hello world”param2= %i在题目所列的这些变量中，这一个比较特殊，因为它不是批处理文件中的变量，只能用于cmd命令行下的for循环中，在命令行中for循环的语法是for %variable in (set) do command [command-parameters]，其中的variable只能是单字母或者非特殊含义的字符，同样的for循环语句如果写在批处理文件中variable之前就要加两个%%了，先来看看%i的用法，直接在命令行中遍历集合打印输出： C:\Users\Administrator\Downloads&gt;for %i in (1,3,5,8) do echo %iC:\Users\Administrator\Downloads&gt;echo 11C:\Users\Administrator\Downloads&gt;echo 33C:\Users\Administrator\Downloads&gt;echo 55C:\Users\Administrator\Downloads&gt;echo 88 如果将其中的%i改成%%i，就会报语法错误，测试结果如下： C:\Users\Administrator\Downloads&gt;for %%i in (1,3,5,8) do echo %%i此时不应有 %%i。 %%i这种类型也是for循环中特有的，与%i相对，属于批处理程序的用法，换句话说就是在for循环中遍历的索引变量，如果在命令行中定义需要一个%，如果相同的语句定义在批处理文件中需要2个%%，语法为for %%variable in (set) do command [command-parameters]，variable同样只能是单个字母或者普通字符，至于为什么同样含义的变量在批处理中要多加一个%，至今也没有找到官方的说法，查找MSDN也没有发现说明，不过就我个人理解可能就像我们在命令行中打印一个%，可以正常打印输出，如果通过printf()想输出%就需要2个%的原理一样吧，测试如下： 1for %%i in (1,3,5,8) do echo %%i 运行结果： C:\Users\Administrator\Downloads&gt;testfor.batC:\Users\Administrator\Downloads&gt;for %i in (1 3 5 8) do echo %iC:\Users\Administrator\Downloads&gt;echo 11C:\Users\Administrator\Downloads&gt;echo 33C:\Users\Administrator\Downloads&gt;echo 55C:\Users\Administrator\Downloads&gt;echo 88 观察运行结果发现，运行批处理文件的时候，实际上去掉了%%i变量的1个%，将文件中代码改为1个%试下： 1for %i in (1,3,5,8) do echo %i 运行结果： C:\Users\Administrator\Downloads&gt;testfor.bat此时不应有 i。 var这个变量看起来挺正常的，也没有那么多奇奇怪怪的字符，和Lua、Python等语言中的变量长得挺像，实际上变量的这种形式很“短暂”，一般只能出现在给变量赋值的时候，也就是set语句之后，作为左值接受赋值时，或者在等号右测可评估的表达式中，举个例子，编写下面代码保存在normalVar.bat中： 1234567@echo offset var1=1set /a var2=var1+1echo var1echo var2 运行之后的结果为: C:\Users\Administrator\Downloads&gt;normalVar.batvar1var2 看完结果之后觉得很神奇是不是，为什么和我学的其他语言不一样呢，我使用set分别为var1和var2赋了值，但是输出的时候居然不是数字而是变量名，其实这就引出了之后%var%这种用法，接着往下看。 %var%在批处理中除了上面所说的在set语句后面的两种情况，再要想引用变量就需要在变量两端各加一个百分号%，明确的告诉引用者这是一个变量，使用时需要评估一下值，而不要当成字符串，上一个例子中echo后面想要输出的变量没有加%，那就被当成一个字符串处理，原样输出了，修改上个例子如下： 12345678910@echo offset var1=1set /a var2=var1+1set var3=%var2%echo %var1%echo %var2%echo %var3% 运行之后运行结果入下： C:\Users\Administrator\Downloads&gt;normalVar.bat122 看了这次的结果感觉正常多了，有一点需要注意，set var3=%var2%这一句中var2变量中的%不能省略，因为它既不属于左值也不属于被评估值的表达式，如果不加%，赋值后var3的值会变成“var2”这个字符串。 !var!这是最后一种常见的变量形式，同时也是一种不太好理解的形式，需要记住一点，这种变量与延迟环境变量扩展有关，如果没开启延迟环境变量扩展，那么!var!就是一个普通的包含5个字母的字符串，如果开启了延迟环境变量扩展，那么它就是变量var的实际值，可能说到这有的人会产生疑惑，引用变量var的值不是使用%var%吗？那么在开启延迟环境变量扩展的情况下，%var%和!var!有什么区别呢？下面举个例子测试下，编写如下代码保存在extVar.bat文件中： 1234@echo offset var1=110set var1=120&amp;echo %var1% 运行之后的结果为： C:\Users\Administrator\Downloads&gt;extVar.bat110 看到结果的时候是不是再次怀疑了世界，在打印变量var1之前明明重新赋值了120，为什么打印出来还是110呢？其实这是批处理脚本执行机制导致的，它会按行执行，在执行之前会先预处理，当执行set var1=110之后，变量var1变成了110，在执行set var1=120&amp;echo %var1%之前先预处理，将变量%var1%替换成了110，然后语句变成了set var1=120&amp;echo 110，所以就得到了我们上面测试的结果。 想要解决这个问题就需要开启延迟环境变量扩展，语句为setlocal enabledelayedexpansion，然后将引用变量的形式由%var1%改为!var1!即可，所以可以修改代码如下： 12345@echo offsetlocal enabledelayedexpansionset var1=110set var1=120&amp;echo !var1! 运行之后的结果为： C:\Users\Administrator\Downloads&gt;extVar.bat120 这回输出的结果符合预期了，开启了延迟环境变量扩展之后，!var!形式的变量在用之前才会评估确切的值，这是一个知识点，也是一个易错点，特别是在for循环中要格外注意，因为for循环语句的循环体括号中，所有的操作被看成是同一行，所以经常会用到延迟环境变量扩展。 总结 for循环在cmd命令行中的固定用法for %i in (set) do (...)，循环变量格式为%i for循环在bat处理程序中的固定用法for %%i in (set) do (...)，循环变量格式为%%i 至于为什么for语法在批处理中需要多写一个%，希望知道的小伙伴能给出答案和参考资料，不胜感激 想要变量被使用的时候再评估值需要开启延迟环境变量扩展，语法为setlocal enabledelayedexpansion，同时使用!var!形式的变量]]></content>
      <categories>
        <category>bat</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下常用的打包、压缩、解压命令（tar、gzip、bzip2、zip）]]></title>
    <url>%2Fblog%2F2019%2F11%2F06%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E5%B8%B8%E7%94%A8%E7%9A%84%E6%89%93%E5%8C%85%E3%80%81%E5%8E%8B%E7%BC%A9%E3%80%81%E8%A7%A3%E5%8E%8B%E5%91%BD%E4%BB%A4%EF%BC%88tar%E3%80%81gzip%E3%80%81bzip2%E3%80%81zip%EF%BC%89%2F</url>
    <content type="text"><![CDATA[前言经常使用电脑的人常常会接触到压缩文件，不管是软件、数据还是资料，下载之后通常就是一个压缩包，在Windows平台上如果安装了WinRAR或者360压缩，不管是什么格式的压缩文件，一般点击压缩文件右键选择解压选项即可，非常地方便。正因为长时间在Windows平台上方便的解压文件，导致我对打包、压缩的概念理解错误，结果在linux操作压缩文件时有很多疑问，今天终于明白了一点，专门总结一下，同时列举常用的压缩、解压命令，方便日后查找使用。 linux上操作压缩文件也是通过命令实现的，但是压缩文件的后缀有很多，比如.tar.gz、.tar.bz2、.gz、.zip、.Z等等，而生成和解压这些文件的命令同样很多，比如tar、gzip、bzip2、zip、unzip等，看得人眼花缭乱，记忆的过程中也常常出现偏差，不是命令不对应就是参数错误，特别是一些不常用的压缩格式，经常需要查询尝试，浪费了不少时间，其实造成这些问题的原因还是由于对打包压缩的概念不太清楚，接下来先了解一下这些概念。 基础概念在Windows上经常直接在图形化界面上操作压缩和解压文件，导致我将这种操作行为带到了linux上，而实际上在linux上压缩和解压文件之外还有一个操作就是“打包”，原因就是linux的压缩和解压通常作用在一个文件上，如果想将一大堆文件压缩最终成为一个文件，需要先打成一个包，然后对这个包文件进行压缩。 打包/归档打包或者叫归档，就是将多个文件和目录（也可以是一个文件）就变成了一个总的文件，但不是将所有文件进行融合，使用tar命令。 压缩压缩是将一个大的文件通过特定的压缩算法尽可能变成一个小文件，可以减少存储空间，加快网络传输效率，使用gzip、bzip2、zip等命令。 解压解压是将压缩生成的最终的小文件还原为压缩之前的大文件，可以使用gzip、gunzip、bunzip2、unzip等命令。 打包压缩通过上面的概念解析我们可以知道，我们之前所说的压缩操作通常是指打包和压缩两个步骤，由于linux大部分的压缩命令都是只能压缩一个文件，所以在压缩之前需要将待压缩的所有文件先进行打包，生成一个文件后再进行压缩操作。 明白了打包和压缩操作的含义，我们可以通过一些约定俗成的命名规则，选择合适的压缩和解压方法，比如下面这些文件： xxx.tar：这是一个归档文件，也就是只通过tar进行了打包操作 xxx.tar.gz：这是一个压缩文件，打包之后，以gzip方式进行了压缩 xxx.tar.bz2：这是一个压缩文件，打包之后，以bzip2方式进行了压缩 xxx.gz：这是一个压缩文件，没有经过打包操作，只是gzip方式进行了压缩 如果能按照这些命名规则生成压缩文件，那么解压文件的时候会方便很多，但有时压缩文件的扩展名是不标准的，可以通过file命令查看文件实际的格式，使用方法如下： 12345[albert@localhost#15:03:05#/home/albert/compress]$file test.tar.bz2test.tar.bz2: bzip2 compressed data, block size = 900k[albert@localhost#15:03:24#/home/albert/compress]$file test.tar.gztest.tar.gz: gzip compressed data, from Unix, last modified: Wed Nov 6 12:02:05 2019 压缩解压命令压缩文件的格式和命令真的是太多，所以在此总结一份常用命令表格，方便日后需要的时候直接拿来就用，加快解决问题的速度。假设原始文件是a.log和b.txt，当前目录下还有一个output目录，可以作为解压后存放文件的目录，那么常用压缩和解压命令如下： 文件格式 压缩命令 命令备注 解压命令 命令备注 xxx.tar tar -cvf test.tar a.log b.txt - tar -xvf test.tar -C ./output 不使用-C则解包在当前目录 xxx.tar.gz tar -zcvf test.tar.gz a.log b.txt - tar -zxvf test.tar.gz -C ./output 不使用-C则解压在当前目录 xxx.tar.bz2 tar -jcvf test.tar.bz2 a.log b.txt - tar -jxvf test.tar.bz2 -C ./output 不使用-C则解压在当前目录 xxx.tar.Z tar -Zcvf test.tar.Z a.log b.txt - tar -Zxvf test.tar.Z -C ./output 不使用-C则解压在当前目录 xxx.gz gzip -c a.log &gt; test.gz、gzip a.log 前者保留a.log，后者直接删除a.log gzip -d test.gz、gunzip test.gz 不能指定解压文件存储目录 xxx.bz2 bzip2 -c a.log &gt; test.bz2、bzip2 a.log 前者保留a.log，后者直接删除a.log bzip2 -d test.bz2、bunzip2 test.bz2 不能指定解压文件存储目录 xxx.Z compress -c a.log &gt; test.Z、compress a.log 前者保留a.log，后者直接删除a.log compress -d test.Z、uncompress test.Z 不能指定解压文件存储目录 xxx.rar rar a test.rar a.log - unrar e test.rar 将e选项换成x可以指定目录 xxx.zip zip test.zip a.log b.txt - unzip test.zip -d ./output 不使用-d则解压在当前目录 分析对比上面的压缩也解压命令可以发现，tar这个命令可以将打包和压缩合并到一起，也可以将解压和解包合并到一起，只需要修改选项中的参数就可以调用不同的程序压缩或者解压，比如-cvf表示只打包不压缩，而-zcvf表示打包后使用gzip压缩，改为-jcvf表示打包后使用bzip2压缩，其实还有很多的压缩方式，可以参考一下tar命令的帮助文档，具体压缩选项如下。 压缩选项: -a, –auto-compress 使用归档后缀名来决定压缩程序 -I, –use-compress-program=PROG 通过 PROG 过滤(必须是能接受 -d 选项的程序) -j, –bzip2 通过 bzip2 过滤归档 -J, –xz 通过 xz 过滤归档 –lzip 通过 lzip 过滤归档 –lzma 通过 lzma 过滤归档 –lzop –no-auto-compress 不使用归档后缀名来决定压缩程序 -z, –gzip, –gunzip, –ungzip 通过 gzip 过滤归档 -Z, –compress, –uncompress 通过 compress 过滤归档 总结 上述这些命令只是基础用法，还有很多参数选型没有提到，比如tar -tf test.tar可以不解压直接查看归档文件中的内容。 gzip命令只能压缩一个文件，如果在命令后面添加多个文件，则会分别压缩生成多个文件。 据说compress命令是一个相当古老的 unix 档案压缩指令，现在基本被gzip命令取代了。 由于文中涉及的命令较多，难免有些笔误，为了不传播错误用法，我也进行了多次检查，如果大家还发现其他错误，欢迎批评指正。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>tar</tag>
        <tag>gzip</tag>
        <tag>bzip2</tag>
        <tag>zip</tag>
        <tag>打包</tag>
        <tag>压缩</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb调试程序时跳进函数和跳出函数]]></title>
    <url>%2Fblog%2F2019%2F11%2F01%2Fgdb%E8%B0%83%E8%AF%95%E7%A8%8B%E5%BA%8F%E6%97%B6%E8%B7%B3%E8%BF%9B%E5%87%BD%E6%95%B0%E5%92%8C%E8%B7%B3%E5%87%BA%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言说实话平时在Windows平台上开发，gdb调试用的并不是很多，但是一些在linux平台才会出现的BUG，或者在linux运行时宕机产生了core文件，这些还是需要使用gdb调试的，之前的文章《linux环境下服务器程序的查看与gdb调试》列举了常用的gdb命令，基本上调试一些core文件和简单bug使用这些命令足以了，但是新的需求总是会出现。 新的需求也很常见，就是跳进一个函数，调试一部分代码后还要跳出这个函数，一般情况就是这个函数特别长，调试前几行已经明白函数的逻辑和用意，如果使用 next 命令逐行运行需要花费较多时间，所以需要跳出函数回到调用的位置，这两个操作在Visual Studio中的快捷键分别是F11和Shift+F11，使用起来非常的方便，其实在gdb调试的过程中也有对应的命令，分别是step(s)和finish(fin)，括号中的内容为命令的简写，此外还有一个return命令也可以使函数返回，接下来可以看一下它们的区别。 测试代码测试的代码很简单，只需要写一个简单的函数，并且在主函数中调用这个函数即可，代码如下： 12345678910111213141516171819#include &lt;iostream&gt;using namespace std;int son_func()&#123; int a = 100; int b = 1; return a + b;&#125;int main()&#123; int i = 10; cout &lt;&lt; i &lt;&lt; endl; int result = son_func(); cout &lt;&lt; result &lt;&lt; endl;&#125; 代码编译编译代码时只需要注意一点，那就是加上-g选项，否则可能会影响调试： 1albert@localhost#11:56:18#/home/albert/gdbtest]$g++ -g stepfinish.cpp -o stepfinishtest step/finish组合这个组合不会影响函数的运行结果，简单的调试过程如下： 1234567891011121314151617181920212223242526272829303132333435363738394041[albert@localhost#11:32:17#/home/albert/gdbtest]$gdb stepfinishtestGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/gdbtest/stepfinishtest...done.(gdb) startTemporary breakpoint 1 at 0x400809: file stepfinish.cpp, line 13.Starting program: /home/albert/gdbtest/stepfinishtestTemporary breakpoint 1, main () at stepfinish.cpp:1313 int i = 10;Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-23.el6.x86_64(gdb) n14 cout &lt;&lt; i &lt;&lt; endl;(gdb) n1016 int result = son_func();(gdb) stepson_func () at stepfinish.cpp:66 int a = 100;(gdb) finishRun till exit from #0 son_func () at stepfinish.cpp:60x0000000000400831 in main () at stepfinish.cpp:1616 int result = son_func();Value returned is $1 = 101(gdb) n18 cout &lt;&lt; result &lt;&lt; endl;(gdb) n10119 &#125;(gdb) cContinuing.Program exited normally.(gdb) 首先使用start命令启动程序，然后使用next(n)命令让程序运行到调用函数son_func()所在的行，使用step命令进入函数，我们看到a的值为100，假设这时我们想回到这个函数被调用的位置，直接敲finish命令就可以，函数完整的执行并返回结果101，最后连续执行next(n)命令，程序正常退出，整个过程只是调试查看数据，并没有改变程序运行结果。 step/return组合这个组合有可能会影响函数的运行结果，具体要看return命令使用的位置和返回的参数： 12345678910111213141516171819202122232425262728293031323334353637383940414243[albert@localhost#11:53:42#/home/albert/gdbtest]$gdb stepfinishtestGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/gdbtest/stepfinishtest...done.(gdb) startTemporary breakpoint 1 at 0x400809: file stepfinish.cpp, line 13.Starting program: /home/albert/gdbtest/stepfinishtestTemporary breakpoint 1, main () at stepfinish.cpp:1313 int i = 10;Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-23.el6.x86_64(gdb) n14 cout &lt;&lt; i &lt;&lt; endl;(gdb) n1016 int result = son_func();(gdb) stepson_func () at stepfinish.cpp:66 int a = 100;(gdb) n7 int b = 1;(gdb) return 119Make son_func() return now? (y or n) y#0 0x0000000000400831 in main () at stepfinish.cpp:1616 int result = son_func();(gdb) n18 cout &lt;&lt; result &lt;&lt; endl;(gdb) print result$1 = 119(gdb) cContinuing.119Program exited normally.(gdb) 首先同样使用start命令启动程序，然后使用next(n)命令让程序运行到调用函数son_func()所在的行，使用step命令进入函数，我们看到a的值为100，这时再敲入next(n)命令让程序运行一步，可以看到b的值为1，假设这时我们想返回一个自定义值而不返回a+b的结果，可以直接敲命令return 119，表示直接返回119这个值，再打印返回值变量result发现是值119，跳出函数的同时，程序运行结果也已经被我们改变了。 总结 gdb中跳入函数的命令是step，相当于Visual Studio中的快捷键F11 gdb中跳出函数的命令是finish，相当于Visual Studio中的快捷键Shift+F11，函数完整执行后返回 gdb中还有一个直接返回的命令是return，它会跳过当前函数后面的语句直接返回，返回值可以自定义，紧跟在return命令后面即可]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>linux</tag>
        <tag>gdb</tag>
        <tag>step</tag>
        <tag>finish</tag>
        <tag>return</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python使用scatter函数绘制点在线的上层]]></title>
    <url>%2Fblog%2F2019%2F10%2F30%2FPython%E4%BD%BF%E7%94%A8scatter%E5%87%BD%E6%95%B0%E7%BB%98%E5%88%B6%E7%82%B9%E5%9C%A8%E7%BA%BF%E7%9A%84%E4%B8%8A%E5%B1%82%2F</url>
    <content type="text"><![CDATA[前言前几天在QQ群里发现有人问这样一个问题，使用Python的matplotlib库绘制图形时，函数 scatter() 绘制的点总是在 plot() 函数绘制的线下边，看起来样子很丑，大概就是下图这个样子，问有没有方法让点显示到线的上面。 看到这个问题一开始以为是绘制顺序的原因，调整 scatter() 函数和 plot() 函数的调用顺序并没有达到预想的效果，点还是在线的下面，原来一直没注意这个问题，是因为我一直把线和标注用的点使用了同一种颜色，所有看不出来是谁覆盖了谁，现在抛出这个问题居然让人有点不知所措，直觉上认定肯定有个属性可以设置这个显示顺序，但究竟是图的属性？坐标轴的属性？还是函数的参数呢？这个还需要查一查。 解决办法最后经过一顿查找发现函数 scatter() 和 plot() 都有个参数 zorder，这时候才恍然大悟，做游戏界面开发时常常使用这个参数来控制UI的层级，现在怎么突然忘了呢，赶紧设置一下发现与原来在游戏开发中的参数含义相同，zorder这个整数越大，显示的时候越靠上，所以写了下面的测试代码： 1234567891011121314import numpy as npimport matplotlib.pyplot as pltdef draw_point_on_line(): plt.title("draw point on line") plt.xlabel("x-axis") plt.ylabel("y-axis") X = np.linspace(1, 100, 10, endpoint=True) Y = np.random.randint(60, 100, len(X)) plt.plot(X, Y, color ='blue', linewidth=3.5, zorder=1) # 在第一层画线 plt.scatter(X, Y, 50, color ='red', zorder=2) # 在第二层画点 plt.show() 效果展示这次终于正常了，因为scatter()函数中的zorder值较大，所以放到上面绘制，效果如下： 总结 帮助他人解决问题是一个自我提升的好机会 有很多我们认为很简单的事情，其实并不是我们想的那样 代码文件前后图例代码对比-传送门]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>matplotlib</tag>
        <tag>plt</tag>
        <tag>scatter</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python切割超大日志文件、保留文件最后几行]]></title>
    <url>%2Fblog%2F2019%2F10%2F24%2FPython%E5%88%87%E5%89%B2%E8%B6%85%E5%A4%A7%E6%97%A5%E5%BF%97%E6%96%87%E4%BB%B6%E3%80%81%E4%BF%9D%E7%95%99%E6%96%87%E4%BB%B6%E6%9C%80%E5%90%8E%E5%87%A0%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[前言关于日志这个东西的存在，主要是为了记录发生的事情，编程的过程中也常常用到，记得我们在刚刚学习编程的时候，常常会出现程序错误，这时候就需要输出一下，其实这个输出也是日志的一种体现，随着编程水平的提升，各种调试工具和方法渐渐进入我们的视线，但是输出一下这种方法却一直被使用，特别是一些偶发性问题，调试工具很难捕捉到他们，这时候往往需要将中间过程输出到日志文件中，这些日志文件就是我们分析问题的基础。 随着程序规模的渐渐扩大，出现问题时需要打印的日志也越来越多，最近就出现这样一个情况，游戏程序总是莫名的崩溃，看代码找不到问题的原因，所以采用了打印日志文件的方法，有时候大约跑半天就能出现崩溃，日志文件大概600M，Windows系统自带的记事本很难打开，但是使用Notepad++等几秒钟是可以看到内容的。 比较变态的是最近一次跑了2天才崩溃，导出日志文件发现大概有3G，这次使用Notepad++打开时也卡死了，使用sublime打开时进度卡在了80%左右，据说非常强大的GVim打开文件时也毫无反应了，这就尴尬了，崩溃之前的日志内容就在文件中，可是我们却看不见。 问题出现问题很明显摆在这了，文件由于太大无法看到其中的内容，得想个办法。很直接的一个想法就进入了脑海，把文件拆开成几份，这样每个文件缩小了就可以看到了啊，所以我们找到了一个解决问题的办法，接下来使用Python来简单写一下切分文件。 分割日志文件按照文件大小分割分割文件的规则需要先确定一下，可以很简单的按照文件大小分割，一个源文件大小为10M的日志文件，可以切分成10个大小为1M的日志文件，分割的大小不用太绝对，每一份近似相等就可以，整体思路就是先获得源文件的大小，然后计算出分割结束每个文件的大小，接着不断从源文件中读内容，往目标文件中写内容，达到之前计算的字节大小时，再生成新的目标文件，简单代码如下： 12345678910111213141516171819202122import osDATA_LEN_PER_READ = 1024 * 1024def split_file_by_size(file_name, parts=3): file_size = os.path.getsize(file_name) per_file_size = file_size//parts file_size_list = [] for x in range(parts-1): file_size_list.append(per_file_size) file_size_list.append(file_size-per_file_size*(parts-1)) output_file, ext = os.path.splitext(file_name) with open(file_name, 'rb') as rfile: for n in range(parts): with open('&#123;0&#125;_part&#123;1&#125;&#123;2&#125;'.format(output_file, n+1, ext), 'wb') as wfile: read_size = 0 while read_size &lt; file_size_list[n]: want_read = min(DATA_LEN_PER_READ, file_size_list[n] - read_size) wfile.write(rfile.read(want_read)) read_size += want_read 按照文件行数分割以上按照文件大小分割的日志文件有一点小问题，不能保证行是完整的，当遇到汉字这种占用多字节的字符，甚至都不能保证汉字是完整的，所以我们可以换一个思路，尝试使用按照行数分割，整体思路就是先获得文件的行数，然后计算出分割结束每个文件的行数，接着不断从源文件中一行行读内容，往目标文件中一行行写内容，达到之前计算的文件行数时，再生成新的目标文件，简单代码如下： 12345678910111213141516171819202122232425import osdef get_file_line_count(file_name): line_count = 0 for index, line in enumerate(open(file_name, 'r')): line_count += 1 return line_countdef split_file_by_line(file_name, parts=3): total_line = get_file_line_count(file_name) per_file_line = total_line//parts file_line_list = [] for x in range(parts-1): file_line_list.append(per_file_line) file_line_list.append(total_line-per_file_line*(parts-1)) output_file, ext = os.path.splitext(file_name) with open(file_name, 'rb') as rfile: for n in range(parts): with open('&#123;0&#125;_part&#123;1&#125;&#123;2&#125;'.format(output_file, n+1, ext), 'wb') as wfile: read_line = 0 while read_line &lt; file_line_list[n]: wfile.write(rfile.readline()) read_line += 1 获取日志文件尾部内容对于分析奔溃这类问题，出现问题的日志往往就在最后几行，所以没有必要非得打开整个日志文件，也不一定需要将整个文件分割成几部分，只需将日志文件的最后一部分读出来写到新的文件中供我们分析就可以了，这时候开头几个字符的不完整也是可以接受的，所以没必要按行读取，只需按照经验，从尾部截取指定字节大小的内容就可以了，比如我们的日志，最后有用的部分也就10M左右，一般的文本文件就都能打开了。 代码思路就是先打开文件，然后将读指针定位到尾部往前10M左右，然后读取所有内容保存到新的文件中，简单的代码示例如下： 12345678import osdef tailslice(file_name, data_size= 1024): output_file, ext = os.path.splitext(file_name) with open(file_name, 'rb') as rfile: rfile.seek(-data_size, 2) with open('&#123;0&#125;_tail&#123;1&#125;'.format(output_file, ext), 'wb') as wfile: wfile.write(rfile.read()) 总结 有时候要问题需要变通一下，如果一个文件大到打不开的地步，我们就把它分割成可以接受的范围 当文件中的内容只有一部分可用时，我们完全可以不分割，直接取出可用部分即可。 代码传送门 分割超大日志文件 获取日志文件尾部内容]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>日志文件</tag>
        <tag>split</tag>
        <tag>切割</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中查询当前用户、当前数据库等基础信息]]></title>
    <url>%2Fblog%2F2019%2F10%2F14%2FMysql%E4%B8%AD%E6%9F%A5%E8%AF%A2%E5%BD%93%E5%89%8D%E7%94%A8%E6%88%B7%E3%80%81%E5%BD%93%E5%89%8D%E6%95%B0%E6%8D%AE%E5%BA%93%E7%AD%89%E5%9F%BA%E7%A1%80%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[前言生活中有时会出现灵魂三问：我是谁？我在哪？我在做什么？特别的喝醉酒的第二天，完全不记得昨天发生了什么。而在数据库操作中也会出现这种灵魂拷问，我用的是哪个用户，为什么会没有权限？我操作的是哪个数据库，刚刚不会把线上正式服务器数据删了吧？ 上面描述的问题常常出现在切换数据库处理问题的时候，通过一个客户端连接到Mysql数据库服务器，操作数据库1，然后切换再操作数据库2，这时如果中间有人打扰，很容易忘记刚刚操作的是哪个数据库，或者中途处理个其他紧急的事情，回来连操作的用户都忘了，这时就需要一些基础信息的查询命令，帮助你来恢复记忆。 数据库基础信息查询数据库的基础信息涉及到方方面面，这里只列举几个常用的查询命令，用来回答上面的灵魂拷问，其他命令还有很多，用到了再总结吧。 查询当前操作的用户1234567mysql&gt; select user();+----------------+| user() |+----------------+| root@localhost |+----------------+1 row in set (0.07 sec) 查询当前操作的数据库1234567mysql&gt; select database();+------------+| database() |+------------+| sqltest2 |+------------+1 row in set (0.09 sec) 查询当前数据库端口1234567mysql&gt; show variables like 'port';+---------------+-------+| Variable_name | Value |+---------------+-------+| port | 3306 |+---------------+-------+1 row in set (0.07 sec) 查询当前数据库版本1234567mysql&gt; select version();+------------+| version() |+------------+| 5.7.21-log |+------------+1 row in set (0.06 sec) 数据库结构信息查询这里的结构我指的是DDL中定义的那些元素，比如表、存储过程等，有一些常用的查询命令，要是一段时间不使用还是会忘记，比如查询一个数据库中的存储过程，每次查询时都要上网搜一下，所以今天总结在一起方便查找。 查询当前数据库中的所有表1234567891011121314mysql&gt; show tables;+--------------------+| Tables_in_sqltest2 |+--------------------+| a || b || c || d || m || p || tb_test || tb_with_index |+--------------------+14 rows in set (0.11 sec) 查询创建表的sql语句12345678910mysql&gt; show create table a;+-------+----------------------------------------+| Table | Create Table |+-------+----------------------------------------+| a | CREATE TABLE `a` ( `id` int(11) DEFAULT NULL, `num` int(11) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8 |+-------+----------------------------------------+1 row in set (0.11 sec) 查询指定表中的所有字段12345678mysql&gt; desc a;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.12 sec) 查询当前数据库中的所有存储过程这个命令我得吐槽一下，为什么不能像查询当前数据库的中所有表一样，搞个show procedures;命令，非得通过where子句指定数据库呢，具体的原因还不知道，等我弄明白了再回来补充。123456789mysql&gt; show procedure status where db='sqltest2';+----------+-----------------------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+| Db | Name | Type | Definer | Modified | Created | Security_type | Comment | character_set_client | collation_connection | Database Collation |+----------+-----------------------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+| sqltest2 | fill_slow_query_test | PROCEDURE | root@localhost | 2019-03-25 11:14:01 | 2019-03-25 11:14:01 | DEFINER | | utf8mb4 | utf8mb4_general_ci | utf8_general_ci || sqltest2 | fill_tb_without_index | PROCEDURE | root@localhost | 2019-03-18 09:53:32 | 2019-03-18 09:53:32 | DEFINER | | utf8mb4 | utf8mb4_general_ci | utf8_general_ci || sqltest2 | fill_tb_with_index | PROCEDURE | root@localhost | 2019-03-18 09:53:33 | 2019-03-18 09:53:33 | DEFINER | | utf8mb4 | utf8mb4_general_ci | utf8_general_ci |+----------+-----------------------+-----------+----------------+---------------------+---------------------+---------------+---------+----------------------+----------------------+--------------------+3 rows in set (0.17 sec) 查询创建存储过程的sql语句1234567891011121314151617mysql&gt; show create procedure fill_tb_with_index;+--------------------+----------------------------------------------------------------+-------------------+----------------------+----------------------+--------------------+| Procedure | sql_mode | Create Procedure | character_set_client | collation_connection | Database Collation |+--------------------+----------------------------------------------------------------+-------------------+----------------------+----------------------+--------------------+| fill_tb_with_index | STRICT_TRANS_TABLES,NO_AUTO_CREATE_USER,NO_ENGINE_SUBSTITUTION |CREATE DEFINER=`root`@`localhost` PROCEDURE `fill_tb_with_index`()BEGIN DECLARE i int default 1; WHILE i &lt;= 100000 do insert into tb_with_index values(i, i, i); set i = i + 1; END WHILE;END | utf8mb4 | utf8mb4_general_ci | utf8_general_ci |+--------------------+----------------------------------------------------------------+-------------------+----------------------+----------------------+--------------------+1 row in set (0.09 sec) 查询指定表上的索引123456789mysql&gt; show index from tb_with_index;+---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |+---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+| tb_with_index | 1 | id_index | 1 | id | A | 100035 | NULL | NULL | YES | BTREE | | || tb_with_index | 1 | num_index | 1 | num | A | 98715 | NULL | NULL | YES | BTREE | | || tb_with_index | 1 | money_index | 1 | money | A | 100035 | NULL | NULL | YES | BTREE | | |+---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+3 rows in set (0.03 sec) 查询当前用户连接的权限1234567mysql&gt; show grants;+---------------------------------------------------------------------+| Grants for root@localhost |+---------------------------------------------------------------------+| GRANT ALL PRIVILEGES ON *.* TO 'root'@'localhost' WITH GRANT OPTION || GRANT PROXY ON ''@'' TO 'root'@'localhost' WITH GRANT OPTION |+---------------------------------------------------------------------+ 查询指定用户连接的权限1234567mysql&gt; show grants for 'guest';+---------------------------------------------------------------------------------------------------------------+| Grants for guest@% |+---------------------------------------------------------------------------------------------------------------+| GRANT ALL PRIVILEGES ON *.* TO 'guest'@'%' IDENTIFIED BY PASSWORD '*6C8DE74065898C44C21EF74D67A834C5256BFA1C' |+---------------------------------------------------------------------------------------------------------------+1 row in set (0.00 sec) 总结 以上总结的查询语句都是我经常用到，相比Mysql所有查询语句来说简直是冰山一角，总结到一起主要是方便日后查找，同时也希望给他人带来帮助 查看这些语句会发现，有些是select开头，有些是show开头，实际上很多show开头的都是对information_schema数据库数据的封装 information_schema 数据库是Mysql系统自带的数据库，记录了整个数据库实例上所有数据结构信息，更像是记录数据库的数据库，包含表结构、字符集，权限等太多的信息，有机会后续找时间聊聊这个数据库，在此就不展开了 正因为很多show开头的都是对information_schema数据库数据的封装，所以这些查询语句基本都可以通过在information_schema数据库查询得到，比如show procedure status where db=&#39;sqltest2&#39;;就可以改写成select routine_name from information_schema.routines where routine_schema=&#39;sqltest2&#39;; 此时此刻，我正在距离天安门500多米的现场等待阅兵仪式的开始，一边学习一边为祖国庆生的感觉真好！（注：500多米多了5公里，现场是卧室床前的电视机旁，这么近的距离不知道一会能不能看见接受检阅的飞机o(\￣︶￣*)o）*]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>用户</tag>
        <tag>当前信息</tag>
        <tag>表结构</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下C++代码打印函数堆栈调用情况]]></title>
    <url>%2Fblog%2F2019%2F09%2F06%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8BC-%E4%BB%A3%E7%A0%81%E6%89%93%E5%8D%B0%E5%87%BD%E6%95%B0%E5%A0%86%E6%A0%88%E8%B0%83%E7%94%A8%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[前言关于什么是函数调用堆栈在上篇文章《windows环境下C++代码打印函数堆栈调用情况》中已经介绍过了，简单的来说就是可以展现出函数之间的调用关系，上篇文章展示了如何在windows上打印出函数调用堆栈，其中用到了windows系统上的API，这些接口在linux上是无法使用的，因为工作的关系，也常常需要在linux的调试程序，所以本文介绍一下如何在linux上打印出C++程序的调用堆栈。 实现打印堆栈信息的函数在linux系统上想打印函数调用堆栈信息，需要引用头文件&lt;execinfo.h&gt;，然后利用函数backtrace、backtrace_symbols来获取当时的函数调用堆栈信息，以下的代码实现了一个简单的打印堆栈新的函数，堆栈深度最大同样设置为12层。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162#include &lt;execinfo.h&gt;#include &lt;unistd.h&gt;#include &lt;string.h&gt;#include &lt;stdio.h&gt;#define STACK_INFO_LEN 1024void ShowTraceStack(const char* szBriefInfo)&#123; static const int MAX_STACK_FRAMES = 12; void *pStack[MAX_STACK_FRAMES]; static char szStackInfo[STACK_INFO_LEN * MAX_STACK_FRAMES]; char ** pStackList = NULL; int frames = backtrace(pStack, MAX_STACK_FRAMES); pStackList = backtrace_symbols(pStack, frames); if (NULL == pStackList) return; strcpy(szStackInfo, szBriefInfo == NULL ? "stack traceback:\n" : szBriefInfo); for (int i = 0; i &lt; frames; ++i) &#123; if (NULL == pStackList[i]) break; strncat(szStackInfo, pStackList[i], STACK_INFO_LEN); strcat(szStackInfo, "\n"); &#125; printf("%s", szStackInfo); // 输出到控制台，也可以打印到日志文件中&#125;void func2()&#123; bool isError = true; if (isError) &#123; ShowTraceStack("error in func2\n"); &#125; else &#123; printf("this is func2\n"); &#125;&#125;void func1()&#123; int sum = 0; for (int i = 0; i &lt; 100; ++i) sum += i; func2();&#125;int main(int argc, char* argv[])&#123; printf("hello world\n"); func1(); return 0;&#125; 显示堆栈调用信息上面的测试代码中函数的调用逻辑为：main()函数调用func1()函数，然后func1()函数调用func2()函数，当func2()中发生问题的时候打印当时的堆栈信息，然后我们编译一下查看运行结果 12345678910[albert@localhost#10:59:03#/home/albert/test/backtrace]$g++ -rdynamic linuxtraceback.cpp -o linuxtraceback[albert@localhost#10:59:05#/home/albert/test/backtrace]$./linuxtracebackhello worlderror in func2./linuxtraceback(_Z14ShowTraceStackPKc+0x25) [0x400a19]./linuxtraceback(_Z5func2v+0x1c) [0x400b06]./linuxtraceback(_Z5func1v+0x32) [0x400b46]./linuxtraceback(main+0x1e) [0x400b66]/lib64/libc.so.6(__libc_start_main+0xfd) [0x7fbbcae43d1d]./linuxtraceback() [0x400939] 上面的运行结果已经展示了程序函数的调用关系，其中编译选项中的-rdynamic是很重要的，它实际上是一个链接选项，作用是把所有符号（而不仅仅只是程序已使用到的外部符号）都添加到动态符号表里，以便那些通过 dlopen() 或 backtrace()这样的函数使用，换句话说就是如果不加这个选项在调用堆栈中就可能看不到函数名。 上面的调用堆栈中函数名大致能看出来，但是有些奇怪的字母，可以通过工具c++fileter来处理，处理之后就可以看到正常的函数名了，具体使用方式如下：123456789[albert@localhost#10:59:12#/home/albert/test/backtrace]$./linuxtraceback | c++filthello worlderror in func2./linuxtraceback(ShowTraceStack(char const*)+0x25) [0x400a19]./linuxtraceback(func2()+0x1c) [0x400b06]./linuxtraceback(func1()+0x32) [0x400b46]./linuxtraceback(main+0x1e) [0x400b66]/lib64/libc.so.6(__libc_start_main+0xfd) [0x7f73aea34d1d]./linuxtraceback() [0x400939] 编译时无法添加-rdynamic选项如果是自己写的小项目或者小程序，编译选项是可以随便改的，没有什么关系，需要查看堆栈信息加上-rdynamic就可以了，但是如果是公司的大型项目，编译选项是不会随便改的，可能是直接使用automake生成的，先来看一下不添加-rdynamic选项编译之后的运行结果 12345678910[albert@localhost#11:22:15#/home/albert/test/backtrace]$g++ linuxtraceback.cpp -o linuxtraceback[albert@localhost#11:22:18#/home/albert/test/backtrace]$./linuxtracebackhello worlderror in func2./linuxtraceback() [0x4007d9]./linuxtraceback() [0x4008c6]./linuxtraceback() [0x400906]./linuxtraceback() [0x400926]/lib64/libc.so.6(__libc_start_main+0xfd) [0x7f4e12ba2d1d]./linuxtraceback() [0x4006f9] 可以看到不添加-rdynamic选项编译之后运行虽然能显示出调用堆栈，但都是一些函数地址，无法看到函数名，这时可以通过工具addr2line帮助我们定位问题，这个工具的作用就是将函数地址转换成函数所在的行，使用方法就是在命令行运行addr2line 0x4008c6 -e ./linuxtraceback，具体使用时替换函数地址和可运行程序的名字即可 说实话这个小程序中使用运行addr2line 0x4008c6 -e ./linuxtraceback没有看到我想要的，只显示了??:0，仿佛被优化掉了，但是我在正式的项目中使用这个方法是可以得到函数所在行的，这也帮助我查到了一个隐藏很深的BUG。 总结 linux平台下可以利用函数backtrace、backtrace_symbols、backtrace_symbols_fd来获取当时的函数调用堆栈信息 使用上述函数时，需要引用头文件&lt;execinfo.h&gt;，编译时最好加上-rdynamic选项 如果实在无法添加-rdynamic，可以通过addr2line辅助查找问题 程序源码打印堆栈信息–源码传送门]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>linux</tag>
        <tag>函数</tag>
        <tag>堆栈</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[windows环境下C++代码打印函数堆栈调用情况]]></title>
    <url>%2Fblog%2F2019%2F09%2F03%2Fwindows%E7%8E%AF%E5%A2%83%E4%B8%8BC-%E4%BB%A3%E7%A0%81%E6%89%93%E5%8D%B0%E5%87%BD%E6%95%B0%E5%A0%86%E6%A0%88%E8%B0%83%E7%94%A8%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[前言程序运行的过程中，函数之间的是会相互调用的，在某一时刻函数之间的调用关系，可以通过函数调用堆栈表现出来，这个调用堆栈所展现的就是函数A调用了函数B，而函数B又调用了函数C，这些调用关系在代码中都是静态的，不需要程序运行就可以知道。 既然函数之间的调用关系可以通过分析代码就可以知道，那么查看函数调用的堆栈是不是作用不大了呢？事实上恰恰相反，查看函数调用堆栈的作用非常大。因为在较大型的项目中，函数之间的调用不是简单的一条线，常常会出现复杂的网状结构，这时如果函数C被调用了，可能不是仅仅是B函数调用过来的，也有可能是D、E、F等函数调用了C函数，所以知道在程序运行时究竟是哪个函数调用了C函数显得很重要，特别是有众多函数会调用C函数的时候。 查看函数堆栈的作用举个例子就明白了，假如C函数中逻辑的执行需要一些特殊条件状态，理论上执行C函数时这些条件都应该满足的，但是程序在运行的过程中有时运行C函数时条件就是不满足的，那就说明有些调用C函数的逻辑分支有问题，无法满足C函数中逻辑所需条件，这时候知道是谁调用C函数导致条件不满足就是确定问题的关键。 如果是在VS调试状态下，在C函数不满足条件的逻辑中打一个断点，然后运行程序等待断点触发时，就可以通过VS工具自带的调用堆栈窗口，就可以看到程序从主函数main()开始怎样一步步调用的出错的函数C的。 可实际项目中，出错的时候不总是在VS的调试状态下，也有可能发生在程序实际的工作环境中，这时没有办法通过加断点来查看调用堆栈，如果此时有一个函数，可以打印当前的函数调用堆栈那就太好了，这样我就可以在需要调试的逻辑中，调用这个函数，将当时的函数调用堆栈信息打印到文件中，方便查找程序逻辑问题，这篇文章要做的就是在Windows环境下，利用现有的API实现这样一个函数。 实现打印堆栈信息的函数在Windows系统上想打印函数调用堆栈信息，需要引用头文件&lt;dbghelp.h&gt;，添加库引用DbgHelp.Lib，然后利用函数CaptureStackBackTrace、SymFromAddr、SymGetLineFromAddr64来获取当时的函数调用堆栈信息，以下的代码实现了一个简单的打印堆栈新的函数，堆栈深度最大设置为12层，实际情况肯定是越深越好，设置为12一般就可以查到问题了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include &lt;windows.h&gt;#include &lt;dbghelp.h&gt;#include &lt;stdio.h&gt;#if _MSC_VER#define snprintf _snprintf#endif#define STACK_INFO_LEN 1024void ShowTraceStack(char* szBriefInfo)&#123; static const int MAX_STACK_FRAMES = 12; void *pStack[MAX_STACK_FRAMES]; static char szStackInfo[STACK_INFO_LEN * MAX_STACK_FRAMES]; static char szFrameInfo[STACK_INFO_LEN]; HANDLE process = GetCurrentProcess(); SymInitialize(process, NULL, TRUE); WORD frames = CaptureStackBackTrace(0, MAX_STACK_FRAMES, pStack, NULL); strcpy(szStackInfo, szBriefInfo == NULL ? "stack traceback:\n" : szBriefInfo); for (WORD i = 0; i &lt; frames; ++i) &#123; DWORD64 address = (DWORD64)(pStack[i]); DWORD64 displacementSym = 0; char buffer[sizeof(SYMBOL_INFO)+MAX_SYM_NAME * sizeof(TCHAR)]; PSYMBOL_INFO pSymbol = (PSYMBOL_INFO)buffer; pSymbol-&gt;SizeOfStruct = sizeof(SYMBOL_INFO); pSymbol-&gt;MaxNameLen = MAX_SYM_NAME; DWORD displacementLine = 0; IMAGEHLP_LINE64 line; line.SizeOfStruct = sizeof(IMAGEHLP_LINE64); if (SymFromAddr(process, address, &amp;displacementSym, pSymbol) &amp;&amp; SymGetLineFromAddr64(process, address, &amp;displacementLine, &amp;line)) &#123; snprintf(szFrameInfo, sizeof(szFrameInfo), "\t%s() at %s:%d(0x%x)\n", pSymbol-&gt;Name, line.FileName, line.LineNumber, pSymbol-&gt;Address); &#125; else &#123; snprintf(szFrameInfo, sizeof(szFrameInfo), "\terror: %d\n", GetLastError()); &#125; strcat(szStackInfo, szFrameInfo); &#125; printf("%s", szStackInfo); // 输出到控制台，也可以打印到日志文件中&#125;void func2()&#123; bool isError = true; if (isError) &#123; ShowTraceStack("error in func2\n"); &#125; else &#123; printf("this is func2\n"); &#125;&#125;void func1()&#123; int sum = 0; for (int i = 0; i &lt; 100; ++i) sum += i; func2();&#125;int main(int argc, char* argv[])&#123; printf("hello world\n"); func1(); return 0;&#125; 显示堆栈调用信息上面的测试代码中函数的调用逻辑为：main()函数调用func1()函数，然后func1()函数调用func2()函数，当func2()中发生问题的时候打印当时的堆栈信息，然后我们查看一下打印结果 hello worlderror in func2 ShowTraceStack() at e:\vs2013projects\trackback\windowstrackback\windowstrackback.cpp:24(0xe01440) func2() at e:\vs2013projects\trackback\windowstrackback\windowstrackback.cpp:59(0xe01840) func1() at e:\vs2013projects\trackback\windowstrackback\windowstrackback.cpp:74(0xe017c0) main() at e:\vs2013projects\trackback\windowstrackback\windowstrackback.cpp:82(0xe018c0) __tmainCRTStartup() at f:\dd\vctools\crt\crtw32\dllstuff\crtexe.c:626(0xe01d40) mainCRTStartup() at f:\dd\vctools\crt\crtw32\dllstuff\crtexe.c:466(0xe020c0) error: 487 error: 487 error: 487 总结 Windows平台下可以利用函数CaptureStackBackTrace、SymFromAddr、SymGetLineFromAddr64来获取当时的函数调用堆栈信息 使用上述函数时，需要引用头文件&lt;dbghelp.h&gt;，添加库引用DbgHelp.Lib 程序源码打印堆栈信息–源码传送门]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>函数</tag>
        <tag>堆栈</tag>
        <tag>windows</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[.bat批处理（七）：PC端从手机内复制文件到本地]]></title>
    <url>%2Fblog%2F2019%2F08%2F21%2Fbat%E6%89%B9%E5%A4%84%E7%90%86%EF%BC%88%E4%B8%83%EF%BC%89%EF%BC%9APC%E7%AB%AF%E4%BB%8E%E6%89%8B%E6%9C%BA%E5%86%85%E5%A4%8D%E5%88%B6%E6%96%87%E4%BB%B6%E5%88%B0%E6%9C%AC%E5%9C%B0%2F</url>
    <content type="text"><![CDATA[前言解决方案都是在实际工作中遇到问题时想出来解决方法，很多方法乍一看根本用不上，但实际操作中发现真的很有用，今天提到的这个方法就是这种类型的。 游戏开发中常常会将一些关键信息或者调试信息写入到日志文件中，这样可以在出现BUG的情况时，通过分析日志文件来进一步定位问题的原因，在真机上跑游戏时就需要将手机中的日志文件导出到电脑上，方便查看，这就是这篇文章所讲的内容。 可能有人会说，现在手机连接电脑很方便，直接插一根数据线，在“我的电脑”里找到手机，然后就可以像从其他文件夹复制一下，从手机中把文件复制下来，可事实上并不是这样的，手机连接电脑有个缓存的毛病。 这种问题就是第一次连接的时候查看文件是正常，但是复制删除几次文件以后就会出现缓存的现象，我明明新建了一个文件就是找不到，比如产生了新的日志文件，通过数据线连接电脑以后，在文件夹中看不到，这时可以通过adb命令复制出来，虽然看不到，但是文件是确实存在的。 准备条件 需要电脑安装adb，常用来调试手机的电脑一定会安装过这个东西，有些版本直接可以使用，具体怎么安装，网上的教程有很多。 手机需要打开USB调试模式，打开模式前可能需要开启开发者选项，同样开启USB调试的教程也有很多。 实现代码1234567891011121314151617@SET LOG_FILE_NAME=project_%date:~0,4%%date:~5,2%%date:~8,2%%time:~0,2%%time:~3,2%%time:~6,2%.logadb pull /storage/emulated/0/project2.log ./%LOG_FILE_NAME%@echo offecho running result:if %errorlevel%==0 goto endSuccess:endFailecho Copy data from phone to pc falied!!!pauseexit /b 1:endSuccessecho Copy data from phone to pc success!!!pauseexit /b 0 代码分析其实这一大段中核心的代码只有一句adb pull /storage/emulated/0/project2.log ./%LOG_FILE_NAME%，之前的变量LOG_FILE_NAME是为了解决多次导出文件时同名会覆盖的问题，加上时间字符串可以防止重名出现，adb pull 手机中路径+文件名 本地PC路径+文件名就是实际复制的过程 如果复制过程中不报错就会走到:endSuccess代码段，如果报错就会走到:endFail代码段，两段代码会返回不同的值供调用者判断，整个代码文件加了一些提示消息，如果嫌麻烦的话直接使用adb pull /storage/emulated/0/project2.log ./%LOG_FILE_NAME%也是可以的。 代码测试直接在cmd命令行中运行就可以，假设以上的bat文件名为CopydataPhone2PC.bat，手机根目录下有文件project.log，我们可以尝试拷贝project.log和project2.log两个文件到手机看看效果，当然project2.log文件是不存在的肯定会失败 拷贝成功1234567E:\batTool&gt;CopydataPhone2PC.batE:\batTool&gt;adb pull /storage/emulated/0/project.log ./project_20190822102324.log124 KB/s (1284 bytes in 0.010s)running result:Copy data from phone to pc success!!!请按任意键继续. . . 拷贝失败1234567E:\batTool&gt;CopydataPhone2PC.batE:\batTool&gt;adb pull /storage/emulated/0/project2.log ./project_20190822102422.logremote object '/storage/emulated/0/project2.log' does not existrunning result:Copy data from phone to pc falied!!!请按任意键继续. . . 总结有些领域真的很奇妙，如果你之前没有接触过，直接告诉你，手机里有个很普通的文件，但是你就是看不到，你会不会觉得很奇怪，针对于这些奇怪的问题其实别人可能早就有了解决方案，百思不得其解时不妨浏览一下。]]></content>
      <categories>
        <category>bat</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[std::bind（二）：包装成员函数]]></title>
    <url>%2Fblog%2F2019%2F08%2F15%2Fstd-bind%EF%BC%88%E4%BA%8C%EF%BC%89%EF%BC%9A%E5%8C%85%E8%A3%85%E6%88%90%E5%91%98%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言关于std::bind()对普通函数的包装作用，在之前的总结文章《std::bind（一）：包装普通函数》已经举例说明过了，后来发现丢下了普通函数嵌套包装的情况，所以在这篇文章中继续说明一下，然后重点总结std::bind()函数对成员函数的包装，在面向对象的大潮还未褪去的今天，还是成员函数见到的更多一些，所以讲讲对它的包装。 普通函数嵌套包装实际上就是普通函数包装的变形和组合，直接写个例子吧，如果test1_1()、test1_2()、test1_3()三个函数的输出结果都答对了就说明已经掌握了。12345678910111213141516171819202122232425262728293031323334353637void func(int n1, int n2, int n3)&#123; cout &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; endl;&#125;int calc_value(int c1)&#123; return c1 * c1;&#125;void calc_value2(int c1)&#123; int result = c1 * c1;&#125;void test1_1()&#123; auto f1 = std::bind(func, placeholders::_1, 101, std::bind(calc_value, placeholders::_2)); f1(11, 2); // same as call func(11, 101, calc_value(2))&#125;void test1_2()&#123; int n = 2; auto f1 = std::bind(func, placeholders::_1, 101, std::bind(calc_value, std::ref(n))); n = 4; f1(11, 2); // same as call func(11, 101, calc_value(44)) 多出的参数2无人使用&#125;void test1_3()&#123; auto f1 = std::bind(func, placeholders::_1, 101, std::bind(calc_value2, placeholders::_2)); //f1(11, 2); // 编译出错，无法将参数 3 从“void”转换为“int”&#125;// 11 101 4// 11 101 16 第一个test1_1函数的逻辑应该很容易理解，就是把函数calc_value(2)的返回值作为函数func的第三个参数，而函数test1_2中利用了std::ref()传递引用的功能，将变量n作为引用变量进行传递，在包装调用之前可以感知到参数n的变化。 其实难点在第三个函数test1_3，可能大家知道这里会报错，因为我们需要返回值但是却包装了一个没有返回值的函数，但其实把第二行注释掉之后，程序就可以成功编译，也就是说包装错误的函数如果不被调用，是不会报错的，这一点和模板函类不使用就不会创建很相似，最终是相同的。 包装类成员在深入学习std::bind()这个函数之前一直以为它只能用来包装函数，后来通过进一步了解发现它还能用来包装成员变量，我们一起来看一下简单的实现方法。 成员函数的包装这里我们不考虑静态成员函数，因为静态函数没有this指针，和普通的函数基本一样，在用法上也没有很大的差异，所以此处的包装只考虑成员非静态函数，可以尝试分析以下几个例子。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364class CTest&#123;public: CTest() &#123;&#125; ~CTest() &#123;&#125;public: void func1(int n1, int n2) &#123; cout &lt;&lt; "func1 " &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; endl; &#125; int n_public;private: void func2(int n1, int n2) &#123; cout &lt;&lt; "func2 " &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; endl; &#125; int n_private;&#125;;void test2_1()&#123; CTest testObj; auto f2 = std::bind(&amp;CTest::func1, testObj, 101, placeholders::_1); f2(1); // same as call testObj.func1(101, 1)&#125;void test2_2()&#123; CTest testObj; auto f2 = std::bind(&amp;CTest::func1, &amp;testObj, 101, placeholders::_1); f2(2); // same as call testObj.func1(101, 2)&#125;void test2_3()&#123; CTest testObj; CTest&amp; obj = testObj; auto f2 = std::bind(&amp;CTest::func1, obj, 101, placeholders::_1); f2(3); // same as call testObj.func1(101, 3)&#125;void test2_4()&#123; CTest testObj; auto f2 = std::bind(&amp;CTest::func1, placeholders::_1, placeholders::_2, 101); f2(testObj, 4); // same as call testObj.func1(4, 101)&#125;void test2_5()&#123; CTest testObj; // auto f2 = std::bind(&amp;CTest::func2, &amp;testObj, 101, placeholders::_1); // 编译错误，func2不可访问&#125;//func1 101 1//func1 101 2//func1 101 3//func1 4 101 前三个函数tes2_1()、tes2_2()、tes2_3()的作用基本一致，就是将一个类的非静态成员函数和对象绑定，并且可以动态绑定一些参数，三种调用方式都可以，暂时没有发现什么问题，大家知道区别的可以指导我一下，我补充上来，需要注意的是函数std::bind()参数个数需要在原函数参数个数的基础上加两个，第一个很明显就是函数名，而第二个必须是调用这个函数的对象，至于传递的是指针还是引用都没有什么问题，这两个参数过后才是真正的原函数的参数。 函数test2_4()相对于前三个来说更加灵活，将对象也最为参数在调用时传入，这就相当于把一个成员函数看成，一个普通函数然后在第一个参数前加this指针的形式，后面这种调用方式在查看C++调用堆栈时应该很容易看到，本质上是一样，其实这里还有一个对象传递的问题，我们在成员变量时再测试一下。 函数test2_5()出现了编译错误，原因是在使用函数std::bind()的时候也要考虑到原函数的访问权限，在测试函数中访问对象的私有函数显然是不可以的。 成员变量的包装1234567891011121314151617181920212223242526272829303132333435void test3_1()&#123; CTest testObj; auto f3 = std::bind(&amp;CTest::n_public, testObj); f3(1) = 10; cout &lt;&lt; f3(1) &lt;&lt; endl; cout &lt;&lt; testObj.n_public &lt;&lt; endl;&#125;void test3_2()&#123; CTest testObj; auto f4 = std::bind(&amp;CTest::n_public, placeholders::_1); f4(testObj) = 4; cout &lt;&lt; f4(testObj) &lt;&lt; endl; cout &lt;&lt; testObj.n_public &lt;&lt; endl;&#125;void test3_3()&#123; CTest testObj; auto f3 = std::bind(&amp;CTest::n_public, std::ref(testObj)); f3(1) = 11; cout &lt;&lt; f3(1) &lt;&lt; endl; cout &lt;&lt; testObj.n_public &lt;&lt; endl;&#125;//10//-858993460//4//4//11//11 这个成员变量的绑定测试结果，有没有让人意想不到呢？或者说这种f3(1) = 10;写法已经让人很惊讶了，其实我在写例子的时候就是简单试试，没想到这样写居然可以，看起来好像把一个值赋值给了一个函数一样。 函数test3_1()的第二个输出可能有点想不到，但是看到结果是有些人可能就明白了，因为在上一篇里提到“std::bind()函数中的参数在被复制或者移动时绝不会以引用的方式传递，除非你使用了std::ref()或者std::cref()包装的参数”。 因为没有使用std::ref()函数包装，所以std::bind()函数绑定的testObj对象实际上是原对象的副本，那么针对于副本的操作和修改自然就不会反应到原对象上，这也就是打印testObj.n_public会输出随机值的原因。 函数test3_2()在绑定时并没有具体到特定的对象，而是使用了placeholders::_1占位符，这样生成的函数，在调用的时候再传入操作对象，那么此时修改对象属性就可以起作用了。 函数test3_3()是针对于函数test3_1()的，添加了std::cref()包装的原对象，可以通过绑定后的函数修改。 总结 std::bind()函数可以嵌套绑定 std::bind()函数绑定成员函数时，函数名参数后面需要紧跟着类的对象作为参数 std::bind()不仅可以绑定普通函数、成员函数、还可以绑定成员变量 完整代码代码传送门]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>bind</tag>
        <tag>placeholders</tag>
        <tag>class</tag>
        <tag>object</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[雷电模拟器一键宏实现循环点击]]></title>
    <url>%2Fblog%2F2019%2F08%2F09%2F%E9%9B%B7%E7%94%B5%E6%A8%A1%E6%8B%9F%E5%99%A8%E4%B8%80%E9%94%AE%E5%AE%8F%E5%AE%9E%E7%8E%B0%E5%BE%AA%E7%8E%AF%E7%82%B9%E5%87%BB%2F</url>
    <content type="text"><![CDATA[前言今天在使用雷电模拟器测试游戏的时候，有一个领奖界面需要点击领奖100次，程序猿作为解放劳动力的先锋，必须想个办法解决这个事情，按键精灵是个好东西，但是重装系统之后还没有安装，然后发现这个雷电模拟器里除了简单的按键映射，还有一键宏的功能，那就用它解决了。 解决过程关于雷电模拟器的按键操控功能，官方论坛-帮助教程已经写得很清楚了，一键宏怎么设置教程里也写的很清楚，唯一的缺点就是各个截图中的代码太模糊了，根本看不清，所以我在尝试的过程中还花了点时间，其中遇到了几个坑和大家分享下。 我用的模拟器版本是3.54，这个版本在编写一键宏的时候可以直接在界面上获得对应点的坐标，非常的方便，在开始写一键宏的时候有一个误区，就是怎么控制我写的这段宏代码的开始与结束，起初我还控制按键的按下和抬起，发现没有什么用，最后测试发现，就是设置的按键按下时执行，如果存在循环就一直执行，按键抬起时执行结束，简单粗暴。 代码编写其实这个一键宏也算不上代码，最多也就算个伪代码，然后通过模拟器解析一下，要实现循环点击的功能需要的指令不多，只有4个： size：指定模拟器的分辨率 loop：说明以下的指令开始循环 touch：点击屏幕上的像素点 wait：休息一下，防止点击过快，单位是毫秒 其中坑人最深的就是size这个命令，我一开始以为是设置分辨率的，而我玩游戏默认的分辨率是1600X900，所以设置的点击位置也是在这个分辨率下取的点，然后就没加这个指令，结果一键宏一直不生效，后来加上了size 1600 900这一句才好使，这时我才明白这个指令不是设置分辨率的，而是告诉以下指令，当前的分辨率是多少，在操作像素点时不至于选错，宏的内容很简单，只有四句： 1234size 1600 900looptouch 1400 350wait 1000 这个宏组合的意思也很清楚，在分辨率1600X900的情况下，循环点击(1400, 350)这个像素点，每次点击间隔1s，防止点击过快。 总结 一键宏设置完成后，按键按下执行，如果是循环指令，则按键抬起结束 size指令并不是设置分辨率，而是说明现在的分辨率]]></content>
      <categories>
        <category>game</category>
      </categories>
      <tags>
        <tag>雷电</tag>
        <tag>模拟器</tag>
        <tag>按键操控</tag>
        <tag>一键宏</tag>
        <tag>loop</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[std::bind（一）：包装普通函数]]></title>
    <url>%2Fblog%2F2019%2F08%2F01%2Fstd-bind%EF%BC%88%E4%B8%80%EF%BC%89%EF%BC%9A%E5%8C%85%E8%A3%85%E6%99%AE%E9%80%9A%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言不知道大家在做项目写程序的过程中有没有遇到这样的情况，别的模块类提供了一个拥有很多参数接口函数，但是我这个功能只用到其中几个，其他的参数都是固定的，可是为了调用这个接口函数，不得不将所有的参数写一遍，每次写一堆固定参数都感觉在浪费生命。 有的人可能想到默认参数，的确，默认参数可以解决部分问题，因为默认参数只能出现参数列表的尾部，如果4个参数中，我需要传递的参数是第4个，而前3个参数想默认的话，默认参数是做不到这种效果的，并且别人的接口函数也不一定会有默认参数。 函数封装，这是一个办法，我们在自己的模块中添加一个对接口函数进行包装后的函数，将不变的参数进行固定，然后只留可变的参数供我们自己调用，如果我们有3种常用的调用方式可能就需要定义3个函数，这种方法可行，不过比较麻烦，而std::bind()函数就是为了包装函数而生的，使用起来更加方便。 std::bind()的作用std::bind()的作用就是对原函数进行包装，可以将参数值固定，调换顺序然后生成新的函数供我们调用。举个例子，一块铁片你可以拿它来做很多事情，打造一下可以做成一把刀，敲敲打打可以做成一个桶，甚至直接拿来就可以挡窗户上的洞。std::bind()的作用就是把这块铁的作用固定，比如给她安上一个刀把，这样我们每次使用就可以把这块铁片当成菜刀来使用了。 std::bind()可以包装各种函数，但是这篇文章只总结一下包装普通函数的方法，因为在学习的过程中我发现单单是包装普通函数也会遇到很多问题，所以为了列举出诸多可能，说明各种注意事项，本文还是只关注于普通函数的包装，至于成员函数的包装还是放到以后的文章，给自己埋下一个坑。 在包装普通函数时，std::bind()的第1个参数就是原函数的名字，当然也可以是指向函数的指针，或者函数引用，从第2个参数开始，填写的内容依次对应原函数中的各个参数，所以说如果原函数是3个参数，如果想包装它，那么std::bind()需要传入4个参数，如果原函数是8个参数，那么包装它的std::bind()就需要传入9个参数，这里为了将原函数和包装后的函数参数建立联系，需要引入命名空间std::placeholders。 placeholders的作用std::placeholders的命名空间下有多个参数占位符，比如placeholders::_1、placeholders::_2等等，最大为placeholders::_20，在包装普通函数时，固定的参数很好说，就是填写固定值就可以，但是要想原函数的参数和包装后函数的参数建立联系就需要用到刚刚提到的占位符， placeholders::_1就表示包装后函数的调用时的第1个参数，同理placeholders::_2就表示包装后函数的调用时的第2个参数。 有了占位符的概念，我们就可以推断出，包装后的函数与原函数相比，不但可以减少函数参数，也可以增加函数参数，虽然暂时没有想到什么实际的使用场景，但是理论上是可行的。 std::bind()使用测试首先需要先引入头文件，免得找不到命名空间和函数定义123#include &lt;iostream&gt;#include &lt;functional&gt;using namespace std; 固定参数、调换顺序1234567891011121314151617181920void func1(int n1, int n2, int n3)&#123; cout &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; endl;&#125;void test1_1()&#123; auto f1 = std::bind(func1, placeholders::_1, 101, placeholders::_2); f1(11, 22); // same as call func1(11, 101, 22)&#125;void test1_2()&#123; auto f1 = std::bind(func1, placeholders::_2, 101, placeholders::_1); f1(11, 22); // same as call func1(22, 101, 11)&#125;// 输出//11 101 22//22 101 11 函数test1_1()展示了std::bind()函数最常见的用法，其中参数n2被固定为101，参数n1使用占位符placeholders::_1表示，表示包装后函数的第1个参数会传给形参n1使用，同理包装后函数的第2个参数会传给形参n3使用，所以调用函数f1(11, 22) 就等同于调用函数 func1(11, 101, 22)，test1_2()函数简单展示了调换参数顺序的方法，只要明白了placeholders的作用，这两个例子也就明白了。 包装后函数的参数个数可增可减123456789101112131415161718192021222324252627void func2(int n1, int n2, int n3)&#123; cout &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; endl;&#125;void test2_1()&#123; auto f2 = std::bind(func2, placeholders::_3, 101, placeholders::_1); f2(11, 22, 33); // same as call func2(33, 101, 11)&#125;void test2_2()&#123; auto f2 = std::bind(func2, placeholders::_1, 101, placeholders::_1); f2(11); // same as call func2(11, 101, 11)&#125;void test2_3()&#123; auto f2 = std::bind(func2, placeholders::_1, 101, placeholders::_2); f2(11); // 报错，因为没有参数传给placeholders::_2&#125;// 输出//33 101 11//11 101 11//编译错误 其实在理解了placeholders的作用之后，这个测试结果也能想到的，函数test2_1()中使用了placeholders::_3，所以包装后函数的参数至少要传3个才不会报错，而test2_2()函数中使用了placeholders::_1，所以被包装函数调用时只需要传入一个参数，最后是函数test2_3()，绑定时引用了placeholders::_2，而在调用时只传了一个参数，所以出现编译错误。 bind()绑定时参数个数固定，类型需匹配12345678910111213141516171819202122void func3(int n1, int n2, int n3)&#123; cout &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; endl;&#125;void test3_1()&#123; auto f3 = std::bind(func3, placeholders::_1, 101); //f3(11); // 编译错误，因为bind函数中少了一个参数&#125;void test3_2()&#123; auto f3 = std::bind(func3, placeholders::_1, 101, 102, 103); //f3(11); // 编译错误，因为bind函数中多了一个参数&#125;void test3_3()&#123; auto f3 = std::bind(func3, placeholders::_1, "test", placeholders::_1); //f3(11); // 编译错误，第二个参数类型不匹配，无法将参数 2 从“const char *”转换为“int”&#125; 看了之前的测试之后，是不是觉得参数的个数很随意，可以随便增加和减少，所以在绑定的时候也不好好写了，结果发现上述3个函数全部编译错误，test3_1()函数中因为绑定时少了一个参数而报错，test3_2()函数中因为绑定时多了一个参数而报错，而test3_3()函数中因为绑定时第二个参数的类型不匹配而报错，所以参数个数的增减只能是包装后的函数，而绑定时必须严格与原函数的参数个数以及类型相匹配。 普通函数的参数中有引用类型弄明白上面的例子之后，可能会产生一种我会了的错觉，想象一下如果原函数参数中包含引用类型应该怎样写，可以自己先想一下，然后看看下面的例子1234567891011121314151617181920212223242526272829303132333435363738394041424344void func4(int n1, int n2, int&amp; n3)&#123; cout &lt;&lt; n1 &lt;&lt; ' ' &lt;&lt; n2 &lt;&lt; ' ' &lt;&lt; n3 &lt;&lt; endl; n3 = 101;&#125;void test4_1()&#123; int n = 10; auto f4 = std::bind(func4, 11, 22, n); n = 33; f4(); // same as call func4(11, 22, 10) cout &lt;&lt; "n = " &lt;&lt; n &lt;&lt; endl;&#125;void test4_2()&#123; const int n = 30; auto f4 = std::bind(func4, 11, 22, n); f4(); // same as call func4(11, 22, 30)&#125;void test4_3()&#123; int n = 30; auto f4 = std::bind(func4, 11, 22, ref(n)); n = 33; f4(); // same as call func4(11, 22, n) cout &lt;&lt; "n = " &lt;&lt; n &lt;&lt; endl;&#125;void test4_4()&#123; const int n = 30; auto f4 = std::bind(func4, 11, 22, ref(n)); //f4(); // 编译错误，无法将参数 3 从“const int”转换为“int &amp;”&#125;// 输出//11 22 10//n = 33//11 22 30//11 22 33//n = 101 如果能准确说出test4_1()函数的输出结果，那么后面的内容应该是不需要看了，如果只回答对了部分内容，或者干脆全错了，那么我们还有很长的路要走。 在std::bind()的官方文档中有这样一句话，std::bind()函数中的参数在被复制或者移动时绝不会以引用的方式传递，除非你使用了std::ref()或者std::cref()包装的参数，如果知道了这个限定，就很容易明白函数test4_1()函数的输出结果了。 在函数test4_1()中std::bind(func4, 11, 22, n)就相当于std::bind(func4, 11, 22, 10)，所以输出结果为11 22 10，可是函数func4()中还有一句 n3 = 101;，这就很让人奇怪了，我们知道常数是没办法作为参数传递给可变引用变量的，如果说把10作为参数传递给参数int&amp; n3肯定会报错，而函数test4_1()却正常执行，没有任何问题。 我们猜测常数10到参数int&amp; n3并不是直接传递，而是发生了拷贝，而函数func4()中修改的n3变量也是修改的拷贝内容，所以我们做了test4_2()这个实验，发现将变量n改为常量也是可以正常执行的，甚至直接写成std::bind(func4, 11, 22, 10)也是没问题的，这也验证了我们上面的想法。 既然文档了提到了std::ref()和std::cref()函数，那么我们想传递引用给原函数只能使用它们了，看下函数test4_3()的实现，这才是正确传递引用变量的方式，变量n被函数 std::ref() 包装之后，既能够感受到本函数中变量n的变化，也能够传入到原函数中被原函数的逻辑改变，并将结果反映回来。 函数test4_4()只是一个常量传递的简单测试，将一个常量作为可变引用变量来传递肯定是无法通过编译的，这在函数调用时很明确，但是在std::bind()加入之后显得有些混乱，只要记住一点，常量不应该被改变，如果传递之后内容可能会变化，那么很可能这种写法就是错误的。 总结 其实std::bind()函数测试到现在远远没有结束，配合std::ref()和std::cref()函数会产生多种组合情况，不过主要的问题上面都提到了一些，出现问题的时候对照着定义和概念看看应该就能理解了。 需要理解std::placeholders的占位作用，它们是std::bind()函数最基本的用法。 完整代码代码传送门]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>bind</tag>
        <tag>placeholders</tag>
        <tag>auto</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中char和varchar的区别]]></title>
    <url>%2Fblog%2F2019%2F07%2F27%2FMysql%E4%B8%ADchar%E5%92%8Cvarchar%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言这个标题起的过于俗套，前一段时间我还写了一篇总结《Mysql5.7版本中数据表字段可用的类型》来批判这种对比，原因是对比时没有指明数据库，内容写的是char、varchar和nvarchar的对比，结果我测试了半天发现Mysql当前版本根本没有nvarchar，浪费来了不少时间。 问题起因真香定律来的总是这么快，这才过了几天，我也来写写Mysql中char和varchar究竟有什么区别，起因是看到CSDN好友“铁柱同学”一篇关于innodb主键长度最大为767字节的讲解，里面涉及到一个char类型最大存储255个字符，按照utf8编码来看最大的字节数应该是255*3=765个字节的知识点。现在来看767的来源好像并不是256*3-1，而是255*3+2，这个2就是存储char类型字段中实际有多少个字节的。 有点跑题了，实际上是在研究索引长度的过程中，我发现我对char和varchar这两个类型一直存在着误解，因为一直做游戏开发的缘故，游戏数据的存储一般使用varbinary来存，导致我把字符和字节有点弄混了，所以我一直认为在utf8编码下char(9)可以存储9个英文字符，或者3个中文汉字，实际我做完实验后发现char(9)也可以正常存储9个汉字。 提到字符和字节，初学者可能会有点蒙，实际上它们两者之间是需要通过编码来转换的，之前做过游戏的多语言版本，所以对这一块还是比较熟的，字节就是计算机中的8个二进制位，而字符是每个语言中的不可分割的单元，字符转换成字节需要依赖编码，实际上编码就是一本大字典，里面对应了每个字符在当前编码下转换成字节是什么样的，ANSI是一本字典，UTF8也是一本字典，编码的类型还有很多，每种编码都记录了各自的转换结果。 举个例子，“中”这个字是汉字中的一个字符，在ANSI这本字典中对应的是2个字节，而在UTF8这本字典中对应的是3个字节，而C这个字母是英文中的一个字符，在ANSI这本字典中对应的是1个字节，而在UTF8这本字典中对应的同样是1个字节，从这个例子中可以简单理解下字节与字符的关系。 多说一句，不要认为UTF8编码中汉字转换成字节都是3个字节，实际情况是常用字一般都占用了3个字节，但是中国语言博大精深，光语言平面就单独占了好几个，有些汉字转换成UTF8编码可能需要4个字节，5个字节甚至是6个字节，这一点不要形成思维定式，认为汉字在UTF8编码下都是3个字节。 length 和 char_length今天之前我是不知道Mysql还有一个char_length函数的，发现这个函数后越发感觉Mysql的强大，这两个函数的区别就是length用来统计字段中的字节数，char_length用来统计字段中的字符数，接下来我们用一个例子来看看这两个函数以及char、varchar的区别。 测试环境 Windows 10Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 10Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 测试过程 首先创建一个带有char和varchar类型的测试表，查看表结构发现编码为utf8 1234567891011121314mysql&gt; create table diff(id int, s1 char(10), s2 varchar(10));Query OK, 0 rows affected (0.07 sec)mysql&gt; show create table diff;+-------+------------------------------------------------------------------------+| Table | Create Table |+-------+------------------------------------------------------------------------+| diff | CREATE TABLE `diff` ( `id` int(11) DEFAULT NULL, `s1` char(10) DEFAULT NULL, `s2` varchar(10) DEFAULT NULL) ENGINE=InnoDB DEFAULT CHARSET=utf8 |+-------+------------------------------------------------------------------------+1 row in set (0.07 sec) 插入少于10个字符的测试数据，然后查看结果，发现字节数为10，字符数为6 12345678910mysql&gt; insert into diff values(1, "测试test", "测试test");Query OK, 1 row affected (0.01 sec)mysql&gt; select id, s1, length(s1), char_length(s1), s2, length(s2), char_length(s2) from diff;+----+----------+------------+-----------------+----------+------------+-----------------+| id | s1 | length(s1) | char_length(s1) | s2 | length(s2) | char_length(s2) |+----+----------+------------+-----------------+----------+------------+-----------------+| 1 | 测试test | 10 | 6 | 测试test | 10 | 6 |+----+----------+------------+-----------------+----------+------------+-----------------+1 row in set (0.06 sec) 增加插入长度后发现，可以超过10个字节，可以完整存储10个汉字 1234567891011mysql&gt; insert into diff values(2, "测试策划和开发做游戏", "测试策划和开发做游戏");Query OK, 1 row affected (0.01 sec)mysql&gt; select id, s1, length(s1), char_length(s1), s2, length(s2), char_length(s2) from diff;+----+----------------------+------------+-----------------+----------------------+------------+-----------------+| id | s1 | length(s1) | char_length(s1) | s2 | length(s2) | char_length(s2) |+----+----------------------+------------+-----------------+----------------------+------------+-----------------+| 1 | 测试test | 10 | 6 | 测试test | 10 | 6 || 2 | 测试策划和开发做游戏 | 30 | 10 | 测试策划和开发做游戏 | 30 | 10 |+----+----------------------+------------+-----------------+----------------------+------------+-----------------+2 rows in set (0.10 sec) 分别增加s1和s2字段长度后发现，均无法正常插入，Mysql给出报错信息 12345mysql&gt; insert into diff values(2, "测试策划和开发做游戏OK", "测试策划和开发做游戏");1406 - Data too long for column 's1' at row 1mysql&gt; insert into diff values(2, "测试策划和开发做游戏", "测试策划和开发做游戏OK");1406 - Data too long for column 's2' at row 1mysql&gt; 至此没有看出区别，在插入内容前后都加上空格测试一下 123456789mysql&gt; select id, s1, concat('#', s1, '$'), length(s1) as len_s1, char_length(s1) as clen_s1, s2, concat('#', s2, '$'), length(s2) as len_s2, char_length(s2) as clen_s2 from diff;+----+----------------------+------------------------+--------+---------+----------------------+------------------------+--------+---------+| id | s1 | concat('#', s1, '$') | len_s1 | clen_s1 | s2 | concat('#', s2, '$') | len_s2 | clen_s2 |+----+----------------------+------------------------+--------+---------+----------------------+------------------------+--------+---------+| 1 | 测试test | #测试test$ | 10 | 6 | 测试test | #测试test$ | 10 | 6 || 2 | 测试策划和开发做游戏 | #测试策划和开发做游戏$ | 30 | 10 | 测试策划和开发做游戏 | #测试策划和开发做游戏$ | 30 | 10 || 3 | OK | # OK$ | 3 | 3 | OK | # OK $ | 4 | 4 |+----+----------------------+------------------------+--------+---------+----------------------+------------------------+--------+---------+ 这一次出现了区别，char类型的字段去掉了尾部的空格，而varcahr了类型的字段原样存储，没有去掉尾部空格，两者对于头部的空格都是存储的，这导致两者显示的字节数和字符数都不相同了。 分别使用不带空格、带头部空格，头尾都带空格进行测试12345678910111213141516171819202122232425262728293031323334353637mysql&gt; select * from diff where s1 = 'OK ';Empty setmysql&gt; select * from diff where s2 = 'OK ';Empty setmysql&gt; select * from diff where s1 = ' OK ';+----+-----+------+| id | s1 | s2 |+----+-----+------+| 3 | OK | OK |+----+-----+------+1 row in set (0.05 sec)mysql&gt; select * from diff where s2 = ' OK ';+----+-----+------+| id | s1 | s2 |+----+-----+------+| 3 | OK | OK |+----+-----+------+1 row in set (0.05 sec)mysql&gt; select * from diff where s1 = ' OK';+----+-----+------+| id | s1 | s2 |+----+-----+------+| 3 | OK | OK |+----+-----+------+1 row in set (0.05 sec)mysql&gt; select * from diff where s2 = ' OK';+----+-----+------+| id | s1 | s2 |+----+-----+------+| 3 | OK | OK |+----+-----+------+1 row in set (0.04 sec) 测试结果可能让人出乎意料，虽然s1和s2中存储的内容不同（差一个空格），但是查找时的行为却完全一样，这说明查找时尾部的空格并不会被考虑。 char和varchar区别做了半天试验发现char和varchar还是没有多大区别，实际上有些区别通过表面数据是测试不出来的，具体区别整理如下： 行为 char字段 varchar字段 最大长度 255字符 65535个字节，所以括号中最大的字符数还得通过编码来算 是否定长 定长，不足的部分用隐藏空格填充 不定长 空间使用 会有浪费 更加节省 查找效率 高 低 尾部空格 插入时省略 插入时不会省略，查找时省略 like查找 语句中like后的’ ‘不会省 语句中like后的’ ‘不会省，字段结尾的空格也不会省 总结 char(n)中的n是字符数，范围是0~255（额外需要1到2个字节来存长度） varchar(n)中的n也是字符数，但是最大值需要通过编码来算，不能超过65535字节（从中还需要拿出1到2个字节来存长度） 一般定长的数据选用char类型，比如身份证号，手机号，电话等，长度变化很大的可以使用varchar类型 注意尾部空格的匹配，特别是插入时和使用like查找时]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>char</tag>
        <tag>varchar</tag>
        <tag>length</tag>
        <tag>char_length</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[时分秒针在一天之内重合多少次]]></title>
    <url>%2Fblog%2F2019%2F07%2F23%2F%E6%97%B6%E5%88%86%E7%A7%92%E9%92%88%E5%9C%A8%E4%B8%80%E5%A4%A9%E4%B9%8B%E5%86%85%E9%87%8D%E5%90%88%E5%A4%9A%E5%B0%91%E6%AC%A1%2F</url>
    <content type="text"><![CDATA[前言分析问题之前先给出问题的答案：2次，送给急需要知道答案又不求甚解的朋友。 这个问题之前听过类似的，一直没有当回事，今天在解题的时候发现了这道题，于是动脑筋想了一下，从12点位置时分秒3个表针重合开始，第一次应该在1点5分之后，那是分针转了一圈快追上时针了，再稍微走一点就能追上，然后秒针再转过来就完成了第一次重合，同理在2点10分之后也有一次，在3点15之后还有一次，这样算下来12小时之内有11次，那么一天24小时就有22次。 正在为自己的想法得意时，查了一下参考答案发现我被幼稚的想法打败了，实际上一天24小时内，时分秒针只重合了2次，原因就是我设想从12点开始到1点5分，分针转了一圈快追上时针了，此刻时针与分针确实会有一次相遇，但是此时的秒针却没办法跟他们相逢，因为三个表针是联动的，针对于每个精确到秒的时间，三个针都有固定的位置，不是想重合就能重合的。 在1点5分附近的情况就是，时针和分针快要重合了，然后秒针匆匆赶来，然后时针和分针重合了，秒针还差一点才能到，然后秒针继续走，但是秒针走会继续带动分针和时针运动，然后秒针赶到了分针时针相遇的附近，却发现它俩已经“分手”了，秒针只能大步流星的一个个越过它们俩，期待着下次它们仨能相遇在一处。 时针和分针的相遇在考虑时分秒三针重合情况之前，我们可以先想一下一天24小时内，分针和时针相遇了多少次，其实这才是我刚才想的那个答案22次，知道了次数之后我们还想知道具体的时间，可不可以算出来呢？当然可以！ 接下来我们以一种通俗的方式来解这个问题，那就是列方程式求解，首先将时间作为连续值来看待，我们设时针的角速度是ω，因为时针走1格，分针会走1圈，也就是12格，所以分针的角速度是12ω，分针转了一圈追上时针用的是t，时针和分针转过角度差为1圈，也就是2π，那么此时可以列出方程： $$12ωt-ωt=2π$$ 关于角速度ω的值，因为1圈的角度是2π，转一圈需要花的时间是12小时，所以ω=2π/12小时，带入方程得到t=12小时/11，同理如果分针转两圈追上时针，那么方程式为： $$12ωt-ωt=4π$$ 可以求得t=24小时/11，由此我们就得到了，时针分针相遇时刻与分针转的圈数i的关系： $$t=i*12小时/11$$ 代码实现有了上面的分析，我们可以写代码计算一下一天之中时针和分针相遇具体时刻，因为开着lua编辑器，顺手就用lua写了，代码如下： 123456789101112function print_meet(id, meet) local h = math.floor(meet) local t = meet - h; local ts = t * 3600; local m = ts // 60; local s = ts - m * 60; print(string.format("%02dth meet, time = %02d:%02d:%05.2f", id, h, m, s));endfor i=1,24 do print_meet(i, i * 12 / 11)end 运行结果 01th meet, time = 01:05:27.2702th meet, time = 02:10:54.5503th meet, time = 03:16:21.8204th meet, time = 04:21:49.0905th meet, time = 05:27:16.3606th meet, time = 06:32:43.6407th meet, time = 07:38:10.9108th meet, time = 08:43:38.1809th meet, time = 09:49:05.4510th meet, time = 10:54:32.7311th meet, time = 12:00:00.0012th meet, time = 13:05:27.2713th meet, time = 14:10:54.5514th meet, time = 15:16:21.8215th meet, time = 16:21:49.0916th meet, time = 17:27:16.3617th meet, time = 18:32:43.6418th meet, time = 19:38:10.9119th meet, time = 20:43:38.1820th meet, time = 21:49:05.4521th meet, time = 22:54:32.7322th meet, time = 24:00:00.0023th meet, time = 25:05:27.2724th meet, time = 26:10:54.55 分析从上面的结果来看，处于一天内的时间相遇时刻只有前22次，12点之后第一次相遇是在01:05:27.27，此时虽然时针和分针相遇，但是秒针大概在27秒的位置，离他们还很远，同理分针时针第二次相遇时刻02:10:54.55，秒针也没有跟他们在一起，但是有两次例外，那就是12:00:00.00和24:00:00.00，这两次时针、分针、秒针完全重合了，所以我们也得到了本文标题中的答案。 总结 时分秒针在一天之内重合2次 从连续的时间来看，时针和分针在一天之内重合22次 有一种现实情况就是表盘上的时间是离散的，不连续的，最小的时间间隔是1秒，此时我们计算的第一次相遇时间01:05:27.27是不存在的，01:05:27的时候分针在时针之前，而01:05:28的时候分针在时针之后，它们也错过了，所以时针和分针考虑离散的情况，一天之后也只是重合2次。]]></content>
      <categories>
        <category>Algorithm</category>
      </categories>
      <tags>
        <tag>Lua</tag>
        <tag>interview</tag>
        <tag>time</tag>
        <tag>clock</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OSI七层模型中各层协议及作用]]></title>
    <url>%2Fblog%2F2019%2F07%2F18%2FOSI%E4%B8%83%E5%B1%82%E6%A8%A1%E5%9E%8B%E4%B8%AD%E5%90%84%E5%B1%82%E5%8D%8F%E8%AE%AE%E5%8F%8A%E4%BD%9C%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言OSI七层模型在网络这门学科中占有很大的比重，最近在看《图解TCP/IP》这本书，其中对模型中的各个层的作用和对应的协议讲的很详细，而自己有时候总是记错，所以想总结一下，巩固记忆，毕竟好记性不如烂笔头嘛，现在烂笔头不好找了，应该说烂键盘吗？ 各层简析对比 名称 作用 常用协议或标准 相关设备 传输单位 应用层 特定应用对接收数据的处理 HTTP、FTP、SMTP 终端、服务器 - 表示层 设备数据格式与网络标准数据格式转换 LPP、GIF、JPEG 终端、服务器 - 会话层 通信管理，建立和断开通信连接 RPC、SSL、TLS 终端、服务器 - 传输层 管理两个网络终端之间的数据传输 TCP、UDP 终端、服务器 段 网络层 网络地址管理和路由选择 IP/IPv6、ICMP 路由器、三层交换机 分组、包 数据链路层 互联设备之间传送和识别数据帧 ARP、PARP 网桥、二层交换机 帧 物理层 比特流与电子信号之间的转换 IEEE 802.3/802.2 网卡、网线、集线器、中继器、调制解调器 比特位 总结 这里只是我看书之后的基础理解与总结，后续关系紧密的内容也会更新到这里。 本文很多内容中掺杂着个人的理解，如果有不正确的地方欢迎批评指正，我会尽快修改，这也是一种有效的学习方式。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Network</tag>
        <tag>OSI</tag>
        <tag>七层模型</tag>
        <tag>网络协议</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C++自定义全部替换函数replace]]></title>
    <url>%2Fblog%2F2019%2F07%2F16%2FC-%E8%87%AA%E5%AE%9A%E4%B9%89%E5%85%A8%E9%83%A8%E6%9B%BF%E6%8D%A2%E5%87%BD%E6%95%B0replace%2F</url>
    <content type="text"><![CDATA[前言今天遇到一个问题，需要把源字符串中的所有A串替换成B串，可能是最近写脚本写的太多了，第一反应就是使用replace()函数就完成了，在 Lua 和 Python 中确实如此，但是我现在正在写C++啊，查询std::string发现确实有一个repalce()函数，但是查看定义后发现事情却不像想象的那样简单。 C++中的这个replace()函数显得过于“原始”，相比于其他脚本语言来说，用起来显得不太方便，不过很符合基础工具语言的特点，这个自带的repalce(pos, len, dst)函数的作用是从源字符串的第pos个字符开始，往后数len个字符，然后将这一部分替换成dst串。 有了这个替换函数，我们完全可以使用循环和查找函数完成全部替换，查找函数可以选择string::find()，从返回的找到的位置开始替换即可，若没有找到则会返回 string::npos，这时也就完成了所有的替换。 函数实现代码很简单，就是利用循环、string::find()函数、string::replace()函数来进行适当的组合，逻辑很清晰，代码如下：1234567891011121314#include &lt;string&gt;#include &lt;iostream&gt;using namespace std;string replace(string&amp; base, string src, string dst)&#123; int pos = 0, srclen = src.size(), dstlen = dst.size(); while ((pos = base.find(src, pos)) != string::npos) &#123; base.replace(pos, srclen, dst); pos += dstlen; &#125; return base;&#125; 关于是否需要返回值完全看你自己定义，我这里加了返回值只要是为了测试输出方便。 测试函数12345678910111213141516int main()&#123; string base1 = "1.0.0.1"; cout &lt;&lt; replace(base1, ".", "[.]") &lt;&lt; endl; string base2 = "1【.】0【.】0【.】1"; cout &lt;&lt; replace(base2, "【.】", "[.]") &lt;&lt; endl; string base3 = "1【.】0【.】0【.】1"; cout &lt;&lt; replace(base3, "【.】", ".") &lt;&lt; endl; string base4 = "this is a book"; cout &lt;&lt; replace(base4, "is", "are") &lt;&lt; endl; return 0;&#125; 运行结果 1[.]0[.]0[.]11[.]0[.]0[.]11.0.0.1thare are a book 总结 注意string::replace()函数与脚本中常用替换函数的不同 使用string::find()函数查找不到待查串时会返回string::npos]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>字符串</tag>
        <tag>替换</tag>
        <tag>replace</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb使用watch命令设置数据断点]]></title>
    <url>%2Fblog%2F2019%2F07%2F16%2Fgdb%E4%BD%BF%E7%94%A8watch%E5%91%BD%E4%BB%A4%E8%AE%BE%E7%BD%AE%E6%95%B0%E6%8D%AE%E6%96%AD%E7%82%B9%2F</url>
    <content type="text"><![CDATA[前言“数据断点”这个说法是沿用在Visual Studio中学到的设置断点的方法，在gdb中一般被叫做“硬件断点”，算是断点调试中一种较为高级的调试方法了，这个方法起初是在VS中学会的，属于有需求必有响应的产物。刚开始调试程序的时候只会设置普通断点，就是在要调试的程序代码所在行设置断点，然后等程序运行到断点处可以单步执行，查看内存变量，遇到多个位置修改一个变量并且要查看是谁改变了变量的时候，就要设置多个断点，当时就想如果可以设置一个断点，当变量值被改变就触发这个断点那该多好啊。 当年果然是太年轻，后来发现这个功能就是VS中的数据断点，同样作用的还有gdb工具的中硬件断点，硬件断点不仅可以处理上面提到的需求，更是查找内存写超过的强大工具，要想知道一个正常的变量如何被“不正常”地修改了，硬件断点可以说是最佳工具了。 数据变化断点在gdb工具中设置普通断点的语法是b 变量名/函数名/文件位置，设置数据变化断点（硬件断点）语法也很简单，只需要一个watch命令即可，写法为watch 变量名，但是与普通断点不同的是，数据断点必须在程序运行时设置，在敲入r命令之前对变量设置数据断点会提示找不到符号。 编写测试程序代码 首先新建测试文件watchtest.cpp然后添加下面的代码： 123456789101112131415161718#include &lt;iostream&gt;using namespace std;int main()&#123; int k = 1; int n; n = 1; k = 2; cout &lt;&lt; n &lt;&lt; "," &lt;&lt; k &lt;&lt; endl; n = 3; k = 4; cout &lt;&lt; n &lt;&lt; "," &lt;&lt; k &lt;&lt; endl; return 0;&#125; 将C++源代码编译成可执行文件，为了调试记得加-O0 -g选项 1[albert@localhost#17:08:00#/home/albert/test]$g++ watchtest.cpp -O0 -g -o watchtest 加数据断点并调试 以下为gdb添加数据变化断点（硬件断点）并调试的整个过程，(gdb)后面的内容为敲入的命令： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354[albert@localhost#17:52:47#/home/albert/test]$gdb watchtestGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/test/watchtest...done.(gdb) b watchtest.cpp : 6Breakpoint 1 at 0x40085c: file watchtest.cpp, line 6.(gdb) watch nNo symbol "n" in current context.(gdb) rStarting program: /home/albert/test/watchtestBreakpoint 1, main () at watchtest.cpp:66 int k = 1;Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-23.el6.x86_64(gdb) watch nHardware watchpoint 2: n(gdb) cContinuing.Hardware watchpoint 2: nOld value = 0New value = 1main () at watchtest.cpp:1010 k = 2;(gdb) cContinuing.1,2Hardware watchpoint 2: nOld value = 1New value = 3main () at watchtest.cpp:1414 k = 4;(gdb) cContinuing.3,4Watchpoint 2 deleted because the program has left the block inwhich its expression is valid.0x00007ffff72c6d1d in __libc_start_main () from /lib64/libc.so.6(gdb) qA debugging session is active. Inferior 1 [process 18567] will be killed.Quit anyway? (y or n) y[albert@localhost#17:55:04#/home/albert/test]$ 总结 设置数据断点需要在程序启动之后，在运行r命令之前设置断点给出信息：No symbol &quot;n&quot; in current context. 当程序运行到监控变量的作用域之外以后，断点自动被删除，这一点观察执行q命令之前的文字可以看出 添加数据变化断点（硬件断点）格式：watch 变量名]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>linux</tag>
        <tag>gdb</tag>
        <tag>watch</tag>
        <tag>断点</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql5.7版本中数据表字段可用的类型]]></title>
    <url>%2Fblog%2F2019%2F07%2F02%2FMysql5-7%E7%89%88%E6%9C%AC%E4%B8%AD%E6%95%B0%E6%8D%AE%E8%A1%A8%E5%AD%97%E6%AE%B5%E5%8F%AF%E7%94%A8%E7%9A%84%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[前言为什么会有这个总结，因为在测试Mysql的字符串函数时发现，char 和 varchar 有些不同，网上搜索一番发现了各种char、varchar、nvarchar 类型的对比，还有一些奇奇怪怪的这里就不说了，然后我就开始了对这几种类型字符串的测试，接着就悲剧了，测试多次之后发现创建为nvarchar类型的字段居然是varchar类型的，再查询官方文档后发现，当前版本（5.7.21）的Mysql根本就没有nvarchar类型的字段，白白浪费了时间，所以要把Mysql支持的字段列举在这里，方便后面查找使用。 从13年开始工作到现在，数据库主要使用Mysql，关于常使用的字段类型无非 int、char、varchar、blob、datetime 这几种，工作之前用的最多的是SqlServer，其次就是Oracle和db2了，当时数据库的规模也不大，也没有注意到字段都有哪些类型，基本也是使用上述几种，因为今天在Mysql中的数据类型这栽了跟头，所以查了下官方文档，看看到底都有哪些类型。 支持类型真是不查不知道，查询后发现当前版本（5.7.21-log MySQL Community Server）支持的数据类型居然有40种，这还是超出我的想象的，以字典排序列举在此方便查找： bigint，binary，bit，blob，char，date，datetime，decimal，double，enum，float，geometry，geometrycollection，int，integer，json，linestring，longblob，longtext，mediumblob，mediumint，mediumtext，multilinestring，multipoint，multipolygon，numeric，point，polygon，real，set，smallint，text，time，timestamp，tinyblob，tinyint，tibytext，varbinary，varchar，year。 类型简述数字类型 BIT[(M)]比特值类型，M默认为1，范围是[1,64]。 TINYINT[(M)] [UNSIGNED] [ZEROFILL]单字节整数，有符号时范围是[-128,127]，无符号时范围是[0,255]。 BOOL, BOOLEAN布尔值类型，需要注意的是创建表时如果指定这两种类型会被自动转为TINYINT类型，0代表false，非0代表true。 SMALLINT[(M)] [UNSIGNED] [ZEROFILL]两字节整数，有符号时范围是[-32768,32767]，无符号时范围是[0,65535]。 MEDIUMINT[(M)] [UNSIGNED] [ZEROFILL]三字节整数，有符号时范围是[-8388608,8388607]，无符号时范围是[0,16777215]，这个类型在编程语言中很少见。 INT[(M)] [UNSIGNED] [ZEROFILL]四字节整数，有符号时范围是[-2147483648,2147483647]，无符号时范围是[0,4294967295]，与INTEGER等价。 BIGINT[(M)] [UNSIGNED] [ZEROFILL]八字节整数，有符号时范围是[-9223372036854775808,9223372036854775807]，无符号时范围是[0, 18446744073709551615]。 SERIAL是BIGINT UNSIGNED NOT NULL AUTO_INCREMENT UNIQUE类型的别名，感觉可以直接拿来做主键。 DECIMAL[(M[,D])] [UNSIGNED] [ZEROFILL]用于存储精确小数，M表示有效数字位数，范围是[1,65]，默认是10，D表示小数点后位数，范围是[0,30]，默认是0。 NUMERIC[(M[,D])] [UNSIGNED] [ZEROFILL]是DECIMAL的别名，同样含义的还有DEC[(M[,D])] [UNSIGNED] [ZEROFILL]、FIXED[(M[,D])] [UNSIGNED] [ZEROFILL]。 FLOAT[(M,D)] [UNSIGNED] [ZEROFILL]单精度浮点数，M表示有效数字位数，D表示小数点后位数，范围有三部分[-3.402823466E+38,-1.175494351E-38]，0，[1.175494351E-38,3.402823466E+38]，该类型属于Mysql自己的扩展，依赖硬件和操作系统，指定UNSIGNED表示禁用负数。 FLOAT(p) [UNSIGNED] [ZEROFILL]单精度浮点数，p用来表示精度，取值为0-24等价于没有M和D的FLOAT，取值为25-53等价于没有M和D的DOUBLE。 DOUBLE[(M,D)] [UNSIGNED] [ZEROFILL]双精度浮点数，表示有效数字位数，D表示小数点后位数，范围有三部分[-1.7976931348623157E+308,-2.2250738585072014E-308]，0，[2.2250738585072014E-308, 1.7976931348623157E+308]，该类型属于Mysql自己的扩展，依赖硬件和操作系统，指定UNSIGNED表示禁用负数。等价于DOUBLE PRECISION[(M,D)] [UNSIGNED] [ZEROFILL]。 REAL[(M,D)] [UNSIGNED] [ZEROFILL]一般情况等价于DOUBLE[(M,D)] [UNSIGNED] [ZEROFILL]，但如果SQL mode指定了REAL_AS_FLOAT，那么它等价于FLOAT[(M,D)] [UNSIGNED] [ZEROFILL]。 日期和时间类型 DATE日期类型，展示格式为’YYYY-MM-DD’，支持的范围是[‘1000-01-01’ , ‘9999-12-31’]。 DATETIME[(fsp)]日期时间格式，展示格式为’YYYY-MM-DD hh:mm:ss[.fraction]，支持范围是[‘1000-01-01 00:00:00.000000’, ‘9999-12-31 23:59:59.999999’]，fsp表示小数位数，默认是0，取值范围是[0,6]。 TIMESTAMP[(fsp)]时间戳，范围是[‘1970-01-01 00:00:01.000000’ UTC, ‘2038-01-19 03:14:07.999999’ UTC]，注意到起始秒数从1开始，是因为0被保留用来代表’0000-00-00 00:00:00’了，fsp表示小数位数，默认是0，取值范围是[0,6]。 TIME[(fsp)]时间类型，展示格式为 ‘hh:mm:ss[.fraction]’，支持的范围是[‘-838:59:59.000000’, ‘838:59:59.000000’]，fsp表示小数位数，默认是0，取值范围是[0,6]。 YEAR[(4)]代表年份类型，展示格式为’YYYY’，支持的范围是[1901, 2155]和0000。 字符串类型 [NATIONAL] CHAR[(M)] [CHARACTER SET charset_name] [COLLATE collation_name]固定长度的字符串，M表示字符串最大长度，范围是(0,255]，若实际长度不足M，实际串右侧会填充空格，M默认为1。 [NATIONAL] VARCHAR(M) [CHARACTER SET charset_name] [COLLATE collation_name]可变长度的字符串，M表示字符串最大长度，范围是(0, 65535],当存储UTF8编码中文时，一般需要3个字节存储一个汉字。 BINARY[(M)]与CHAR类似，只是存储的是二进制字节串而非普通的字符串。 VARBINARY(M)]与VARCHAR类似，只是存储的是二进制字节串而非普通的字符串。 TINYBLOB字节串，最大长度是255。 TINYTEXT [CHARACTER SET charset_name] [COLLATE collation_name]字符串，最大长度是255。 BLOB[(M)]字节串，最大长度64K-1，若指定M，则会创建一个能存储M字节最小的BLOB类型，比如TINYBLOB。 TEXT[(M)] [CHARACTER SET charset_name] [COLLATE collation_name]字符串，最大长度64K-1，若指定M，则会创建一个能存储M字节最小的BLOB类型，比如TINYTEXT。 MEDIUMBLOB字节串，最大长度16M-1。 MEDIUMTEXT [CHARACTER SET charset_name] [COLLATE collation_name]字符串，最大长度16M-1。 LONGBLOB字节串，最大长度4G-1。 LONGTEXT [CHARACTER SET charset_name] [COLLATE collation_name]字符串，最大长度4G-1。 ENUM(‘value1’,’value2’,…) [CHARACTER SET charset_name] [COLLATE collation_name]枚举值，一个字符串代表一个值，内部通过整数实现，理论上最多可以有65535个不同的值，但实际上这个值小于3000。 SET(‘value1’,’value2’,…) [CHARACTER SET charset_name] [COLLATE collation_name]集合，包含一组字符串，其内部还是呈现为一个整数，最大可以有64个不同的字符串对象。 特殊数据类型 Mysql提供了GEOMETRY、POINT、LINESTRING、POLYGON等特殊类型来与OpenGIS类一一对应，用来存储一些图形数据，同时还有MULTIPOINT、MULTILINESTRING、MULTIPOLYGON、GEOMETRYCOLLECTION可以表示这些集合，我感觉我是没机会用这些了，用到了再展开说吧。 Json数据类型 自从Mysql5.7.8之后添加的一种类型，可以存储{“k1”: “val”, “k2”: 110}形式的数据。 常用数据类型大小 类型 存储数据范围（只考虑无符号） 单位 TINYINT 0-255 整数 SMALLINT 0-65535 整数 MEDIUMINT 0-16777215 整数 INT 0-4294967295 整数 BIGINT 0-18446744073709551615 整数 DATETIME 1000-01-01 00:00:00.000000 -&gt; 9999-12-31 23:59:59.999999 时间点 TIMESTAMP 1970-01-01 00:00:01.000000 UTC -&gt; 2038-01-19 03:14:07.999999 UTC. 时间点 TIME -838:59:59.000000 -&gt; 838:59:59.000000 时间点 CHAR 0-255 字符数 VARCHAR 0-65535 字符数 BINARY 0-255 字节数 VARBINARY 0-65535 字节数 TINYBLOB 255 字节数 BLOB 65535(64K-1) 字节数 MEDIUMBLOB 16777215(16M-1) 字节数 LONGBLOB 4294967295(4G-1) 字节数]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>char</tag>
        <tag>varchar</tag>
        <tag>blob</tag>
        <tag>varbinary</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[逐步砍掉树杈的堆排序]]></title>
    <url>%2Fblog%2F2019%2F06%2F29%2F%E9%80%90%E6%AD%A5%E7%A0%8D%E6%8E%89%E6%A0%91%E6%9D%88%E7%9A%84%E5%A0%86%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言在实现堆排序之前，我们先来看看常见的数据结构，在网上我看到了一个特别全的版本：数组，栈，链表，队列，树，堆，图，散列表，本着鸡蛋里挑骨头的态度，我们来看看数组和链表，这两个到底算不算数据结构，貌似它们应该算是线性表这个结构，它们更应该被称作是一个实现结构的元素，比如通过数组和链表可以实现线性表、队列、栈，二叉树等等，可是看看数据结构的定义是计算机存储、组织数据的方式，貌似它们又算是数据结构，反正这个概念模模糊糊，不太清楚，要按我的理解常见结构应该只有线性表、栈、队列、树、图，其他的像堆其实是一种树，散列表很多的内部实现也是树。 好了，数据结构的事情也放一边，今天的目的是排序，主角是堆，那么究竟什么是堆呢？它的形状和山一样，只不过比山要“便宜”，比如土堆、煤堆、垃圾堆，这和金山、银山、绿水青山是没法比的，但是形状相似，只是小一点而已，上边小下边大，尖尖的，从侧面看就是第一个三角形。堆排序中的堆也是这种形状，上边窄下边宽呈现出一个三角形，其本质是一颗完全二叉树，一个n层的二叉树只有最后一层叶子节点可能不完整，但是都靠左排列，最多只有一个单叶子节点，如果说到这里你根本不知道什么是完全二叉树，甚至对树结构都是一头雾水，那么请去补补课，查询一下相关的定义就明白了。 一棵树要想被称为堆结构，光满足完全二叉树还不够，其中的元素也有要求，如果每个父节点都大于等于左右子节点被称为大根堆，如果每个父节点都小于等于左右子节点被称为小根堆，这样我们就知道在堆这个结构中，堆的顶端不是最大的值就是最小的值。 堆顶元素恰恰是堆排序的关键，试想一个有大根堆，我们把堆顶的数据拿下来放到一旁，把剩下的元素再调整成一个大根堆，然后再把堆顶数据拿下来放在刚才拿出那个元素的前面，再调整剩下的元素，反复这样操作，最后拿出来的这些元素就构成了一个有序序列，也就达到了排序的目的。 在进行升序排列时常使用大根堆，降序排列时常使用小根堆，这个知识点不是绝对的，也不需要记忆，只是这样操作更加方便，当你理解了堆排序的流程之后，很自然就能明白这样的用意，并且到那时候你完全可以反着操作来提升自己，不过效果和可读性可能会差一点。 堆排序树结构可以用数组表示出来，特别是完全二叉树用数组表示起来更加方便，从上往下，从左往右依次把数据放入数组，我们就把一颗完全二叉树塞进了一维数组里，本来打算一个图都不画的，但是突然良心发现了，不能对你们太残忍，还是画一个吧，下面这个图展示了完全二叉树与数组的对应关系，这可是本文中唯一的一个图了，可要珍惜一下，把这个图弄明白，之后我们就只操作数组，不再画树了，因为我太懒了。 1234567891011graph TB 2--&gt;3; 2--&gt;9; 3--&gt;4; 3--&gt;7; 9--&gt;12; 9--&gt;6; 4--&gt;1; 4--&gt;11; 7--&gt;5; 7--&gt;8; idx_0 idx_1 idx_2 idx_3 idx_4 idx_5 idx_6 idx_7 idx_8 idx_9 idx_10 2 3 9 4 7 12 6 1 11 5 8 这个用数组表示的完全二叉树有一个性质，这个性质是我编的，你之前可能没有听过，那就是从后面删除n个节点之后，剩下的元素还是一颗完全二叉树，这一点隐含在堆排序的整个过程中，并且二叉树的父节点都排列在数组前面，叶子节点都排在数组后边，父节点和子节点对应的索引满足一定的关系： 假设父节点索引是i，左节点索引=2*i+1 假设父节点索引是i，右节点索引=2*i+2 假设子节点索引是i，父节点的索引=(int)((i-1)/2) 明白了上面的关系，先简单描述一下堆排序的整个过程，操作的数据源就是这个数组，长度n=11，先将整个数组表示的完全二叉树调整成一个大根堆，这时树的根节点也就是数组的第一个元素就是最大值，把它和数组的最后一个元素交换，之后不再管最后这个数据，相当于把这个树杈砍掉了，根据上段提到的性质，砍掉最后一个叶子节点的二叉树仍然是一颗完全二叉树，调整数据使得前n-1个节点再次成为一个大根堆，继续把根节点索引为0的元素，也就是这个次最大值，与倒数第二个元素交换，之后也放弃倒数第二个元素了，相当于再次砍掉了这棵二叉树的一个树杈，如此反复操作，当“砍”到根节点时，整个数组也就从小到大排好序了。 排序过程通过上面描述可能还是不太明白堆排序的过程，接下来可以通过一个例子来实际操作一次，看看数组是怎样在不断调整大根堆的过程中慢慢变成有序的，数组的初始状态是： idx_0 idx_1 idx_2 idx_3 idx_4 idx_5 idx_6 idx_7 idx_8 idx_9 idx_10 2 3 9 4 7 12 6 1 11 5 8 先将数组代表的完全二叉树调整成一个大根堆 首先需要确认的是这个调整应该从下往上调整，先看最下边的子树，调整父节点和子节点的数据，使得父节点数据最大，然后再看前一个子树，继续把父子节点的数据调整好，这样一直调整到根节点时，整个完全二叉树的最大值就被调整到根节点了。这个过程有点像冒泡，从下往上，把最大的数据慢慢的冒到最上面。 反过来想想，如果是从上往下挨个子树来看，当从根节点调整到最后一个（最下最右）子树，并不能保证根节点数据最大，只是把较大数据向上整体移动了一次，所以还是要从下往上调整。 知道了这一点以后就要找到最后一个子树的位置，其实就是找到最后一个父节点，这个节点之前的数据都在非叶子节点上，这个节点之后的数据都在叶子节点上，只要调整这个最后父节点以及前面的所有节点就可以影响所有数据，关键是找到这个节点的位置。 要想找到最后一个父节点需要用到之前我们提到的公式，整个数组的元素个数n=11，最后一个元素的索引为n-1，那么其父节点就是最后一个子树的父节点，其索引应该为(int)((n-1-1)/2)，也就是n/2-1，这就是最后一个子树父节点的在数组中的索引，其数值为4，接着从这个节点开始从后往前调整子树： 子树父节点，索引i=4时，调整父节点和右孩子的值（从左右孩子中找一个较大的值，并且要大于父节点） |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|9|4|7(parent)|12|6|1|11|5(left)|8(right)| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|9|4|8(parent)|12|6|1|11|5(left)|7(right)| 子树父节点，索引i=3时，调整父节点和右孩子的值 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|9|4(parent)|8|12|6|1(left)|11(right)|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|9|11(parent)|8|12|6|1(left)|4(right)|5|7| 子树父节点，索引i=2时，调整父节点和左孩子的值 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|9(parent)|11|8|12(left)|6(right)|1|4|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3|12(parent)|11|8|9(left)|6(right)|1|4|5|7| 子树父节点，索引i=1时，调整父节点和左孩子的值，这时左孩子同时也是下面子树的父节点，所以还要调整一下该节点作为父节点的子树 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|3(parent)|12|11(left)|8(right)|9|6|1|4|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|11(parent)|12|3(left)|8(right)|9|6|1|4|5|7| 左子树节点作为父节点进行调整 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|11|12|3(tmp parent)|8|9|6|1(tmp left)|4(tmp right)|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2|11|12|4(tmp parent)|8|9|6|1(tmp left)|3(tmp right)|5|7| 子树父节点，索引i=0时，调整父节点和右孩子的值，这时右孩子同时也是下面子树的父节点，同样还要调整一下该节点作为父节点的子树 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||2(parent)|11(left)|12(right)|4|8|9|6|1|3|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||12(parent)|11(left)|2(right)|4|8|9|6|1|3|5|7| 右子树节点作为父节点进行调整 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||12|11|2(tmp parent)|4|8|9(tmp left)|6(tmp right)|1|3|5|7| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||12|11|9(tmp parent)|4|8|2(tmp left)|6(tmp right)|1|3|5|7| 到此为止整个大根堆就调整完成了，为了看的更加清楚。我不得不打脸再画一个图了，有时候还是看图更加方便，一图胜千言啊： |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||12|11|9|4|8|2|6|1|3|5|7| 1234567891011graph TB 12--&gt;11; 12--&gt;9; 11--&gt;4; 11--&gt;8; 9--&gt;2; 9--&gt;6; 4--&gt;1; 4--&gt;3; 8--&gt;5; 8--&gt;7; 将大根堆根节点保存的最大值与当前大根堆最后一个节点进行交换，然后将这个节点“砍掉” 交换数据后，将剩余的这个完全二叉树继续调整成大根堆，既然已经打脸了，那就再画个图，这个砍树杈的动作已经和标题呼应了，每次生成大根堆后，将根节点和堆的最后一个结点交换，然后砍掉这个树杈，等整棵树被砍的只剩下根节点，排序也就完成了。 |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||12(head)|11|9|4|8|2|6|1|3|5|7(tail)| |idx_0|idx_1|idx_2|idx_3|idx_4|idx_5|idx_6|idx_7|idx_8|idx_9|idx_10||:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:||7(head)|11|9|4|8|2|6|1|3|5|12(tail)| 1234567891011graph TB 7--&gt;11; 7--&gt;9; 11--&gt;4; 11--&gt;8; 9--&gt;2; 9--&gt;6; 4--&gt;1; 4--&gt;3; 8--&gt;5; 8--&gt;|X|12; 重复上面的步骤，循环执行调整剩余元素为大根堆，首位交换，砍掉末尾元素这三步 这里需要注意的是除了第一次初始化成大根堆的过程比较麻烦，后面重复调整成大根堆的过程都很容易，因为只有这一个根节点不满足大根堆的定义，所以只从这个节点调整就可以，同时递归调整其不符合条件的子树即可。 每次交换之后都会“砍掉”树杈，所以大根堆每次都会减少元素，交换的索引也发生这变化，第一个是array[0]和array[n-1]，然后是array[0]和array[n-2]，最后一直交换到array[0]和array[1]，也就完成了整体的排序。 代码实现1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*功能： 交换两个变量参数： element1--被交换的第一个元素的地址 element2--被交换的第二个元素的地址返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void swap_data(int* element1, int* element2)&#123; int middle_value = *element1; *element1 = *element2; *element2 = middle_value;&#125;/*功能： 从start到end构成最大堆，前提是start之后的部分已满足最大堆， 也就是说start存在左右子树的情况下，子树已经是最大堆参数： array--表示待排序的数组，此处会退化成指针 start--需要调整的父节点索引 end --最后一个可以被调整的节点索引，当形成最大堆后，第一个节点与当前最后节点交换后，那么这个当前最后节点下一轮就不能被调整了返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void max_heapify(int array[], int start, int end)&#123; int parent_index = start; int child_index = start * 2 + 1; while (child_index &lt;= end) &#123; if (child_index + 1 &lt;= end &amp;&amp; array[child_index] &lt; array[child_index + 1]) ++child_index; // 如果右边的孩子更大，选择右边的 if (array[parent_index] &gt; array[child_index]) break; swap_data(&amp;array[parent_index], &amp;array[child_index]); parent_index = child_index; child_index = parent_index * 2 + 1; &#125;&#125;/*功能： 堆排序，实现数组元素从小到大排列参数： array--表示待排序的数组，此处会退化成指针 count--数组元素的个数返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void heap_sort(int array[], int count)&#123; for (int pos = count / 2 - 1; pos &gt;= 0; --pos) max_heapify(array, pos, count - 1); for (int target_pos = count - 1; target_pos &gt; 0; --target_pos) &#123; swap_data(&amp;array[0], &amp;array[target_pos]); max_heapify(array, 0, target_pos - 1); &#125;&#125; 代码分析堆排序其实是一种选择排序，但是堆排序的代码比选择排序要复杂一下，其实理解了算法思路这些代码还是很容易看懂的，函数heap_sort是堆排序的主体逻辑，第一个for循环是从最后一个父节点开始调整，将父节点与较大的子节点交换，一直调整到根节点，初始化成一个大根堆。 第二个for循环就是重复做交换首尾元素，然后调整剩余元素使其成为大根堆这两件事，重复n-1轮，排序过程也就完成了。 运行测试在线编辑器是一个很方便的测试代码的环境，如果想本地调试一下，也可以直接下载堆排序–源码，在本地编译后进行调试，其实单步调试是理解算法思路很有效的方式。]]></content>
      <categories>
        <category>Sort</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>算法</tag>
        <tag>概念</tag>
        <tag>Sort</tag>
        <tag>堆</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[float的精度和取值范围]]></title>
    <url>%2Fblog%2F2019%2F06%2F27%2Ffloat%E7%9A%84%E7%B2%BE%E5%BA%A6%E5%92%8C%E5%8F%96%E5%80%BC%E8%8C%83%E5%9B%B4%2F</url>
    <content type="text"><![CDATA[前言关于float的精度和取值范围这个问题，我查询了很多次，每次都是用完就忘了，等到再使用的时候还需要再次查询，关键是这个问题大家给出的结果并不都是一致的，我得从众多的资料当中选择出正确的观点，这还要额外花一些时间，所以我决定也总结一次，方便我以后拿来直接用了，如果能给大家带来帮助那就更好了。下面提到一些说法很多都是我个人的理解，如果大家有疑义，欢迎讨论。 精度限制首先考虑下为什么会产生精度问题，是因为存储数据的空间有限，以一个四字节整数int n;为例，一共有32位，取值范围是 [-2147483648‬, 21474836487] ，一共是4,294,967,296种可能，它的精度可以说是小数点后一位都不保留，也就是只有整数，换句话说变量n可以表示实数范围内的4,294,967,296个数值。 如果换成float类型呢？一个变量float f所能表示多少个数呢？实际上由于存储空间未发生变化，同样是4字节32位，那么float类型也只能表示，或者说精确表示4,294,967,296个数值（实际上由于一些特殊的规则，最终所表示的数字个数还要少），说到这里很多人可能会疑惑，因为他知道float可以表示比4,294,967,296大的数，同时也能表示小数，如果只有4,294,967,296种可能，那究竟是怎么做到的呢？ 这里也就开始提到精度了，整数很好理解，每个数字的间隔都是1，int类型所表示的4,294,967,296个数字都是等间距的，步长为1。而float也只能表示4,294,967,296个数字，同时要表示比int还大的范围，一个很直观的想法就是把间距拉大，这样范围就大了，但是float还要表示小数，像0.2、0.4这样的数字间距明显要小于1啊，想要存储小数貌似要把间距缩小，这就和前面矛盾了啊。 实际上float类型存储数据的间隔不是等间距的，而是在0的附近间距小，在远离0的位置间距大，为什么会这样，一会我们看一下float类型数据的存储规则就明白了，这里先来看一下int类型和float类型所表示数字的范围对比，这只是一个示意图。 1234//int [ * * * 0 * * * ]//float[ * * * * * * * * * * * 0 * * * * * * * * * * * ] 上面的示意图就是两者表示数字范围的差异，每个星号*就表示一个数字，float通过这种不等间距的分布，既扩大了范围也表示了小数，那么有没有问题呢？ 当然有问题，饭就这么多，人多了自然不够吃了，因为远离0的位置间距越来越大，当要表示间距中间的一个数字时，只能找它附近离它最近的一个可以表示的数字来代替，这就导致了精度问题，比如我给一个float类型变量分别赋值为 4294967244 和 4294967295 ，再次输出时都变成了 4294967296，因为超过了精度，所以只能找最接近的数字代替。 float存储方式这部分内容基本上各篇文章说的都一致，我也简单描述下，后面根据这部分的定义来推算一下float的精度和取值范围。 首先我们知道常用科学计数法是将所有的数字转换成(±)a.b x $10^c$ 的形式，其中a的范围是1到9共9个整数，b是小数点后的所有数字，c是10的指数。而计算机中存储的都是二进制数据，所以float存储的数字都要先转化成(±)a.b x $2^c$，由于二进制中最大的数字就是1，所以表示法可以写成(±)1.b x $2^c$的形式，float要想存储小数就只需要存储(±)，b和c就可以了。 float的存储正是将4字节32位划分为了3部分来分别存储正负号，小数部分和指数部分的： Sign（1位）：用来表示浮点数是正数还是负数，0表示正数，1表示负数。 Exponent（8位）：指数部分。即上文提到数字c，但是这里不是直接存储c，为了同时表示正负指数以及他们的大小顺序，这里实际存储的是c+127。 Mantissa（23位）：尾数部分。也就是上文中提到的数字b。 三部分在内存中的分布如下，用首字母代替类型 S E E E E E E E E M M M M M M M M M M M M M M M M M M M M M M 0 1 0 0 0 0 0 0 1 1 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 0 1 1 0 float存储示例以数字6.5为例，看一下这个数字是怎么存储在float变量中的： 先来看整数部分，模2求余可以得到二进制表示为110。 再来看小数部分，乘2取整可以得到二进制表示为.1（如果你不知道怎样求小数的二进制，请主动搜索一下）。 拼接在一起得到110.1然后写成类似于科学计数法的样子，得到1.101 x $2^2$。 从上面的公式中可以知道符号为正，尾数是101，指数是2。 符号为正，那么第一位填0，指数是2，加上偏移量127等于129，二进制表示为10000001，填到2-9位，剩下的尾数101填到尾数位上即可 S E E E E E E E E M M M M M M M M M M M M M M M M M M M M M M 0 1 0 0 0 0 0 0 1 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 内存中二进制数01000000 11010000 00000000 00000000表示的就是浮点数6.5 float范围明白了上面的原理就可求float类型的范围了，找到所能表示的最大值，然后将符号为置为1变成负数就是最小值，要想表示的值最大肯定是尾数最大并且指数最大，那么可以得到尾数为 0.1111111 11111111 11111111，指数为 11111111，但是指数全为1时有其特殊用途，所以指数最大为 11111110，指数减去127得到127，所以最大的数字就是1.1111111 1111111 11111111 x $2^{127}$，这个值为 340282346638528859811704183484516925440，通常表示成 3.4028235E38，那么float的范围就出来了： [-3.4028235E38, 3.4028235E38] float精度float 类型的数据精度取决于尾数，相信大家都知道这一点，但是精度怎么算我也是迷糊了好久，最近在不断尝试的过程中渐渐的明白了，首先是在不考虑指数的情况下23位尾数能表示的范围是[0, $2^{23}-1$]，实际上尾数位前面还隐含了一个”1”，所以应该是一共24位数字，所能表示的范围是[0, $2^{24}-1$]（因为隐含位默认是”1”，所以表示的数最小是1不是0，但是先不考虑0，后面会特殊介绍，这里只按一般值计算），看到这里我们知道这24位能表示的最大数字为$2^{24}$-1，换算成10进制就是16777215，那么[0, 16777215]都是能精确表示的，因为他们都能写成1.b x $2^c$的形式，只要配合调整指数c就可以了。 16777215 这个数字可以写成1.1111111 11111111 1111111 $2^{23}$，所以这个数可以精确表示，然后考虑更大的数16777216，因为正好是2的整数次幂，可以表示1.0000000 00000000 00000000 $2^{24}$，所以这个数也可以精确表示，在考虑更大的数字16777217，这个数字如果写成上面的表示方法应该是 1.0000000 00000000 00000000 1 * $2^{24}$，但是这时你会发现，小数点后尾数位已经是24位了，23位的存储空间已经无法精确存储，这时浮点数的精度问题也就是出现了。 看到这里发现 16777216 貌似是一个边界，超过这个数的数字开始不能精确表示了，那是不是所有大于16777216的数字都不能精确表示了呢？其实不是的，比如数字 33554432 就可以就可以精确表示成1.0000000 00000000 00000000 * $2^{25}$，说道这里结合上面提到的float的内存表示方式，我们可以得出大于 16777216 的数字（不超上限），只要可以表示成小于24个2的n次幂相加，并且每个n之间的差值小于24就能够精确表示。换句话来说所有大于 16777216 的合理数字，都是[0, 16777215]范围内的精确数字通过乘以$2^n$得到的，同理所有小于1的正数，也都是 [0, 16777215] 范围内的精确数字通过乘以$2^n$得到的，只不过n取负数就可以了。 16777216 已经被证实是一个边界，小于这个数的整数都可以精确表示，表示成科学技术法就是1.6777216 * $10^{7}$，从这里可以看出一共8位有效数字，由于最高位最大为1不能保证所有情况，所以最少能保证7位有效数字是准确的，这也就是常说float类型数据的精度。 float小数从上面的分析我们已经知道，float可表示超过16777216范围的数字是跳跃的，同时float所能表示的小数也都是跳跃的，这些小数也必须能写成2的n次幂相加才可以，比如0.5、0.25、0.125…以及这些数字的和，像5.2这样的数字使用float类型是没办法精确存储的，5.2的二进制表示为101.0011001100110011001100110011……最后的0011无限循环下去，但是float最多能存储23位尾数，那么计算机存储的5.2应该是101.001100110011001100110，也就是数字 5.19999980926513671875，计算机使用这个最接近5.2的数来表示5.2。关于小数的精度与刚才的分析是一致的，当第8位有效数字发生变化时，float可能已经无法察觉到这种变化了。 float特殊值我们知道float存储浮点数的形式是(±)1.b x $2^c$，因为尾数位前面一直是个1，所以无论b和c取什么样的值，都无法得到0，所以在float的表示方法中有一些特殊的约定，用来表示0已经其他的情况。 float的内存表示指数位数有8位，范围是[0, 255]，考虑偏移量实际的指数范围是[-127,128]，但实际情况下指数位表示一般数字时不允许同时取0或者同时取1，也就是指数位的实际范围是[-126,127]，而指数取-127和128时有其特殊含义，具体看下面表格： 符号位 指数位 尾数位 数值 含义 0 全为0 全为0 +0 正数0 1 全为0 全为0 +0 负数0 0 全为0 任意取值f $0.f * 2^{-126}$ 非标准值，尾数前改为0，提高了精度 1 全为0 任意取值f $-0.f * 2^{-126}$ 非标准值，尾数前改为0，提高了精度 0 全为1 全为0 +Infinity 正无穷大 1 全为1 全为0 -Infinity 负无穷大 0/1 全为1 不全为0 NaN 非数字，用来表示一些特殊情况 总结 float的精度是保证至少7位有效数字是准确的 float的取值范围[-3.4028235E38, 3.4028235E38]，精确范围是[-340282346638528859811704183484516925440, 340282346638528859811704183484516925440] 一个简单的测试float精度方法，C++代码中将数字赋值给float变量，如果给出警告warning C4305: “=”: 从“int”到“float”截断，则超出了float的精度范围，在我的测试中赋值为16777216及以下整数没有警告，赋值为16777217时给出了警告。]]></content>
      <categories>
        <category>concepts</category>
      </categories>
      <tags>
        <tag>float</tag>
        <tag>精度</tag>
        <tag>取值范围</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中使用count加条件统计]]></title>
    <url>%2Fblog%2F2019%2F06%2F03%2FMysql%E4%B8%AD%E4%BD%BF%E7%94%A8count%E5%8A%A0%E6%9D%A1%E4%BB%B6%E7%BB%9F%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[前言最近发现在处理Mysql问题时，count()函数频繁上镜，常常出现在分组统计的情景下，但是有时候并不是使用group by分好组就可以直接统计了，比如说一个常见的需求，统计每个班级男生所占的比例，这种情况一般会按照班级分组，但是分组内不但要统计班级的人数，还要统计男生的人数，也就是说统计是有条件的，之前确实没有考虑过怎样实心，后来查询了资料，总结在这里，方便日后查找使用。 Mysql中count()函数的一般用法是统计字段非空的记录数，所以可以利用这个特点来进行条件统计，注意这里如果字段是NULL就不会统计，但是false是会被统计到的，记住这一点，我们接下来看看几种常见的条件统计写法。 测试环境 Windows 10Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 准备工作 新建一个Mysql数据表a，包含id和num两个字段 12mysql&gt; create table a(id int, num int);Query OK, 0 rows affected (0.04 sec) 插入测试数据，为了看count()函数的效果，我们插入两个空数据 123mysql&gt; insert into a values (1,100),(2,200),(3,300),(4,300),(8,null),(9,null);Query OK, 6 rows affected (0.01 sec)Records: 6 Duplicates: 0 Warnings: 0 查询表a中的数据，与后面的统计做比较 123456789101112mysql&gt; select * from a;+----+------+| id | num |+----+------+| 1 | 100 || 2 | 200 || 3 | 300 || 4 | 300 || 8 | NULL || 9 | NULL |+----+------+6 rows in set (0.09 sec) 调用count()函数看效果，如果使用count(*)会查询出所有的记录数，但如果使用count(num)发现只有4条数据，num为NULL的记录并没有统计上 123456789101112131415mysql&gt; select count(*) from a;+----------+| count(*) |+----------+| 6 |+----------+1 row in set (0.03 sec)mysql&gt; select count(num) from a;+------------+| count(num) |+------------+| 4 |+------------+1 row in set (0.04 sec) 条件统计 count()函数中使用条件表达式加or null来实现，作用就是当条件不满足时，函数变成了count(null)不会统计数量 1234567mysql&gt; select count(num &gt; 200 or null) from a;+--------------------------+| count(num &gt; 200 or null) |+--------------------------+| 2 |+--------------------------+1 row in set (0.22 sec) count()函数中使用if表达式来实现，当条件满足是表达式的值为非空，条件不满足时表达式值为NULL; 1234567mysql&gt; select count(if(num &gt; 200, 1, null)) from a;+-------------------------------+| count(if(num &gt; 200, 1, null)) |+-------------------------------+| 2 |+-------------------------------+1 row in set (0.05 sec) count()函数中使用case when表达式来实现，当条件满足是表达式的结果为非空，条件不满足时无结果默认为NULL; 1234567mysql&gt; select count(case when num &gt; 200 then 1 end) from a;+---------------------------------------+| count(case when num &gt; 200 then 1 end) |+---------------------------------------+| 2 |+---------------------------------------+1 row in set (0.07 sec) 总结使用count()函数实现条件统计的基础是对于值为NULL的记录不计数，常用的有以下三种方式，假设统计num大于200的记录 select count(num &gt; 200 or null) from a; select count(if(num &gt; 200, 1, null)) from a select count(case when num &gt; 200 then 1 end) from a]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>count</tag>
        <tag>条件统计</tag>
        <tag>if</tag>
        <tag>casewhen</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gdb启动多进程程序并切换调试进程]]></title>
    <url>%2Fblog%2F2019%2F05%2F24%2Fgdb%E5%90%AF%E5%8A%A8%E5%A4%9A%E8%BF%9B%E7%A8%8B%E7%A8%8B%E5%BA%8F%E5%B9%B6%E5%88%87%E6%8D%A2%E8%B0%83%E8%AF%95%E8%BF%9B%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言gdb是linux环境下调试C/C++程序的强大工具，但是最近在使用gdb启动一个多进程程序的时候总是意外退出，显示信息中包含Detaching after fork from child process 25377.这一句，而用attach命令附加到正在运行的进程却没有问题，因为需要调试启动逻辑的部分代码，所以必须使用gdb启动多进程程序，后来发现可以通过gdb的follow-fork-mode选项来切换进程，达到调试指定进程的目的。 使用方法1set follow-fork-mode [parent|child] 这个命令只要gdb启动程序之后，在运行r命令之前敲入即可，如果不设置默认是parent模式，如果调试的child模式，就需要手动切换，我遇到的问题就是，程序启动使用fork()函数创建出子进程之后就把父进程退出了，gdb默认调试parent进程，也跟着结束了，所以出现了之前所说的Detaching after fork from child process 25377.信息，接下来可以写个简单的例子测试一下。 测试环境123456789101112131415[albert@localhost#20:15:45#/home/albert/gdbtest]$cat /etc/issueCentOS release 6.3 (Final)Kernel \r on an \m[albert@localhost#20:16:25#/home/albert/gdbtest]$gdb --versionGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;.[albert@localhost#20:16:36#/home/albert/gdbtest]$^C 具体例子 先写一个简单的多进程程序，模拟我遇到的问题，父进程退出，子进程继续工作 1234567891011121314151617181920212223242526#include &lt;unistd.h&gt;#include &lt;stdlib.h&gt;int main ()&#123; pid_t pid; //pid表示fork函数返回的值，会根据不同进程返回不同值 pid = fork(); if (pid &lt; 0) &#123; exit(-1); &#125; else if (pid == 0) // 子进程返回pid为0 &#123; unsigned int u = 0; while(true) &#123; ++u; sleep(1); &#125; &#125; else // 父进程返回pid为子进程的id，大于0 &#123; exit(1); &#125; return 0;&#125; 将代码编译成可执行程序 1[albert@localhost#20:04:31#/home/albert/gdbtest]$g++ multiprocess.cpp -o multiprocess gdb启动程序并运行，其中我只输入了r和q两个gdb命令，发现程序运行r之后输出几行信息就退出了 1234567891011121314151617181920212223242526[albert@localhost#20:04:45#/home/albert/gdbtest]$gdb ./multiprocessGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/gdbtest/multiprocess...(no debugging symbols found)...done.(gdb) rStarting program: /home/albert/gdbtest/multiprocesswarning: the debug information found in "ld-2.12.so.debug" does not match "ld-linux-x86-64.so.2" (CRC mismatch).warning: the debug information found in "ld-2.12.so.debug" does not match "ld-linux-x86-64.so.2" (CRC mismatch).warning: the debug information found in "libm-2.12.so.debug" does not match "libm.so.6" (CRC mismatch).warning: the debug information found in "libm-2.12.so.debug" does not match "libm.so.6" (CRC mismatch).warning: the debug information found in "libc-2.12.so.debug" does not match "libc.so.6" (CRC mismatch).warning: the debug information found in "libc-2.12.so.debug" does not match "libc.so.6" (CRC mismatch).Detaching after fork from child process 25377.Program exited with code 01.Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-18.el6_9.2.x86_64(gdb) q[albert@localhost#20:05:03#/home/albert/gdbtest] 使用set follow-fork-mode child命令调试子进程，在r之前输入即可，这次发现程序停在了[New process 27522]，此时就可以打断点调试了 12345678910111213141516171819202122232425262728[albert@localhost#20:23:12#/home/albert/gdbtest]$gdb ./multiprocessGNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/gdbtest/multiprocess...(no debugging symbols found)...done.(gdb) set follow-fork-mode child(gdb) rStarting program: /home/albert/gdbtest/multiprocesswarning: the debug information found in "ld-2.12.so.debug" does not match "ld-linux-x86-64.so.2" (CRC mismatch).warning: the debug information found in "ld-2.12.so.debug" does not match "ld-linux-x86-64.so.2" (CRC mismatch).warning: the debug information found in "libm-2.12.so.debug" does not match "libm.so.6" (CRC mismatch).warning: the debug information found in "libm-2.12.so.debug" does not match "libm.so.6" (CRC mismatch).warning: the debug information found in "libc-2.12.so.debug" does not match "libc.so.6" (CRC mismatch).warning: the debug information found in "libc-2.12.so.debug" does not match "libc.so.6" (CRC mismatch).[New process 27522]^CProgram received signal SIGINT, Interrupt.[Switching to process 27522]0x00007ffff7354c30 in __nanosleep_nocancel () from /lib64/libc.so.6Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-18.el6_9.2.x86_64(gdb) b multiprocess.cpp:17 总结 gdb调试多进程程序时使用set follow-fork-mode [parent|child]命令 默认调试parent进程，想调试child进程，使用set follow-fork-mode child命令切换]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>linux</tag>
        <tag>gdb</tag>
        <tag>fork</tag>
        <tag>child</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql调优之Using filesort]]></title>
    <url>%2Fblog%2F2019%2F05%2F16%2FMysql%E8%B0%83%E4%BC%98%E2%80%94%E4%B9%8BUsing-filesort%2F</url>
    <content type="text"><![CDATA[前言在使用 explain 命令优化SQL语句的时候常常会在Extra列的描述中发现 Using filesort 选项，其实这个名字很容易造成误解，一开始我以为是“文件排序”的意思，进一步说可能就是使用了磁盘空间来进行排序，但是这个理解是错误的，Using filesort 真正含义其实只有 sort 这一个单词，和 file 没有什么关系，Mysql一般是通过内存进行排序的，不过，要是超过了配置中的限制，应该会生成临时表。 分析Using filesort 的含义很简单，就是使用了排序操作，出现这个选项的常见情况就是 Where 条件和 order by 子句作用在了不同的列上，这种情况还有优化的余地，有些场景由于数据量太小或者语句的简单性可能都不需要优化，既然说Using filesort是使用了排序的意思，那么是不是包含了 order by 子句的查询语句都会有这个选项呢？其实这个排序操作有时是可以避免的。 如果你想把一个表中的所有数据按照指定顺序输出，那么整个排序几乎是不可避免的，比如这个语句select * from a order by id，即使在id列上建立了索引，为了生成指定顺序的数据，那么整个数据的排序也是需要，不过个别时候这个排序还是可以省略的，比如id是该表的主键，并且是自增长的，数据本身就是有序的，那么直接返回数据就行了，相当于 order by id 这一部分被忽略了。 上面提到的常见情况，SQL语句通常写成这样select * from a where type = 5 order by id，这类语句一般会产生 Using filesort 这个选项，即使你在 type 和 id 上分别添加了索引。我们想一下它的工作过程，先根据type的索引从所有数据信息中挑选出满足 type = 5 条件的，然后根据id列的索引信息对挑选的数据进行排序，所以产生了Using filesort选项，想想怎样可以把后面排序的这个步骤省略掉？联合索引可以解决这个问题。 可以在 type, id 两列上建立一个联合索引，索引类型一般是 BTREE，根据Mysql索引的最左原则，可以知道一共建立了type_index和type_id_index两条索引，由于有了 type_id_index 这个联合索引，后面的排序步骤就可以省略了，在按照type = 5 条件挑选数据时，挂在type = 5 节点下的数据，其实按照id列的值也是有顺序的，我们只需要在挑选数据的同时，按照id从小到大的顺序挑选即可，最后得到的数据就是有序的，直接返回就行了，从这一点可以看出，“排序”操作并不是不存在了，只是隐含在了前面必要的步骤中，不需要单独操作了而已，下面举个简单例子，看看具体的效果。 测试环境 Windows 10Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 具体操作 先建立一个测试表格tb，一般为了加快查询速度，会在常用的字段上建立索引 12mysql&gt; create table tb(id int, type int, weight int, index t_index(type), index w_index(weight));Query OK, 0 rows affected (0.02 sec) 创建一个存储fill_test_data用来插入测试数据，创建完成调用一下 12345678910111213141516CREATE PROCEDURE `fill_test_data`()BEGIN DECLARE i int default 1; DECLARE w int default 100; DECLARE t int default 1; WHILE i &lt;= 100000 do insert into tb values(i, t, w); set i = i + 1; set w = (w + 10) % 1000; set t = (t + 1) % 10; END WHILE;ENDmysql&gt; call fill_test_data();Query OK, 1 row affected (25.36 sec) 查询数据，让 Where 条件和 order by 子句作用在不同的列上 1234567891011121314mysql&gt; select * from tb where type = 3 order by weight;+-------+------+--------+| id | type | weight |+-------+------+--------+| 193 | 3 | 20 || 293 | 3 | 20 || 393 | 3 | 20 |...| 99683 | 3 | 920 || 99783 | 3 | 920 || 99883 | 3 | 920 || 99983 | 3 | 920 |+-------+------+--------+10000 rows in set (2.22 sec) 使用 explain命令分析查询语句，就会发现Using filesort出现在了Extra条目中 123456789101112131415mysql&gt; explain select * from tb where type = 3 order by weight\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb partitions: NULL type: refpossible_keys: t_index key: t_index key_len: 5 ref: const rows: 17672 filtered: 100.00 Extra: Using index condition; Using filesort1 row in set, 1 warning (0.00 sec) 使用SQL命令给表tb的type列和id列添加联合索引 123mysql&gt; alter table tb add index tw_index(type, weight);Query OK, 0 rows affected (0.17 sec)Records: 0 Duplicates: 0 Warnings: 0 再次查询数据，看看与上一次的查询时间相比有没有变化 1234567891011121314mysql&gt; select * from tb where type = 3 order by weight;+-------+------+--------+| id | type | weight |+-------+------+--------+| 193 | 3 | 20 || 293 | 3 | 20 || 393 | 3 | 20 |...| 99683 | 3 | 920 || 99783 | 3 | 920 || 99883 | 3 | 920 || 99983 | 3 | 920 |+-------+------+--------+10000 rows in set (2.13 sec) 再次使用 explain命令分析查询语句，就会发现Using filesort选项已经消失了 123456789101112131415mysql&gt; explain select * from tb where type = 3 order by weight\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: tb partitions: NULL type: refpossible_keys: t_index,tw_index key: tw_index key_len: 5 ref: const rows: 17672 filtered: 100.00 Extra: Using index condition1 row in set, 1 warning (0.00 sec)]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>查询</tag>
        <tag>Usingfilesort</tag>
        <tag>排序</tag>
        <tag>调优</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下查看C/C++程序的堆栈信息]]></title>
    <url>%2Fblog%2F2019%2F05%2F08%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%9F%A5%E7%9C%8BC-C-%E7%A8%8B%E5%BA%8F%E7%9A%84%E5%A0%86%E6%A0%88%E4%BF%A1%E6%81%AF%2F</url>
    <content type="text"><![CDATA[前言经常在Windows上开发的工程师们可能已经习惯了图形化的调试界面，在源代码的编辑框上点击就可以添加断点，在调用堆栈的窗口就可以看到程序运行的堆栈信息，但是在 linux 环境下，面对命令行的天下，我们需要掌握一些命令，才能够查看C/C++程序的堆栈信息。 测试环境1234567[albert@localhost#13:58:34#/home/albert]$cat /etc/issueCentOS release 6.3 (Final)Kernel \r on an \m[albert@localhost#13:58:43#/home/albert]$g++ --versiong++ (GCC) 4.4.7 20120313 (Red Hat 4.4.7-18)Copyright ?? 2010 Free Software Foundation, Inc. 查看方法 使用gdb程序调试core文件，格式为 gdb test_proc core.proc_id 使用gdb程序附加到调试程序的进程上，格式为 gdb attach proc_id 使用pstack程序输出调试程序的堆栈信息，格式为 pstack proc_id 使用strace程序打印调试程序的运行信息，格式为 strace -p proc_id 具体实践 一般查看堆栈信息时常常面对的都是多线程的程序，所以我们也来写一个简单的多线程小程序，代码如下： 12345678910111213141516171819202122232425262728293031323334353637#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;pthread.h&gt;#include &lt;unistd.h&gt;static void* thread_proc(void* arg)&#123; unsigned int sum = 3; while(true) &#123; for (int idx = 0; idx &lt; 1000000000; ++idx) sum += idx; printf("thread sum = %u\n", sum); sleep(2); &#125; return 0;&#125;int main()&#123; pthread_t thread_id; pthread_create(&amp;thread_id, NULL, thread_proc, NULL); unsigned int sum = 0; while(true) &#123; for (int idx = 0; idx &lt; 1000000000; ++idx) sum += idx; printf("main sum = %u\n", sum); sleep(1); &#125; return 0;&#125; 编译程序并运行，程序开始不断的打印计算结果 1234567891011[albert@localhost#15:06:54#/home/albert/test/threadtest]$g++ threadtest.cpp -O0 -pthread -o threadtest[albert@localhost#15:08:27#/home/albert/test/threadtest]$./threadtestthread sum = 3051657987main sum = 3051657984thread sum = 1808348675main sum = 1808348672main sum = 565039360thread sum = 565039363main sum = 3616697344thread sum = 3616697347... 现在可以通过上面描述的方法来查看threadtest程序堆栈信息了，几乎所有的命令都需要进程id，所以我们可以再开一个终端先通过pidof命令来获得： 12[albert@localhost#15:39:35#/home/albert/test/threadtest]$pidof threadtest21473 gdb调试core文件 通过kill命令产生core文件 使用命令 kill -11 21473可以将正在运行的程序杀死，并且产生core文件core.21473，-11表示段错误信号，通常是访问了无效的内存导致 通过gcore命令产生core文件 使用命令 gcore 21473可以产生core文件core.21473，但是不会杀死程序，适用于调试线上程序，又不影响用户使用的情况，可以测试一下： 12345678910111213[albert@localhost#15:39:43#/home/albert/test/threadtest]$gcore 21473warning: the debug information found in "/usr/lib/debug//lib64/libm-2.12.so.debug" does not match "/lib64/libm.so.6" (CRC mismatch)warning: the debug information found in "/usr/lib/debug/lib64/libm-2.12.so.debug" does not match "/lib64/libm.so.6" (CRC mismatch)warning: the debug information found in "/usr/lib/debug//lib64/libpthread-2.12.so.debug" does not match "/lib64/libpthread.so.0" (CRC mismatch)warning: the debug information found in "/usr/lib/debug/lib64/libpthread-2.12.so.debug" does not match "/lib64/libpthread.so.0" (CRC mismatch)[New LWP 21474][Thread debugging using libthread_db enabled]warning: the debug information found in "/usr/lib/debug//lib64/libc-2.12.so.debug" does not match "/lib64/libc.so.6" (CRC mismatch)warning: the debug information found in "/usr/lib/debug/lib64/libc-2.12.so.debug" does not match "/lib64/libc.so.6" (CRC mismatch)warning: the debug information found in "/usr/lib/debug//lib64/ld-2.12.so.debug" does not match "/lib64/ld-linux-x86-64.so.2" (CRC mismatch)warning: the debug information found in "/usr/lib/debug/lib64/ld-2.12.so.debug" does not match "/lib64/ld-linux-x86-64.so.2" (CRC mismatch)0x00000000004006eb in main ()Saved corefile core.21473 然后使用gdb调试core文件： 123456789101112131415161718192021222324252627[albert@localhost#15:47:13#/home/albert/test/threadtest]$gdb threadtest core.21473GNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...Reading symbols from /home/albert/test/threadtest/threadtest...(no debugging symbols found)...done.[New Thread 21474][New Thread 21473]Missing separate debuginfo forTry: yum --enablerepo='*-debug*' install /usr/lib/debug/.build-id/80/1b9608daa2cd5f7035ad415e9c7dd06ebdb0a2Reading symbols from /usr/lib64/libstdc++.so.6...(no debugging symbols found)...done.Loaded symbols for /usr/lib64/libstdc++.so.6Reading symbols from /lib64/libm.so.6......省略无关信息(no debugging symbols found)...done.Loaded symbols for /lib64/ld-linux-x86-64.so.2Core was generated by `./threadtest'.#0 0x0000000000400691 in thread_proc(void*) ()Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-18.el6_9.2.x86_64(gdb) 显示所有线程信息，可以使用gdb命令thread apply all bt： 123456789(gdb) thread apply all btThread 2 (Thread 0x7f1b4e1d2720 (LWP 21473)):#0 0x00000000004006eb in main ()Thread 1 (Thread 0x7f1b4d270700 (LWP 21474)):#0 0x0000000000400691 in thread_proc(void*) ()#1 0x00007f1b4d60caa1 in start_thread () from /lib64/libpthread.so.0#2 0x00007f1b4d359bcd in clone () from /lib64/libc.so.6 gdb附加到进程可以通过 gdb attach pid 直接附加到正在运行的程序上，然后查看线程信息thread apply all bt：123456789101112131415161718192021222324252627282930313233343536[albert@localhost#15:54:59#/home/albert/test/threadtest]$gdb attach 21473GNU gdb (GDB) Red Hat Enterprise Linux (7.2-83.el6)Copyright (C) 2010 Free Software Foundation, Inc.License GPLv3+: GNU GPL version 3 or later &lt;http://gnu.org/licenses/gpl.html&gt;This is free software: you are free to change and redistribute it.There is NO WARRANTY, to the extent permitted by law. Type "show copying"and "show warranty" for details.This GDB was configured as "x86_64-redhat-linux-gnu".For bug reporting instructions, please see:&lt;http://www.gnu.org/software/gdb/bugs/&gt;...attach: 没有那个文件或目录.Attaching to process 21473Reading symbols from /home/albert/test/threadtest/threadtest...(no debugging symbols found)...done.Reading symbols from /usr/lib64/libstdc++.so.6...(no debugging symbols found)...done.Loaded symbols for /usr/lib64/libstdc++.so.6Reading symbols from /lib64/libm.so.6......省略无关信息(no debugging symbols found)...done.Loaded symbols for /lib64/ld-linux-x86-64.so.20x00007f1b4d31dc4d in nanosleep () from /lib64/libc.so.6Missing separate debuginfos, use: debuginfo-install glibc-2.12-1.209.el6_9.2.x86_64 libstdc++-4.4.7-18.el6_9.2.x86_64(gdb) thread apply all btThread 2 (Thread 0x7f1b4d270700 (LWP 21474)):#0 0x00007f1b4d31dc4d in nanosleep () from /lib64/libc.so.6#1 0x00007f1b4d31dac0 in sleep () from /lib64/libc.so.6#2 0x00000000004006b6 in thread_proc(void*) ()#3 0x00007f1b4d60caa1 in start_thread () from /lib64/libpthread.so.0#4 0x00007f1b4d359bcd in clone () from /lib64/libc.so.6Thread 1 (Thread 0x7f1b4e1d2720 (LWP 21473)):#0 0x00007f1b4d31dc4d in nanosleep () from /lib64/libc.so.6#1 0x00007f1b4d31dac0 in sleep () from /lib64/libc.so.6#2 0x0000000000400721 in main () pstack输出堆栈信息如果不需要调试，只想查看运行程序当前的堆栈信息，可以使用pstack命令，输出信息很简洁：123456789[albert@localhost#15:57:53#/home/albert/test/threadtest]$pstack 21473Thread 2 (Thread 0x7f1b4d270700 (LWP 21474)):#0 0x0000000000400683 in thread_proc(void*) ()#1 0x00007f1b4d60caa1 in start_thread () from /lib64/libpthread.so.0#2 0x00007f1b4d359bcd in clone () from /lib64/libc.so.6Thread 1 (Thread 0x7f1b4e1d2720 (LWP 21473)):#0 0x00007f1b4d31dc4d in nanosleep () from /lib64/libc.so.6#1 0x00007f1b4d31dac0 in sleep () from /lib64/libc.so.6#2 0x0000000000400721 in main () strace打印程序运行情况strace输出的不是堆栈信息，而是类似于程序的运行步骤，具体信息如下：123456789101112131415161718[albert@localhost#15:57:56#/home/albert/test/threadtest]$strace -p 21473Process 21473 attachedwrite(1, "main sum = 2580918016\n", 22) = 22rt_sigprocmask(SIG_BLOCK, [CHLD], [], 8) = 0rt_sigaction(SIGCHLD, NULL, &#123;SIG_DFL, [], 0&#125;, 8) = 0rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0nanosleep(&#123;1, 0&#125;, 0x7fff56a49c50) = 0write(1, "main sum = 1337608704\n", 22) = 22rt_sigprocmask(SIG_BLOCK, [CHLD], [], 8) = 0rt_sigaction(SIGCHLD, NULL, &#123;SIG_DFL, [], 0&#125;, 8) = 0rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0nanosleep(&#123;1, 0&#125;, 0x7fff56a49c50) = 0write(1, "main sum = 94299392\n", 20) = 20rt_sigprocmask(SIG_BLOCK, [CHLD], [], 8) = 0rt_sigaction(SIGCHLD, NULL, &#123;SIG_DFL, [], 0&#125;, 8) = 0rt_sigprocmask(SIG_SETMASK, [], NULL, 8) = 0nanosleep(&#123;1, 0&#125;, 0x7fff56a49c50) = 0^CProcess 21473 detached 总结 在解决实际问题的过程中，上述几种方法可以结合使用，选取合适的使用方法，比如面对程序突然崩溃，那么gdb proc core就是调试的首选方法。 如果只是想简单的查看堆栈信息，可以使用pstack pid这种方式，免去了生成巨大core文件的麻烦。 如果还想查看运行逻辑中的变量信息，那么gdb使我们可以帮助我们动态调试程序，查看一些程序运行时的状态。]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>linux</tag>
        <tag>gdb</tag>
        <tag>strace</tag>
        <tag>pstack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python利用requests模块实现代理访问网络]]></title>
    <url>%2Fblog%2F2019%2F05%2F05%2FPython%E5%88%A9%E7%94%A8requests%E6%A8%A1%E5%9D%97%E5%AE%9E%E7%8E%B0%E4%BB%A3%E7%90%86%E8%AE%BF%E9%97%AE%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[前言代理相信很多人都听过，即使没有自己感受到，在无形之中可能也使用过，网络代理作为一项技术，在访问互联网时被广泛使用，那是因为使用代理有着诸多好处。 使用代理IP能够突破自身的访问限制，不要把突破限制看成是坏事情，有时后恰恰是为了网络安全才使用了代理，比如内网的一台服务器只针对特定的IP提供访问权限，这时如果给内部人员分配指定的代理就可以进行访问，不比对所有的IP地址都开放，代理IP还可以进行自主管理。 使用代理IP还提高访问速度，通常代理IP服务器都配置了一个较大的硬盘缓冲区，当缓冲区中保存有用户的请求信息时，则直接由缓冲区中取出信息，返回给用户，以提高访问速度。 测试环境12PS E:\&gt; python --versionPython 3.6.7 代码实现其实在Python 3中利用requests可以很方便的使用代理访问网络，比如下面这个简单的get方法：1requests.get(target_url, proxies=proxy_data) 其中需要注意的就是 proxies 参数的值，这里换成可以代理的ip就可以了，网上流传着众多的代理IP，只要可用就可以拿来代理IP访问，不过这些免费的IP失效性非常差，常常过几分钟就失效了，下面就给出一个完整的例子，检测代理IP是否可用： 1234567891011121314151617181920212223242526272829303132import requeststest_ip = '116.209.56.118'test_port = '9999'def test_proxy_request(ip, port): # 代理IP地址 proxy_data = &#123; 'http': 'http://' + ip + ':' + port, 'https': 'http://' + ip + ':' + port, &#125; # 客户端说明 head_data = &#123; 'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0', 'Connection': 'keep-alive' &#125; try: # 该返回当前的IP地址，http://icanhazip.com提供返回当前外网IP的服务 response = requests.get('http://icanhazip.com', headers=head_data, proxies=proxy_data) outer_ip = response.text.strip().replace('\n', '') return outer_ip == ip except: return Falseif __name__ == '__main__': test_result = test_proxy_request(test_ip, test_port) if test_result: print("IP代理成功 ==&gt; &#123;0&#125;:&#123;1&#125;".format(test_ip, test_port)) else: print("IP代理失败 ==&gt; &#123;0&#125;:&#123;1&#125;".format(test_ip, test_port)) 需要注意，其中只有这一句requests.get(&#39;http://icanhazip.com&#39;, headers=head_data, proxies=proxy_data)是代理的重点。 测试结果 IP代理成功 ==&gt; 116.209.56.118:9999]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>IP</tag>
        <tag>Python</tag>
        <tag>requests</tag>
        <tag>网络代理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中explain命令简析]]></title>
    <url>%2Fblog%2F2019%2F04%2F27%2FMysql%E4%B8%ADexplain%E5%91%BD%E4%BB%A4%E7%AE%80%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言之前总结了Mysql慢查询日志的开启与配置方法，通过分析慢查询日志可以锁定执行效率差的SQL，但是这仅仅是发现了需要优化的部分，还要分析执行缓慢的原因，这时候就可以使用EXPLAIN命令去分析，所执行的操作究竟慢在哪里，是不是可以通过加索引或者改变查询方法来解决。 通过查询资料发现除了EXPLAIN命令，还有一个DESCRIBE命令，看起来很陌生是不是，但是如果写出简写desc应该很多人的就熟悉了，这不是查询表结构的时候常用的命令吗？实际上以上三个命令在mysql中是等价的，不过在使用时有些习惯性的偏向，通常使用 EXPLAIN 来分析SQL语句的执行缓慢的问题，而使用 DESCRIBE 或者 desc 来查看表的结构，就类似于惯用法，知道就好。 测试环境 Windows 10Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. EXPLAIN 的使用关于 EXPLAIN 使用其实很简单，就是在正常的执行语句之前加一个explain 就可以了，不过这里也存在一个疑问，就是发现很多篇文章，提到下面这种说法： explain 只能解释select查询，并不会对存储过程、insert、update、delete或其他语句做解释 但是我查阅了官方文档发现，EXPLAIN 后面可以跟 SELECT、 DELETE、 INSERT、 REPLACE、和 UPDATE语句，另外之前使用的 EXPLAIN EXTENDED 选项现在也默认开启，EXTENDED 关键字后续会在 Mysql 8.0 版本删除，应该是版本问题导致了explain语句使用的差异，所以请记住在使用新版本的Mysql时，需要分析语句执行情况的，只需要在语句前面添加一个 explain关键字即可。 不过在分析 select 语句时，explain命令会给出额外的提示信息，帮助我们优化查询语句，这也是我们需要学习的重点，先来简单看一下使用方法： 普通的查询语句 123456789mysql&gt; select * from a;+----+-----+| id | num |+----+-----+| 1 | 100 || 2 | 200 || 3 | 300 |+----+-----+3 rows in set (0.05 sec) 使用 EXPLAIN 来分析普通的查询语句 1234567mysql&gt; explain select * from a;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+| 1 | SIMPLE | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | NULL |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------+1 row in set (0.04 sec) 通过上面的例子可以很清楚的知道 EXPLAIN 命令的使用方法，使用了 EXPLAIN 关键之后会生成一个分析结果的表格，该表格有id、select_type、table、partitions、type、possible_keys、key、key_len、ref、rows、filtered、Extra一共12列，而这12列中的内容代表的含义是我们学习的重点，也是我们进行优化的依据，这个结果集可能包含多行，其中每一行都是关于一个表的查询信息，可以针对于具体的表查询优化。 本来想每种情况后面紧跟一个例子的，但是发现这样会造成重点内容分散，不利于整体把握，所以还是先把各列可能的取值说清楚，然后在文末针对于上文的取值给出例子，如果看描述就能明白就可以省略例子的内容，否则可以对照着例子的写法理解一下, [eg：&lt;id-1&gt;]表示参考后面的例子&lt;id-1&gt;，想对照的话搜索即可。 EXPLAIN 各列的可能取值idid 列的取值通常是一组数字，表示select查询的序号，也有可能是一个NULL： 取值 含义 例子编号 id数字相同 优先级相同，从上往下执行 [eg：&lt;id-1&gt;] id数字不同 数字越大优先级越高，越先执行，比如包含子查询的语句，内部查询优先执行 [eg：&lt;id-2&gt;] id值为NULL 通常是使用了union，表示该行是一个结果集，不需要使用它来进行查询 [eg：&lt;id-2&gt;] select_typeselect_type 列表示查询的类型，主要是用于区分普通查询、联合查询、子查询等复杂的情况： 取值 含义 例子编号 SIMPLE 简单的查询语句，查询中不包括UNION操作和子查询 [eg：&lt;id-1&gt;] PRIMARY 在复杂查询中处于最外层的查询 [eg：&lt;id-2&gt;] UNION 查询语句中处于 UNION 关键字之后的查询 [eg：&lt;id-2&gt;] DEPENDENT UNION 查询语句中处于 UNION 关键字之后的查询，需要依赖于外部查询 [eg：`&lt;id-&gt;`]* UNION RESULT 表示 UNION 操作之后的结果，本身并不需要参与查询，通常该记录id字段为 NULL [eg：&lt;id-2&gt;] SUBQUERY 在子查询中的第一个查询 [eg：`&lt;id-&gt;`]* DEPENDENT SUBQUERY 在子查询中的第一个查询，需要依赖于外部查询 [eg：`&lt;id-&gt;`]* DERIVED 在 FROM 列表中包含的子查询 [eg：&lt;id-4&gt;] MATERIALIZED 物化子查询 [eg：&lt;id-5&gt;] UNCACHEABLE SUBQUERY 一个结果不能被缓存并且对于外部查询的每一行都需要重新评估自身的子查询 [eg：`&lt;id-&gt;`]* UNCACHEABLE UNION 查询语句中处于 UNION 关键字之后的子查询，并且其结果属于UNCACHEABLE SUBQUERY类型 [eg：`&lt;id-&gt;`]* tabletable 列表示查询所引用到的表名，如果查询中使用了别名，那么会显示别名，此外还有一些其他类型的引用： 取值 含义 例子编号 表名、别名 查询时引用了这个表 [eg：&lt;id-1&gt;] &lt;unionM,N&gt; 查询时引用了由id为M和N的两个查询的结果集构成的临时结果集 [eg：&lt;id-2&gt;] &lt;derivedN&gt; 查询时引用了id为N的查询形成的结果集 [eg：&lt;id-4&gt;] &lt;subqueryN&gt; 查询时引用了id为N的物化子查询形成的结果集 [eg：&lt;id-5&gt;] partitionspartitions 列表示查询结果集所涉及到的分区，值为 NULL 时表示该表并未分区： 取值 含义 例子编号 分区名 查询结果集引用到了这个分区 [eg：&lt;id-6&gt;] NULL 该表格并未分区，或者结果集中数据不再分区中 [eg：&lt;id-1&gt;] typetype 列表示访问类型，也就是找到所需数据所能使用的最好方式，取值类型很多，在下表中从上到下效果越来越差： 取值 含义 例子编号 NULL 查询经过优化执行时不用访问表数据，可能通过索引就搞定了，或者根本没有数据 [eg：&lt;id-8&gt;] system 在MyISAM类型的表中只有一行数据时出现，如果在 Innodb 类型表中只有一行数据通常显示 ALL [eg：&lt;id-9&gt;] const 表格使用了唯一索引或者主键，并且将其作为判定相等的筛选条件，得到一条记录 [eg：&lt;id-10&gt;] eq_ref 连接查询时，驱动表的每一条记录的条件列，与后面连接表的主键或唯一索引判定相等，后表采用的连接方式 [eg：&lt;id-11&gt;] ref 连接查询时，驱动表的每一条记录的条件列，与后面连接表的索引列判定相等，后表采用的连接方式，索引列数据不要求唯一，不连接表时就是查索引列等于一个具体的值 [eg：&lt;id-7&gt;] ref_or_null 与 ref 基本一致，另外包含查询索引列为 NULL 的记录 [eg：&lt;id-12&gt;] fulltext 包含全文索引的表的查询方式，全文索引的优先级要高于普通索引 [eg：`&lt;id-&gt;`]* index_merge 至少用到了两个索引，并且用到了索引合并优化 [eg：`&lt;id-&gt;`]* unique_subquery where条件in形式的子查询子查询返回唯一结果时，等价于将类型为 eq_ref 的查询作为子查询 [eg：`&lt;id-&gt;`]* index_subquery where条件in形式的子查询引用了非唯一索引，等价于将类型为 ref 的查询作为子查询 [eg：`&lt;id-&gt;`]* range 对于表的索引列使用范围判定的查询 [eg：&lt;id-13&gt;] index 除了查找索引树之外，与 ALL 选项基本一致，通常由于索引较小查询会快一点 [eg：&lt;id-14&gt;] ALL 完整浏览整个表格，查找符合条件的结果，属于最差的访问方式 [eg：&lt;id-1&gt;] possible_keyspossible_keys 列表示查询所需数据过程可能用到的索引名，具体是否使用还要依赖于查询过程中表的连接顺序，该值为 NULL 时表示无索引可用，此时需要考虑对表进行优化来改善查询结果情况了。 取值 含义 例子编号 索引名 查询时可能用到的索引名，是否使用取决于查询连接顺序 [eg：&lt;id-7&gt;] NULL 该查询没有可用索引，需要考虑优化 [eg：&lt;id-1&gt;] keykey 列表示查询所需数据过程确实用到的索引名，该值为 NULL 时表示无索引可用，此时也需要考虑对表进行优化。 取值 含义 例子编号 索引名 查询时确实用到的索引名 [eg：&lt;id-7&gt;] NULL 查询时没有可用索引，需考虑优化 [eg：&lt;id-1&gt;] key_lenkey_len 列表示查询所需数据过程用到的索引长度，该值为 NULL 时表示没有使用索引，由于存储格式的不同，对于可以为 NULL 的列储存索引所需空间要比不能为 NULL 列的大一个字节。 取值 含义 例子编号 索引长度 查询时确实用到的索引长度 [eg：&lt;id-7&gt;] NULL 没有使用到索引 [eg：&lt;id-1&gt;] refkey_len 列表示查询时使用常数或者某一列来和索引列比较，有时会显示 func，表示使用了一些函数的结果与索引比较，值为 NULL 时表示没用到索引比较 取值 含义 例子编号 引用列名 查询时与索引比较的列名，形式可能为&lt;subquery2&gt;.id，表示引用了子查询结果中的id列 [eg：&lt;id-5&gt;] const 查询时与索引比较的为常数 [eg：&lt;id-10&gt;] func 查询时与索引比较的一些函数结果 [eg：`&lt;id-&gt;`]* NULL 不是上述几种情况，可能没有使用索引比较 [eg：&lt;id-1&gt;] rowsrows 列表示查询符合条件的结果时所要检查的数据行数，在 InnoDB 类型的表中，这个值是一个估计值，可用来参考并不精确，值为 NULL 时表示表中无数据，或者无法找到匹配行，比如查找一条主键中不包含的数据。 取值 含义 例子编号 数字 查询时所要检查的数据行数 [eg：&lt;id-3&gt;] NULL 没有数据或者不需要检测 [eg：&lt;id-1&gt;] filteredfiltered 列表示通过筛选条件的记录数占可能参与检查的记录数，是一个估计值，该值与 rows 的乘积大概就是结果集中的记录数： 取值 含义 例子编号 数字 通过筛选条件的记录数占可能参与检查的记录数，最大为 100.00 [eg：&lt;id-3&gt;] ExtraExtra 列表示Mysql处理查询所使用的额外信息，类型很多，其中一些情况是需要进行优化的信号，对于SQL分析很有帮助： 取值 含义 例子编号 Child of &#39;tbl_name&#39; pushed join@1 当表被当做另一个表’tbl_name’的子表能被存放在 NDB 内核的时候，该值只出现在存储选项被开启的 NDB 集群上 - const row not found 当一个系统表没有数据可查的时候 - Deleting all rows 对于 DELETE 操作， MyISAM 引擎支持一个可以简单快速删除表数据的方法，如果使用了整个优化则显示此选项 - Distinct 查询时使用了 distinct 关键字，当查找到一个第一个匹配值后，相同匹配就不再搜索了 - const 当一个系统表没有数据可查的时候 - FirstMatch(tbl_name) 当 semi-join FirstMatch 访问简化策略被使用时候， 通常出现在 Where的 in 子句中，找到一个值后，后面相同值不再匹配出现 - Full scan on NULL key 当优化器不能使用索引查找访问方法时，将会显示该值，表示将子查询作为一种后备策略 - Impossible HAVING 当 HAVING 子句的条件总是不成立，无法匹配出任何数据 [eg：&lt;id-23&gt;] Impossible WHERE 当 WHERE 子句的条件总是不成立，无法匹配出任何数据 [eg：&lt;id-22&gt;] Impossible WHERE noticed after reading const tables 在读取const表和system表时，WHERE 子句的条件总是不成立 - LooseScan(m..n) 当 semi-join LooseScan 策略被使用的时候. m 和 n 是索引的编号 - No matching min/max row 在查询中包括系统函数，但是通过条件查询无法匹配出数据的时候， 比如SELECT MIN(...) FROM ... WHERE CONDITION - no matching row in const table 当连表查询时有一个空表或者没有匹配唯一索引的数据时，会给出此提示 [eg：&lt;id-18&gt;] No tables used 当查询中没有 FROM 子句或者只有 FROM DUAL子句时 [eg：&lt;id-20&gt;] Not exists 发生在左外连接的优化，当要求右侧表字段为空时，如果查找到一条不为空匹配，则停止查找匹配这项记录， 比如 SELECT * FROM t1 LEFT JOIN t2 ON t1.id=t2.id WHERE t2.id IS NULL - Plan isn&#39;t ready yet 执行命令 EXPLAIN FOR CONNECTION 时，优化器在命名连接中还没有完成为语句执行创建执行计划 - Range checked for each record(index map: N) 当没有好的默认索引可使用时，但当我们可以将以前表中的所有列都视为常量时，可能会使用某些索引就是这种情况 - Scanned N databases 表示在执行对INFORMATION_SCHEMA表的查询时，服务器执行了多少次目录扫描，数字可以是0,1或者任何整数 - Select tables optimized away 优化器发现只有一行，并且通过索引直接皆可以获得想要的数据，而不需要真正访问表数据，比如在索引列使用聚合函数 [eg：&lt;id-16&gt;] Skip_open_table 对于 INFORMATION_SCHEMA 表的查询，不需要打开表，只需要浏览目录就可以完成查询 - Open_frm_only 对于 INFORMATION_SCHEMA 表的查询，需要打开 .frm 文件完成查询 - Open_full_table 对于 INFORMATION_SCHEMA 表的查询，需要打开 .frm, .MYD, .MYI 文件完成查询 - Start temporary,End temporary 表示使用临时表用于 semi-join Duplicate Weedout 策略 [eg：&lt;id-15&gt;] unique row not found 当一个拥有 UNIQUE 索引或者 PRIMARY 索引的表没有查到满足条件数据时 - Using filesort 无法仅通过引用索引就完成排序，需要一个额外的阶段来进行外部排序，并且按排序结果取回记录 [eg：&lt;id-17&gt;] Using index 只通过索引排序就可以取得排序后的数据，无需做额外的搜索真实记录数据的工作 [eg：&lt;id-7&gt;] Using index condition 首先通过访问索引元组的方式来读取表格，除非必要时会通过索引索引信息延迟读取整个表格数据 - Using index for group-by 索引用于处理包含 GROUP BY 和 DISTINCT 的查询，由于重复项会被快速跳过。所以非常高效 - Using join buffer (Block Nested Loop) 连接访问之前表格数据被部分读入连接缓存区，然后使用缓存中的行与当前表进行连接，括号内容为使用算法 [eg：&lt;id-1&gt;] Using join buffer (Batched Key Access) 连接访问之前表格数据被部分读入连接缓存区，然后使用缓存中的行与当前表进行连接，括号内容为使用算法 - Using MRR 表格数据会通过 Multi-Range Read 优化策略来读取 - Using sort_union(...), Using union(...), Using intersect(...) 针对于 index_merge 选项，表明索引浏览被合并的特定算法 - Using temporary 需要创建一个临时表来存储结果，通常出现在包含了作用在不同列的上的 GROUP BY 子句和 ORDER BY子句 [eg：&lt;id-2&gt;] Using where 当查询使用了 WHERE 子句来过滤结果发送给客户端的时候 [eg：&lt;id-3&gt;] Using where with pushed condition 仅适用于 NDB 类型表，它意味着NDB集群正在使用 “条件存储”优化选项来提高接近于非索引列和常量之间直接比较的效率。 - Zero limit 当查询语句包含 LIMIT 0子句并不能查到任何记录的时候 [eg：&lt;id-19&gt;] EXPLAIN 各列的可能取值对应的例子建表操作(1为了展示id取值的不同先创建 a、b两个表，然后插入测试数据，由于是测试的开始，我们分别查看表结构和数据，之后为了减少篇幅，只给出命令，不再查询表结构和数据，接着我们开始测试： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051mysql&gt; create table a(id int, num int);Query OK, 0 rows affected (0.04 sec)mysql&gt; insert into a values(1, 100),(2,200),(3,300);Query OK, 3 rows affected (0.01 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; desc a;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.02 sec)mysql&gt; select * from a;+----+-----+| id | num |+----+-----+| 1 | 100 || 2 | 200 || 3 | 300 |+----+-----+3 rows in set (0.02 sec)mysql&gt; create table b(id int, num int);Query OK, 0 rows affected (0.03 sec)mysql&gt; insert into b values(1, 100),(2,200),(4,400);Query OK, 3 rows affected (0.00 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; desc b;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | | NULL | || num | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+2 rows in set (0.03 sec)mysql&gt; select * from b;+----+-----+| id | num |+----+-----+| 1 | 100 || 2 | 200 || 4 | 400 |+----+-----+3 rows in set (0.03 sec) &lt;id-1&gt;12345678mysql&gt; explain select * from a, b;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+| 1 | SIMPLE | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | NULL || 1 | SIMPLE | b | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | Using join buffer (Block Nested Loop) |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+---------------------------------------+2 rows in set (0.05 sec) &lt;id-2&gt;123456789mysql&gt; explain select * from a union select * from b;+------+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+------+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+| 1 | PRIMARY | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | NULL || 2 | UNION | b | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | NULL || NULL | UNION RESULT | &lt;union1,2&gt; | NULL | ALL | NULL | NULL | NULL | NULL | NULL | NULL | Using temporary |+------+--------------+------------+------------+------+---------------+------+---------+------+------+----------+-----------------+3 rows in set (0.05 sec) &lt;id-3&gt;12345678mysql&gt; explain select id from a where id = (select id from b where num = 100);+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| 1 | PRIMARY | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 33.33 | Using where || 2 | SUBQUERY | b | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 33.33 | Using where |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+2 rows in set (0.06 sec) &lt;id-4&gt;123456789101112131415161718192021222324252627282930313233mysql&gt; select @@version;+-----------+| @@version |+-----------+| 5.6.33 |+-----------+1 row in set (0.05 sec)mysql&gt; explain select num from (select * from a) t where t.id &gt; 1;+----+-------------+------------+------+---------------+------+---------+------+------+-------------+| id | select_type | table | type | possible_keys | key | key_len | ref | rows | Extra |+----+-------------+------------+------+---------------+------+---------+------+------+-------------+| 1 | PRIMARY | &lt;derived2&gt; | ALL | NULL | NULL | NULL | NULL | 3 | Using where || 2 | DERIVED | a | ALL | NULL | NULL | NULL | NULL | 3 | NULL |+----+-------------+------------+------+---------------+------+---------+------+------+-------------+2 rows in set (0.06 sec)-- 很神奇的是我在5.7版本操作了半天也没出现，内部进行了优化，相同的语句操作如下：mysql&gt; select @@version;+------------+| @@version |+------------+| 5.7.21-log |+------------+1 row in set (0.05 sec)mysql&gt; explain select num from (select * from a) t where t.id &gt; 1;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| 1 | SIMPLE | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 33.33 | Using where |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+1 row in set (0.05 sec) 建表操作(2新建两个带索引的表格 c 和 d，其中表格c带有普通索引，表格d带有主键，这两个表格会参与后面用作展示的例子： 12345678910111213mysql&gt; create table c(id int, num int, key idindex(id));Query OK, 0 rows affected (0.21 sec)mysql&gt; insert into c values(1,103),(2,203),(6,603);Query OK, 3 rows affected (0.05 sec)Records: 3 Duplicates: 0 Warnings: 0mysql&gt; create table d(id int, num int, primary key(id));Query OK, 0 rows affected (0.14 sec)mysql&gt; insert into d values(1,104),(2,204),(6,504);Query OK, 3 rows affected (0.11 sec)Records: 3 Duplicates: 0 Warnings: 0 &lt;id-5&gt;123456789mysql&gt; explain select id from d where id in (select id from a);+----+--------------+-------------+------------+--------+---------------+---------+---------+----------------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+--------------+-------------+------------+--------+---------------+---------+---------+----------------+------+----------+-------------+| 1 | SIMPLE | &lt;subquery2&gt; | NULL | ALL | NULL | NULL | NULL | NULL | NULL | 100.00 | Using where || 1 | SIMPLE | d | NULL | eq_ref | PRIMARY | PRIMARY | 4 | &lt;subquery2&gt;.id | 1 | 100.00 | Using index || 2 | MATERIALIZED | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | NULL |+----+--------------+-------------+------------+--------+---------------+---------+---------+----------------+------+----------+-------------+3 rows in set (0.05 sec) 建表操作(3为了测试 partitions 字段的取值，创建表格 p，其实就是创建了一个带有分区的表，这个表格会参与后面用作展示的例子： 123456mysql&gt; create table p(id int, num int) partition by range(id)(partition p0 values less than(3), partition p1 values less than(6));Query OK, 0 rows affected (0.02 sec)mysql&gt; insert into p values(1, 111),(2,222),(4,444),(5,555);Query OK, 4 rows affected (0.01 sec)Records: 4 Duplicates: 0 Warnings: 0 &lt;id-6&gt;1234567mysql&gt; explain select * from p where id &lt; 5;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+| 1 | SIMPLE | p | p0,p1 | ALL | NULL | NULL | NULL | NULL | 4 | 33.33 | Using where |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------+1 row in set (0.05 sec) &lt;id-7&gt;1234567mysql&gt; explain select id from c where id = 1;+----+-------------+-------+------------+------+---------------+---------+---------+-------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+---------+---------+-------+------+----------+-------------+| 1 | SIMPLE | c | NULL | ref | idindex | idindex | 5 | const | 1 | 100.00 | Using index |+----+-------------+-------+------------+------+---------------+---------+---------+-------+------+----------+-------------+1 row in set (0.06 sec) 建表操作(4为了测试 type 字段的取值，有时需要特定的数据引擎才可以，所以创建了以 MyISAM引擎类型的表格 m，然后进行一些测试： 12mysql&gt; create table m(id int, num int)engine=myisam;Query OK, 0 rows affected (0.02 sec) &lt;id-8&gt;1234567mysql&gt; explain select * from m;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | no matching row in const table |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+1 row in set (0.03 sec) &lt;id-9&gt;12345678910mysql&gt; insert into m values(1,1001);Query OK, 1 row affected (0.00 sec)mysql&gt; explain select * from m;+----+-------------+-------+------------+--------+---------------+------+---------+------+------+----------+-------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+--------+---------------+------+---------+------+------+----------+-------+| 1 | SIMPLE | m | NULL | system | NULL | NULL | NULL | NULL | 1 | 100.00 | NULL |+----+-------------+-------+------------+--------+---------------+------+---------+------+------+----------+-------+1 row in set (0.04 sec) &lt;id-10&gt;1234567mysql&gt; explain select id from d where id = 1;+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------------+| 1 | SIMPLE | d | NULL | const | PRIMARY | PRIMARY | 4 | const | 1 | 100.00 | Using index |+----+-------------+-------+------------+-------+---------------+---------+---------+-------+------+----------+-------------+1 row in set (0.04 sec) &lt;id-11&gt;12345678mysql&gt; explain select a.id from a, d where a.id = d.id;+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+-------------+| 1 | SIMPLE | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | Using where || 1 | SIMPLE | d | NULL | eq_ref | PRIMARY | PRIMARY | 4 | sqltest2.a.id | 1 | 100.00 | Using index |+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+-------------+2 rows in set (0.05 sec) &lt;id-12&gt;1234567mysql&gt; explain select id from c where id = 1 or id is null;+----+-------------+-------+------------+-------------+---------------+---------+---------+-------+------+----------+--------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+-------------+---------------+---------+---------+-------+------+----------+--------------------------+| 1 | SIMPLE | c | NULL | ref_or_null | idindex | idindex | 5 | const | 2 | 100.00 | Using where; Using index |+----+-------------+-------+------------+-------------+---------------+---------+---------+-------+------+----------+--------------------------+1 row in set (0.04 sec) &lt;id-13&gt;1234567mysql&gt; explain select id from c where id &gt; 1;+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+--------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+--------------------------+| 1 | SIMPLE | c | NULL | range | idindex | idindex | 5 | NULL | 2 | 100.00 | Using where; Using index |+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+--------------------------+1 row in set (0.04 sec) &lt;id-14&gt;1234567mysql&gt; explain select id from c;+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+| 1 | SIMPLE | c | NULL | index | NULL | idindex | 5 | NULL | 3 | 100.00 | Using index |+----+-------------+-------+------------+-------+---------------+---------+---------+------+------+----------+-------------+1 row in set (0.03 sec) &lt;id-15&gt;123456789mysql&gt; explain select id from c where id in (select a.id from a, d where a.id = d.id);+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+------------------------------+| 1 | SIMPLE | a | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | Using where; Start temporary || 1 | SIMPLE | c | NULL | ref | idindex | idindex | 5 | sqltest2.a.id | 1 | 100.00 | Using index || 1 | SIMPLE | d | NULL | eq_ref | PRIMARY | PRIMARY | 4 | sqltest2.a.id | 1 | 100.00 | Using index; End temporary |+----+-------------+-------+------------+--------+---------------+---------+---------+---------------+------+----------+------------------------------+3 rows in set (0.04 sec) &lt;id-16&gt;1234567mysql&gt; explain select min(id) from c;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | Select tables optimized away |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------------------+1 row in set (0.05 sec) &lt;id-17&gt;1234567mysql&gt; explain select id from c order by num;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+| 1 | SIMPLE | c | NULL | ALL | NULL | NULL | NULL | NULL | 3 | 100.00 | Using filesort |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+1 row in set (0.04 sec) &lt;id-18&gt;1234567mysql&gt; explain select id from d where id = 100;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | no matching row in const table |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+--------------------------------+1 row in set (0.04 sec) &lt;id-19&gt;1234567mysql&gt; explain select id from d limit 0;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | Zero limit |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------+1 row in set (0.04 sec) &lt;id-20&gt;1234567mysql&gt; explain select 1 from dual;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | No tables used |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+----------------+1 row in set (0.04 sec) &lt;id-22&gt;1234567mysql&gt; explain select * from a where 1 = 2;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | Impossible WHERE |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+------------------+1 row in set (0.03 sec) &lt;id-23&gt;1234567mysql&gt; explain select sum(num) from a group by id having 1 =2;+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------+| id | select_type | table | partitions | type | possible_keys | key | key_len | ref | rows | filtered | Extra |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------+| 1 | SIMPLE | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | NULL | Impossible HAVING |+----+-------------+-------+------------+------+---------------+------+---------+------+------+----------+-------------------+1 row in set (0.04 sec) 总结 关于 EXPLAIN 命令的所有可能取值后面，还有部分例子是空的，完全是由于个人水平有限，等找到所说的取值情况再补充，也欢迎大家提供例子 另外 EXPLAIN 提供的信息中没有关于触发器、存储过程的信息或者评估用户自定义函数对查询的影响情况 所有的可能取值中 possible_keys、rows、filtered中的统计信息基本是估算的，并非精确值，只能用来做优化参考 Extra 列的信息对于尝试优化起到了至关重要的作用，当出现 Using filesort、Using temporary、Using join buffer的时候一般就要考虑采取优化方案了 首先了解这些可能出现的情况，之后我们留这里利用这些说明来进行查询优化了]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>查询</tag>
        <tag>EXPLAIN</tag>
        <tag>Extra</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[gcc编译生成可执行文件的过程中发生了什么]]></title>
    <url>%2Fblog%2F2019%2F04%2F16%2Fgcc%E7%BC%96%E8%AF%91%E7%94%9F%E6%88%90%E5%8F%AF%E6%89%A7%E8%A1%8C%E6%96%87%E4%BB%B6%E7%9A%84%E8%BF%87%E7%A8%8B%E4%B8%AD%E5%8F%91%E7%94%9F%E4%BA%86%E4%BB%80%E4%B9%88%2F</url>
    <content type="text"><![CDATA[前言一直好奇程序的编译过程到底做了哪些工作，后来学会在Ubuntu上使用gcc编译程序，知道了生成可执行文件需要分为预编译、编译、汇编和链接4个步骤，逐渐了解了其中的细节，但是过一段时间之后总是记不太清楚了，所以总结一下增强记忆，同时方便日后查找使用。 编译方式一步到位使用gcc命令可以一步将main.c源文件编译生成最终的可执行文件main_direct 1gcc main.c –o main_direct 分步执行gcc的编译流程通常认为包含以下四个步骤，实际上就是将上面的命令分成4步执行，这也是gcc命令实际的操作流程，生成的可执行文件main与上面单条命令生成的可执行文件main_direct是一模一样的 预处理，生成预编译文件（.i文件）：gcc –E main.c –o main.i 编译，生成汇编代码（.s文件）：gcc –S main.i –o main.s 汇编，生成目标文件（.o文件）：gcc –c main.s –o main.o 链接，生成可执行文件（executable文件）：gcc main.o –o main 编译流程这里的编译是指将源文件（.c）生成可执行文件（executable）的这个完整的过程，而不是上面提到的四个步骤中的第二步，为了弄清楚编译过程究竟都做了哪些工作，接下来我们可以分步骤来看一下gcc编译.c文件的过程，了解了每一步的内容，也就明白了整个编译流程，先给出源文件 mian.c 的源代码。1234567891011121314151617#include &lt;stdio.h&gt;#define A 100// calc sumint sum(int a, int b)&#123; return a + b;&#125;int main()&#123; int b = 1; int c = sum(A, b); printf("sum = %d\n", c); return 0;&#125; 预处理预处理又叫预编译，是完整编译过程的第一个阶段，在正式的编译阶段之前进行。预处理阶段将根据已放置在文件中的预处理指令来修改源文件的内容，对于C语言来说预处理的可执行程序叫做 cpp，全称为C Pre-Processor（C预处理器），是一个与 C 编译器独立的小程序，预编译器并不理解 C 语言语法，它仅是在程序源文件被编译之前，实现文本替换的功能。简单来说，预处理就是将源代码中的预处理指令根据语义预先处理，并且进行一下清理、标记工作，然后将这些代码输出到一个 .i 文件中等待进一步操作。 一般地，C/C++ 程序的源代码中包含以 # 开头的各种编译指令，被称为预处理指令，其不属于 C/C++ 语言的语法，但在一定意义上可以说预处理扩展了 C/C++。根据ANSI C 定义，预处理指令主要包括：文件包含、宏定义、条件编译和特殊控制等4大类。 预处理阶段主要做以下几个方面的工作： 文件包含：#include 是 C 程序设计中最常用的预处理指令，格式有尖括号 #include &lt;xxx.h&gt; 和双引号 #include &quot;xxx.h&quot; 之分，分别表示从系统目录下查找和优先在当前目录查找，例如常用的 #include &lt;stdio.h&gt; 指令，就表示使用 stdio.h 文件中的全部内容，替换该行指令。 添加行号和文件名标识： 比如在文件main.i中就有类似 # 2 &quot;main.c&quot; 2 的内容，以便于编译时编译器产生调试用的行号信息及用于编译时产生编译错误或警告时能够显示行号。 宏定义展开及处理： 预处理阶段会将使用 #define A 100 定义的常量符号进行等价替换，文中所有的宏定义符号A都会被替换成100，还会将一些内置的宏展开，比如用于显示文件全路径的__FILE__，另外还可以使用 #undef 删除已经存在的宏，比如 #undef A 就是删除之前定义的宏符号A。 条件编译处理: 如 #ifdef，#ifndef，#else，#elif，#endif等，这些条件编译指令的引入使得程序员可以通过定义不同的宏来决定编译程序对哪些代码进行处理，将那些不必要的代码过滤掉，防止文件重复包含等。 清理注释内容： // xxx 和 /*xxx*/ 所产生的的注释内容在预处理阶段都会被删除，因为这些注释对于编写程序的人来说是用来记录和梳理逻辑代码的，但是对编译程序来说几乎没有任何用处，所以会被删除，观察 main.i 文件也会发现之前的注释都被删掉了。 特殊控制处理: 保留编译器需要使用 #pragma 编译器指令，另外还有用于输出指定的错误信息，通常来调试程序的 #error 指令。 查看main.i文件 编译编译过程是整个程序构建的核心部分，也是最复杂的部分之一，其工作就是把预处理完生成的 .i 文件进行一系列的词法分析、语法分析、语义分析以及优化后产生相应的汇编代码文件，也就是 .s 文件，这个过程调用的处理程序一般是 cc 或者 ccl。汇编语言是非常有用的，因为它给不同高级语言的不同编译器提供了可选择的通用的输出语言，比如 C 和 Fortran 编译产生的输出文件都是汇编语言。 词法分析： 主要是使用基于有线状态机的Scanner分析出token，可以通过一个叫做 lex 的可执行程序来完成词法扫描，按照描述好的词法规则将预处理后的源代码分割成一个个记号，同时完成将标识符存放到符号表中，将数字、字符串常量存放到文字表等工作，以备后面的步骤使用。 语法分析： 对有词法分析产生的token采用上下文无关文法进行分析，从而产生语法树，此过程可以通过一个叫做 yacc 的可执行程序完成，它可以根据用户给定的语法规则对输入的记号序列进行解析，从而构建一棵语法树，如果在解析过程中出现了表达式不合法，比如括号不匹配，表达式中缺少操作符、操作数等情况，编译器就会报出语法分析阶段的错误。 语义分析： 此过程由语义分析器完成，编译器 cc 所能分析的语义都是静态语义，是指在编译期间可以确定的语义，通常包括声明和类型的匹配，类型的转换等。比如将一个浮点型的表达式赋值给一个整型的表达式时，语义分析程序会发现这个类型不匹配，编译器将会报错。而动态语义一般指在运行期出现的语义相关问题，比如将0作为除数是一个运行期语义错误。语义分析过程会将所有表达式标注类型，对于需要隐式转换的语法添加转换节点，同时对符号表里的符号类型做相应的更新。 代码优化： 此过程会通过源代码优化器会在源代码级别进行优化，针对于编译期间就可以确定的表达式（例如：100+1）给出确定的值，以达到优化的目的，此外还包括根据机器硬件执行指令的特点对指令进行一些调整使目标代码比较短，执行效率更高等操作。 查看main.s文件 汇编汇编过程是整个程序构建中的第三步，是将编译产生的汇编代码文件转变成可执行的机器指令。相对来说比较简单，每个汇编语句都有相对应的机器指令，只需根据汇编代码语法和机器指令的对照表翻译过来就可以了，最终生成目标文件，也就是 .o 文件，完成此工作的可执行程序通常是 as。目标文件中所存放的也就是与源程序等效的目标的机器语言代码，通常至少包含代码段和数据段两个段，并且还要包含未解决符号表，导出符号表和地址重定向表等3个表。汇编过程会将extern声明的变量置入未解决符号表，将static声明的全局变量不置入未解决符号表，也不置入导出符号表，无法被其他目标文件使用，然后将普通变量及函数置入导出符号表，供其他目标文件使用。 代码段： 包含主要是程序的指令。该段一般是可读和可执行的，但一般却不可写。 数据段： 主要存放程序中要用到的各种全局变量或静态的数据，一般数据段都是可读，可写，可执行的。 未解决符号表： 列出了在本目标文件里有引用但不存在定义的符号及其出现的地址。 导出符号表： 列出了本目标文件里具有定义，并且可以提供给其他目标文件使用的符号及其在出现的地址。 地址重定向表： 列出了本目标文件里所有对自身地址的引用记录。 查看main.o文件 链接链接过程是程序构建过程的最后一步，通常调用可执行程序 ld 来完成，可以简单的理解为将目标文件和库文件打包组装成可执行文件的过程，其主要内容就是把各个模块之间相互引用的部分都处理好，将一个文件中引用的符号同该符号在另外一个文件中的定义连接起来，使得各个模块之间能够正确的衔接，成为一个能够被操作系统装入执行的统一整体。 虽然汇编之后得到的文件已经是机器指令文件，但是依然无法立即执行，其中可能还有尚未解决的问题，比如源代码 main.c 中的 printf 这个函数名就无法解析，需要链接过程与对应的库文件对接，完成的重定位，将函数符号对应的地址替换成正确的地址。前面提到的库文件其实就是一组目标文件的包，它们是一些最常用的代码编译成目标文件后打成的包。比如 printf的头文件是 stdio.h，而它的实现代码是放在动态库 libc.so.6 中的，链接的时候就要引用到这个库文件。 从原理上讲，连接的的工作就是把一些指令对其他符号地址的引用加以修正，主要包括了地址和空间分配、符号决议和重定位等步骤，根据开发人员指定的链接库函数的方式不同，链接过程可分为静态链接和动态链接两种，链接静态的库，需要拷贝到一起，链接动态的库需要登记一下库的信息。 静态链接： 函数的代码将从其所在地静态链接库中被拷贝到最终的可执行程序中。这样该程序在被执行时，代码将被装入到该进程的虚拟地址空间中，静态链接库实际上是一个目标文件的集合，其中的每个文件含有库中的一个或者一组相关函数的代码，最终生成的可执行文件较大。 动态链接： 函数的代码被放到动态链接库或共享对象的某个目标文件中。链接处理时只是在最终的可执行程序中记录下共享对象的名字以及其它少量的登记信息。在这样该程序在被执行时，动态链接库的全部内容将被映射到运行时相应进程的虚地址空间，根据可执行程序中记录的信息找到相应的函数代码。这种连接方法能节约一定的内存，也可以减小生成的可执行文件体积。 ​查看main可执行文件 总结 gcc编译器的工作过程：源文件 --&gt; 预处理 --&gt; 编译 --&gt; 汇编 --&gt; 链接 --&gt; 可执行文件 gcc编译过程文件变化：main.c –&gt; main.i –&gt; mian.s –&gt; main.o –&gt; main 通过上面分阶段的解释编译过程，我们也明白了gcc其实只是一个后台程序的包装，它会根据阶段要求来调用 cpp、cc、as、ld 等命令 源代码整个编译过程产生的中间文件及最终结果可以通过传送门—— gcc编译项目 来获得，其中还有gcc和g++分别调用的对比，查看生成的文件可以发现，同样的源代码使用gcc和g++生成的文件是不一样的，总的来说使用g++编译生成的可执行文件要大一些。]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>gcc</tag>
        <tag>预处理</tag>
        <tag>编译</tag>
        <tag>汇编</tag>
        <tag>链接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[C/C++版本更迭历程]]></title>
    <url>%2Fblog%2F2019%2F04%2F09%2FC-C-%E7%89%88%E6%9C%AC%E6%9B%B4%E8%BF%AD%E5%8E%86%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言使用 C/C++ 实现功能的时候经常需要上网搜索一些解决方案，但是当你把代码粘贴到自己项目中时偶尔会出现编译失败的问题，其中一个原因就是新加的代码所使用的特性在当前的编译环境中并不支持，就好像不久前我们还在使用VS2003写着C++98标准的代码（2015年），虽然对C++11的特性垂涎已久，但是无奈在项目中就是无法使用，只能是遥望着它发飞快地发展出了C++14和C++17。 涉及到C/C++版本和标准的最常见的地方就是编译选项了，比如常见的 -std=c++11 就是使用C++11的标准编译，关于 C/C++ 各个版本标准的差异我们可能无法全部记住，但是一些主要的版本更替，还是很有必要了解一下的。 C语言版本更迭 年份 C标准 通用名 别名 标准编译选项 GNU扩展选项 1972 Birth C - - - - 1978 K&amp;R C - - - - 1989-1990 X3.159-1989, ISO/IEC 9899:1990 C89 C90, ANSI C, ISO C -ansi, -std=c90, -std=iso9899:1990 -std=gnu90 1995 ISO/IEC 9899/AMD1:1995 AMD1 C94, C95 -std=iso9899:199409 - 1999 ISO/IEC 9899:1999 C99 - -std=c99, -std=iso9899:1999 -std=gnu99 2011 ISO/IEC 9899:2011 C11 - -std=c11, -std=iso9899:2011 -std=gnu11 2018 ISO/IEC 9899:2018 C18 - -std=c18, -std=iso9899:2018 -std=gnu18 C++版本更迭 年份 C++标准 通用名 别名 标准编译选项 GNU扩展选项 1978 C with Classes - - - - 1998 ISO/IEC 14882:1998 C++98 - -std=c++98 -std=gnu++98 2003 ISO/IEC 14882:2003 C++03 - -std=c++03 -std=gnu++03 2011 ISO/IEC 14882:2011 C++11 C++0x std=c++11, std=c++0x std=gnu++11, std=gnu++0x 2014 ISO/IEC 14882:2014 C++14 C++1y std=c++14, std=c++1y std=gnu++14, std=gnu++1y 2017 ISO/IEC 14882:2017 C++17 C++1z std=c++17, std=c++1z std=gnu++17, std=gnu++1z 2020 to be determined C++20 C++2a -std=c++2a std=gnu++2a 号外C/C++标准 看了C++的发展史才知道，原来从1978年Bjarne Stroustrup就开始了C++雏形的使用，直到20年后的1998年才确定了第一个C++标准 C++11之前被称为C++0x，据说C++0x是C++11的草案，所以有些编译器使用C++11的编译参数是：-std=c++0x，后来使用：-std=c++11，但是据说不完全相同 关于C++20，协程的加入应该是一大惊喜了，值得期待！官方还表示，C++20 应该会是一个像 C++11 那样的大版本 gcc/g++ gcc发展到今天已经不单单可以编译C语言了，还可以编译C++、Java、Object-C等多种其他语言 有一种说法是GCC的全名是GNU Compiler Collection(GUN 编译器集合)，而gcc是GCC中用于编译c语言的编译器 事实上，gcc看起来并不像是一个编译器，而像一个调度器，针对于不同的文件调用不同编程语言的编译器 对于后缀为*.c的文件，gcc把它当作是C语言程序源代码，而g++当作是C++程序源代码 对于后缀为*.cpp的文件，gcc和g++都会当作是C++程序源代码 使用g++编译文件时，g++会自动链接标准库STL，而gcc不会自动链接STL，所以再使用gcc编译C++程序是有时会报错 在用gcc编译C++文件时，为了能够使用STL，需要加参数 –lstdc++ ，但这并不代表 gcc –lstdc++ 和 g++等价 据说g++会调用gcc，对于C++代码，因为gcc命令不能自动和C++程序使用的库联接，所以通常用g++来完成链接 需要注意的是，虽说g++会调用gcc，对于*.c文件来说，编译出来的可执行文件也不一样，因为gcc会当成C语言程序编译，而g++调用的gcc会把它当做C++语言程序来编译，这或许就能解释为什么用g++就可以编译所有C/C++的程序，还要有gcc的存在（就我测试来看，同样的C语言代码，g++编译出来的程序体积要大一些）]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>历史</tag>
        <tag>标准</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql表连接：内连接、外连接、交叉连接、自然连接真的都不一样吗]]></title>
    <url>%2Fblog%2F2019%2F04%2F03%2FMysql%E8%A1%A8%E8%BF%9E%E6%8E%A5%EF%BC%9A%E5%86%85%E8%BF%9E%E6%8E%A5%E3%80%81%E5%A4%96%E8%BF%9E%E6%8E%A5%E3%80%81%E4%BA%A4%E5%8F%89%E8%BF%9E%E6%8E%A5%E3%80%81%E8%87%AA%E7%84%B6%E8%BF%9E%E6%8E%A5%E7%9C%9F%E7%9A%84%E9%83%BD%E4%B8%8D%E4%B8%80%E6%A0%B7%E5%90%97%2F</url>
    <content type="text"><![CDATA[前言提起这几种表连接方式就让人头大，想当初还因为这个面试被刷了，长得挺像，用法挺像，可就是有点不一样，其实的它们的差异不是固定的，要在一个具体的环境下才能进行对比，比如在Mysql环境下, JOIN, INNER JOIN, CROSS JOIN 三者在语法上是等价的，也就是作用相同，但是在标准的SQL下却又存在差异。 选一个自己熟悉的环境对比一下，那就是Mysql数据库的表连接了，测试的多了渐渐的发现了一些规律和神坑，貌似一切表连接都是以内连接为基础，然后再此基础上进行变换可以得到一种新的连接，接下来就采用这种对比的逻辑，看看这些连接类型都有什么区别和联系。 测试环境 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 8Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. 创建测试数据 新建第一个测试表格a，包含id和name两列 1create table a(id int, name varchar(64), primary key(id)); 插入测试数据 1234insert into a values(1, 'albert');insert into a values(2, 'bella');insert into a values(3, 'amy');insert into a values(4, 'forier'); 新建第二个测试表格b，包含id和age两列 1create table b(id int, age int, primary key(id)); 插入测试数据 1234insert into b values(1, 18);insert into b values(2, 19);insert into b values(3, 25);insert into b values(5, 70); 分别查看两表中的数据如下 123456789101112131415161718192021mysql&gt; select * from a;+----+--------+| id | name |+----+--------+| 1 | albert || 2 | bella || 3 | amy || 4 | forier |+----+--------+4 rows in set (0.04 sec)mysql&gt; select * from b;+----+-----+| id | age |+----+-----+| 1 | 18 || 2 | 19 || 3 | 25 || 5 | 70 |+----+-----+4 rows in set (0.05 sec) 对比测试这篇对比文章可能和以往你看到的不太一样，对比的基础是内连接，其他的连接基本可以看做是在内连接的基础上加了一些条件和扩展得到的，所以首先我们需要先来看一下内连接。 内连接内连接基础语法是a inner join b，不过其中的inner可以省略，也就是可以写成a join b，如果不添加条件就是a表中的每条记录分别与b表中的每条记录做匹配，形成笛卡尔积，查询结果如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445mysql&gt; select * from a inner join b;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 1 | 18 || 3 | amy | 1 | 18 || 4 | forier | 1 | 18 || 1 | albert | 2 | 19 || 2 | bella | 2 | 19 || 3 | amy | 2 | 19 || 4 | forier | 2 | 19 || 1 | albert | 3 | 25 || 2 | bella | 3 | 25 || 3 | amy | 3 | 25 || 4 | forier | 3 | 25 || 1 | albert | 5 | 70 || 2 | bella | 5 | 70 || 3 | amy | 5 | 70 || 4 | forier | 5 | 70 |+----+--------+----+-----+16 rows in set (0.03 sec)mysql&gt; select * from a join b;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 1 | 18 || 3 | amy | 1 | 18 || 4 | forier | 1 | 18 || 1 | albert | 2 | 19 || 2 | bella | 2 | 19 || 3 | amy | 2 | 19 || 4 | forier | 2 | 19 || 1 | albert | 3 | 25 || 2 | bella | 3 | 25 || 3 | amy | 3 | 25 || 4 | forier | 3 | 25 || 1 | albert | 5 | 70 || 2 | bella | 5 | 70 || 3 | amy | 5 | 70 || 4 | forier | 5 | 70 |+----+--------+----+-----+16 rows in set (0.04 sec) 需要注意的是内连接的连接条件是可选择，如果不加就是笛卡尔积，如果想加的话可以选择on子句或者using子句，比如需要得到a表与b表中id一致的数据记录就可以使用如下on子句的写法： 123456789mysql&gt; select * from a join b on a.id = b.id;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 |+----+--------+----+-----+3 rows in set (0.04 sec) 同时对于上述例子中这个on子句中是被连接的两表的同时存在的字段时，可以使用using子句简化，写成如下查询，需要注意下结果集的变化，记录的条数与on子句相同，但是共有的id列被优化掉了一个，这也是on和using子句的区别，使用时根据需要选择： 123456789mysql&gt; select * from a join b using(id);+----+--------+-----+| id | name | age |+----+--------+-----+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 |+----+--------+-----+3 rows in set (0.04 sec) 交叉连接交叉连接基础语法是a cross join b，在Mysql的语法环境中，内连接与交叉连接完全一致，这一点可以通过下面几条查询与内连接的查询做对比得知： 123456789101112131415161718192021222324252627282930313233343536373839404142mysql&gt; select * from a cross join b;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 1 | 18 || 3 | amy | 1 | 18 || 4 | forier | 1 | 18 || 1 | albert | 2 | 19 || 2 | bella | 2 | 19 || 3 | amy | 2 | 19 || 4 | forier | 2 | 19 || 1 | albert | 3 | 25 || 2 | bella | 3 | 25 || 3 | amy | 3 | 25 || 4 | forier | 3 | 25 || 1 | albert | 5 | 70 || 2 | bella | 5 | 70 || 3 | amy | 5 | 70 || 4 | forier | 5 | 70 |+----+--------+----+-----+16 rows in set (0.04 sec)mysql&gt; select * from a cross join b on a.id = b.id;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 |+----+--------+----+-----+3 rows in set (0.04 sec)mysql&gt; select * from a cross join b using(id);+----+--------+-----+| id | name | age |+----+--------+-----+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 |+----+--------+-----+3 rows in set (0.04 sec) 外连接在Mysql中外连接分为左外连接和右外连接，但不存在全外连接，这一点与Oracle有些不同，不过可以通过左外连接和右外连接合并出全外连接的结果集，需要注意的是外连接必须添加on子句或者using子句，否则会报语法错误，对于左、有外连接可以分别看一下： 左外连接左外连接基础语法是a left outer join b，其中的outer可以省略，与内连接相比就是在与内连接相同条件下，在内连接的结果集中添加a表在b表中找不到匹配的记录，换句话说就是，结果集中会包含a表中的所有记录，如果b表中有匹配的记录就出现在结果集，否则使用NULL代替，也就是把a表看成根本，不可缺失记录，查询结果如下: 123456789101112131415161718192021mysql&gt; select * from a left outer join b on a.id = b.id;+----+--------+------+------+| id | name | id | age |+----+--------+------+------+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 || 4 | forier | NULL | NULL |+----+--------+------+------+4 rows in set (0.04 sec)mysql&gt; select * from a left join b on a.id = b.id;+----+--------+------+------+| id | name | id | age |+----+--------+------+------+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 || 4 | forier | NULL | NULL |+----+--------+------+------+4 rows in set (0.03 sec) 这个左外连接查询同样可以使用using子句来化简，并且也会将共有的字段省略一个： 12345678910mysql&gt; select * from a left join b using(id);+----+--------+------+| id | name | age |+----+--------+------+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 || 4 | forier | NULL |+----+--------+------+4 rows in set (0.04 sec) 右外连接右外连接基础语法是a right outer join b，其中的outer可以省略，与内连接相比就是在与内连接相同条件下，在内连接的结果集中添加b表在a表中找不到匹配的记录，换句话说就是，结果集中会包含b表中的所有记录，如果a表中有匹配的记录就出现在结果集，否则使用NULL代替，也就是把b表看成根本，不可缺失记录，作用与左外连接恰好相反，查询结果如下: 1234567891011121314151617181920212223242526272829303132mysql&gt; select * from a right outer join b on a.id = b.id;+------+--------+----+-----+| id | name | id | age |+------+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 || NULL | NULL | 5 | 70 |+------+--------+----+-----+4 rows in set (0.03 sec)mysql&gt; select * from a right join b on a.id = b.id;+------+--------+----+-----+| id | name | id | age |+------+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 || NULL | NULL | 5 | 70 |+------+--------+----+-----+4 rows in set (0.04 sec)mysql&gt; select * from a right join b using(id);+----+-----+--------+| id | age | name |+----+-----+--------+| 1 | 18 | albert || 2 | 19 | bella || 3 | 25 | amy || 5 | 70 | NULL |+----+-----+--------+4 rows in set (0.04 sec) 自然连接自然连接从名字来看就是两个表很自然的就连接上了，这要求两个表需要有可以参照的数据，具体到表设计上就是要求两个表必须要有相同的列，需要注意的是自然连接不允许添加连接子句，否则会报语法错误。自然连接分为一般自然连接、左外连接和自然右外连接连接，还是以内连接为标准，看看自然连接有什么不同： 一般自然连接一般自然连接基础语法是a natural join b，它不能加连接条件，使用两个表共有的字段id来“自然”地链接，同时会省略共有的字段，其作用相同于内连接使用using子句来查询，通过下面的对比，你会发现他们的作用是一样的。 12345678910111213141516171819mysql&gt; select * from a natural join b;+----+--------+-----+| id | name | age |+----+--------+-----+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 |+----+--------+-----+3 rows in set (0.03 sec)mysql&gt; select * from a join b using(id);+----+--------+-----+| id | name | age |+----+--------+-----+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 |+----+--------+-----+3 rows in set (0.04 sec) 自然左外连接自然左外连接基础语法是a natural left outer join b，其中的outer可以省略，它也不能加连接条件，使用两个表共有的字段id来“自然”地链接，同时会省略共有的字段，其作用相同于内连接使用using子句同时包含a表中的所有记录，以a表作为根本，包含所有记录，并且显示b表中匹配记录，如没有与a表匹配的记录则以NULL代替，其实就是左外连接省略掉using子句： 1234567891011121314151617181920212223242526272829303132mysql&gt; select * from a natural left outer join b;+----+--------+------+| id | name | age |+----+--------+------+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 || 4 | forier | NULL |+----+--------+------+4 rows in set (0.04 sec)mysql&gt; select * from a natural left join b;+----+--------+------+| id | name | age |+----+--------+------+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 || 4 | forier | NULL |+----+--------+------+4 rows in set (0.03 sec)mysql&gt; select * from a left join b using(id);+----+--------+------+| id | name | age |+----+--------+------+| 1 | albert | 18 || 2 | bella | 19 || 3 | amy | 25 || 4 | forier | NULL |+----+--------+------+4 rows in set (0.03 sec) 自然右外连接自然左外连接基础语法是a natural right outer join b，其中的outer可以省略，它也不能加连接条件，其作用与自然左外连接相反，其实就是右外连接省略掉using子句： 1234567891011121314151617181920212223242526272829303132mysql&gt; select * from a natural right outer join b;+----+-----+--------+| id | age | name |+----+-----+--------+| 1 | 18 | albert || 2 | 19 | bella || 3 | 25 | amy || 5 | 70 | NULL |+----+-----+--------+4 rows in set (0.04 sec)mysql&gt; select * from a natural right join b;+----+-----+--------+| id | age | name |+----+-----+--------+| 1 | 18 | albert || 2 | 19 | bella || 3 | 25 | amy || 5 | 70 | NULL |+----+-----+--------+4 rows in set (0.04 sec)mysql&gt; select * from a right join b using(id);+----+-----+--------+| id | age | name |+----+-----+--------+| 1 | 18 | albert || 2 | 19 | bella || 3 | 25 | amy || 5 | 70 | NULL |+----+-----+--------+4 rows in set (0.04 sec) STRAIGHT_JOINSTRAIGHT_JOIN的基础语法是a STRAIGHT_JOIN b，确实没有找到这种连接的中文说法，不过它与内连接几乎一样，只是它总是把左侧a表作为驱动表优先读入，它只能加on子句，无法使用using子句，在Sql优化的过程中常常使用，也就是拒绝了Mysql的语句优化，而使用自己指定的顺序来连接表格，不过使用时需慎重，你得比Mysql聪明才可以！ 123456789mysql&gt; select * from a straight_join b on a.id = b.id;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 |+----+--------+----+-----+3 rows in set (0.04 sec) 逗号分隔连接表在from之后用逗号分隔的两个表格像极了内连接，只不过用逗号分隔的表不能使用子句连接，只可以用where来做条件筛选，不过作用之后的结果是一致的，可以对比看一下： 12345678910111213141516171819mysql&gt; select * from a join b on a.id = b.id;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 |+----+--------+----+-----+3 rows in set (0.04 sec)mysql&gt; select * from a, b where a.id = b.id;+----+--------+----+-----+| id | name | id | age |+----+--------+----+-----+| 1 | albert | 1 | 18 || 2 | bella | 2 | 19 || 3 | amy | 3 | 25 |+----+--------+----+-----+3 rows in set (0.04 sec) 各种连接对比通过描述可能有些关系还是没理解太清楚，所以整理了下面的表格，对比的更清楚一点，其中[]中的内容在编写sql时可以省略： 连接类型 语法 不加条件 加ON子句 加USING子句 与内连接关系 内连接 a [INNER] JOIN b 两表中任意两条记录分别匹配，形成笛卡尔积 只按照条件匹配，所有列均显示 按照共有的列匹配，去除重复列 X 交叉连接 a [CROSS] JOIN b 两表中任意两条记录分别匹配，形成笛卡尔积 只按照条件匹配，所有列均显示 按照共有的列匹配，去除重复列 语法等价，完全相同 左外连接 a LEFT [OUTER] JOIN b 必须加条件，否则报语法错误 只按照条件匹配，并且包含a表中没有匹配上的记录 按照共有的列匹配，并且包含a表中没有匹配上的记录 额外包含a表中没有匹配上的记录 右外连接 a RIGHT [OUTER] JOIN b 必须加条件，否则报语法错误 只按照条件匹配，并且包含b表中没有匹配上的记录 按照共有的列匹配，并且包含b表中没有匹配上的记录 额外包含b表中没有匹配上的记录 一般自然连接 a NATURAL JOIN b 使用两表中共有的字段匹配 不能使用ON子句 不能使用USING子句 相当于内连接使用USING子句 自然左外连接 a NATURAL LEFT [OUTER] JOIN b 使用两表中共有的字段匹配，并且包含a表中没有匹配上的记录 不能使用ON子句 不能使用USING子句 相当于内连接使用USING子句，并且包含a表中没有匹配上的记录 自然右外连接 a NATURAL RIGHT [OUTER] JOIN b 使用两表中共有的字段匹配，并且包含b表中没有匹配上的记录 不能使用ON子句 不能使用USING子句 相当于内连接使用USING子句，并且包含b表中没有匹配上的记录 STRAIGHT_JOIN a STRAIGHT_JOIN b 两表中任意两条记录分别匹配，形成笛卡尔积 只按照条件匹配，所有列均显示 不能使用USING子句 在内连接基础上确定读表顺序 逗号分隔表 a, b 两表中任意两条记录分别匹配，形成笛卡尔积 不能使用ON子句 不能使用USING子句 不能使用连接子句，只能使用Where筛选 总结 总的来看外连接中的outer是最没有存在感的，凡是它出现的地方都可以省略 黑魔法：a inner join b与a cross join b是等价的，后来我偶然间拼写错误发现a across join b也是可以的，另外a love join b也行，开始还以为发现了bug，后来再理解应该是拼错的单词作了表a的别名，虚惊一场！ 通过上面的表格发现每种连接貌似都和内连接扯上了关系，那就以内连接为基础，通过扩展来记忆也是不错的 如果表格不够清晰，换成思维导图或许会更好一些]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>查询</tag>
        <tag>表连接</tag>
        <tag>内连接</tag>
        <tag>外连接</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[IP地址常见分类：A类、B类、C类、D类、E类]]></title>
    <url>%2Fblog%2F2019%2F04%2F03%2FIP%E5%9C%B0%E5%9D%80%E5%B8%B8%E8%A7%81%E5%88%86%E7%B1%BB%EF%BC%9AA%E7%B1%BB%E3%80%81B%E7%B1%BB%E3%80%81C%E7%B1%BB%E3%80%81D%E7%B1%BB%E3%80%81E%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[前言虽然IPv6渐渐出现在了人们的视线之中，但是目前来看IPv4仍然占据着主导地位，在日常的编码过程中两者都会接触到，但实际上两者在使用范围、消息头结构等细节上有诸多不同，具体的那些细节对于应用层来说可能体会不到，所以我们先从两者的表示方式来看看，学会认出哪些是IPv4类型的地址，而哪些是IPv6类型的地址。 IPv4地址表示方法每个IPv4地址占用4个字节，长度为32位，由网络号和主机号部分组成，最常采用点分十进制表示法，格式为 ddd.ddd.ddd.ddd，其中 0 &lt;= ddd &lt;= 255，而每个 d 都是十进制数，可省略前导零，比如常见的192.168.1.1，理论上最多能表示的地址个数为$2^32$。 IPv6地址表示方法每个IPv6地址占用16个字节，长度为128位，占用空间是IPv4地址的4倍，但是这里要注意，IPv4所能表示的地址个数相比于IPv4来说可不是4倍的关系，IPv6理论上最多能表示的地址个数为$2^128$，是IPv4能力的$2^96$倍，换算成10进制也就是大约79228162514264337593543950336倍，在很长一段时间内不用再担心IP地址不够用的问题了。 而IPv6地址由于占用位数较多，所以采用更容易书写和理解的冒分十六进制表示法，格式为xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx:xxxx，其中每个 x 表示一个十六进制的符号，也就是0-9A-F，比如一个普通IPv6地址23CD:0F01:0005:0789:ABED:EF01:2345:67D9，前导零也是可以省略的，例如前一个地址可以记作23CD:F01:5:789:ABED:EF01:2345:67D9。 在某些情况下，一个IPv6地址内可能包含很长的一段0，这时可以把连续的一段0压缩为::, 但要注意是，地址中::只能出现一次，这样才能保证地址解析的唯一性，比如地址FF20:A:0:0:0:0:0:1AC2，可以写成FF20:A::1AC2，而地址FF20:A:0:0:1:0:0:1AC2中间有两段0，为保证解析的唯一性，只能选择一段0来压缩，比如写成FF20:A::1:0:0:1AC2或者是FF20:A:0:0:1::1AC2。 为了实现IPv4地址和IPv6地址互相通信，在IPv6的环境下，IPv4地址会被扩展成IPv6地址，此时地址的格式常表示为：xxxx:xxxx:xxxx:xxxx:xxxx:FFFF:ddd.ddd.ddd.ddd，前面的96位采用IPv6冒分十六进制表示，而后面32位地址则使用IPv4的点分十进制表示，例如常用的IPv4地址192.168.1.1与表示成IPv6地址就是FFFF:192.168.1.1。 IPv4地址常见分类192.168.1.1这个IP地址随着路由器的普及逐渐为人们所熟知，有些人可能知道这是一个C类地址，究竟什么是C类地址？难道还有A类、B类地址？不是说IP地址是惟一表示一台主机的吗，为什么我家的路由器和邻居家的路由器地址都是192.168.1.1，关于这些问题就涉及到了IPv4地址的常见分类，其实IPv4地址一般被分为A、B、C、D、E五类，其中还包含一些保留地址和局域网地址，关于这些信息为了对比方便，我整理了下面这幅图，有关分类的疑惑可以看图了解一下： 书愤陆游早岁那知世事艰，中原北望气如山。楼船夜雪瓜洲渡，铁马秋风大散关。塞上长城空自许，镜中衰鬓已先斑。出师一表真名世，千载谁堪伯仲间。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Network</tag>
        <tag>网络</tag>
        <tag>IP</tag>
        <tag>IPv4</tag>
        <tag>Ipv6</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql开启、查看慢查询日志]]></title>
    <url>%2Fblog%2F2019%2F03%2F25%2FMysql%E5%BC%80%E5%90%AF%E3%80%81%E6%9F%A5%E7%9C%8B%E6%85%A2%E6%9F%A5%E8%AF%A2%E6%97%A5%E5%BF%97%2F</url>
    <content type="text"><![CDATA[前言想要优化现有的数据库结构或者查询语句，首先要找到需要的优化的地方，不然就会出现费了很大精力优化却不达目的的情况，这就和上学考试一样，想要取得好的成绩，先要分析自己差在哪里，重点学习才会有快速的提升。 关于查询Mysql的瓶颈，或者说查询Mysql出现操作缓慢的问题，我们可以使用Mysql自带的慢查询日志来分析，优化不是改正错误，那种错误在开发过程中叫做BUG，伴随着软件开发工程师的一生，而优化是指在逻辑正确的前提下，让程序运行的更快更稳定，一般来说就是优化比较耗时的操作，提升用户体验。比如一个信息系统，如果输入账号密码后需要10分钟才能登录成功，我想基本上也不会有人使用了。 慢查询日志就是一种特殊的记录，用于统计Mysql操作过程中一些耗时的语句，生成文件或者表格，为优化Mysql操作提供分析数据，从名字也很好理解，慢查询日志就是记录一些查询的比较慢的记录，帮助使用者定位具体的问题，接下来就简单地描述一下慢查询日志是如何开启和查看的。 测试环境 Windows 10Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 7Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners.Type ‘help;’ or ‘\h’ for help. Type ‘\c’ to clear the current input statement. 开启慢查询日志修改过Mysql配置的小伙伴应该知道，Mysql的一些环境配置可以通过命令行直接修改，也可以修改配置文件后重新启动Mysql服务来生效，我们这次选择修改配置文件的方法，首先找到配置文件my.ini（Mysql5.7Windows版本，Linux版本应该叫my.cnf吧），一般在安装目录所在的ProgramData目录下，比如我的是在 C:/ProgramData/MySQL/MySQL Server 5.7 ，如果找不到可以下载一个叫Everything的软件搜一下（顺便安利一下，真的挺好用）。 用记事本或者其他编辑软件打开，搜索 long_query_time找到配置区域，其中有一些其他的配置，与慢查询无关已经剔除：12345# General and Slow logging.log-output=FILEslow-query-log=1slow_query_log_file="0491NPORIURNUYO-slow.log"long_query_time=0.01 slow-query-log：慢查询日志的开关，1表示开启，0表示关闭。Mysql5.1之前貌似是默认关闭的，而我这个版本在安装完成后自动开启了，如果没有可以将其设置为1，重启服务后会自动开启 long_query_time：这个参数很关键，表示慢查询日志的阈值，花费时间超过这个值的sql语句才会被记录，单位是秒，这一点需要注意，网上有些文章说这个参数是毫秒，不知道是不是版本问题，使用时可以测试一下，经测试可以配置成小数 log-output：表示日志存储的方式。FILE 表示将日志存入文件，默认值是FILE，另外可以取值 TABLE ，表示将日志存入数据库表，当然也可以两者都选择，配成 FILE,TABLE 。需要注意的是将日志记录到数据库表中，需耗费更多的系统资源，建议优先记录到文件 log-slow_query_log_file：当配置将日志记录到文件中时，这个参数可以指定文件名，路径一般在配置文件的同级的Data目录下，比如我的是在C:/ProgramData/MySQL/MySQL Server 5.7/Data，当发现sql运行较慢时可以打开这个文件看一下 具体例子 首先我们将long_query_time设置为0.05，也就是记录查询时间超过50毫秒的sql操作，这是个很随意的值，具体的生产环境根据具体情况配置，重启Mysql服务使其生效 创建一张测试表格 slow_query_test 1create table slow_query_test(id int, num int, money int); 然后创建一个存储过程，用来给数据表填充数据，命名为fill_slow_query_test 123456789CREATE PROCEDURE `fill_slow_query_test`()BEGIN DECLARE i int default 1; WHILE i &lt;= 100000 do insert into slow_query_test values(i, i, i); set i = i + 1; END WHILE;END 调用存储过程插入测试数并查询，得到以下结果 12345678910mysql&gt; call fill_slow_query_test();Query OK, 1 row affected (24.45 sec)mysql&gt; select * from slow_query_test where id = 9990;+------+------+-------+| id | num | money |+------+------+-------+| 9990 | 9990 | 9990 |+------+------+-------+1 row in set (0.09 sec) 通过观察结果可以发现，两次操作的时间都超过了0.05s，所以都应该被记录到慢查询日志日志中，打开日志查看内容 12345678910111213C:\Program Files\MySQL\MySQL Server 5.7\bin\mysqld.exe, Version: 5.7.21-log (MySQL Community Server (GPL)). started with:TCP Port: 3306, Named Pipe: (null)Time Id Command Argument# Time: 2019-03-25T03:14:50.241968Z# User@Host: root[root] @ localhost [::1] Id: 2# Query_time: 24.447215 Lock_time: 0.000364 Rows_sent: 0 Rows_examined: 0SET timestamp=1553483690;call fill_slow_query_test();# Time: 2019-03-25T03:15:27.862107Z# User@Host: root[root] @ localhost [::1] Id: 2# Query_time: 0.050133 Lock_time: 0.000133 Rows_sent: 1 Rows_examined: 100000SET timestamp=1553483727;select * from slow_query_test where id = 9990; 日志中的内容与我们猜想的基本一致，但是还要多一些，首先前3行是Mysql服务启动的记录，接下来的是Mysql慢查询日志的正文，每组都通过3行注释分隔： Time：记录执行操作时的日期和时间，默认没有包含时区信息，是标准的UTC时间 User@Host 记录执行操作的主机和用户，以及Mysql连接id等信息 Query_time 记录了查询消耗的时间，以及其他的一些操作信息接下来未被注释的内容就是真正执行的操作，包含当时的时间戳和具体执行的语句 简单优化针对于上述的例子，我们可以运用上一篇文章《Mysql查询可通过给条件字段添加索引提高查询速度》 提到的方法，简单优化一下： 首先给id字段添加简单索引 123mysql&gt; ALTER TABLE slow_query_test ADD INDEX id_index(id);Query OK, 0 rows affected (0.14 sec)Records: 0 Duplicates: 0 Warnings: 0 然后使用相同的sql语句再次查询 1234567mysql&gt; select * from slow_query_test where id = 9990;+------+------+-------+| id | num | money |+------+------+-------+| 9990 | 9990 | 9990 |+------+------+-------+1 row in set (0.04 sec) 对比前后的查询我们发现，加了索引的表格查询耗时已经小于0.05s，所以该查询不会被记录到慢查询日志中了 慢查询日志格式化处理有时面对慢查询日志文件内众多的数据确实无从下手，这是可以考虑使用mysql自带的mysqldumpslow工具来分析慢查询日志，该工具一般与mysql可执行文件在同一目录，比如我的是在C:/Program Files/MySQL/ySQL Server 5.7/bin&gt;，直接运行发现会报错 12C:\Program Files\MySQL\MySQL Server 5.7\bin&gt;mysqldumpslow'mysqldumpslow' 不是内部或外部命令，也不是可运行的程序或批处理文件。 仔细观察会发现，这个工具不知何时已经从可执行文件变成了一个Perl脚本mysqldumpslow.pl（之前使用linux版本是可执行文件）了，不能直接运行，需要安装Perl运行环境，这里有官方的下载地址，如果下载太慢的话可以下载我的备份文件，版本是一样的。 安装完成之后查看帮助（注意文件路径）12345678910111213141516171819202122232425262728PS C:\Program Files\MySQL\MySQL Server 5.7\bin&gt; perl mysqldumpslow.pl --helpUsage: mysqldumpslow [ OPTS... ] [ LOGS... ]Parse and summarize the MySQL slow query log. Options are --verbose verbose --debug debug --help write this text to standard output -v verbose -d debug -s ORDER what to sort by (al, at, ar, c, l, r, t), 'at' is default al: average lock time ar: average rows sent at: average query time c: count l: lock time r: rows sent t: query time -r reverse the sort order (largest last instead of first) -t NUM just show the top n queries -a don't abstract all numbers to N and strings to 'S' -n NUM abstract numbers with at least n digits within names -g PATTERN grep: only consider stmts that include this string -h HOSTNAME hostname of db server for *-slow.log filename (can be wildcard), default is '*', i.e. match all -i NAME name of server instance (if using mysql.server startup script) -l don't subtract lock time from total time 看完使用方法，我们可以按照查询消耗的时间排序输出前两条日志（注意日志的路径，为方便可以拷贝到mysqldumpslow工具目录）: 12345678PS C:\Program Files\MySQL\MySQL Server 5.7\bin&gt; perl mysqldumpslow.pl -s t -v -t 2 0491NPORIURNUYO-slow.logReading mysql slow query log from 0491NPORIURNUYO-slow.logCount: 1 Time=24.45s (24s) Lock=0.00s (0s) Rows=0.0 (0), root[root]@localhost call fill_slow_query_test()Count: 1 Time=0.05s (0s) Lock=0.00s (0s) Rows=1.0 (1), root[root]@localhost select * from slow_query_test where id = N 可以发现还是很方便的，最耗时的操作已经排到了第一位，在实际的优化过程中，这或许就是我们需要拿来开刀的目标了。 总结 通过修改配置文件my.ini中的slow-query-log、long_query_time来调整慢查询日志的开关和具体阈值 通过mysqldumpshow工具可以格式化慢查询日志，方便定位问题和分析问题]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>慢查询</tag>
        <tag>日志</tag>
        <tag>分析</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql查询可通过给条件字段添加索引提高查询速度]]></title>
    <url>%2Fblog%2F2019%2F03%2F15%2FMysql%E6%9F%A5%E8%AF%A2%E5%8F%AF%E9%80%9A%E8%BF%87%E7%BB%99%E6%9D%A1%E4%BB%B6%E5%AD%97%E6%AE%B5%E6%B7%BB%E5%8A%A0%E7%B4%A2%E5%BC%95%E6%8F%90%E9%AB%98%E6%9F%A5%E8%AF%A2%E9%80%9F%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[前言当使用sql语句查询表数据时，会发现随着表中记录的增多，查询的速度也会也来越慢，特别是那种日志记录，少则几十万，多则上百万，甚至上千万数据，如果查询一次耗时太长，会严重影响业务逻辑，这时候可以考虑给经常作为条件的字段添加索引了，这样做会大大加快查询速度，这里所说的条件字段，就是指sql语句中放到where条件中用于筛选记录的字段，关于加索引提高查询速度的做法，我们可以做一下试验，对比一下看看是否真的有效。 测试环境 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 8Server version: 5.7.21-log MySQL Community Server (GPL)Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. 测试过程 首先创建一个不带有索引的数据表 tb_without_index 1create table tb_without_index(id int, num int, money int); 然后创建一个存储过程，用来给无索引数据表填充数据，命名为fill_tb_without_index 123456789CREATE PROCEDURE `fill_tb_without_index`()BEGIN DECLARE i int default 1; WHILE i &lt;= 100000 do insert into tb_without_index values(i, i, i); set i = i + 1; END WHILE;END 接着创建一个带有索引用来做对比的数据表 tb_with_index 1create table tb_with_index(id int, num int, money int, key `id_index`(id)); 同样创建一个给带索引数据表填充数据的存储过程 fill_tb_with_index 123456789CREATE PROCEDURE `fill_tb_with_index`()BEGIN DECLARE i int default 1; WHILE i &lt;= 100000 do insert into tb_with_index values(i, i, i); set i = i + 1; END WHILE;END 分别调用存储过程来填充数据，每个表填充需要20多秒，还是挺费时间的 12345mysql&gt; call fill_tb_without_index();Query OK, 1 row affected (25.48 sec)mysql&gt; call fill_tb_with_index();Query OK, 1 row affected (25.64 sec) 查询对比 对于单条数据的查询对比 123456789101112131415mysql&gt; select * from tb_with_index where id = 67853;+-------+-------+-------+| id | num | money |+-------+-------+-------+| 67853 | 67853 | 67853 |+-------+-------+-------+1 row in set (0.05 sec)mysql&gt; select * from tb_without_index where id = 67853;+-------+-------+-------+| id | num | money |+-------+-------+-------+| 67853 | 67853 | 67853 |+-------+-------+-------+1 row in set (0.08 sec) 对于范围数据的查询对比 123456789101112131415mysql&gt; select count(id) from tb_without_index where id &gt; 87862;+-----------+| count(id) |+-----------+| 12138 |+-----------+1 row in set (0.09 sec)mysql&gt; select count(id) from tb_with_index where id &gt; 87862;+-----------+| count(id) |+-----------+| 12138 |+-----------+1 row in set (0.05 sec) 结果分析 通过上面两种情况的对比，我们可以发现虽然每组对比只差零点零几秒的时间，但是从耗时来看有索引的表格查询比没有索引的表格查询节省了大约40%的时间，由此可见，给待查字段添加上索引，确实可以加快查询速度。 既然加上索引的效率可以提升这么多，那么可不可以把所有字段都加上索引呢？答案是不可以，这一点可以从测试过程的第5步结果来分析，这一步中给表格 tb_without_index 添加10万条数据耗时25.48秒，给表格 tb_with_index 添加10万条数据耗时25.64秒，也就是给有索引的表添加数据时要多花0.16秒的时间，这不是偶然的，可以反复测试，每次的测试结果都是有索引表的数据插入过程更耗时一点。 通过上面的对比和分析，可以知道，虽然添加索引可以加快查找速度，但是会拖慢插入和更新的速度，因为在有索引的数据表上更新和插入需要多花费时间来维护索引，至于两者之间的平衡，就需要使用者自己把握了。 添加索引 像上面提到的那样，可以在建表的时候就定义好索引，查询表结构发现字段id所在行的Key列值为MUL，表示它的值是可以重复的索引，其他两个字段都没有 12345678910create table tb_with_index(id int, num int, money int, key `id_index`(id));mysql&gt; desc tb_with_index;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | MUL | NULL | || num | int(11) | YES | | NULL | || money | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+3 rows in set (0.05 sec) 在已有的表格上创建索引，比如可以在列num上创建一个索引，语法：CREATE INDEX index_name ON table_name(column_list) 12345678910111213mysql&gt; CREATE INDEX num_index ON tb_with_index(num);Query OK, 0 rows affected (0.23 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc tb_with_index;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | MUL | NULL | || num | int(11) | YES | MUL | NULL | || money | int(11) | YES | | NULL | |+-------+---------+------+-----+---------+-------+3 rows in set (0.05 sec) 修改表结构添加索引，比如可以给列num添加一个索引，语法：ALTER TABLE table_name ADD INDEX index_name(column_list) 12345678910111213mysql&gt; ALTER TABLE tb_with_index ADD INDEX money_index(money);Query OK, 0 rows affected (0.21 sec)Records: 0 Duplicates: 0 Warnings: 0mysql&gt; desc tb_with_index;+-------+---------+------+-----+---------+-------+| Field | Type | Null | Key | Default | Extra |+-------+---------+------+-----+---------+-------+| id | int(11) | YES | MUL | NULL | || num | int(11) | YES | MUL | NULL | || money | int(11) | YES | MUL | NULL | |+-------+---------+------+-----+---------+-------+3 rows in set (0.06 sec) 查看索引可以查看一个表上的所有索引信息，语法为：show index from table_name，查询结果如下 123456789 mysql&gt; show index from tb_with_index; +---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+ ---------------+ | Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment | +---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+ ---------------+ | tb_with_index | 1 | id_index | 1 | id | A | 98715 | NULL | NULL | YES | BTREE | | | | tb_with_index | 1 | num_index | 1 | num | A | 100035 | NULL | NULL | YES | BTREE | | | | tb_with_index | 1 | money_index | 1 | money | A | 100035 | NULL | NULL | YES | BTREE | | | +---------------+------------+-------------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+ ---------------+3 rows in set (0.06 sec) 总结 给条件字段添加索引可以大大加快数据的查询速度，提高系统的性能。 不要考虑在所有的字段上添加索引，创建索引和维护索引都要耗费时间，这种时间随着数据量的增加而增加。 适合添加索引的字段：总是作为条件查询的字段、常用来做连接的字段、作为主键或者强调唯一的列上。 不适合加索引的字段：块数据类型的字段、取值很少的字段。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>索引</tag>
        <tag>index</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下查找包含指定内容的文件及其所在行数]]></title>
    <url>%2Fblog%2F2019%2F03%2F13%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%9F%A5%E6%89%BE%E5%8C%85%E5%90%AB%E6%8C%87%E5%AE%9A%E5%86%85%E5%AE%B9%E7%9A%84%E6%96%87%E4%BB%B6%E5%8F%8A%E5%85%B6%E6%89%80%E5%9C%A8%E8%A1%8C%E6%95%B0%2F</url>
    <content type="text"><![CDATA[前言在linux系统下搜索文件一般情况下一个命令就搞定了，之前搜索文件的时候一直使用find，今天排查问题时想查一个函数的调用者在哪个文件中，发现不会写了，搜了一下发现使用grep命令就可以实现，改变了我对grep命令的理解，原来使用grep命令的情况通常是作为结果的过滤函数，比如ps aux | grep gameserver，这次发现他居然还可以直接用来搜索，其实也是过滤的一种。 使用方法这里直接给出命令的写法，简单替换搜索内容就可以使用，也方便自己后续查找使用(例如查找包含stream的文件)：1grep -rn 'stream' . --include='*.cpp' 命令解析上述命令是一种比较常用的写法，就是在当前目录下（一定要注意那个.）查找包含stream的文件，并显示其所在的行，搜索的文件类型是.cpp，其实--include=后面的内容是遵循glob语法的，详细的就不展开了，简单来说就是支持通配符，而查找选项-rn中的r表示递归查找，其中的n表示显示行号，此外还可以使用选项-i表示忽略大小写，下面简单展示一下3个选项的功能： -r：只递归查找不显示行号 1234567891011[albert@localhost#18:17:41#/home/albert/test]$grep -r 'stream' . --include='*.cpp'./testPtr.cpp:#include &lt;iostream&gt;./crab-server/code/main/crab.cpp:#include &lt;iostream&gt;./testConstructor.cpp:#include &lt;iostream&gt;./smartptr/auto_ptr.cpp:#include &lt;iostream&gt;./io.cpp:#include &lt;fstream&gt;./io.cpp: ofstream logfile("./logs/players_distribution.txt", ios::out);./ptr.cpp:#include &lt;iostream&gt;./gdbtest/main.cpp:#include &lt;iostream&gt;./test_t.cpp:#include &lt;iostream&gt;./testshareptr.cpp:#include &lt;iostream&gt; -rn：递归查找并显示行号 1234567891011[albert@localhost#18:17:48#/home/albert/test]$grep -rn 'stream' . --include='*.cpp'./testPtr.cpp:4:#include &lt;iostream&gt;./crab-server/code/main/crab.cpp:3:#include &lt;iostream&gt;./testConstructor.cpp:1:#include &lt;iostream&gt;./smartptr/auto_ptr.cpp:4:#include &lt;iostream&gt;./io.cpp:1:#include &lt;fstream&gt;./io.cpp:9: ofstream logfile("./logs/players_distribution.txt", ios::out);./ptr.cpp:4:#include &lt;iostream&gt;./gdbtest/main.cpp:1:#include &lt;iostream&gt;./test_t.cpp:1:#include &lt;iostream&gt;./testshareptr.cpp:4:#include &lt;iostream&gt; -rni：递归查找显示行号并且忽略大小写 12345678910111213141516171819202122[albert@localhost#18:17:53#/home/albert/test]$grep -rni 'stream' . --include='*.cpp'./testPtr.cpp:4:#include &lt;iostream&gt;./crab-server/code/main/crab.cpp:3:#include &lt;iostream&gt;./testConstructor.cpp:1:#include &lt;iostream&gt;./epoll_cs_demo/testfd.cpp:5: int listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/testfd.cpp:8: listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/testfd.cpp:11: listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/testfd.cpp:14: listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/testfd.cpp:21: listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/testfd.cpp:25: listen_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/client.cpp:18: int client_fd = socket(AF_INET, SOCK_STREAM, 0);./epoll_cs_demo/server.cpp:24: int listen_fd = socket(AF_INET, SOCK_STREAM, 0);./smartptr/auto_ptr.cpp:4:#include &lt;iostream&gt;./io.cpp:1:#include &lt;fstream&gt;./io.cpp:9: ofstream logfile("./logs/players_distribution.txt", ios::out);./network/zgetaddrinfo.cpp:37: hints.ai_socktype = SOCK_STREAM;/* Stream socket */./linux_version/client.cpp:15: int client_fd = socket(AF_INET, SOCK_STREAM, 0);./linux_version/server.cpp:15: int listen_fd = socket(AF_INET, SOCK_STREAM, 0);./ptr.cpp:4:#include &lt;iostream&gt;./gdbtest/main.cpp:1:#include &lt;iostream&gt;./test_t.cpp:1:#include &lt;iostream&gt;./testshareptr.cpp:4:#include &lt;iostream&gt; 总结 查找指定内容的简单命令：grep -rn &#39;stream&#39; . --include=&#39;*.cpp&#39; 这个grep有很多附加的参数，看了文档之后发现了一个点，原来用法：egrep即grep -E，fgrep即rep -F，但是 egrep 和 fgrep现在都不建议使用了，无论是man手册还是--help选项中都提到了这一点]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>find</tag>
        <tag>linux</tag>
        <tag>grep</tag>
        <tag>查找</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为目标打好基础的希尔排序]]></title>
    <url>%2Fblog%2F2019%2F03%2F09%2F%E4%B8%BA%E7%9B%AE%E6%A0%87%E6%89%93%E5%A5%BD%E5%9F%BA%E7%A1%80%E7%9A%84%E5%B8%8C%E5%B0%94%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言刚刚分析过的插入排序通常被叫做简单插入排序或者直接插入排序，而这篇文章刚好以插入排序为基础来说说希尔排序，还是先从名字开始，结果发现完全没有头绪，说实话第一次听说这个排序时还以为是个特别神奇的高端算法，结果了解一番之后发现其实是一个被改造的插入排序，“希尔”居然是发明者的名字，所以从名字来判断算法思想在这里行不通，甚至说快速排序起码说明了这种方法排序快，而希尔排序等于什么都没说。 希尔排序的基础是插入排序，整个排序也是在新元素不断插入到有序序列适当位置的过程中完成的，唯一的不同的就是通过不同的步长将整个序列划分为不同的小序列不断插入，直到步长为1时就退化成了最基本的直接插入排序，但是此时整个序列已经“基本”有序了，需要交换的元素对比一开始直接插入的方法明显减少，从而可以加快排序的速度，因为最后步长为1的一次插入排序与简单插入排序完全相同，所以前面的几趟排序完全可以看做是最后的排序目标“打基础”，让最后一次的排序序列尽可能有序，下面描述一下希尔排序的过程，前提是你已经了解简单插入排序的过程，可以参考文章抓扑克牌风格的插入排序熟悉一下。 希尔排序希尔排序的有一个关键的元素是步长，关于步长的选择有很多种方法，比如只选奇数，选择互为质数等等，其目的就是为了减少重复比较的次数，我们现在只为了解希尔排序的过程，所以先选择一种简单的步长选定方法，以元素个数的一半为基础，每次减少一半直到步长降为1，比如10个元素的步长选择分别为5,2,1，本质思想就是分别以步长5,2,1对整个待排序列进行简单的插入排序，最后就完成了整个序列的排序。 我们用物品重量排序作为例子吧，原来插入排序的例子是将新得到的扑克牌不断插入到有序序列中得到最终排序，这次可以直接先给出物品质量序列的初始排列，假设为99, 34, 54, 65, 11, 1, 5, 12, 89, 42，一共10件物品摆在面前，目标为将物品重量从小到大排序，首先选取步长5开始排序过程： 最开始的排序序列如下:99, 34, 54, 65, 11, 1, 5, 12, 89, 42 以步长为5将整个序列分为5组，分组情况如下：99, _, _, _, _, 1, _, _, _, __, 34, _, _, _, _, 5, _, _, __, _, 54, _, _, _, _, 12, _, __, _, _, 65, _, _, _, _, 89, __, _, _, _, 11, _, _, _, _, 42 将这五组子序列分别使用简单插入排序，得到以下序列：1, _, _, _, _, 99, _, _, _, __, 5, _, _, _, _, 34, _, _, __, _, 12, _, _, _, _, 54, _, __, _, _, 65, _, _, _, _, 89, __, _, _, _, 11, _, _, _, _, 42 这五个子序列组成完整的中间临时序列为：1, 5, 12, 65, 11, 99, 34, 54, 89, 42 然后以步长为2将整个序列划分，得到以下分组情况：1, _, 12, _, 11, _, 34, _, 89, __, 5, _, 65, _, 99, _, 54, _, 42 将这两组子序列使用简单插入排序，得到以下序列：1, _, 11, _, 12, _, 34, _, 89, __, 5, _, 42, _, 54, _, 65, _, 99 将子序列整体来看得到中间临时序列：1, 5, 11, 42, 12, 54, 34, 65, 89, 99 最后再将整个待排序列进行一次简单插入排序，便可得到最终排好的序列，实际上最后一次插入排序只有中间几个元素需要移动了：1, 5, 11, 12, 34, 42, 54, 65, 89, 99 代码实现12345678910111213141516171819202122232425262728293031323334353637/*功能： 交换两个变量参数： element1--被交换的第一个元素的地址 element2--被交换的第二个元素的地址返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void swap_data(int* element1, int* element2)&#123; int middle_value = *element1; *element1 = *element2; *element2 = middle_value;&#125;/*功能： 希尔排序，实现数组元素从小到大排列参数： array--表示待排序的数组，此处会退化成指针 count--数组元素的个数返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void shell_sort(int array[], int count)&#123; int step = count / 2; while (step &gt; 0) &#123; for (int pos = step; pos &lt; count; ++pos) &#123; for (int insert_index = pos; insert_index &gt;= step; insert_index -= step) &#123; if (array[insert_index] &lt; array[insert_index - step]) swap_data(&amp;array[insert_index], &amp;array[insert_index - step]); &#125; &#125; step /= 2; &#125;&#125; 对比插入排序源代码，找找不同 1234567891011void insert_sort(int array[], int count)&#123; for (int pos = 1; pos &lt; count; ++pos) &#123; for (int insert_index = pos; insert_index &gt; 0; --insert_index) &#123; if (array[insert_index] &lt; array[insert_index - 1]) swap_data(&amp;array[insert_index], &amp;array[insert_index - 1]); &#125; &#125;&#125; 代码分析以上代码就是希尔排序的实现方式了，对比直接插入的源代码发现，如果将希尔排序的初始步长设置成1，那么整个希尔排序的代码就和简单插入排序完全一样了，这也符合我们之前分析的过程，其实希尔排序就是分多次，每次用不同的步长执行简单插入排序。 还有一点就是代码执行的过程与上面示例中的分组插入看起来有些不同，只是因为这个写起来更方便一些，分组只是为了人脑能更快的理解算法的思想，但是代码编写时还要考虑复杂性，将数据拆分成几组然后分别进行插入排序完全可以做到，但是实际上完全没有必要。 比如分成两组排序的那一步，直观上先排索引为0,2,4,6,8上的元素，依次做插入操作，然后排索引为1,3,5,7,9上的元素，在依次做插入操作，但是在实现的代码中就做了变通，反正都要做插入操作，并且步长都是2，所以可以直接对索引是0,1,2,3,4,5,6,7,8,9上的元素做插入排序，只要注意步长是2，就不会影响到其他组（实际上并不存在）的元素了，整个过程顺着代码，一步步执行就明白了。 运行测试希尔排序–源码 如果你想运行测试一下，可以复制或者下载源代码，在本机运行测试一下，当然也可以选择在线C++编译器，把源代码复制到网页中运行查看结果，建议不明白的可以在本地环境单步调试一下，这样有助于理解算法思路。]]></content>
      <categories>
        <category>Sort</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>算法</tag>
        <tag>概念</tag>
        <tag>Sort</tag>
        <tag>希尔</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下运行程序常用的nohup和&的区别]]></title>
    <url>%2Fblog%2F2019%2F02%2F25%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E8%BF%90%E8%A1%8C%E7%A8%8B%E5%BA%8F%E5%B8%B8%E7%94%A8%E7%9A%84nohup%E5%92%8C-%E7%9A%84%E5%8C%BA%E5%88%AB%2F</url>
    <content type="text"><![CDATA[前言复杂问题简单记，先了解一下概念，对于一般的小程序而言这两种启动方法应该用不上，如果程序瞬间的就结束了，是否挂起与是否后台也就没有了意义，所以标题中提到的方式常用来启动需要一直运行的程序，比如游戏服务器。 假如我们直接通过命令行./game_server运行一个简单的游戏服务器，那么会发现这个运行程序霸占了整个命令窗口，此时，我们无法再运行其他的程序，所有的输入都变成了game_server的输入，而命令终端此时也只能输出game_server程序的输出信息了。 接着再来了解两个信号，针对于霸占了命令终端的game_server我们可以采用以下方式将其终止掉，使用Ctrl+C组合键，实际上是给程序发送了SIGINT信号，可以以直接关掉命令终端，这个进程也会死掉，实际上是给程序发送了SIGHUP信号，而标题中的所说的两种方式就是针对于这两种信号的。 两种方式的区别 nohupnohup是no hang up的缩写，就是不挂断的意思，忽略SIGHUP信号，在关闭命令终端后程序依旧运行 &amp;&amp;是只后台运行，即忽略SIGINT信号，也就是按Ctrl+C不会终止程序，但是关闭命令行终端程序终止 总结所以要想程序忽略SIGINT和SIGHUP两种信号需要两种表示方法一同使用，总结如下 命令 忽略信号 按Ctrl+C结果 关闭终端 标准输入 输出 ./game 无 程序终止 程序终止 只能给game输入 终端输出 nohup ./game SIGHUP 程序终止 依旧运行 输入被忽略 输出到nohup.out文件 ./game &amp; SIGINT 依旧运行 程序终止 输入正常，终端可用 无输出 nohup ./game &amp; SIGINT、SIGHUP 依旧运行 依旧运行 输入正常，终端可用 输出到nohup.out文件]]></content>
      <categories>
        <category>linux</category>
      </categories>
      <tags>
        <tag>linux</tag>
        <tag>nohup</tag>
        <tag>进程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[linux环境下服务器程序的查看与gdb调试]]></title>
    <url>%2Fblog%2F2019%2F01%2F11%2Flinux%E7%8E%AF%E5%A2%83%E4%B8%8B%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%9F%A5%E7%9C%8B%E4%B8%8Egdb%E8%B0%83%E8%AF%95%2F</url>
    <content type="text"><![CDATA[前言这一篇主要是记录下调试服务器程序常用的命令，内容很简单，但是长时间不用很容易记混，因为游戏服务器也不是天天宕机，所以当有一天突然挂掉需要调试的时候，如果记不清调试命令很容易耽误时间，有好几次我就把gdb gameserver core记成了gdb core gameserver，所以干脆把这些内容统计到一起，查询的时候也方便。 查询程序的运行情况 ps aux命令是常用来查询程序进程运行情况的，基本上不会漏掉，但是显示的无关程序太多，看着不方便所以常配合grep过滤 ps aux | grep gameserver可以显示指定过滤内容的程序，但是这种显示方式没有标题，对于不熟悉的人来说看不太明白，就像下面这样 123$ps aux | grep initroot 1 0.0 0.0 19232 976 ? Ss 2018 0:01 /sbin/init510 2042 0.0 0.0 105492 932 pts/2 S+ 10:04 0:00 grep init 所以这里给出ps aux默认的输出格式：USER PID %CPU %MEM VSZ RSS TTY STAT START TIME COMMAND其中STAT: 该行程的状态，linux的进程常见状态：D 不可中断 uninterruptible sleep (usually IO)R 运行 runnable (on run queue)S 中断 sleepingT 停止 traced or stoppedZ 僵死 a defunct or zombie process注: 其它状态还包括W(无驻留页), &lt;(高优先级进程), N(低优先级进程), L(内存锁页). ps -eo pid,lstart,etime,command | grep gameserver有时需要查询特定进程的指定信息，比如运行时间，那么可以通过-o选项来指定，显示信息很明确 1215499 Thu Jan 10 23:22:53 2019 11:24:12 ./gameserver -d18097 Fri Jan 11 10:47:04 2019 00:01 grep gameserver 杀死指定进程 killall -10 gameserver: 按照进程名杀死进程，-10为自定义杀死信号 kill -10 gameserver_pid: 按照进程ID杀死进程，-10为自定义杀死信号 kill -9 gameserver_pid: -9为强制杀死进程的信号，无法被捕捉 kill -6 gameserver_pid: -6可以杀死进程并产生core文件 gdb调试通常要想使用gdb调试需要在编译程序时加上-g选项，之后才能用gdb进行调试：gcc -g main.c -o gameserver，如果想在程序崩溃时产生core文件，还需要设置系统命令ulimit -c unlimited才可以，调试程序又分为直接启动调试、调试core文件和附加到正在运行的进程调试，每种方式的参数略有不同： 直接启动调试，gdb gameserver这种方式相当于直接通过gdb启动了程序，并开启了调试模式，所以是拉取了新的进程 调试core文件，gdb gameserver core.xxx这种方式相当于展示程序崩溃前的堆栈情况，并进行调试，所以也算是拉取了新的进程 附加进程调试，gdb attach gameserver_pid/gdb gameserver gameserver_pid这种方式是将gdb调试工具附加到程序运行的当前进程上，并没有拉取新的进程，操作上也可以先敲gdb回车，然后再attach gameserver_pid，不过这种情况对于其他用户启动的程序，通常会提示“ptrace: 不允许的操作.”，所以需要使用sudo运行gdb gdb常用命令以下命令为调试linux程序常用的gdb命令，都是在调试服务器程序core文件过程中不断积累的，还有一些高级命令一般很少用到，掌握下面这些基本上就可以应付很多场景了，其中打印信息的命令print在打印map、vector等显示不友好，可以参考gdb调试脚本中的内容。 run/r：重新开始运行文件 break/b: 设置断点（I. b filename:linenum, II. b functioname, 条件断点: b position if condition） info/i: 查看信息（I. i b:查看断点信息，i locals: 查看当前帧局部变量值，i threads: 查看线程） delete/d: 删除断点（delete 3：删除通过info breakpoints查到的第3个断点，其实还可以删除别的） list/l: 查看原代码（list -n：显示第n行前后的源代码。list 函数名：查看具体函数） next/n: 逐过程调试（类似于VS的F10） step/s: 逐语句调试（类似于VS的F11） frame/f：切换函数的栈帧（可以调试输出指定函数内的情况） print/p：打印值及地址（用来显示变量值） thread/t: 切换线程（调试指定线程，用来处理多线程程序） continue/c：继续运行（常用调试完断点之后） backtrace/bt：显示堆栈（可以查看函数的调用的栈帧和层级关系） source: 加载脚本（可以在调试过程中使用脚本完成复杂逻辑调试）]]></content>
      <categories>
        <category>gdb</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>linux</tag>
        <tag>gdb</tag>
        <tag>ps</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[抓扑克牌风格的插入排序]]></title>
    <url>%2Fblog%2F2018%2F12%2F04%2F%E6%8A%93%E6%89%91%E5%85%8B%E7%89%8C%E9%A3%8E%E6%A0%BC%E7%9A%84%E6%8F%92%E5%85%A5%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言上次聊到了快速排序，我们说到快排这个名字是非常抽象的，究竟什么是快排，从名字上我们无从得知，或许叫二分排序都比快速排序要形象的多，可是这又和归并排序重复了，所以我们还是不要在意快排的名字了，接下来看一下今天的插入排序，这里指的是简单的插入排序。 插入排序相比于快速排序要形象很多，整个排序过程就是在不断的插入操作中完成的，如果你打过扑克基本上很容易理解这种排序方法，排序的过程几乎与抓扑克牌的过程一模一样，假设三个人斗地主，每人一张牌依次抓取，其实一旦开始抓一张牌，那么牌堆里哪些牌是你的就已经确定了，只不过是隔两张之后的那张就是你的，所有这些归属于你的牌在牌堆里的顺序就是这些牌的初始顺序，而你抓牌摆牌的过程就是给这些牌从小到大（当然可以从大到小）排序的过程。 插入排序整个排序过程可以使用抓牌来模拟，抓第一张牌的时候无所谓顺序，放在手里就好，抓第二张牌的时候和第一张比较，按从小到大排好顺序，抓第三张牌的时候，和前面两张比较，“插入”适当的位置，后面的牌依次类推插入正确位置，最后手里的牌也就排好了顺序，还有一点需要注意，抓牌时可以真的将一张牌插入到另外两张牌之间的（实际上也是占用了原来牌的位置），但是在内存中，比如连续下标的一个数组中，要想在元素2和元素3中间插入一个数字是做不到的，如果确实要放到这两个数中间，那就需要将元素3往后移动，给需要插入的这个数字腾出一个地方，元素3后面如果也有其他元素呢？那就也需要向后移动，一直到后面没有需要移动的元素为止。 想象一下完整的抓牌过程，其中的关键点就在于拿到一张新牌（元素）后，和之前有序的手牌进行比较，找到合适的插入位置，依次移动手牌位置（为了仿照内存中移动，我们把牌向后移动，也就是从后向前比较找插入位置），为新来的牌腾出一个位置，把新抓到的牌放入空位，一直到完成最后一张牌的插入，我们也就同时完成了手牌的排序。其中的关键词有之前有序、移动、插入。 接下来可以举个例子操作一下，假设我开了天眼，可以看到牌堆里所有的牌，那么确定了抓牌顺序之后，我也就知道我会抓到哪些牌了，他们分别是6, 2, 7, 3, 8, 9，下面来模拟一下这个牌堆中的牌到了我的手里时候怎么就有序了，还有一个情况就是我用右手摸牌，左手拿牌，但是左手比较小，只能放的下6张牌，这时候可以看看实际的抓牌流程了。 起初情况是左手没有牌，右手抓了一张6:L=_, _, _, _, _, _，R=6 这时候没有什么犹豫的，直接放到左手第一个位置就好了：L=6, _, _, _, _, _ ，R=_ 然后又抓到一张2，移动左手的牌，拿2和左手有序的牌进行比较，这是左手就1张6，将其向后移动得到：L=_, 6, _, _, _, _ ，R=2 接下来需要把右手的2放到左手腾出的位置即可：L=2, 6, _, _, _, _ ，R=_ 紧接着又抓到一张7，发现放到后面就可以，不用移动元素了：L=2, 6, 7, _, _, _ ，R=_ 然后又抓到一张3，其实找插入位置还有另一种形式，就是放到最后，然后不断的换到合适的位置，用这张3来试一下：L=2, 6, 7, _, _, _ ，R=3 先放到左手最后：L=2, 6, 7, 3, _, _ ，R=_ 然后和前面比3大的换一下位置：L=2, 6, 3, 7, _, _ ，R=_ 再换一次找到了真正插入的位置：L=2, 3, 6, 7, _, _ ，R=_ 后面的8，9两张都不需要交换位置，直接放到最后就得到了最终的结果：L=2, 3, 6, 7, 8, 9 ，R=_ 代码实现1234567891011121314151617181920212223242526272829303132/*功能： 交换两个变量参数： element1--被交换的第一个元素的地址 element2--被交换的第二个元素的地址返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void swap_data(int* element1, int* element2)&#123; int middle_value = *element1; *element1 = *element2; *element2 = middle_value;&#125;/*功能： 插入排序，实现数组元素从小到大排列参数： array--表示待排序的数组，此处会退化成指针 count--数组元素的个数返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void insert_sort(int array[], int count)&#123; for (int pos = 1; pos &lt; count; ++pos) &#123; for (int insert_index = pos; insert_index &gt; 0; --insert_index) &#123; if (array[insert_index] &lt; array[insert_index - 1]) swap_data(&amp;array[insert_index], &amp;array[insert_index - 1]); &#125; &#125;&#125; 代码分析以上代码就是模拟的抓牌过程，新加入的牌放到手牌最后，然后不断的和前面的手牌交换位置，“插入”到有序的手牌序列中，最后得到整体有序，配合前面具体的例子，可以把具体的那些数字带入到这段代码中，头脑中或者在纸上“运行”一下，你就会了解插入排序的原理了。 运行测试快速排序–源码 如果你想运行测试一下，可以复制或者下载源代码，在本机运行测试一下，当然也可以选择在线C++编译器，把源代码复制到网页中运行查看结果，建议不明白的可以在本地环境单步调试一下，这样有助于理解算法思路。]]></content>
      <categories>
        <category>Sort</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>算法</tag>
        <tag>概念</tag>
        <tag>Sort</tag>
        <tag>插入</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql中使用select into语句给变量赋值没有匹配记录时的结果]]></title>
    <url>%2Fblog%2F2018%2F11%2F17%2FMysql%E4%B8%AD%E4%BD%BF%E7%94%A8select-into%E8%AF%AD%E5%8F%A5%E7%BB%99%E5%8F%98%E9%87%8F%E8%B5%8B%E5%80%BC%E6%B2%A1%E6%9C%89%E5%8C%B9%E9%85%8D%E8%AE%B0%E5%BD%95%E6%97%B6%E7%9A%84%E7%BB%93%E6%9E%9C%2F</url>
    <content type="text"><![CDATA[前言对select into语句感兴趣是因为看了项目中的一个存储过程引起的，在程序运行之前看了存储过程的逻辑，本以为没有数据时会报错，结果程序却正常运行，这说明我对select into语句理解的问题，同时也暴露了一个知识盲点，所以写了个小例子测试一下，并把测试的过程记录方便日后查找。 创建测试表格为了更清楚的表明问题，我们创建的表格尽可能的简单，同时为了测试空值的情况，数据列我们不设置默认值，表格命名为’intotest’，创建语句如下： 12345CREATE TABLE `intotest` ( `id` int(4) NOT NULL AUTO_INCREMENT, `number` int(4), PRIMARY KEY (`id`)) ENGINE=InnoDB DEFAULT CHARSET=binary ROW_FORMAT=DYNAMIC; 插入测试数据表格建立完成可以使用可视化工具或者insert语句插入测试数据，插入测试数据后查询结果如下： 123456789mysql&gt; select * from intotest;+----+--------+| id | number |+----+--------+| 1 | 1 || 2 | 2 || 3 | NULL |+----+--------+3 rows in set (0.00 sec) 建立一个存储过程我们建立一个用于测试的存储过程，主要的逻辑就是看看当select into语句找不到匹配记录时，被赋值的变量会怎么样，建立存储过程的代码如下： 1234567CREATE PROCEDURE `select_into_value2`()BEGIN DECLARE _value INT DEFAULT 0; SELECT number FROM intotest WHERE id=1 INTO _value; SELECT _value;END 这个存储过程运行正常，配合刚才我们插入表格的记录可以知道，运行后的结果为1: 123456789mysql&gt; call select_into_value();+--------+| _value |+--------+| 1 |+--------+1 row in set (0.00 sec)Query OK, 0 rows affected (0.00 sec) 测试过程 当查询结果中不存在符合条件的记录时会怎样，修改存储过程定义，然后查看运行结果： 1234567CREATE PROCEDURE `select_into_value2`()BEGIN DECLARE _value INT DEFAULT 0; SELECT number FROM intotest WHERE id=5 INTO _value; SELECT _value;END 123456789mysql&gt; call select_into_value();+--------+| _value |+--------+| 0 |+--------+1 row in set (0.00 sec)Query OK, 0 rows affected (0.00 sec) 结果为0，也就是说当查不到匹配结果时，不会执行select into的赋值效果。 当匹配到查询结果但是查询出来的数值为null会怎样，修改存储过程定义，然后查看运行结果： 1234567CREATE PROCEDURE `select_into_value2`()BEGIN DECLARE _value INT DEFAULT 0; SELECT number FROM intotest WHERE id=3 INTO _value; SELECT _value;END 123456789mysql&gt; call select_into_value();+--------+| _value |+--------+| NULL |+--------+1 row in set (0.00 sec)Query OK, 0 rows affected (0.00 sec) 结果为NULL，也就是说当查到匹配结果时，不管结果时什么都会赋值到指定的变量中（类型不匹配的sql错误除外）。 当连续查询赋值中间出现不匹配会怎样，修改存储过程定义，然后查看运行结果： 12345678CREATE PROCEDURE `select_into_value2`()BEGIN DECLARE _value INT DEFAULT 0; SELECT number FROM intotest WHERE id=2 INTO _value; SELECT number FROM intotest WHERE id=5 INTO _value; SELECT _value;END 123456789mysql&gt; call select_into_value();+--------+| _value |+--------+| 2 |+--------+1 row in set (0.00 sec)Query OK, 0 rows affected (0.00 sec) 想必明白了前两种情况，这第三种也应该明白了，两条语句顺序执行，找到匹配的就赋值，找不到就放弃操作，结果就保留了上一次成功赋值的结果。 总结 关于select into语句赋值的规则就一句话，找到了符合条件的记录就赋值，找不到就算了。 在找到记录的前提下，如果类型不匹配会导致赋值失败并报错，比如查询到字符串赋值给整型变量。]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>查询赋值</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua中关于table对象引用传递的注意事项]]></title>
    <url>%2Fblog%2F2018%2F09%2F18%2FLua%E4%B8%AD%E5%85%B3%E4%BA%8Etable%E5%AF%B9%E8%B1%A1%E5%BC%95%E7%94%A8%E4%BC%A0%E9%80%92%E7%9A%84%E6%B3%A8%E6%84%8F%E4%BA%8B%E9%A1%B9%2F</url>
    <content type="text"><![CDATA[前言最近写了挺长一段时间的Lua，发现Lua这个语言真的是很随意，产生这种感觉的根本原因应该是它把“函数” 作为了“第一类值”，也就是说函数也可以作为变量的“值”，这使得Lua可以随处定义函数，进而改变逻辑的走向，整个流程任你摆布。 虽说把一个函数来回设置方便了许多，但是同样带来了一些不容易发现的问题，如果搞不清定义域和引用关系，常常会导致程序错误，比如最近用Lua写按钮的触发事件时，使用公有函数创建了对应的闭包，一开始感觉table的引用有问题，写了很多中转的代码，最后发现直接就可以使用，浪费了不少时间，最后仔细分析就是闭包最根本的形式，只不过被业务逻辑给干扰了视线，接下来我们一起看看，table和闭包究竟会发生什么关系！ 代码测试 table作为函数参数时的操作 123456789101112131415print("\nexample 1:");data_table = &#123;a = 1, b = 2, 3, 4, 5, 6&#125;;function filter(data_tb) for k,v in pairs(data_tb) do if v % 2 == 0 then data_tb[k] = nil; end endend-- 过滤掉偶数filter(data_table);for k,v in pairs(data_table) do print(k,v)end 1234example 1:1 33 5a 1 以上为去掉table中的偶数的代码，直接操作参数data_tb就可以对传入的data_table进行改变，这样的逻辑一般不会出错，接着我们看下接下来需求，直接将表中数据清空。 1234567891011print("\nexample 2:");data_table = &#123;a = 1, b = 2, 3, 4, 5, 6&#125;;function destroy(data_tb) data_tb = &#123;&#125;;end-- 销毁整个表destroy(data_table);for k,v in pairs(data_table) do print(k,v)end 1234567example 2:1 32 43 54 6b 2a 1 看到这次的输出可能有些人就感到奇怪了，怎么上个例子改变元素可以，而这里直接给变量data_tb赋值，变成空表怎么不行了？这是因为data_tb是对变量data_table的整体引用，所以可以通过data_tb来改变变量data_table内部的值，但是当执行data_tb = {};代码时表示data_tb不再引用data_table，而去引用{}了，也就是data_tb和data_table脱离了关系，这一点可以类比C++代码： 1234567891011121314151617181920#include &lt;iostream&gt;using namespace std;void change_string(char* pStr)&#123; pStr[0] = '5'; pStr[1] = '0'; pStr = "only test\n";&#125;int main()&#123; char szContent[32] = "help"; change_string(szContent); cout &lt;&lt; szContent &lt;&lt; endl; return 0;&#125; 分析一下这段代码的输出结果，如果你能知道结果为50lp，那说明你的C++水平已经超过了入门级别，理解了这段代码有助于清楚的理解前两段Lua代码。 看一个标准闭包实现的计数器 12345678910111213print("\nexample 3:");function counter() local count = 0; return function() count = count + 1; return count; endendfunc = counter();print(func());print(func());print(func()); 1234example 3:123 这段代码的不同之处就在于变量count，这是一个标准的计数器，也是一个标准的闭包，也就是说Lua支持这样的语法，闭包中可以在定义之后一直引用外部的变量，并且在返回函数的整个使用生命周期内都可以引用这个变量，加入外部修改了这个变量，闭包中引用的值也会改变，换句话来说就是闭包这种引用是引用的变量，而不是仅仅保存了一个值。 lua中常见的table引用 12345print("\nexample 4:");local t1 = &#123;i = 1&#125;;local t2 = t1;t1.i = 666;print(t2.i) 12example 4:666 这个例子类似于前面“过滤掉偶数”的代码，首先定义了表t1，然后定义了变量t2引用了变量t1，实际上这里t2不是定义了变量t1本身，而是引用了t1的值，也就是引用的是{i=1}，这里通过t1.i = 666也可以影响到变量t2，其实这个例子看不出引用的究竟是变量t1还是t1的值，可以接着看下面的例子。 12345print("\nexample 5:");local t1 = &#123;i = 1&#125;;local t2 = t1;t1 = &#123;i = 11&#125;;print(t2.i) 12example 5:1 通过这个例子就很清楚了，前面的部分和上个例子一致，但是后面直接给变量t1赋值时并没有改变t2的值，由此可以看出t1和t2已经“分离”了。 table引用和闭包结合的例子 12345678910111213print("\nexample 6:");local tb = &#123;i= 1&#125;;function outer() return function() local t = tb; print(t.i); endendlocal show = outer();tb = &#123;i = 6&#125;;show(); 12example 6:6 这个例子应该会有猜错结果的人，我自己就是在类似的代码中搞糊涂的，一种想法是函数outer定义的时候变量t的值已经定义了，还有一种就是认为在返回函数show的时候变量t的值会定义，但是这两种想法都是错误的，实际上是调用函数show的时候才给t赋值，这时变量t引用的是拥有最新值的tb，所以t.i的值是6，如果你猜对了这个例子的结果，接下来看看下面的代码。 12345678910111213print("\nexample 7:");local tb = &#123;i= 1&#125;;function outer() local t = tb; return function() print(t.i); endendlocal show = outer();tb = &#123;i = 7&#125;;show(); 12example 7:1 如果清楚了上个例子的运行过程，就应该很容易知道这个例子的结果，其中变量t的值是在调用函数outer时确定的，所以后面的赋值tb = {i = 7};对变量t的值没有影响。 总结 lua中操作变量注意值和引用，其实很多语言都有这种区分。 注意闭包可以访问外部变量的特性，程序中使用起来非常方便。 实际使用过程中往往还夹杂着业务逻辑，要学会挖掘本质问题，这样往往可以看到真正的运行逻辑。 测试源码示例传送门：lua中table引用]]></content>
      <categories>
        <category>Lua</category>
      </categories>
      <tags>
        <tag>Lua</tag>
        <tag>C++</tag>
        <tag>table</tag>
        <tag>引用传递</tag>
        <tag>闭包</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[unique_ptr浅析]]></title>
    <url>%2Fblog%2F2018%2F09%2F12%2Funique-ptr%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言unique_ptr这个指针是C++11标准时被引入标准库的，有一种说法称它是boost::scoped_ptr的一个分身，并且它在C++11的时候“转正”了，但是scoped_ptr还被留在boost库中，看来没有转正的机会了，不过unique_ptr与scoped_ptr确实很像，unique_ptr只比scoped_ptr多了一个移动语义，可以通过std::move()函数来转移内部对象的所有权。 其实在我看来，unique_ptr与auto_ptr是最像的，他设计之初就是为了替代auto_ptr，其实两者基本上没有区别，如果把auto_ptr限制一下，使其不能通过拷贝构造和赋值获得所有权，但是可以通过std::move()函数获得所有权，那基本上就变成了unique_pr，这一点通过下面的函数分析也可以看出，两者的函数基本一致。 unique_pr作为一个模板类，可以直接用它来定义一个智能指针的对象，例如std::unique_pr&lt;Test&gt; pa(new Test);，查看unique_pr的代码时发现，它主要有get、release、reset、operator*、operator-&gt;、operator=、swap、operator bool、get_deleter几个函数，相比于auto_ptr常用函数来说，只多了swap、operator bool、get_deleter这三个函数，基本上没什么变化，不过get_deleter这个函数值的详细解释一下，下面通过一些例子来了解一下unique_pr的具体用法。 使用环境 VS2015 + Windows7（应该是C++11标准） 头文件#include &lt;memory&gt; 命名空间using namespace std; 测试过程首先我们先编写一个测试类，用来测试智能指针各个函数的作用，以及可能出现的问题，测试类的代码如下：123456789101112131415161718class Example&#123;public: Example(int param = 0) &#123; number = param; cout &lt;&lt; "Example: " &lt;&lt; number &lt;&lt; endl; &#125; ~Example() &#123; cout &lt;&lt; "~Example: " &lt;&lt; number &lt;&lt; endl; &#125; void test_print() &#123; cout &lt;&lt; "in test print: number = " &lt;&lt; number &lt;&lt; endl; &#125; void set_number(int num) &#123; number = num; &#125;private: int number;&#125;; 测试函数get、release、reset、operator*、operator-&gt;、swap、operator bool这些函数在解释auto_ptr的时候基本都提到过，swap、operator bool作为两个新的函数在解释shared_ptr的时候也演示过，所以此处就不花过多的篇幅举例了，这里写到一个测试函数中，体会一下用法就好： 123456789101112131415161718192021222324252627282930void test1()&#123; unique_ptr&lt;Example&gt; ptr1(new Example(1)); // Example: 1(输出内容) if (ptr1.get()) // 调用get函数，判断内部指针的有效性 &#123; ptr1.get()-&gt;test_print(); // in test print: number = 1(输出内容) ptr1-&gt;set_number(2); // 调用了operator-&gt; (*ptr1).test_print(); // in test print: number = 2(输出内容) &#125; if (ptr1) // 调用operator bool 检测内部对象的有效性 cout &lt;&lt; "ptr1 is valid\n"; // ptr1 is valid(输出内容) Example *p = ptr1.release(); // 调用release函数，取出内部对象 if (!ptr1) // 调用operator bool 检测内部对象的有效性 cout &lt;&lt; "ptr1 is invalid\n"; // ptr1 is invalid(输出内容) ptr1.reset(p); // 调用reset函数，重新设置内部对象 if (ptr1) // 调用operator bool 检测内部对象的有效性 cout &lt;&lt; "ptr1 is valid\n"; // ptr1 is valid(输出内容) ptr1-&gt;test_print(); // in test print: number = 2(输出内容) unique_ptr&lt;Example&gt; ptr2(new Example(20)); // Example: 20(输出内容) ptr1.swap(ptr2); // 调用swap函数，重新设置内部对象 ptr1-&gt;test_print(); // in test print: number = 20(输出内容) ptr2-&gt;test_print(); // in test print: number = 2(输出内容) ptr1.reset(); // ~Example: 20(输出内容)// 重置内部对象被销毁&#125; // ~Example: 2(输出内容) // 出作用域被析构 测试函数operator=operator=这个函数是unique_ptr与auto_ptr最大的区别，因为在auto_ptr中，这个操作函数往往是导致问题出现的罪魁祸首，赋值之后所有权转移，原智能指针对象无效，这样往往会导致程序崩溃，所以在unique_ptr中operator=被禁止使用了，取而代之的是具有移动语义的std::move()函数，如果unique_ptr的对象直接赋值的话，会在编译期间就提示错误： 12345678910void test2()&#123; //unique_ptr&lt;Example&gt; ptr2 = new Example(2);// 编译错误，不支持原始指针到智能指针的隐式转换 unique_ptr&lt;Example&gt; ptr2(new Example(2)); // Example: 2(输出内容) //unique_ptr&lt;Example&gt; ptr3 = ptr2; // 编译错误，...: 尝试引用已删除的函数 //unique_ptr&lt;Example&gt; ptr4(ptr2); // 编译错误，...: 尝试引用已删除的函数 unique_ptr&lt;Example&gt; ptr5(std::move(ptr2)); // 正常编译，使用move移动语义，符合预期效果 ptr5-&gt;test_print(); // in test print: number = 2(输出内容)&#125; // ~Example: 2(输出内容) // 出作用域被析构 测试unique_ptr作为参数和返回值unique_ptr是可以作为参数和返回值的，不过因为operator=不允许使用，所以在作为参数的时候需要使用函数std::move()，但是作为返回值却不需要，这里留个疑问，最后分析一下： 1234567891011121314151617181920212223242526void test3_inner1(unique_ptr&lt;Example&gt; ptr3_1)&#123; ptr3_1-&gt;test_print(); // in test print: number = 3（输出内容）&#125; // ~Example: 3(输出内容) // 出作用域被析构unique_ptr&lt;Example&gt; test3_inner2()&#123; unique_ptr&lt;Example&gt; ptr3_2(new Example(32));// Example:32（输出内容） ptr3_2-&gt;test_print(); // in test print: number = 32（输出内容） return ptr3_2;&#125;void test3()&#123; unique_ptr&lt;Example&gt; ptr3(new Example(3)); // Example:3（输出内容） ptr3-&gt;test_print(); // in test print: number = 3（输出内容） //test3_inner1(ptr3); // 直接作为参数传递会报编译错误,不存在拷贝构造 test3_inner1(std::move(ptr3)); // 但是可以使用std::move的移动语义来实现 if (!ptr3) cout &lt;&lt; "ptr3 is invalid\n"; // ptr1 is valid(输出内容),移动之后ptr3无效 ptr3 = test3_inner2(); // 由于不允许调用构造或者赋值，此处使用了移动语义move ptr3-&gt;test_print(); // in test print: number = 32（输出内容）&#125; // ~Example: 32（输出内容）,出定义域ptr3释放内部对象 测试unique_ptr类型的指针或者引用作为参数这一点没有什么问题，因为不会发生所有权的转移和引用计数的增加，所有的智能指针，包括auto_ptr在内在这种用法的情况下都不会发生问题： 123456789101112131415161718void test4_inner1(unique_ptr&lt;Example&gt;* ptr4_1)&#123; (*ptr4_1)-&gt;test_print(); // in test print: number = 4（输出内容） &#125; // 指针传递没有析构void test4_inner2(unique_ptr&lt;Example&gt;&amp; ptr4_2)&#123; ptr4_2-&gt;test_print(); // in test print: number = 4（输出内容）&#125; // 引用传递没有析构void test4()&#123; unique_ptr&lt;Example&gt; ptr4(new Example(4)); // Example:4（输出内容） ptr4-&gt;test_print(); // in test print: number = 4（输出内容） test4_inner1(&amp;ptr4); // 取地址作为参数 test4_inner2(ptr4); // 引用作为参数&#125; // ~Example: 4（输出内容）,出定义域ptr4释放内部对象 测试unique_ptr作为容器元素前面分析auto_ptr的时候已经说过，auto_ptr在作为容器元素时，是不具有跨平台性质的，因为在有的平台表现很正常，有的环境下直接编译报错，原因就是使用auto_ptr很容易出错，不是说一定会出错，而是可能出问题，所以个别平台直接在编译期报错，防止后续的错误。而unique_ptr作为容器元素时，表现很统一，没有任何问题，但是我感觉这里就有点牵强，后续再说，注意v[6] = unique_ptr&lt;Example&gt;(new Example(56));这一句，是不是感觉很神奇，居然不报编译错误，我感觉和作为返回值时是相同的处理。 12345678910111213141516171819202122232425262728void test5()&#123; vector&lt;unique_ptr&lt;Example&gt;&gt; v(7); for (int i = 0; i &lt; 6; i++) &#123; v[i] = unique_ptr&lt;Example&gt;(new Example(50 + i)); // 依次输出Example:70,...Example:75 &#125; // 直接赋值，迷之成功，不是不能operator=吗,这里实际上调用的还是std::move类似的移动语义？ v[6] = unique_ptr&lt;Example&gt;(new Example(56));// Example:56（输出内容） // 直接将unique_ptr对象push_back v.push_back(unique_ptr&lt;Example&gt;(new Example(57))); // Example:57（输出内容） // 利用移动语义push_back v.push_back(std::move(unique_ptr&lt;Example&gt;(new Example(58)))); // Example:58（输出内容） // 利用make_unique创建unique_ptr,C++14才支持 v.push_back(make_unique&lt;Example&gt;(59)); // Example:59（输出内容） // 循环调用 for (int i = 0; i &lt; 10; i++) &#123; v[i]-&gt;test_print(); &#125;// 依次输出in test print: number = 50....in test print: number = 59&#125;// 依次输出~Example: 50,~Example: 51...~Example: 59 测试函数get_deleter这个函数还是第一次提到，作用就是获得unique_ptr对象的“删除器”，如果不手动指定就会获得默认的删除器，否则就返回你指定的，举个例子一看就明白了，代码如下： 123456789101112131415161718192021222324252627// a custom deleterclass custom_deleter &#123; int flag;public: custom_deleter(int val) : flag(val) &#123;&#125; template &lt;class T&gt; void operator()(T* p) &#123; std::cout &lt;&lt; "use custom deleter, flag=" &lt;&lt; flag ; delete p; &#125;&#125;;void test6()&#123; custom_deleter dlter(666); unique_ptr&lt;Example, custom_deleter&gt; ptr6(new Example(6), dlter); // Example:6（输出内容） ptr6-&gt;test_print(); // in test print: number = 6（输出内容） unique_ptr&lt;Example, custom_deleter&gt; ptr7(new Example(7), ptr6.get_deleter()); // 调用get_deleter // 重置智能指针，内部对象使用自定义删除器删除 ptr6.reset(); // 输出：use custom deleter, flag = 666~Example: 6 ptr7-&gt;test_print(); // in test print: number = 7（输出内容）&#125; // 输出：use custom deleter, flag = 666~Example: 7 现象分析上面的几个例子都很简单，基本上看一遍就知道怎么用了，但是有一点让人很迷惑，就是operator=的使用，最开始已经说过了，unique_ptr中的operator=已经被禁止使用了，但是例子中有两处很有争议，就是unique_ptr作为函数返回值和直接把unique_ptr赋值给vector元素，一开始我也不是太清楚，后来找资料时发现了一些线索，和大家分享一下: 当函数返回一个对象时，理论上会产生临时变量，那必然是会导致新对象的构造和旧对象的析构，这对效率是有影响的。C++编译针对这种情况允许进行优化，哪怕是构造函数有副作用，这叫做返回值优化（RVO)，返回有名字的对象叫做具名返回值优化(NRVO)，就那RVO来说吧，本来是在返回时要生成临时对象的，现在构造返回对象时直接在接受返回对象的空间中构造了。假设不进行返回值优化，那么上面返回unique_ptr会不会有问题呢？也不会。因为标准允许编译器这么做：1.如果支持move构造，那么调用move构造。2.如果不支持move，那就调用copy构造。3.如果不支持copy，那就报错吧。 很显然，unique_ptr本身是支持move构造的，所以unique_ptr对象可以被函数返回，另外我推测将unique_ptr直接赋值给vector元素也利用了相似的操作，这里不太确定，希望了解的小伙伴能告知一下其中的原因。 说到这里，我们对unique_ptr也有了整体的认识，说unique_ptr是auto_ptr的替代品，可是unique_ptr真的优秀了吗？我看未必，它并非不会再犯错，只是犯错的成本大了一些，如果使用std::move()转移了所有权之后，再直接使用原来的智能指针对象，同样会使得程序崩溃。 其实auto_ptr和unique_ptr给我的感觉就是就好比租房子，租房时有些人喜欢看一下房东的房产证，有的人则无所谓，来个人说是房东他就敢跟人签合同，房屋所有权是通过房产证来转移的，使用auto_ptr就好像两个人可以私下交易，把钱和房产证直接交换，房产证的转移很随便，使用unique_ptr就好比在转移房产的时候需要放鞭炮、然后在全世界广播一下，比较麻烦，并且有可能被租房的人看到，但是本质是一样的，都是拿钱来转移房的所有权，关键还是看租房的人，如果租房先看房产证，即使是房产证的转移很随便（也就是使用auto_ptr），也不会出问题，如果租房根本不看房产证，即使房产证交易通知了世界上所有人（即使用unique_ptr），也会租到没证的房子（程序崩溃）。 所以说unique_ptr并没有消除错误，仅仅是提高了犯错的成本。 总结 对比auto_ptr和unique_ptr后发现，unique_ptr几乎只是将auto_ptr的operator=改为std::move()函数。 现在标准库中只剩下了shared_ptr、weak_ptr和unique_ptr三个智能指针，weak_ptr是为了解决shared_ptr的循环引用问题而存在的，有其特定的使用情况，所以只剩下了shared_ptr和unique_ptr的选择，选择的标准就是看是否需要对原对象共享所有权，如果需要使用shared_ptr，如果不需要是独占所有权的使用unique_ptr。 unique_ptr并没有从根本上消除可能错误，仅仅是提高了犯错的成本，并且给出移动所有权的提示，但是在容器vector元素赋值时依然很隐晦，可能造成auto_ptr相同的错误。 测试源码示例传送门：unique_ptr用法]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>智能指针</tag>
        <tag>unique_ptr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[weak_ptr浅析]]></title>
    <url>%2Fblog%2F2018%2F09%2F01%2Fweak-ptr%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言weak_ptr这个指针天生一副“小弟”的模样，也是在C++11的时候引入的标准库，它的出现完全是为了弥补它老大shared_ptr天生有缺陷的问题，其实相比于上一代的智能指针auto_ptr来说，新进老大shared_ptr可以说近乎完美，但是通过引用计数实现的它，虽然解决了指针独占的问题，但也引来了引用成环的问题，这种问题靠它自己是没办法解决的，所以在C++11的时候将shared_ptr和weak_ptr一起引入了标准库，用来解决循环引用的问题。 weak_ptr本身也是一个模板类，但是不能直接用它来定义一个智能指针的对象，只能配合shared_ptr来使用，可以将shared_ptr的对象赋值给weak_ptr，并且这样并不会改变引用计数的值。查看weak_ptr的代码时发现，它主要有lock、swap、reset、expired、operator=、use_count几个函数，与shared_ptr相比多了lock、expired函数，但是却少了get函数，甚至连operator* 和 operator-&gt;都没有，可用的函数数量少的可怜，下面通过一些例子来了解一下weak_ptr的具体用法。 使用环境 VS2015 + Windows7（应该是C++11标准） 头文件#include &lt;memory&gt; 命名空间using namespace std; 测试过程 weak_ptr解决shared_ptr循环引用的问题定义两个类，每个类中又包含一个指向对方类型的智能指针作为成员变量，然后创建对象，设置完成后查看引用计数后退出，看一下测试结果： 123456789101112131415161718192021222324252627282930313233343536373839class CB;class CA&#123;public: CA() &#123; cout &lt;&lt; "CA() called! " &lt;&lt; endl; &#125; ~CA() &#123; cout &lt;&lt; "~CA() called! " &lt;&lt; endl; &#125; void set_ptr(shared_ptr&lt;CB&gt;&amp; ptr) &#123; m_ptr_b = ptr; &#125; void b_use_count() &#123; cout &lt;&lt; "b use count : " &lt;&lt; m_ptr_b.use_count() &lt;&lt; endl; &#125; void show() &#123; cout &lt;&lt; "this is class CA!" &lt;&lt; endl; &#125;private: shared_ptr&lt;CB&gt; m_ptr_b;&#125;;class CB&#123;public: CB() &#123; cout &lt;&lt; "CB() called! " &lt;&lt; endl; &#125; ~CB() &#123; cout &lt;&lt; "~CB() called! " &lt;&lt; endl; &#125; void set_ptr(shared_ptr&lt;CA&gt;&amp; ptr) &#123; m_ptr_a = ptr; &#125; void a_use_count() &#123; cout &lt;&lt; "a use count : " &lt;&lt; m_ptr_a.use_count() &lt;&lt; endl; &#125; void show() &#123; cout &lt;&lt; "this is class CB!" &lt;&lt; endl; &#125;private: shared_ptr&lt;CA&gt; m_ptr_a;&#125;;void test_refer_to_each_other()&#123; shared_ptr&lt;CA&gt; ptr_a(new CA()); shared_ptr&lt;CB&gt; ptr_b(new CB()); cout &lt;&lt; "a use count : " &lt;&lt; ptr_a.use_count() &lt;&lt; endl; cout &lt;&lt; "b use count : " &lt;&lt; ptr_b.use_count() &lt;&lt; endl; ptr_a-&gt;set_ptr(ptr_b); ptr_b-&gt;set_ptr(ptr_a); cout &lt;&lt; "a use count : " &lt;&lt; ptr_a.use_count() &lt;&lt; endl; cout &lt;&lt; "b use count : " &lt;&lt; ptr_b.use_count() &lt;&lt; endl;&#125; 测试结果如下： 123456CA() called!CB() called!a use count : 1b use count : 1a use count : 2b use count : 2 通过结果可以看到，最后CA和CB的对象并没有被析构，其中的引用效果如下图所示，起初定义完ptr_a和ptr_b时，只有①③两条引用，然后调用函数set_ptr后又增加了②④两条引用，当test_refer_to_each_other这个函数返回时，对象ptr_a和ptr_b被销毁，也就是①③两条引用会被断开，但是②④两条引用依然存在，每一个的引用计数都不为0，结果就导致其指向的内部对象无法析构，造成内存泄漏。 解决这种状况的办法就是将两个类中的一个成员变量改为weak_ptr对象，因为weak_ptr不会增加引用计数，使得引用形不成环，最后就可以正常的释放内部的对象，不会造成内存泄漏，比如将CB中的成员变量改为weak_ptr对象，代码如下：1234567891011class CB&#123;public: CB() &#123; cout &lt;&lt; "CB() called! " &lt;&lt; endl; &#125; ~CB() &#123; cout &lt;&lt; "~CB() called! " &lt;&lt; endl; &#125; void set_ptr(shared_ptr&lt;CA&gt;&amp; ptr) &#123; m_ptr_a = ptr; &#125; void a_use_count() &#123; cout &lt;&lt; "a use count : " &lt;&lt; m_ptr_a.use_count() &lt;&lt; endl; &#125; void show() &#123; cout &lt;&lt; "this is class CB!" &lt;&lt; endl; &#125;private: weak_ptr&lt;CA&gt; m_ptr_a;&#125;;测试结果如下：12345678CA() called!CB() called!a use count : 1b use count : 1a use count : 1b use count : 2~CA() called!~CB() called!通过这次结果可以看到，CA和CB的对象都被正常的析构了，引用关系如下图所示，流程与上一例子相似，但是不同的是④这条引用是通过weak_ptr建立的，并不会增加引用计数，也就是说CA的对象只有一个引用计数，而CB的对象只有2个引用计数，当test_refer_to_each_other这个函数返回时，对象ptr_a和ptr_b被销毁，也就是①③两条引用会被断开，此时CA对象的引用计数会减为0，对象被销毁，其内部的m_ptr_b成员变量也会被析构，导致CB对象的引用计数会减为0，对象被销毁，进而解决了引用成环的问题。 测试weak_ptr对引用计数的影响其实weak_ptr本身设计的很简单，就是为了辅助shared_ptr的，它本身不能直接定义指向原始指针的对象，只能指向shared_ptr对象，同时也不能将weak_ptr对象直接赋值给shared_ptr类型的变量，最重要的一点是赋值给它不会增加引用计数： 1234567891011121314151617181920212223void test1()&#123; // 编译错误 // error C2665: “std::weak_ptr&lt;CA&gt;::weak_ptr”: 3 个重载中没有一个可以转换所有参数类型 // weak_ptr&lt;CA&gt; ptr_1(new CA()); shared_ptr&lt;CA&gt; ptr_1(new CA()); cout &lt;&lt; "ptr_1 use count : " &lt;&lt; ptr_1.use_count() &lt;&lt; endl; // 输出：ptr_1 use count : 1 shared_ptr&lt;CA&gt; ptr_2 = ptr_1; cout &lt;&lt; "ptr_1 use count : " &lt;&lt; ptr_1.use_count() &lt;&lt; endl; // 输出：ptr_1 use count : 2 cout &lt;&lt; "ptr_2 use count : " &lt;&lt; ptr_2.use_count() &lt;&lt; endl; // 输出：ptr_1 use count : 2 weak_ptr&lt;CA&gt; wk_ptr = ptr_1; cout &lt;&lt; "ptr_1 use count : " &lt;&lt; ptr_1.use_count() &lt;&lt; endl; // 输出：ptr_1 use count : 2 cout &lt;&lt; "ptr_2 use count : " &lt;&lt; ptr_2.use_count() &lt;&lt; endl; // 输出：ptr_1 use count : 2 // 编译错误 // error C2440 : “初始化”: 无法从“std::weak_ptr&lt;CA&gt;”转换为“std::shared_ptr&lt;CA&gt;” // shared_ptr&lt;CA&gt; ptr_3 = wk_ptr;&#125; 测试weak_ptr常用函数的用法weak_ptr中只有函数lock和expired两个函数比较重要，因为它本身不会增加引用计数，所以它指向的对象可能在它用的时候已经被释放了，所以在用之前需要使用expired函数来检测是否过期，然后使用lock函数来获取其对应的shared_ptr对象，然后进行后续操作： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546void test2()&#123; shared_ptr&lt;CA&gt; ptr_a(new CA()); // 输出：CA() called! shared_ptr&lt;CB&gt; ptr_b(new CB()); // 输出：CB() called! cout &lt;&lt; "ptr_a use count : " &lt;&lt; ptr_a.use_count() &lt;&lt; endl; // 输出：ptr_a use count : 1 cout &lt;&lt; "ptr_b use count : " &lt;&lt; ptr_b.use_count() &lt;&lt; endl; // 输出：ptr_b use count : 1 weak_ptr&lt;CA&gt; wk_ptr_a = ptr_a; weak_ptr&lt;CB&gt; wk_ptr_b = ptr_b; if (!wk_ptr_a.expired()) &#123; wk_ptr_a.lock()-&gt;show(); // 输出：this is class CA! &#125; if (!wk_ptr_b.expired()) &#123; wk_ptr_b.lock()-&gt;show(); // 输出：this is class CB! &#125; // 编译错误 // 编译必须作用于相同的指针类型之间 // wk_ptr_a.swap(wk_ptr_b); // 调用交换函数 wk_ptr_b.reset(); // 将wk_ptr_b的指向清空 if (wk_ptr_b.expired()) &#123; cout &lt;&lt; "wk_ptr_b is invalid" &lt;&lt; endl; // 输出：wk_ptr_b is invalid 说明改指针已经无效 &#125; wk_ptr_b = ptr_b; if (!wk_ptr_b.expired()) &#123; wk_ptr_b.lock()-&gt;show(); // 输出：this is class CB! 调用赋值操作后，wk_ptr_b恢复有效 &#125; // 编译错误 // 编译必须作用于相同的指针类型之间 // wk_ptr_b = wk_ptr_a; // 最后输出的引用计数还是1，说明之前使用weak_ptr类型赋值，不会影响引用计数 cout &lt;&lt; "ptr_a use count : " &lt;&lt; ptr_a.use_count() &lt;&lt; endl; // 输出：ptr_a use count : 1 cout &lt;&lt; "ptr_b use count : " &lt;&lt; ptr_b.use_count() &lt;&lt; endl; // 输出：ptr_b use count : 1&#125; 现象分析引用计数的出现，解决了对象独占的问题，但是也带来了循环引用的困扰，使用weak_ptr可以打破这种循环，当你理不清引用关系的时候，不妨采用文中画图的方式来理一理头绪，或许就会有眼前一亮的感觉。 总结 weak_ptr虽然是一个模板类，但是不能用来直接定义指向原始指针的对象。 weak_ptr接受shared_ptr类型的变量赋值，但是反过来是行不通的，需要使用lock函数。 weak_ptr设计之初就是为了服务于shared_ptr的，所以不增加引用计数就是它的核心功能。 由于不知道什么之后weak_ptr所指向的对象就会被析构掉，所以使用之前请先使用expired函数检测一下。 测试源码示例传送门：weak_ptr用法]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>智能指针</tag>
        <tag>weak_ptr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[shared_ptr浅析]]></title>
    <url>%2Fblog%2F2018%2F08%2F15%2Fshared-ptr%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言这个指针近乎完美，原来出现在boost库中，C++11时引入了标准库，解决了auto_ptr对内部对象独占的机制，转而采用引用计数的方式，每增加一次赋值，则引用计数加1，每析构一个智能指针对象，则引用计数减1，当引用计数为1时销毁智能指针对象的同时，也析构内部对象。这种采用引用计数方式避免了对象所有权转移，所以作为函数返回值，函数参数，容器的元素都不会有问题，但是因为引用计数的加入，相应的会带来对引用计数维护的开销。 与auto_ptr一样，shared_ptr本身也是一个模板类，那么一般情况下直接用它来定义一个智能指针的对象，例如std::shared_ptr&lt;Test&gt; pa(new Test);需要注意的是pa虽然叫智能指针，但是它是一个对象，在它的内部保存着一个原始的对象的指针。查看shared_ptr的代码时发现，它主要有get、swap、reset、unique、use_count、operator bool、operator*、operator-&gt;、operator=几个函数，与auto_ptr相比少了release函数，但是多了swap、unique、use_count、operator bool四个函数,下面通过一些例子来了解一下shared_ptr的具体用法。 使用环境 VS2015 + Windows7（应该是C++11标准） 头文件#include &lt;memory&gt; 命名空间using namespace std; 测试过程首先我们先编写一些测试类，用来测试智能指针各个函数的作用，以及可能出现的问题，测试类的代码如下：1234567891011121314151617181920class Example&#123;public: Example(int param = 0) &#123; number = param; cout &lt;&lt; "Example: " &lt;&lt; number &lt;&lt; endl; &#125; ~Example() &#123; cout &lt;&lt; "~Example: " &lt;&lt; number &lt;&lt; endl; &#125; void test_print() &#123; cout &lt;&lt; "in test print: number = " &lt;&lt; number &lt;&lt; endl; &#125; void set_number(int num) &#123; number = num; &#125; int get_number() &#123; return number; &#125;private: int number;&#125;; 测试函数get reset operator* operator-&gt;这几个函数与auto_ptr智能指针的用法一样，可以参考auto_ptr用法，get函数可以获得智能指针包装的原始指针，可以用来判断被包装对象的有效性，也可以用来访问被包装对象，operator*可以直接对智能指针包装的原始指针解引用，获得被包装的对象，operator-&gt;用来取得原始对象的指针，引用成员时与get函数作用相同，reset函数用于重新设置内部对象，若参数为空，则表示取消对内部对象的引用，此时若引用计数大于1则进行减1操作，否则直接析构内部对象。需要注意的是普通的对象指针是无法隐式转换成shared_ptr的，需要利用构造函数实现，示例代码如下： 123456789101112131415161718void test1()&#123; //error C2440: “初始化”: 无法从“Example *”转换为“std::shared_ptr&lt;Example&gt;” //shared_ptr&lt;Example&gt; ptr1 = new Example(1); shared_ptr&lt;Example&gt; ptr1(new Example(1)); // Example: 1（输出内容） if (ptr1.get()) // 调用函数get，获取原始指针，判断有效性 &#123; cout &lt;&lt; "ptr1 is valid" &lt;&lt; endl; // 原始指针有效 &#125; ptr1-&gt;test_print(); // in test print: number = 1（输出内容），调用operator-&gt; ptr1.reset(); // ~Example: 1（输出内容）,调用函数reset，设置为空，释放原内部对象 ptr1.reset(new Example(2)); // Example: 2（输出内容）,重新申请对象并设置 (*ptr1).test_print(); // in test print: number = 1（输出内容），调用operator*&#125; // ~Example: 1（输出内容）,出定义域，释放内部对象 测试函数operator bool用法operator bool函数其实就是用来判断内部对象是否有效的，若内部对象不为空则返回true，否则返回false，大概的实现就是return this-&gt;get() != nullptr;，测试代码如下： 1234567891011void test2()&#123; shared_ptr&lt;Example&gt; ptr2(new Example(2)); // Example: 2（输出内容） if (ptr2) // 调用operator bool cout &lt;&lt; "ptr2 is valid" &lt;&lt; endl; // ptr2 is valid（输出内容），说明ptr2是有效的 ptr2.reset(); // ~Example: 2（输出内容），设置内部对象为空 if (ptr2) // 调用operator bool cout &lt;&lt; "ptr2 is valid" &lt;&lt; endl; // 没有输出，说明ptr2已经无效&#125; 测试函数swap用法从这个名字就可以看出，这个函数用于交换，那么是用来交换什么的呢？实际上是用来交换内部对象的，看下面的例子一试便知，代码运行过后，通过打印可以发现智能指针对象ptr3和ptr4的内部对象进行了交换： 12345678910111213void test3()&#123; shared_ptr&lt;Example&gt; ptr3(new Example(3)); // Example: 3（输出内容） shared_ptr&lt;Example&gt; ptr4(new Example(4)); // Example: 4（输出内容） ptr3-&gt;test_print(); // in test print: number = 3（输出内容） ptr4-&gt;test_print(); // in test print: number = 4（输出内容） ptr3.swap(ptr4); // 调用函数swap ptr3-&gt;test_print(); // in test print: number = 4（输出内容） ptr4-&gt;test_print(); // in test print: number = 3（输出内容）&#125; // ~Example: 3（输出内容）,出定义域，释放内部对象 // ~Example: 4（输出内容）,出定义域，释放内部对象 测试函数unique use_count operator=用法为什么把这几个函数放到一起来说，因为他们是息息相关的，首先函数operator=是用来处理赋值操作的，而赋值操作就会影响引用计数的变化，也就是赋值操作后，use_count函数查询到的引用计数会发生变化，而当use_count返回引用计数是1时，用来表明是否独自引用内部对象的函数unique也会返回true，换句话说unique函数的实现基本就是return this-&gt;use_count() == 1，测试代码如下： 12345678910111213141516171819202122void test4()&#123; shared_ptr&lt;Example&gt; ptr4(new Example(4)); // Example: 4（输出内容） if (ptr4.unique()) &#123; cout &lt;&lt; "ptr4 is unique" &lt;&lt; endl; // ptr4 is unique（输出内容） cout &lt;&lt; "ptr4 use count : " &lt;&lt; ptr4.use_count() &lt;&lt; endl;// ptr4 use count : 1（输出内容） &#125; shared_ptr&lt;Example&gt; ptr5 = ptr4; if (ptr4) cout &lt;&lt; "ptr4 is valid" &lt;&lt; endl;// ptr4 is valid(输出内容）说明赋值之后两个智能指针对象都有效 if (ptr5) cout &lt;&lt; "ptr5 is valid" &lt;&lt; endl;// ptr5 is valid(输出内容）说明赋值之后两个智能指针对象都有效 if (ptr4.unique()) cout &lt;&lt; "ptr4 is unique" &lt;&lt; endl; // 没有输出，说明ptr4不是唯一管理内部对象的智能指针了 cout &lt;&lt; "ptr4 use count : " &lt;&lt; ptr4.use_count() &lt;&lt; endl; // ptr4 use count : 2（输出内容） cout &lt;&lt; "ptr5 use count : " &lt;&lt; ptr5.use_count() &lt;&lt; endl; // ptr4 use count : 2（输出内容）&#125; // ~Example: 4（输出内容）,出定义域，释放内部对象 测试用同一个对象指针生成两个shared_ptr对象与auto_ptr一样，我测试的结果是崩溃，官方标准网站上说是结果未定义，基本上就是说不靠谱，别这样干，仔细想想也能理解，虽说shared_ptr是通过引用计数方式实现，但也不是无所不能，比如这种情况，两个对象都是通过构造生成的，对内部对象的指针p都是“唯一”引用的，也就是两个对象的内部引用计数都是1，当第一个智能指针对象销毁时，会析构内部对象，当第二个智能指针对象销毁时，同样会析构内部对象，这样就造成了崩溃，测试如下： 12345678910void test5()&#123; Example *p = new Example(5); // Example: 5（输出内容） shared_ptr&lt;Example&gt; ptr5(p); shared_ptr&lt;Example&gt; ptr6(p); cout &lt;&lt; "ptr4 use count : " &lt;&lt; ptr5.use_count() &lt;&lt; endl;// ptr4 use count : 1（输出内容） cout &lt;&lt; "ptr5 use count : " &lt;&lt; ptr6.use_count() &lt;&lt; endl;// ptr5 use count : 1（输出内容）&#125; // ~Example: 3（输出内容）,出定义域，ptr5释放内部对象 // ~Example : -572662307（输出内容）,出定义域，ptr6释放内部对象，程序崩溃 测试shared_ptr作为函数参数和返回值因为shared_ptr内部是引用计数，而不是独占所有权，所以在赋值的时候只改变引用计数，不会发生所有权转移，所以这两种用法基本没有问题，发生在auto_ptr上的崩溃惨剧也不会在这里上演，测试代码如下： 12345678910111213141516171819202122232425void test6_inner1(shared_ptr&lt;Example&gt; ptr6_1)&#123; ptr6_1-&gt;test_print(); // in test print: number = 6（输出内容） cout &lt;&lt; "ptr6_1 use count : " &lt;&lt; ptr6_1.use_count() &lt;&lt; endl;// ptr6 use count : 2（输出内容）&#125;shared_ptr&lt;Example&gt; test6_inner2()&#123; shared_ptr&lt;Example&gt; ptr6_2(new Example(62)); // Example:62（输出内容） ptr6_2-&gt;test_print(); // in test print: number = 62（输出内容） cout &lt;&lt; "ptr6_2 use count : " &lt;&lt; ptr6_2.use_count() &lt;&lt; endl;// ptr6_2 use count : 1（输出内容） return ptr6_2;&#125;void test6()&#123; shared_ptr&lt;Example&gt; ptr6(new Example(6)); // Example:6（输出内容） ptr6-&gt;test_print(); // in test print: number = 6（输出内容） cout &lt;&lt; "ptr6 use count : " &lt;&lt; ptr6.use_count() &lt;&lt; endl;// ptr6 use count : 1（输出内容） test6_inner1(ptr6); cout &lt;&lt; "ptr6 use count : " &lt;&lt; ptr6.use_count() &lt;&lt; endl;// ptr6 use count : 1（输出内容） ptr6 = test6_inner2(); // ~Example: 6（输出内容）,ptr6接管新的对象，原来对象被析构 cout &lt;&lt; "ptr6 use count : " &lt;&lt; ptr6.use_count() &lt;&lt; endl;// ptr6 use count : 1（输出内容）&#125; // ~Example: 62（输出内容）,出定义域，ptr6释放内部对象 测试shared_ptr作为容器元素在这里也不存在auto_ptr作为容器元素时的争议，同样是引用计数的机制发挥了作用，使得他满足的容器的要求——其元素对象的拷贝与原对象相同或者等价，所以这里也不会出现问题，同时那些针对于容器的算法在shared_ptr上也可以大显身手，比如下面这个排序的例子： 12345678910111213141516171819202122232425262728// 一般会写成只读引用类型，这里为了说明问题才这样定义bool comp(shared_ptr&lt;Example&gt; a, shared_ptr&lt;Example&gt; b)&#123; return a-&gt;get_number() &gt; b-&gt;get_number();&#125;void test7()&#123; vector&lt;shared_ptr&lt;Example&gt;&gt; v(10); for (int i = 0; i &lt; 10; i++) &#123; v[i] = shared_ptr&lt;Example&gt;(new Example(70+i)); &#125;// 依次输出Example:70,Example:71,Example:72...Example:79 // 循环调用 for (int i = 0; i &lt; 10; i++) &#123; v[i]-&gt;test_print(); &#125;// 依次输出in test print: number = 70....in test print: number = 79 sort(v.begin(), v.end(), comp); // 这可以正常运行，但是使用auto_ptr会死的很难看 // 循环调用 for (int i = 0; i &lt; 10; i++) &#123; v[i]-&gt;test_print(); &#125;// 依次输出in test print: number = 79....in test print: number = 70&#125;// 依次输出~Example: 79,~Example: 78...~Example: 70 测试使用指针或者引用作为参数虽然shared_ptr作为参数、返回值、容器元素貌似没有丝毫问题了，但是有时还是使用shared_ptr对象的指针或者引用比较好，因为这样可以减少对对象的拷贝，毕竟对象的拷贝是需要消耗时间的，用更好的方式为什么不用呢，参考下面的用法，没有任何问题： 12345678910111213141516171819202122void test8_inner1(shared_ptr&lt;Example&gt;* ptr8_1)&#123; (*ptr8_1)-&gt;test_print(); // in test print: number = 8（输出内容） cout &lt;&lt; "ptr8_1 use count : " &lt;&lt; (*ptr8_1).use_count() &lt;&lt; endl;// ptr8_1 use count : 1（输出内容）&#125;void test8_inner2(shared_ptr&lt;Example&gt;&amp; ptr8_2)&#123; ptr8_2-&gt;test_print(); // in test print: number = 8（输出内容） cout &lt;&lt; "ptr8_2 use count : " &lt;&lt; ptr8_2.use_count() &lt;&lt; endl;// ptr8_2 use count : 1（输出内容）&#125;void test8()&#123; shared_ptr&lt;Example&gt; ptr8(new Example(8)); // Example:8（输出内容） ptr8-&gt;test_print(); // in test print: number = 8（输出内容） cout &lt;&lt; "ptr8 use count : " &lt;&lt; ptr8.use_count() &lt;&lt; endl;// ptr8 use count : 1（输出内容) test8_inner1(&amp;ptr8); cout &lt;&lt; "ptr8 use count : " &lt;&lt; ptr8.use_count() &lt;&lt; endl;// ptr8 use count : 1（输出内容) test8_inner2(ptr8); cout &lt;&lt; "ptr8 use count : " &lt;&lt; ptr8.use_count() &lt;&lt; endl;// ptr8 use count : 1（输出内容)&#125; // ~Example: 8（输出内容）,出定义域，ptr8释放内部对像 现象分析shared_ptr与auto_ptr相比要优秀的多，这得益于其内部引用计数的实现，正是这种非独占所有权的方式，使其摆脱了auto_ptr的种种限制，并将其踢出了C++标准（auto_ptr在C++17中被移除），但是shared_ptr也不是完美无缺的，引用计数不能解决所的问题，并且可能会带来一些问题，比如“循环引用问题”，这个得靠后面我们即将说到的weak_ptr来解决，所以说没有什么结构是完美的，选择合适的就是最好的，综合前面多个测试的例子，可以得到一些经验。 总结 shared_ptr作为目前最优秀的指针，取代auto_ptr是必然的，所以能使用shared_ptr的地方还是尽量使用shared_ptr。 不要使用同一个原始对象的指针生成多个shared_ptr对象，这样使用会导致未定义的行为，比如test5这个函数就导致了崩溃和错误的输出。 shared_ptr不是万能的，如果不加思考的把原始指针都替换成shared_ptr，虽然大部分能防止内存泄露，但是还会造成其他的问题，比如循环引用，这种情况需要使用weak_ptr来解决问题，如果不解决就会造成另一种形式的内存泄漏。 不要使用get返回的指针来初始化一个shared_ptr对象，这种的做法的本质与第2点一样，会造成未定义的行为。 尽量不要保存get函数返回的指针，因为你不知道什么时候这个指针对应的对象就被析构掉了，所以请“随用随取”。 测试源码示例传送门：shared_ptr用法]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>智能指针</tag>
        <tag>shared_ptr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[auto_ptr浅析]]></title>
    <url>%2Fblog%2F2018%2F08%2F08%2Fauto-ptr%E6%B5%85%E6%9E%90%2F</url>
    <content type="text"><![CDATA[前言之前简单的列举了一下各种智能指针的特点，其中提到了这个历经沧桑的指针，C++98中引入，C++11中弃用，C++17中被移除，弃用的原因主要是使用不当容易造成内存崩溃，不能够作为函数的返回值和函数的参数，也不能在容器中保存auto_ptr。其实说这个指针“不能够作为函数的返回值和函数的参数，也不能在容器中保存”，这个结论过于武断了，经过一系列的测试后发现，原来真正的结论不应该说“不能”，准确来说是“不建议”。 auto_ptr本身是一个模板类，那么一般情况下直接用它来定义一个智能指针的对象，例如std::auto_ptr&lt;Test&gt; pa(new Test);需要注意的是pa虽然叫智能指针，但是它是一个对象，在它的内部保存着一个原始的对象的指针，其原理就是 RAII(Resource Acquisition Is Initialization) ，在智能指针构造的时候获取资源，在析构的时候释放资源，并进行相关指针操作的重载，使其使用起来就像普通的指针一样方便。 查看auto_ptr的代码时发现，它主要有get、release、reset、operator*、operator-&gt;、operator=几个函数，下面通过一些例子来了解一下auto_ptr的具体用法。 使用环境 VS2015 + Windows7（应该是C++11标准） 头文件#include &lt;memory&gt; 命名空间using namespace std; 测试过程首先我们先编写一些测试类，用来测试智能指针各个函数的作用，以及可能出现的问题，测试类的代码如下：123456789101112131415161718class Example&#123;public: Example(int param = 0) &#123; number = param; cout &lt;&lt; "Example: " &lt;&lt; number &lt;&lt; endl; &#125; ~Example() &#123; cout &lt;&lt; "~Example: " &lt;&lt; number &lt;&lt; endl; &#125; void test_print() &#123; cout &lt;&lt; "in test print: number = " &lt;&lt; number &lt;&lt; endl; &#125; void set_number(int num) &#123; number = num; &#125;private: int number;&#125;; 测试函数get、operator*、operator-&gt;get函数可以获得智能指针包装的原始指针，可以用来判断被包装对象的有效性，也可以用来访问被包装对象，operator*可以直接对智能指针包装的原始指针解引用，获得被包装的对象，operator-&gt;用来取得原始对象的指针，引用成员时与get函数作用相同，示例代码如下： 1234567891011void test1()&#123; auto_ptr&lt;Example&gt; ptr1(new Example(6)); // Example: 6(输出内容) if (ptr1.get()) // 判断内部指针的有效性 &#123; // 以下为访问成员的3种方法 ptr1.get()-&gt;test_print(); // in test print: number = 6(输出内容) ptr1-&gt;set_number(8); (*ptr1).test_print(); // in test print: number = 8(输出内容) &#125;&#125; // ~Example: 8(输出内容) // 出作用域被析构 测试函数release错误用法release函数是很容易让人误解的函数，一般看到release会想起释放、回收的含义，函数的作用通常就是回收掉申请的资源，但是这里就要注意了，auto_ptr对象的release函数只有释放的意思，指的是释放指针的所有权，说简单点就是auto_ptr的对象与原始的指针脱离关系，但是并不回收原始指针申请的内存，如果不主动释放就会造成内存泄露，就像下面这样： 12345678910111213void test2()&#123; //auto_ptr&lt;Example&gt; ptr2 = new Example(6); // 编译错误，不支持不同指针到智能指针的隐式转换 auto_ptr&lt;Example&gt; ptr2(new Example(6)); // Example: 6(输出内容) if (ptr2.get()) // 判断内部指针的有效性 &#123; ptr2.release(); // 调用release之后会释放内存所有权，但是不会析构，造成内存泄漏 if (!ptr2.get()) cout &lt;&lt; "ptr2 is invalid" &lt;&lt; endl; // ptr2 is invalid(输出内容) ptr2.release(); // 多写一遍没有任何作用 &#125;&#125; 测试函数release正确用法知道了relsease函数的错误用法，那么正确用法也就应该清楚了，需要自己调用delete，话说如果自己调用了delete那还用智能指针干什么，下面展示正常的用法： 123456789101112void test3()&#123; auto_ptr&lt;Example&gt; ptr3(new Example(3)); // Example: 3(输出内容) if (ptr3.get()) // 判断内部指针的有效性 &#123; Example *p = ptr3.release(); // release函数调用之后会释放内存的所有权，并且返回原始指针 if (!ptr3.get()) cout &lt;&lt; "ptr3 is invalid" &lt;&lt; endl; // ptr3 is invalid(输出内容) delete p; // ~Example: 3(输出内容) // 主动析构Example对象 &#125;&#125; 测试函数reset用法reset函数取其字面含义，就是重新设置的意思，也就是给一个指着对象设置一个新的内存对象让其管理，如果设置之前智能指针的已经管理了一个对象，那么在设置之后原来的对象会被析构掉，具体看测试结果： 12345678void test4()&#123; auto_ptr&lt;Example&gt; ptr4(new Example(4)); // Example: 4(输出内容) cout &lt;&lt; "after declare ptr4" &lt;&lt; endl; // after declare ptr4 ptr4.reset(new Example(5)); // Example: 5 // ~Example: 4 cout &lt;&lt; "after function reset" &lt;&lt; endl; // after function reset&#125; 测试函数operator=用法operator=也就是赋值运算符，是智能指针auto_ptr最具争议的一个方法，或者说一种特性，它的种种限制完全来自于这个赋值操作，作为面向的对象中的一部分，如果把一个对象赋值给另一个对象，那么两个对象就是完全一样的，但是这一点却在auto_ptr上打破了，智能指针auto_ptr的赋值，只是移交了所有权，将内部对象的控制所有权从等号的右侧转移到左侧，等号右侧的智能指针丧失对原有内部对象的控制，如果右侧的对象不检测内部对象的有效性，就会造成程序崩溃，测试如下： 1234567891011121314void test5()&#123; auto_ptr&lt;Example&gt; ptr5(new Example(5)); // Example: 5(输出内容) auto_ptr&lt;Example&gt; ptr6 = ptr5; // 没有输出 if (ptr5.get()) cout &lt;&lt; "ptr5 is valid" &lt;&lt; endl; // 没有输出，说明ptr5已经无效，如果再调用就会崩溃 if (ptr6.get()) cout &lt;&lt; "ptr6 is valid" &lt;&lt; endl; // ptr6 is valid(输出内容) ptr6-&gt;test_print(); // in test print: number = 5(输出内容) //ptr5-&gt;test_print(); // 直接崩溃 &#125; 测试auto_ptr类型返回一些文章中指出，auto_ptr不能作为函数的返回值，但是在我的测试环境下，可以正常执行，并且结果正确，但是还是不建议这样做，原因就是operator=，后面统一总结，先看下这个正常的例子： 1234567891011auto_ptr&lt;Example&gt; test6_inner()&#123; auto_ptr&lt;Example&gt; ptr6(new Example(6)); // Example: 6(输出内容) return ptr6;&#125;void test6()&#123; auto_ptr&lt;Example&gt; ptr6 = test6_inner(); // 测试auto_ptr类型返回值 ptr6-&gt;test_print(); // in test print: number = 6(输出内容)&#125; // ~Example: 6(输出内容) // 主动析构Example对 测试auto_ptr作为参数这是常常容易出错的情况，原因还是operator=的操作引起的，因为auto_ptr的赋值会转移控制权，所以你把auto_ptr的对象作为参数传递给一个函数的时候，后面再使用这个对象就会直接崩溃： 1234567891011void test7_inner(auto_ptr&lt;Example&gt; ptr7)&#123; ptr7-&gt;test_print(); // in test print: number = 6(输出内容)&#125; // ~Example: 7(输出内容) // 主动析构Example对象void test7()&#123; auto_ptr&lt;Example&gt; ptr7(new Example(7)); // Example: 7(输出内容) test7_inner(ptr7); // 传递参数 //ptr7-&gt;test_print(); // 直接崩溃&#125; 两个auto_ptr管理一个指针这种错误稍微出现的明显一点，因为智能指针的对象在析构时会回收内部对象的内存，如果两个智能指针同时管理一个内部对象，那么两个auto_ptr对象析构时都会试图释放内部对象的资源，造成崩溃问题： 1234567void test8()&#123; Example *p = new Example(8); // Example: 7(输出内容) auto_ptr&lt;Example&gt; ptr8(p); auto_ptr&lt;Example&gt; ptr9(p);&#125; //~Example: 8(输出内容) // 主动析构Example对象 //~Example: -572662307(输出内容) // 第二次析构崩溃 测试auto_ptr作为容器元素这是一个被广泛讨论的问题，可能你已经猜到了，一般说auto_ptr不能作为容器的元素也是因为operator=操作，但是我在Windows平台上成功运行了下面的代码，并且输出了正常的对象构造信息和析构信息，但是在Linux平台根本就编译不过去，出现大段的编译错误，其中重要的一句就是.../bits/stl_construct.h:73: 错误：对‘std::auto_ptr&lt;Example&gt;::auto_ptr(const std::auto_ptr&lt;Example&gt;&amp;)’的调用没有匹配的函数，其实可以说是operator=的锅，也可以说是拷贝构造函数的锅，但最根本的问题还是赋值时控制权转移导致的，测试代码如下： 123456789void test9()&#123; vector&lt;auto_ptr&lt;Example&gt;&gt; v(10); int i = 0; for (; i &lt; 10; i++) &#123; v[i] = auto_ptr&lt;Example&gt;(new Example(i));// windows下正常构造、析构，linux下无法通过编译 &#125;&#125; 测试auto_ptr的引用作为参数传递这个例子比较正常，就是将auto_ptr的对象进行引用传递，这种方式不会造成控制权转移，所以不会出现问题： 1234567891011void test10_inner(auto_ptr&lt;Example&gt;&amp; ptr10)&#123; ptr10-&gt;test_print(); // in test print: number = 6(输出内容)&#125; // 这里没有析构void test10()&#123; auto_ptr&lt;Example&gt; ptr10(new Example(10)); // Example: 10(输出内容) test10_inner(ptr10); // 传递引用参数 ptr10-&gt;test_print(); // in test print: number = 10(输出内容)&#125; //~Example: 10(输出内容) // 主动析构Example对象 测试auto_ptr的指针作为参数传递这个例子本质上同上个例子一样，就是将auto_ptr的对象的地址传递，这种指针的方式不会造成控制权转移，所以也不会出现问题： 1234567891011void test11_inner(auto_ptr&lt;Example&gt;* ptr11)&#123; (*ptr11)-&gt;test_print(); // in test print: number = 11(输出内容)&#125; // 这里没有析构void test11()&#123; auto_ptr&lt;Example&gt; ptr11(new Example(11)); // Example:11(输出内容) test11_inner(&amp;ptr11); // 传递地址参数 ptr11-&gt;test_print(); // in test print: number = 11(输出内容)&#125; // ~Example: 11(输出内容) // 主动析构Example对象 现象分析上述这些例子比较简单，主要是说明auto_ptr的用法，其中比较有争议的也就是6,7,9三个例子，也就是我们前文所说的“不建议”将auto_ptr作为函数返回值、函数参数、容器内的元素，这三个例子中只有作为函数参数的那个例子崩溃了，但是如果我们调用完函数test7_inner之后，不在使用智能指针ptr7也就不会崩溃了，那么是不是说只要我们注意到可能发生的问题，就可以使用auto_ptr在这些情况呢，目前来看是这样的。 但是为什么在Windows上成功运行的test9在Linux上却编译不过呢？简单点说就是为了怕你犯错，而对你采取管制措施，实际上你可以把auto_ptr作为容器的元素，但是因为这样太容易出错了，所以压根就不允许你这样做。 那么Linux是怎样在编译时期就提示auto_ptr这种错误，而Windows又是怎样绕过这种错误的呢？其实从应用的方便性和安全角度出发，容器应该要求其元素对象的拷贝与原对象相同或者等价，但是很明显auto_ptr做不到这一点，因为它的赋值是实质上是控制权的转移，而不是等价的复制，所以拷贝之后原对象必然被改变，linux版本的auto_ptr就是利用了这一点，使其违反C++的静态类型安全规则，这个版本的auto_ptr只实现构造函数auto_ptr(auto_ptr&amp; other)和赋值函数auto_ptr&amp; operator=(auto_ptr&amp; other)，因为参数都是非const，在构造或者赋值的时候原对象可能会发生变化，所以与容器对元素要求的不符合，这样在编译阶段就会检查出错误，也就是我们上面test9函数中提示的错误.../bits/stl_construct.h:73: 错误：对‘std::auto_ptr&lt;Example&gt;::auto_ptr(const std::auto_ptr&lt;Example&gt;&amp;)’的调用没有匹配的函数，这样就避免了把auto_ptr作为容器的元素。 关于Windows平台上正常运行test9函数的疑惑，实际上可以从两个方面来考虑，一种方式就是放宽容器对元素的要求，也就是说允许容器中的元素赋值之后，原对象被改变；另一种方式就是auto_ptr只提供构造函数auto_ptr(const auto_ptr&amp; other)和赋值函数auto_ptr&amp; operator=(const auto_ptr&amp; other)，这样就就可以通过容器的检测了，但是还有一个问题需要解决，那就是auto_ptr肯定要改变原对象，const类型就没法改变了，其实还有一种神奇的操作叫强制类型转换，使用const_cast就可以改变const对象，这样就达到了使用auto_ptr作为容器元素的目的，具体细节参考: auto_ptr到底能不能作为容器的元素? 前面提到把auto_ptr作为容器元素时很容易出错，这是为什么各个版本的auto_ptr实现的差异会这么大的原因，出错的根本原因就是auto_ptr构造和赋值时控制权的转移，试想一下，对一个容器进行排序，然后提供一个排序函数，然后排序时把容器中的元素传入比较函数，结果容器中元素的内部对象全都被清空了，这显然不是我们想要的，但是如果你不使用类似操作，那么把auto_ptr作为容器元素也没有什么不可。 总结 既然auto_ptr在C++17中已经被移除，那么我们也应该顺应潮流，尽量不使用auto_ptr了。 虽然不建议使用auto_ptr了，但是他的用法和注意事项我们还是应该了解，毕竟存在了这么多年，还有很多老代码中在用着。 由于各平台差异很大，目前auto_ptr作为容器元素不可移植，无论你使用的STL平台是否允许auto_ptr容器，你都不应该这样做。 通过分析发现auto_ptr能不能作为容器的元素并非绝对的，不仅与STL的实现有关，而且与STL容器的需求和安全性以及容器的语义有关。]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>智能指针</tag>
        <tag>auto_ptr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[智能指针分类及简单特性]]></title>
    <url>%2Fblog%2F2018%2F08%2F06%2F%E6%99%BA%E8%83%BD%E6%8C%87%E9%92%88%E5%88%86%E7%B1%BB%E5%8F%8A%E7%AE%80%E5%8D%95%E7%89%B9%E6%80%A7%2F</url>
    <content type="text"><![CDATA[前言智能指针的种类繁多，我听说过的就有这些：auto_ptr、shared_ptr、weak_ptr、unique_ptr、scoped_ptr、scoped_array、shared_array、intrusive_ptr，这些智能指针看起来种类繁多，但实际上常用的就只有两三种，他们是shared_ptr、weak_ptr和unique_ptr，先简单了解一下这几个指针，后续再列出具体的例子和选择标准。 分类及特性 auto_ptr 这个指针历经沧桑，C++98中引入，C++11中弃用，C++17中被移除，弃用的原因主要是使用不当容易造成内存崩溃，不能够作为函数的返回值和函数的参数，也不能在容器中保存auto_ptr。 shared_ptr 据说是最好用的智能指针，使用引用计数实现，每使用它一次，内部的引用计数加1，每析构一次，内部的引用计数减1，减为0时，自动删除所指向的堆内存。shared_ptr内部的引用计数是线程安全的，但是对象的读取需要加锁。 weak_ptr 没有什么存在感，基本只在解除 shared_ptr循环引用时使用，weak_ptr没有共享资源，它的构造不会引起指针引用计数的增加，使用weak_ptr的成员函数use_count()可以观测资源的引用计数，使用成员函数lock()从被观测的shared_ptr获得一个可用的shared_ptr对象。 unique_ptr 一种比auto_ptr更加优秀的指针，可以唯一的拥有一个对象，auto_ptr通过等号赋值改变所有权后，再次引用原对象会造成内存崩溃，但是unique_ptr可以用过std::move改变所有权，并且引用原对象会在编译时期就指出错误，同时在容器算法中也可以使用，另有一种说法是说unique_ptr是scoped_ptr在标准库中的一个分身。 scoped_ptr 存在于boost库而非标准库中，要把资源限制在作用域里的，并且永远不能被复制，是一种轻量级的智能指针，和const auto_ptr很像，但是可以被reset，并可以更加清楚地表明意图。 scoped_array 跟scoped_ptr一样，也是独享所有权的，用于管理动态数组，不支持复制，并且初始化的时候需要使用动态数组，没有重载operator*，需要使用get()函数。 shared_array 跟 shared_ptr 一样，内部使用了引用计数，可以复制，通过参数来传递等，需要使用动态数组来初始化。 intrusive_ptr 这是一种侵入式的智能指针，内部不含有引用计数，要求被存储的对象自己实现引用计数功能，不然编译不过，还要提供intrusive_ptr_add_ref和intrusive_ptr_release函数接口供intrusive_ptr调用。 总结 智能指针的种类很多，但是只要掌握shared_ptr、weak_ptr、unique_ptr这三种指针的用法，就可以处理绝大多数问题。 智能指针的选择就根据特性来选，但是auto_ptr尽量不要用了，虽然历史悠久，但是毕竟由于各种诟病被抛弃了。 以上只给出了分类和简单特性，后续有时间会依次给出示例，指出用法和需要注意的点。]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>智能指针</tag>
        <tag>shared_ptr</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[简述TCP三次握手和四次挥手流程]]></title>
    <url>%2Fblog%2F2018%2F07%2F11%2F%E7%AE%80%E8%BF%B0TCP%E4%B8%89%E6%AC%A1%E6%8F%A1%E6%89%8B%E5%92%8C%E5%9B%9B%E6%AC%A1%E6%8C%A5%E6%89%8B%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[前言关于TCP的连接过程，很多从事程序开发的小伙伴应该都听过三次握手，可这三次握手的细节还是有很多人不太清楚的，特别是有些参数记不清楚，我也经常弄错，所以我根据自己的理解画了两张图，将TCP连接和断开的流程简单记录一下，以方便后续查找复习之用。 三次握手 初始状态：客户端A和服务器B均处于CLOSED状态，然后服务器B创建socket，调用监听接口使得服务器处于LISTEN状态，等待客户端连接。（后续内容用A，B简称代替） A首先向B发起连接，这时TCP头部中的SYN标识位值为1，然后选定一个初始序号seq=x（一般是随机的），消息发送后，A进入SYN_SENT状态，SYN=1的报文段不能携带数据，但要消耗一个序号。 B收到A的连接请求后，同意建立连接，向A发送确认数据，这时TCP头部中的SYN和ACK标识位值均为1，确认序号为ack=x+1，然后选定自己的初始序号seq=y（一般是随机的），确认消息发送后，B进入SYN_RCVD状态，与连接消息一样，这条消息也不能携带数据，同时消耗一个序号。 A收到B的确认消息后，需要给B回复确认数据，这时TCP头部中的ACK标识位值为1，确认序号是ack=y+1，自己的序号在连接请求的序号上加1，也就是seq=x+1，此时A进入ESTABLISHED状态，当B收到A的确认回复后，B也进入ESTABLISHED状态，至此TCP成功建立连接，A和B之间就可以通过这个连接互相发送数据了。 四次挥手 初始状态：客户端A和服务器B之间已经建立了TCP连接，并且数据发送完成，打算断开连接，此时客户端A和服务器B是等价的，双方都可以发送断开请求，下面以客户端A主动发起断开请求为例。（后续内容用A，B简称代替） A首先向B发送断开连接消息，这时TCP头部中的FIN标识位值为1，序号是seq=m，m为A前面正常发送数据最后一个字节序号加1得到的，消息发送后A进入FNI_WAIT_1状态，FIN=1的报文段不能携带数据，但要消耗一个序号。 B收到A的断开连接请求需要发出确认消息，这时TCP头部中的ACK标识位值为1，确认号为ack=m+1，而自己的序号为seq=n,n为B前面正常发送数据最后一个字节序号加1得到的，然后B进入CLOSE_WAIT状态，此时就关闭了A到B的连接，A无法再给B发数据，但是B仍然可以给A发数据（此处存疑），同时B端通知上方应用层，处理完成后被动关闭连接。然后A收到B的确认信息后，就进入了FIN_WAIT_2状态。 B端应用层处理完数据后，通知关闭连接，B向A发送关闭连接的消息，这时TCP头部中的FIN和ACK标识位值均为1，确认号ack=m+1，自己的序号为seq=k，（B发出确认消息后有发送了一段数据，此处存疑），消息发送后B进入LACK_ACK状态。 A收到B的断开连接的消息后，需要发送确认消息，这是这时TCP头部中的ACK标识位值为1，确认号ack=k+1，序号为m+1（因为A向B发送断开连接的消息时消耗了一个消息号），然后A进入TIME_WAIT状态，若等待时间经过2MSL后，没有收到B的重传请求，则表明B收到了自己的确认，A进入CLOSED状态，B收到A的确认消息后则直接进入CLOSED状态。至此TCP成功断开连接。 总结 关于三次握手，参考了很多资料说服务器是被动打开连接，对此有些不解，希望知道的朋友给出提示和建议。 关于四次挥手，在我的叙述中有两处存疑，就是B收到的A的主动断开请求后，进入CLOSE_WAIT状态，是否还能发送数据到A，参考了一些资料说A不能发数据给B，但是B能发数据给A，并且A也可以接收，但是无论我在Windows环境测试还是Linux环境下测试这种状态A都无法收到B的数据，不知道我是不是理解错了，希望明白原理的小伙伴能解答一下。 在四次挥手的最后阶段，有一个等待时间2MSL，这个不是一个时间单位，而是一个表明时间段的名词，这段等待时间就是为了在B没收到确认消息时，接收B的重传请求的，如果不等待这一段时间直接进入CLOSED状态，那么B未收到A的确认消息就会发送重传请求，而此时A已经关闭，就不会再给B重传了，其中MSL的是Maximum Segment Lifetime英文的缩写，可简单译为“报文最大生存时间”，也就是说如果B没有收到确认信息，那么在2MSL这段时间内很大概率就会发送重传请求，并且被A收到，RFC 793中规定MSL为2分钟，实际应用中常用的是30秒，1分钟和2分钟等。 在连接和断开的过程都有提到ACK和ack，这一点要注意区分，大写的ACK代表TCP头部中6个标识位之一，是表明这是个确认报文，而小写的ack拜师确认序号，表明对方发来的数据到ack这个序号前的都已经收到了。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Network</tag>
        <tag>Socket</tag>
        <tag>网络连接</tag>
        <tag>网络断开</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[结构体sockaddr、sockaddr_in、sockaddr_in6之间的区别和联系]]></title>
    <url>%2Fblog%2F2018%2F07%2F10%2F%E7%BB%93%E6%9E%84%E4%BD%93sockaddr%E3%80%81sockaddr-in%E3%80%81sockaddr-in6%E4%B9%8B%E9%97%B4%E7%9A%84%E5%8C%BA%E5%88%AB%E5%92%8C%E8%81%94%E7%B3%BB%2F</url>
    <content type="text"><![CDATA[前言最近在学习网络相关的知识，虽然之前代码写了不少，但是长时间不写难免会忘记，简单地复习了一下IO多路复用的方式，对比了解了一下epoll模式和select模式的异同，不过写代码的时候发现，这个socket连接中有几个结构还是挺让人头大的，用着用着突然就强转成其他的类型了，加上年前改了半天IPv6的连接，这几个结构体更加混乱，所以今天角色放到一起，从源码的角度看一下sockaddr、sockaddr_in、sockaddr_in6这三个结构体之间的联系，以及为什么有些情况可以直接强转。 代码分析 看一下这三个结构的定义，先说明一下版本，操作系统为CentOS，头文件版本应该挺古老了，在’/usr/include/netinet/in.h’ 中发现版权信息：Copyright (C) 1991, 1992, 1994-2001, 2004, 2006, 2007, 2008, 2009, 2010，看着很古老，但之后的版本应该没有改动很大吧，反正不太清楚，我们就分析当前这一个版本吧。 1234567891011121314151617181920212223242526272829303132333435/* /usr/include/bits/socket.h *//* Structure describing a generic socket address. */struct sockaddr&#123; __SOCKADDR_COMMON (sa_); /* Common data: address family and length. */ char sa_data[14]; /* Address data. */&#125;;/* /usr/include/netinet/in.h *//* Structure describing an Internet socket address. */struct sockaddr_in&#123; __SOCKADDR_COMMON (sin_); in_port_t sin_port; /* Port number. */ struct in_addr sin_addr; /* Internet address. */ /* Pad to size of `struct sockaddr'. */ unsigned char sin_zero[sizeof (struct sockaddr) - __SOCKADDR_COMMON_SIZE - sizeof (in_port_t) - sizeof (struct in_addr)];&#125;;/* /usr/include/netinet/in.h */#ifndef __USE_KERNEL_IPV6_DEFS/* Ditto, for IPv6. */struct sockaddr_in6&#123; __SOCKADDR_COMMON (sin6_); in_port_t sin6_port; /* Transport layer port # */ uint32_t sin6_flowinfo; /* IPv6 flow information */ struct in6_addr sin6_addr; /* IPv6 address */ uint32_t sin6_scope_id; /* IPv6 scope-id */&#125;;#endif /* !__USE_KERNEL_IPV6_DEFS */ 看到3个结构的定义想到了什么？只是看着有点像吧，真正的区别我们往下看，其中3个结构里都包含了 __SOCKADDR_COMMON 这个宏，我们先把它的定义找到，最后在’usr/inlcue/bits/sockaddr.h’中找到如下代码， 1234567891011/* POSIX.1g specifies this type name for the `sa_family' member. */typedef unsigned short int sa_family_t;/* This macro is used to declare the initial common members of the data types used for socket addresses, `struct sockaddr', `struct sockaddr_in', `struct sockaddr_un', etc. */#define __SOCKADDR_COMMON(sa_prefix) \ sa_family_t sa_prefix##family#define __SOCKADDR_COMMON_SIZE (sizeof (unsigned short int)) 由此我们知道，这三个结构的第一个字段都是一个unsigned short int 类型，只不过用宏来定义了三个不同的名字，至此第一个结构就清楚了，在一般环境下（short一般为2个字节），整个结构占用16个字节，变量sa_family占用2个字节，变量sa_data 保留14个字节用于保存IP地址信息。 接着我们发现第二个结构中还有in_port_t和struct in_addr两个类型没有定义，继续找下去吧，在文件‘/usr/include/netinet/in.h’发现以下定义 123456789/* Type to represent a port. */typedef uint16_t in_port_t;/* Internet address. */typedef uint32_t in_addr_t;struct in_addr&#123; in_addr_t s_addr;&#125;; 这么看来sockaddr_in这个结构也不复杂，除了一开始的2个字节表示sin_family，然后是2个字节的变量sin_port表示端口，接着是4个字节的变量sin_addr表示IP地址，最后是8个字节变量sin_zero填充尾部，用来与结构sockaddr对齐 现在我们该分析结构sockaddr_in6了，这里边只有一个未知的结构in6_addr，经过寻找发现其定义也在’/usr/include/netinet/in.h’中 12345678910111213141516171819#ifndef __USE_KERNEL_IPV6_DEFS/* IPv6 address */struct in6_addr&#123; union &#123; uint8_t __u6_addr8[16];#if defined __USE_MISC || defined __USE_GNU uint16_t __u6_addr16[8]; uint32_t __u6_addr32[4];#endif &#125; __in6_u;#define s6_addr __in6_u.__u6_addr8#if defined __USE_MISC || defined __USE_GNU# define s6_addr16 __in6_u.__u6_addr16# define s6_addr32 __in6_u.__u6_addr32#endif&#125;;#endif /* !__USE_KERNEL_IPV6_DEFS */ 这个结构看起来有点乱，但是如果抛开其中的预编译选项，其实就是8个字节，用来表示IPV6版本的IP地址，一共128位，只不过划分字节的段数有些不同，每段字节多一点那么段数就少一点，反义亦然。 那接下来我们整理一下，为了看的清楚，部分结构使用伪代码，不能通过编译，主要是方便对比，整理如下 12345678910111213141516171819202122232425/* Structure describing a generic socket address. */struct sockaddr&#123; uint16 sa_family; /* Common data: address family and length. */ char sa_data[14]; /* Address data. */&#125;;/* Structure describing an Internet socket address. */struct sockaddr_in&#123; uint16 sin_family; /* Address family AF_INET */ uint16 sin_port; /* Port number. */ uint32 sin_addr.s_addr; /* Internet address. */ unsigned char sin_zero[8]; /* Pad to size of `struct sockaddr'. */&#125;;/* Ditto, for IPv6. */struct sockaddr_in6&#123; uint16 sin6_family; /* Address family AF_INET6 */ uint16 sin6_port; /* Transport layer port # */ uint32 sin6_flowinfo; /* IPv6 flow information */ uint8 sin6_addr[16]; /* IPv6 address */ uint32 sin6_scope_id; /* IPv6 scope-id */&#125;; 这么来看是不是就清晰多了，由此我们发现结构 sockaddr 和 sockaddr_in 字节数完全相同，都是16个字节，所以可以直接强转，但是结构 sockaddr_in6 有28个字节，为什么在使用的时候也是直接将地址强制转化成(sockaddr*)类型呢？ 强转的可能性其实sockaddr 和 sockaddr_in 之间的转化很容易理解，因为他们开头一样，内存大小也一样，但是sockaddr和sockaddr_in6之间的转换就有点让人搞不懂了，其实你有可能被结构所占的内存迷惑了，这几个结构在作为参数时基本上都是以指针的形式传入的，我们拿函数bind()为例，这个函数一共接收三个参数，第一个为监听的文件描述符，第二个参数是sockaddr*类型，第三个参数是传入指针原结构的内存大小，所以有了后两个信息，无所谓原结构怎么变化，因为他们的头都是一样的，也就是uint16 sa_family，那么我们也能根据这个头做处理，原本我没有看过bind()函数的源代码，但是可以猜一下: 1234567891011121314151617int bind(int socket_fd, sockaddr* p_addr, int add_size)&#123; if (p_addr-&gt;sa_family == AF_INET) &#123; sockaddr_in* p_addr_in = (sockaddr_in*)p_addr; //... &#125; else if (p_addr-&gt;sa_family == AF_INET6) &#123; sockaddr_in6* p_addr_in = (sockaddr_in6*)p_addr; //... &#125; else &#123; //... &#125;&#125; 由以上代码完全可以实现IPv4和IPv6的版本区分，所以不需要纠结内存大小的不同 总结 通过等价替换的方式我们可以更好的了解sockaddr、sockaddr_in、sockaddr_in6之间的异同。 网路接口函数针对于IPv4和IPv6虽然有不同的结构，但是接口基本相同，主要是为了用户（开发者）使用方便吧。 有时间可以看一下bind()、accept()等函数，看看其中对于结构的使用到底是怎样的。]]></content>
      <categories>
        <category>Network</category>
      </categories>
      <tags>
        <tag>Network</tag>
        <tag>Socket</tag>
        <tag>网络编程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[VS2015调试dump文件时提示未找到xxx.exe或xxx.dll]]></title>
    <url>%2Fblog%2F2018%2F06%2F23%2FVS%E8%B0%83%E8%AF%95dump%E6%96%87%E4%BB%B6%E6%97%B6%E6%8F%90%E7%A4%BA%E6%9C%AA%E6%89%BE%E5%88%B0Xxxx-exe%E6%88%96xxx-dlll%2F</url>
    <content type="text"><![CDATA[前言游戏开发的过程中，经常会出现客户端宕机的问题，这时候一个小小的dump文件可以记录当时的内存及堆栈情况，对于解决崩溃的问题有巨大的帮助，之前用VS2008的时候调试过dump文件，但是最近客户端升级为VS2015以后，调试dump文件时经常会出现未找到xxx.exe或xxx.dll的情况，之前一直好使的方法现在却行不通了，于是决定找找解决的办法。 问题原因起初尝试过新建dump文件所显示的路径，复制exe或dll到指定路径下，复制dump文件到exe所在路径下都提示找不到，甚至是手动指定dll或者exe文件都无法打开，这就很奇怪了，原来只要把dump文件放在exe所在目录就可以啊，怎么这次不行了呢？终于，经过多次试验之后发现，原来在VS2015上调试dump文件，要求dump文件的版本与产生dump文件的exe或者dll必须一致，也就是说你要调试一个dump文件，就必须找到找到对应版本dll和exe，否则就会提示无法找到xxx.exe或xxx.dll，下面我们来试验一下。 产生dump文件产生dump文件的方法网上很容易找到，如果想测试的话可以自己找一找，也可以使用下面的代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081#include "stdafx.h"#include "Windows.h"#include "DbgHelp.h"int GenerateMiniDump(PEXCEPTION_POINTERS pExceptionPointers)&#123; // 定义函数指针 typedef BOOL(WINAPI * MiniDumpWriteDumpT)( HANDLE, DWORD, HANDLE, MINIDUMP_TYPE, PMINIDUMP_EXCEPTION_INFORMATION, PMINIDUMP_USER_STREAM_INFORMATION, PMINIDUMP_CALLBACK_INFORMATION ); // 从 "DbgHelp.dll" 库中获取 "MiniDumpWriteDump" 函数 MiniDumpWriteDumpT pfnMiniDumpWriteDump = NULL; HMODULE hDbgHelp = LoadLibrary(_T("DbgHelp.dll")); if (NULL == hDbgHelp) &#123; return EXCEPTION_CONTINUE_EXECUTION; &#125; pfnMiniDumpWriteDump = (MiniDumpWriteDumpT)GetProcAddress(hDbgHelp, "MiniDumpWriteDump"); if (NULL == pfnMiniDumpWriteDump) &#123; FreeLibrary(hDbgHelp); return EXCEPTION_CONTINUE_EXECUTION; &#125; // 创建 dmp 文件件 TCHAR szFileName[MAX_PATH] = &#123; 0 &#125;; TCHAR* szVersion = _T("dump_file_v1.0"); SYSTEMTIME stLocalTime; GetLocalTime(&amp;stLocalTime); wsprintf(szFileName, L"%s-%04d%02d%02d-%02d%02d%02d.dmp", szVersion, stLocalTime.wYear, stLocalTime.wMonth, stLocalTime.wDay, stLocalTime.wHour, stLocalTime.wMinute, stLocalTime.wSecond); HANDLE hDumpFile = CreateFile(szFileName, GENERIC_READ | GENERIC_WRITE, FILE_SHARE_WRITE | FILE_SHARE_READ, 0, CREATE_ALWAYS, 0, 0); if (INVALID_HANDLE_VALUE == hDumpFile) &#123; FreeLibrary(hDbgHelp); return EXCEPTION_CONTINUE_EXECUTION; &#125; // 写入 dmp 文件 MINIDUMP_EXCEPTION_INFORMATION expParam; expParam.ThreadId = GetCurrentThreadId(); expParam.ExceptionPointers = pExceptionPointers; expParam.ClientPointers = FALSE; pfnMiniDumpWriteDump(GetCurrentProcess(), GetCurrentProcessId(), hDumpFile, MiniDumpWithDataSegs, (pExceptionPointers ? &amp;expParam : NULL), NULL, NULL); // 释放文件 CloseHandle(hDumpFile); FreeLibrary(hDbgHelp); return EXCEPTION_EXECUTE_HANDLER;&#125;LONG WINAPI ExceptionFilter(LPEXCEPTION_POINTERS lpExceptionInfo)&#123; // 这里做一些异常的过滤或提示 if (IsDebuggerPresent()) &#123; return EXCEPTION_CONTINUE_SEARCH; &#125; return GenerateMiniDump(lpExceptionInfo);&#125;void create_dump()&#123; // 给空指针赋值，使程序崩溃产生 Dump 文件 int *ptr = NULL; *ptr = 101;&#125;int main()&#123; // 加入崩溃dump文件功能 SetUnhandledExceptionFilter(ExceptionFilter); create_dump();&#125; 将上述代码编译成exe文件，然后点击运行就会在exe所在目录产生一个dump文件，例如我产生的dump文件为dump_file_v1.0-20180623-123940.dmp 调试dump文件双击打开刚刚生成的dump文件，会出现如下界面： 点击右侧 “使用 仅限本机 进行调试” 按钮，就会显示出程序崩溃时的堆栈信息和内存情况以及崩溃位置的代码，如下图： 以上是正常的调试情况，接下来不需要改变代码，重新编译一下程序，得到新版本的exe文件，然后双击刚刚的dump文件dump_file_v1.0-20180623-123940.dmp，点击右侧 “使用 仅限本机 进行调试” 按钮，情况就会发生变化，显示结果如下图： 点击 “中断” 按钮，就会出现标题所说的未找到vsDump.exe。在小型转储中未找到 vsDump.exe。 您需要加载二进制文件才能查找当前堆栈帧的源代码。 看到了吧，只要是dump文件不是这个exe产生的，不管源代码是不是一样，结果都会提示找不到exe，至此我们就找到了“VS2015调试dump文件时提示未找到xxx.exe或xxx.dll”的原因。 总结 VS2015调试dump文件时需要保证dump文件和exe、dll版本一致 遇到奇怪的问题可以手动模拟一下，往往可以重现，然后找到具体的原因]]></content>
      <categories>
        <category>VS</category>
      </categories>
      <tags>
        <tag>VS</tag>
        <tag>实用工具</tag>
        <tag>dump文件调试</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[操作指向类成员的指针需要了解的两个操作符->*和.*]]></title>
    <url>%2Fblog%2F2018%2F05%2F12%2F%E6%93%8D%E4%BD%9C%E6%8C%87%E5%90%91%E7%B1%BB%E6%88%90%E5%91%98%E7%9A%84%E6%8C%87%E9%92%88%E9%9C%80%E8%A6%81%E4%BA%86%E8%A7%A3%E7%9A%84%E4%B8%A4%E4%B8%AA%E6%93%8D%E4%BD%9C%E7%AC%A6-%E5%92%8C%2F</url>
    <content type="text"><![CDATA[前言关于 -&gt;* 这种写法在很早就在项目代码里见过了，并且还写过，不过当时并没有正确的理解这样写的含义，一直到最近发现这样写很奇怪，于是根据自己的理解，开始改代码，发现无论怎么改都无法通过编译，仔细搜索后才发现这是一种固定的写法，也就是说 -&gt;* 是一个操作符，无法拆分，同时还有一个 .* 也是相同的作用，只不过是用于对象上，而 -&gt;* 是用于对象的指针上。 那么这两个操作符究竟有什么作用呢？实际上它们主要用于操作指向类成员的指针，可能你会说指向类成员的指针直接定义就好了，为什么这么麻烦，还要是用这两个操作符呢？接下来我们举几个例子就明白了。 指向类数据成员的指针12345678910111213141516#include &lt;iostream&gt;class C&#123;public: int m;&#125;;int main()&#123; int C::* p = &amp;C::m; // pointer to data member m of class C C c = &#123;7&#125;; std::cout &lt;&lt; c.*p &lt;&lt; '\n'; // prints 7 C* cp = &amp;c; cp-&gt;m = 10; std::cout &lt;&lt; cp-&gt;*p &lt;&lt; '\n'; // prints 10&#125; 看到上述代码中的p指针有什么不同了吧，这是一个指向类成员变量的指针，如果我们不这样定义p也想操作c对象的成员变量m要怎么办呢？我们可以这样写： 123456789101112131415#include &lt;iostream&gt;class C&#123;public: int m;&#125;;int main()&#123; C c = &#123;7&#125;; int *p = &amp;c.m; std::cout &lt;&lt; *p &lt;&lt; '\n'; // prints 7 *p = 10; std::cout &lt;&lt; *p &lt;&lt; '\n'; // prints 10&#125; 这样代码中的变量p就变成了一个简单的指向整型数据的指针，我们也可以通过它访问c对象的m变量，并且给它赋值，但是你有没有发现区别，前一种指针p只依赖于类C的定义，可以在类C创建对象之前就给指针p定义赋值，但是后一种数据指针p就只能在类C创建对象之后才能给它赋值，还有一点，前一种指针p可以根据调用它的对象不同而访问不同类C对象的值，而后一种指针p就只能访问它所指向的那个对象的m值，如果要访问其他对象，需要重新给p赋值。 注意指向类成员指针的定义和赋值方法，是int C::* p = &amp;C::m;，取变量m的地址还有两种写法，&amp;(C::m) 或者 &amp;m这两种写法只能写在类C的成员函数中，所表示的也就是一个简单的指向整型变量的指针，即int*，与 &amp;C::m的含义是大不相同的。 而操作符-&gt;* 和.*在代码中起什么作用呢，我们只看这一句std::cout &lt;&lt; cp-&gt;*p &lt;&lt; &#39;\n&#39;;，其中表达式cp-&gt;*p用到了操作符-&gt;*，根据我的理解这个操作符的作用就是将后面的指针解引用，然后再被前面的对象调用，首先我们看cp是一个指向c对象的指针，如果想访问m变量，可以直接使用cp-&gt;m，假设现在不想这么写，我们有一个指向类C中m变量的指针p，那么直接写成cp-&gt;p肯定是不行的，因为p并不是类C的成员，它只是一个指向类C成员的指针，所以需要将其解引用，转换成真正的成员才能被cp指针引用到，那么*cp其实就是类C中的m，组合到一起就是cp-&gt; *p，这只是理解，其实-&gt;*是一个不可分割的操作符，需要紧挨着写成cp-&gt;*p才能编译通过。 另外关于指向类成员指针，在操作对象是父类对象和子类对象时有什么不同呢?答案是：指向可访问的非虚拟基类的数据成员的指针可以隐式地转换为指向派生类的同一数据成员的指针，反过来结果就是未定义的了，可以参考代码： 1234567891011121314151617#include &lt;iostream&gt;class Base&#123;public: int m;&#125;;class Derived : public Base &#123;&#125;;int main()&#123; int Base::* bp = &amp;Base::m; int Derived::* dp = bp; Derived d; d.m = 1; std::cout &lt;&lt; d.*dp &lt;&lt; '\n'; // prints 1 std::cout &lt;&lt; d.*bp &lt;&lt; '\n'; // prints 1&#125; 指向类成员函数的指针其实前面的例子我在工作中还真没遇到过，但是指向类数据成员的指针确实经常用，熟悉函数指针的工程师都知道，类似于void (*func)(); 就是定义了指向一个无返回值无参数函数的指针，调用时只要写成(*func)();就行，但是如果定义指向类成员函数的指针可就麻烦一点了，接下来看一个例子： 1234567891011121314class C&#123;public: void f(int n) &#123; std::cout &lt;&lt; n &lt;&lt; '\n'; &#125;&#125;;int main()&#123; void (C::* p)(int) = &amp;C::f; // pointer to member function f of class C C c; (c.*p)(1); // prints 1 C* cp = &amp;c; (cp-&gt;*p)(2); // prints 2&#125; 这个例子中的函数指针p是有作用域的，也就是只能指向类C中的无返回值并且有一个整型参数的函数，代码中赋值为&amp;C::f，这个形式与数据成员指针的赋值一样，其实函数f就是类C的一个成员而已。 那么它是怎么通过p指针调用到函数f的呢？我们看一句代码(cp-&gt;*p)(2);其实-&gt;*在这里还是起到了解引用并访问的作用，如果要访问f函数，只要cp-&gt;f(2)即可，但是这里没有f只有一个指向f的指针p，所以将f替换成*p编程cp-&gt;*p(2);但是这样无法通过编译，它无法区分那一部分是函数体，那一部分是参数，所以加个括号指明一下变成(cp-&gt;*p)(2);就可以正常访问f函数了。 实际上对面向对象编程了解的深入一点就会知道，调用对象的成员函数，实际上就是把对象的指针this作为函数第一个参数传进去，比如cp-&gt;f(2)，假如函数f的函数指针是func，那么cp-&gt;f(2)就是调用func(cp, 2)，这样在函数f中就可以调用对象的成员变量或者其他的成员函数了，但是如果你的成员函数中没有访问成员内容，那么这个this指针传什么都可以，也就是说func(cp, 2)和func(0, 2)、func(0x1234567890, 2)都是等价的，在这个例子中就是这样，所有你可以这样来写一段代码：(((C*)0)-&gt;*p)(2)，也是可以打印出数字2的。 另外关于指向类成员函数指针，在操作对象是父类对象和子类对象时与成员变量的规则一致：指向可访问的非虚拟基类的成员函数的指针可以隐式地转换为指向派生类的同一成员函数的指针，反过来也是未定义，可以参考代码： 12345678910111213141516#include &lt;iostream&gt;class Base&#123;public: void f(int n) &#123; std::cout &lt;&lt; n &lt;&lt; '\n'; &#125;&#125;;class Derived : public Base &#123;&#125;;int main()&#123; void (Base::* bp)(int) = &amp;Base::f; void (Derived::* dp)(int) = bp; Derived d; (d.*dp)(1); (d.*bp)(2);&#125; 具体使用前面提到过指向类数据成员的指针我之前真的没用到过，但是指向成员函数的指针，我却用了不少，一般都是放在函数数组中使用，比如有这样一个场景，游戏npc根据状态执行对应的状态函数，这些状态函数是成员函数，为此我们需要将npc所有的状态函数添加到一个函数数组中，假设有idle、run、walk、jump四种状态，下面是实现代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263#include &lt;iostream&gt;class CNpc&#123; typedef void (CNpc::*StateFunction)();public: int state; // 0,1,2,3 对应 idle、run、walk、jump StateFunction state_function_array[4];public: CNpc() &#123; state = 0; state_function_array [0] = &amp;CNpc::idle; state_function_array [1] = &amp;CNpc::run; state_function_array [2] = &amp;CNpc::walk; state_function_array [3] = &amp;CNpc::jump; &#125; void change_state(int new_state) &#123; state = new_state; &#125; void process_state() &#123; if (state_function_array[state]) &#123; (this-&gt;*state_function_array[state])(); // 调用函数指针的地方 &#125; &#125;private: void idle() &#123; std::cout &lt;&lt; "state = idle" &lt;&lt; std::endl; &#125; void run() &#123; std::cout &lt;&lt; "state = run" &lt;&lt; std::endl; &#125; void walk() &#123; std::cout &lt;&lt; "state = walk" &lt;&lt; std::endl; &#125; void jump() &#123; std::cout &lt;&lt; "state = jump" &lt;&lt; std::endl; &#125;&#125;;int main()&#123; CNpc npc; npc.process_state(); npc.process_state(); npc.change_state(1); npc.process_state(); npc.change_state(3); npc.process_state(); npc.process_state(); npc.process_state(); npc.change_state(2); npc.process_state(); npc.change_state(0); npc.process_state(); npc.process_state(); return 0;&#125; 运行结果 123456789state = idlestate = idlestate = runstate = jumpstate = jumpstate = jumpstate = walkstate = idlestate = idle 总结 牢记-&gt;*和.*也是一种操作符，使用的时候不要拆开 理解操作符中的*符号的解引用的作用 如果有理解不正确的地方欢迎大家批评指正]]></content>
      <categories>
        <category>C/C++</category>
      </categories>
      <tags>
        <tag>C/C++</tag>
        <tag>类成员访问</tag>
        <tag>成员指针</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bat批处理替换字符串中匹配的子串]]></title>
    <url>%2Fblog%2F2018%2F04%2F12%2Fbat%E6%89%B9%E5%A4%84%E7%90%86%E6%9B%BF%E6%8D%A2%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E5%8C%B9%E9%85%8D%E7%9A%84%E5%AD%90%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[前言关于字符串的操作通常是编程生涯中不可避免的，在各种竞赛中、工作中常常能使用到，许多语言中都有专门负责处理字符串的模块或者类，对于字符串的替换一般也有专门的函数，比如Lua中的string.gsub()、Python中的replece()等，那么批处理在进行字符串操作的时候，有没有好用的替换函数呢？ 前两天在使用批处理更新资源文件的时候发现，批处理中也有专门处理字符串替换的方法，并且这是我见到的最有意思的字符串替换方式，就是利用A:B=C的方式来替换字符串，具体含义就是在字符串变量A中查找所有的子串B并且替换成子串C，看起来很有意思吧？下面举一个具体的示例看一下。 代码示例12345678910111213141516171819202122@echo offSET INPUT_PARAM=%1rem 替换输入变量中的world为Chinaecho source string is %INPUT_PARAM%echo === China replace world ===echo replace result is %INPUT_PARAM:world=China%echo.rem 将路径中的反斜杠替换成斜杠SET IMAGE_PATH=C:\NVIDIA\AndroidWorks\001echo source string is %IMAGE_PATH%echo === \ replace / ===echo replace result is %IMAGE_PATH:\=/%echo.echo ABCD:A=apause 代码中举了两个例子，将变量中的world为China、将路径中的反斜杠替换成斜杠都成功地替换了子串的内容，但是我们发现这个的作用对象只能是变量，对于最后一句echo ABCD:A=a并没有发生替换，下面可以看一下运行结果。 运行结果1234567891011E:\batTool&gt;Replace.bat &quot;Hello wolrd, All over the world!&quot;source string is &quot;Hello wolrd, All over the world!&quot;=== China replace world ===replace result is &quot;Hello wolrd, All over the China!&quot;source string is C:\NVIDIA\AndroidWorks\001=== \ replace / ===replace result is C:/NVIDIA/AndroidWorks/001ABCD:A=a请按任意键继续. . . 总结 bat处理字符串替换的方式比较有意思，需要知道A:B=C形式的替换方法 字符串替换只能是针对变量，对于文本貌似不起作用。]]></content>
      <categories>
        <category>bat</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[略显神秘的快速排序]]></title>
    <url>%2Fblog%2F2018%2F04%2F08%2F%E7%95%A5%E6%98%BE%E7%A5%9E%E7%A7%98%E7%9A%84%E5%BF%AB%E9%80%9F%E6%8E%92%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[前言继续我的填坑旅程，上次说到《排序算法系列之（二）——冒泡排序名字最为形象的一个》2017-09-16 10:42:07，又过了半年多，终于再一次鼓起勇气决定聊一聊快速排序的思路，不过与冒泡排序不同的是，这个快速排序的名字似乎和算法的思路没有什么关系，这个名字太抽象了，起这个名字可能当初仅仅是因为它比别的排序快一点。咳咳！ 抽象的名字不利于我们对于算法思路的理解，或许这就是我为什么当初认为快速排序是最难理解的排序算法，也可能是当初还没接触过堆排序、希尔排序等这些另类的排序吧！毕竟工作5年之后再来看这个快速排序，思路也是很清晰的，忽然发现它当初那份神秘的气息消散了许多。 快速排序我们今天同样略过各种复杂度，直奔主题——快速排序，既然它的名字不是说算法思路，那就是说性质了，通俗点说就是在一般情况下它比选择排序、冒泡排序要快，先不用关心它为什么快，我们先来模拟一个最简单的快速排序。 快速排序的核心思想是分治、递归，将原本问题的规模不断缩小，递归求解，这类算法往往代码很简单，但是理解起来难度大一点，说一下总体思路，我们先来举个例子。假设将N个数从小到大排序，首先是在等待排序的数组N中随便选一个数M，为了简单我们选择第一个，然后遍历待排数组，把比M小的数放到M的左边，把比M大的数放到M的右边，一次遍历结束M左边有m1个数，右边有m2个数(m1+m2+1=N)，然后就形成了两个待排数组N1和N2，对于每个待排数组重复上述操作，直到待排数组缩小到一个数字，则待排数据排序完毕，整个数组变为有序。 因为这个排序比较抽象，所以前面的橘子、苹果的例子很难解释清楚，但是我们可以用标了号的橙子来理解，是不是感觉橙子伟大了一点，为什么橙子可以，因为早上刚刚吃过橙子，嗯！就是这么任性！假设桌上摆着一排橙子，他们的重量分别是6, 2, 7, 3, 8, 9，什么？你问我重量单位是什么，那就是斤吧，谁叫这些橙子变异了呢，大的大，小的小，好了，能帮助我们理解算法就好了，自从有了转基因，今后多重的橙子都可能遇到。 事先解释一下，我们这些橙子在桌上排成了一排，并且每一个橙子都放在了盘子里，盘子不移动，我们只移动盘子里的橙子，空盘子用*表示，手里的橙子用M表示，为了省点力气，我们尽可能的少移动橙子。 起初桌子上盘子里的橙子情况是这样的:6, 2, 7, 3, 8, 9，M=* 用手拿起第一个盘子里的橙子后：*, 2, 7, 3, 8, 9 ，M=6 从后往前找到第一个比M小的橙子放到前面，9、8、3，发现3是第一个符合条件的，把它拿到前面的盘子，变成了这样：3, 2, 7, *, 8, 9 ，M=6 然后第一个不算从前往后找到第一个比M大的橙子放到后面，2、7，发现7是第一个符合条件的，把它放在后面的空盘子：3, 2, *, 7, 8, 9 ，M=6 到此为止，我们已经把所有位置都遍历一遍了，这就是所谓的一趟排序，如果中间还有位置没有比较，重复步骤3和步骤4，直到所有的位置的橙子都被遍历到，把M=6放到最后的空盘子中就变成了：3, 2, 6, 7, 8, 9 ，M=* 执行到这个步骤，原来的这些橙子就被分成了两部分，比M=6小的放到了它的前面，比M=6大的放到了它的后面，现在就变成了两个规模较小的数组排序，我们以前面的待排数组N1为例，重复步骤2，先取出第一个橙子，拿在手里：*, 2 ，M=3 重复步骤3，从后往前找到第一个比M小的橙子放到前面，发现2这个橙子，然后把它放到前面的空盘子，现在的情况如下：2, * ，M=3 本来应该重复步骤4，但是此时发现所有的位置已经遍历过了，所以步骤4省略，直接步骤5，把M=3放在空盘子中：2, 3 ，M=* 此时被M=3分割的就过只有一部分，并且不大于一个橙子，所以左半部分排序结果，总体来看顺序为：2, 3, 6, 7, 8, 9 ，M=* 接着就要对步骤5后面的右半部分排序了，也就算是对7, 8, 9，虽然现在数据少我们一眼就能看出这结果数是有序的，但是如果在程序代码中，还是会对这部分橙子重复步骤3、4、5来达到有序，这里就不再逐步解释了，最后的结果就是：2, 3, 6, 7, 8, 9 ，M=* 代码实现1234567891011121314151617181920212223242526272829/*功能： 快速排序，实现数组元素从小到大排列参数： array--表示待排序的数组，此处会退化成指针 low --待排序区间的起始索引 high --待排序区间的结束索引返回值：无注意： 只用来表示思路，不考虑指针为空等特殊情况*/void quick_sort(int array[], int low, int high)&#123; if (low &gt;= high) return; int front = low, back = high, key = array[low]; // 选取第一个元素作为中轴 while (front &lt; back) &#123; while (front &lt; back &amp;&amp; array[back] &gt;= key) --back; array[front] = array[back]; // 从后面找到第一个比中轴小的交换 while (front &lt; back &amp;&amp; array[front] &lt;= key) ++front; array[back] = array[front]; // 从前面找到第一个比中轴大的交换 &#125; array[front] = key; quick_sort(array, low, front - 1); // 递归快排前半段 quick_sort(array, low, front + 1); // 递归快排后半段&#125; 代码分析上述代码与橙子排序的示例思路完全一致，key = array[low]是步骤2，选取第一个元素作为中轴；最外层的while循环是反复重复步骤3和步骤4，保证遍历所有位置的橙子；内部的第一个while循环是步骤3，从后面找到第一个比中轴小的；内部的第二个while循环是步骤4，从前面找到第一个比中轴大的；array[front] = key;就是步骤5，把手里的橙子放回到空盘子中；接下来的两个函数调用都是调用自己，也就是递归调用，分别处理小于M的一段和大于M的一段，怎么样？代码是不是好理解多了？如果觉得我理解的有问题或者代码有错，也欢迎大家批评指正。 运行测试快速排序–源码 如果你想运行测试一下，可以复制或者下载源代码，在本机运行测试一下，当然也可以选择在线编辑器，这是我新发现的在线编译器，样子还挺好看的，把源代码复制到网页中运行查看结果。]]></content>
      <categories>
        <category>Sort</category>
      </categories>
      <tags>
        <tag>排序</tag>
        <tag>算法</tag>
        <tag>概念</tag>
        <tag>Sort</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[神秘莫测的时间复杂度]]></title>
    <url>%2Fblog%2F2018%2F03%2F29%2F%E7%A5%9E%E7%A7%98%E8%8E%AB%E6%B5%8B%E7%9A%84%E6%97%B6%E9%97%B4%E5%A4%8D%E6%9D%82%E5%BA%A6%2F</url>
    <content type="text"><![CDATA[前言说到时间复杂度，作为程序员或多或少都会有所接触，特别是算法工程师肯定是天天和这个概念打交道，其实前几篇总结排序的文章我一直没有提时间复杂度，因为网上太多的文章讲这个概念了，所以我只总结了一下我对几种排序算法的理解，以及简单的实现代码，而当我今天准备总结一下快速排序的时候，我发现各个关于快速排序的文章都有讲到时间复杂度，有的甚至直接就给出 O(N*log(N))，这个对数是以2为底的，还是以10为底的都没有说清楚，这简直让人感到莫名其妙，所以我决定还是简单说一下我对时间复杂度这个概念的理解。 其实时间复杂的作用很简单，就是用来表示算法运行时间与数据规模的关系，其中的数据规模常常用字母N或者n表示，将算法的运行时间表示为n的函数表达式应该为 t=f(n) ，而时间复杂度就是表达式中幂最高的那一项，然后去掉常数系数，比如当算法运行时间表达式为 t = f(n) = 3 * n^2 + n 时，那么这个算法的时间复杂度就是O(n^2)，字母O用来表示时间复杂度，也就是该算法与数据规模成平方阶的关系，为什么要去掉一次项n，因为在数据规模扩大时，它相对于平方阶来说基本可以忽略不计。 时间复杂度计算方法虽然很多编程工作者都接触过时间复杂度，但是真正要想把时间复杂度算明白可不是件容易的事，特别是遇到时间复杂度中包含对数项的，那就更让人糊涂了，很多人搞不明白为什么会有对数次的运算，实际上二分法常常是导致时间复杂度中出现对数项的一种算法，要算出时间复杂度，本质上就是算出执行完算法算所需要的操作次数，这种操作通常是比较、赋值、交换等等，而时间复杂度与数据规模相关，通常把一个算法执行完所需的操作次数，表示成和数据规模n相关的函数，这就是我们所说的时间复杂度。时间复杂度是用来衡量算法所需时间资源的，所以只保留最高次幂的项就可以，不用纠结于是O(n^2+n)还是O(n^2)，在大规模的数据面前，这两种时间复杂度几乎相等，总之一句话，看一个算法的时间复杂度，就是数这个算法执行完所需要的操作次数，并且把这个次数表示成与n相关的简单函数。 时间复杂度示例接下来我们举几个简单的例子，来理解一下什么是时间复杂度，并且了解一下“计算时间复杂度就是数算法执行操作的次数”这句话的意思，接下来我们一起数一下： 常规方法计算区间[1,n]中所有整数的和 12345int sum = 0, n = 10000;for (int i = 1; i &lt;= n; i++)&#123; sum += i;&#125; 上述代码就是一个很简单的计算方法，具体操作就是遍历区间[1,n]内的所有整，然后依次相加，执行次数很好数吧？就是n次，因为每遍历一个数，就会执行一次累加操作，一共有n个数字，所以执行完这段代码需要进行n次累加运算，随着数据规模的扩大，也就是数字n的扩大，计算次数也在扩大，但是还是n次，所以可以用n来表示这段代码的时间复杂度，也就是O(n)。 利用等差数列公式计算区间[1,n]中所有整数的和 12int n = 10000;int sum = (1 + n) * n / 2; 等差数列的求和公式相信很多人都是知道的，那么这种计算方法对于遍历来说快了太多，因为它是直接计算出来的，也就是1次就能计算出结果，计算次数不会随着数据规模的扩大而扩大，那么这个算法的时间复杂度就是O(1)，也许有的人会纠结这里有加法、乘法、除法，不应该是3次运算吗？实际上就是3次运算，但是常数级的时间复杂度都会用O(1)来表示，它是一个衡量的指标，不需要精确到具体的次数，即使这个常数次数是1000也写成O(1)即可，所以通过这点可以看出，时间复杂度是O(1)的算法未必就比时间复杂度是O(n)的算法计算次数少，比如这个例子中，当n小于3时，第一种算法反而计算的次数少，但是时间复杂度通常是用来衡量数据规模很大的时候，算法所需时间的情况，所以通常情况下O(1)的算法在时间上还是优于O(n)的算法。 利用冒泡排序对所给数组进行排序 12345678910111213void bubble_sort(int array[], int n)&#123; for (int bubble_count = 0; bubble_count &lt; n - 1; ++bubble_count) &#123; for (int bubble_pos = 0; bubble_pos &lt; n - 1 - bubble_count; ++bubble_pos) &#123; if (array[bubble_pos] &gt; array[bubble_pos + 1]) &#123; swap_data(&amp;array[bubble_pos], &amp;array[bubble_pos + 1]); // 交换数据 &#125; &#125; &#125;&#125; 冒泡排序算是排序算法中规则比较简单的了，那么它的时间复杂度怎样来计算呢，或者说怎样来数它的执行次数呢，本例的执行操作次数指的是比较和交换，随着数据规模的扩大，也就只有这些操作次数是跟着变的，那么我们来数一数执行这些操作的次数，首先这是个双重循环，外层循环会遍历n-1次，随着外层循环增多内层循环次数会逐渐减少，听起来很麻烦的，外层和内层都在变化，怎么计算呢？其实可以回归本质，我们看看一共执行了多少次比较运算就可以，第一遍冒泡，内层循环执行了n-1次比较，第二遍冒泡，内层循环执行了n-2次比较，依次类推最后肯定是执行了1次比较，一共比较了多少次是不是就很好计算了，这些次数就是一个等差数列，求和就是这个算法的执行次数，f(n) = (1 + n - 1) * (n - 1) / 2 = n * (n - 1) / 2 = n^2 / 2 - n /2，根据时间复杂度定义，取最高次幂的项去掉系数就得到冒泡排序的时间复杂度O(n^2)。 计算一个十进制数的所有位上（个位、十位、百位…）上1的个数，例如12341这个数中包含2个1 123456789101112int count_one(int n)&#123; int count = 0; while(n &gt; 0) &#123; if ((n % 10) == 1) ++count; n /= 10; &#125; return count;&#125; 这也是一个很简单的算法，我们只要取出每一位上的数字，看看是不是1就可以，如果是1的话统计的变量count就加1就可以，那么这个算法的操作次数与数据规模n有什么关系呢，实际上这次数我们很清楚，就是n一共有几位数，就需要执行几次操作，当数字是34时，我们需要执行两次操作，当数字是24353的时候我们需要执行5次操作，那么怎么把这个次数表示成n的函数呢，仔细想想者原来就是对数，在本例中f(n) = (int)lg(n) + 1，也就是对n取10的对数，然后取整后加1，那么这个算法的时间复杂度就出来了，就是去掉常数项和修饰符变为O(lg(n))。 总结写这篇总结的初衷就是网上太多的算法直接给出了时间复杂度，而缺乏必要的说明，其实时间复杂度的计算并不算太复杂，只要你回归定义的本质，仔细的算算究竟需要多少次操作就可以得到大概的时间复杂度，并且一个算法的时间复杂度也不是固定的，比如快速排序，一般大家都喜欢说它是N乘以对数级的，但是当它的最坏情况发生时，它会退化成平方级的。]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>算法</tag>
        <tag>概念</tag>
        <tag>O(n)</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[bat批处理遍历指定目录下文件并更新]]></title>
    <url>%2Fblog%2F2018%2F03%2F21%2Fbat%E6%89%B9%E5%A4%84%E7%90%86%E9%81%8D%E5%8E%86%E6%8C%87%E5%AE%9A%E7%9B%AE%E5%BD%95%E4%B8%8B%E6%96%87%E4%BB%B6%E5%B9%B6%E6%9B%B4%E6%96%B0%2F</url>
    <content type="text"><![CDATA[前言先来看这样一个需求，假设有A，B两个目录，其中A目录是资源目录，B目录是工作目录，其中资源目录不定期更新，资源文件都在A目录下，并且没有子目录层级关系，但是资源要被使用时需要更新到B工作目录，B目录根据工程需要建立了一个包含众多子目录的层级体系，这样当A目录中的一个资源文件更新后，需要手动复制A目录中更新的资源文件，然后在B目录中找到对应的位置，然后进行粘贴替换，这样的操作如果很久一次、或者每次只有1、2个文件还好，如果资源文件大范围更新，那么要一个个找到更新文件在B目录中的位置然后替换就成了一件令人苦恼的事情，所以根据这个需求，才有了下面的探索过程。 思路的转变一开始想把A目录作为出发点，毕竟A目录中包含了修改后的资源文件，但是A目录更新后怎样才能准确的修改对应的B目录呢？我想到了配表，每次新增资源后，都会修改配置表，将A目录中的各个文件资源与B目录中的位置建立对应关系，这样A目录下的资源更新后就可以根据配置文件统一更新B目录了。 但这样的做法就是，需要经常维护配置文件，特别是增加或者删除资源的时候，然后我就想到了现在的这个做法，从B目录出发，注意本文主要解决的是资源文件的更新，而不是新增，更新就说明是原有的文件，只是内容发生了变化，比如一些UI文件，这些文件经常会做布局格式的调整，控件的增加和删除等等，调整结束后需要更新到工作目录。 实现过程实现的过程并没有想象的那么顺利，期间遇到了诸多问题和一些新的概念，比如for循环的语法，for循环中的变量定义，if条件的语法，字符串变量的替换，文件目录的处理，延迟环境变量扩展等等，这些问题每一项都可以作为一个单独的知识点，后续我会抽时间慢慢总结到一起，总之最后终于可以用了，前后大约花了1个半小时的时间，想想也是醉了，下面是一个具体的示例及对应的实现代码。 A资源目录对应实际的”E:/dirZ”，结构如下： 12345678910root:[E:/dirZ]+--aaa.txt+--bbb.txt+--ccc.txt+--ddd.txt+--eee.txt+--extra.c+--extra.h+--fff.txt+--ggg.txt B工作目录对应实际的”E:/dirA”，结构如下： 123456789101112131415root:[E:/dirA]+--aaa.txt+--bbb.txt+--dirB| +--ccc.txt| +--extra.c| +--extra.h+--dirC| +--ddd.txt| +--dirD| | +--eee.txt+--dirE| +--dirF| | +--fff.txt| | +--ggg.txt 现在需要把E:/dirZ目录中的txt文件，按照E:/dirA目录的层级结构，更新到对应位置，并且不更新ggg.txt文件，以下是实现的代码: 1234567891011121314151617181920212223242526272829303132333435@echo offrem 启用延迟环境变量扩展setlocal enabledelayedexpansionrem 定义不需要更新的文件SET EXCEPT_FILE=ggg.txtrem 定义工作目录和资源目录SET WORK_PATH=E:\dirA\SET RESO_PATH=E:\dirZ\rem 简单输出查看一下echo WORK_PATH is %WORK_PATH%echo RESO_PATH is %RESO_PATH%echo ------------------------rem for循环递归遍历WORK_PATH目录中的.txt文件，文件的全路径放在变量f中for /R %WORK_PATH% %%f in (*.txt) do ( rem 使用TARGET_FILE变量记录绝对文件名，注意延迟变量的使用 SET TARGET_FILE=%%f echo !TARGET_FILE! rem 去掉路径，只保留文件名及扩展名 SET "FILE_PATH_NO_EXT=%%~nxf" rem 利用资源路径和文件名，拼接出资源的绝对全路径 SET SOURCE_FILE=%RESO_PATH%!FILE_PATH_NO_EXT! echo !SOURCE_FILE! rem 条件判断是否是不需要更新的文件 if NOT !FILE_PATH_NO_EXT!==%EXCEPT_FILE% ( copy !SOURCE_FILE! !TARGET_FILE! ))pause 运行结果 123456789101112131415161718192021222324WORK_PATH is E:\dirA\RESO_PATH is E:\dirZ\------------------------E:\dirA\aaa.txtE:\dirZ\aaa.txt已复制 1 个文件。E:\dirA\bbb.txtE:\dirZ\bbb.txt已复制 1 个文件。E:\dirA\dirB\ccc.txtE:\dirZ\ccc.txt已复制 1 个文件。E:\dirA\dirC\ddd.txtE:\dirZ\ddd.txt已复制 1 个文件。E:\dirA\dirC\dirD\eee.txtE:\dirZ\eee.txt已复制 1 个文件。E:\dirA\dirE\dirF\fff.txtE:\dirZ\fff.txt已复制 1 个文件。E:\dirA\dirE\dirF\ggg.txtE:\dirZ\ggg.txt请按任意键继续. . . 总结到此为止我们就解决了这个资源更新的实际问题，每次资源更新后只要运行这个批处理文件就可以更新工作目录中对应的资源文件了，在这个例子中关于目录的截取，一开始走了很多弯路，其实有很多现成的方式，所以需要在此记录一下，方便以后查找使用，具体查看示例代码： 12345678910111213141516171819202122232425ECHO offSETlOCAL enabledelayedexpansion SET FIND_DIR=E:\dirA\dirC\dirDfor /R %FIND_DIR% %%f in (*.txt) do ( SET FULL_PATH=%%f ECHO 完整的路径: !FULL_PATH! SET FILE_DIR=%%~dpf ECHO 所在的目录: !FILE_DIR! SET FILE_NAME=%%~nf ECHO 无后缀文件: !FILE_NAME! SET FILE_EXT=%%~xf ECHO 文件名后缀: !FILE_EXT! SET "FILE_NAME_NOT_PATH=%%~nxf" ECHO 无路径文件: !FILE_NAME_NOT_PATH! SET "FULL_PATH_NOT_EXT=%%~dpnf" ECHO 无后缀全名: !FULL_PATH_NOT_EXT!)pause 运行结果： 123456完整的路径: E:\dirA\dirC\dirD\eee.txt所在的目录: E:\dirA\dirC\dirD\无后缀文件: eee文件名后缀: .txt无路径文件: eee.txt无后缀全名: E:\dirA\dirC\dirD\eee]]></content>
      <categories>
        <category>bat</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>bat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[关于游戏中仓库类的设计]]></title>
    <url>%2Fblog%2F2018%2F02%2F25%2F%E5%85%B3%E4%BA%8E%E6%B8%B8%E6%88%8F%E4%B8%AD%E4%BB%93%E5%BA%93%E7%B1%BB%E7%9A%84%E8%AE%BE%E8%AE%A1%2F</url>
    <content type="text"><![CDATA[前言这个游戏中的仓库类设计开始于春节前，和大家一样，我也是期盼着放假而无心工作，所以在放假前一天虽然蹦出了思维的火花，我却没有使用文字记录下来，但是大致的思路我已经记录到脑子中了，这一次的突然感悟，与上次突然明白什么是选择排序，什么是冒泡排序很类似，都是一瞬间突然明白，是一个从量变到质变的过程，接下来简单记录下我关于仓库的理解。 初觉不妥游戏中的仓库是用来存放道具的，这是我在接触这套游戏代码时形成的稳固的印象，结果就是代码中充斥着道具属性的判断，因为是很古老的代码，一开始我并没有产生疑问，同时也是修修补补的解决了许多BUG，可是渐渐的问题暴露了出来，设计上仓库里存储的是道具的索引，通过索引可以找到唯一的一个道具，这个思想根深蒂固，导致在写代码时自然而然的就在仓库的类里直接判断了道具属性，仔细想想这是不正确的。 起初感觉有问题时，大概是工作两年后，第一次重构道具系统的时候，当时在写放入道具和取出道具的时候总感觉怪怪的，但是又说不出问题出在哪里，其实就是在放入和取出的逻辑中，操作了道具的属性，修改了道具的坐标。也就是在仓库类的代码中设置了道具的属性，但是他们两个类不是依赖关系，硬生生的产生了依赖关系。 新的任务道具系统的第一次重构，我并没有找到为什么代码怪怪的，也就没有修改，但是新的任务在工作4年之后给了我一个新的机会，再写一遍道具系统，这时候那段奇怪的代码给我的感觉更强烈了，绝对有问题，也就是那么一瞬，我似乎明白了，仓库这个类被我们强加了太多的东西，谁说仓库中就一定要放道具了，我们在游戏中也没有直接把道具的对象保存在仓库中，而是把道具的索引存在了仓库中，也就是仓库中存储了道具的身份证，同理如果我们把人的身份中存在仓库中，那么仓库就是管理人的，如果我们把车牌号存储在仓库中，那么仓库就是管理车辆的。 因为起初游戏中的仓库只保存了道具的索引，所以我们想当然的认为仓库中只能保存道具，所以把一大堆的道具操作代码写到了仓库类中，是时候把代码提出来了，仓库就是仓库，它只根据坐标存储对应数据的ID，而这个ID对应的数据，应该在仓库以外的类中操作，这个ID可能对应道具、可能对应人、也可能对应车辆，干干净净的仓库管理了一组数据的ID，至于对ID对应数据的操作，一概不应该放在仓库类中进行。 重构的结果仓库类简简单单，保存着道具ID，只提供按位置放入ID，按位置取出ID，能够给出仓库的使用情况，能够初始化仓库的状态，仓库类有以上这些操作足以，仓库本身并不应该知道自己存的是道具还是车辆，真正要修改道具的属性，或者要查找指定属性的道具，放到道具管理类中来编写逻辑即可。]]></content>
      <categories>
        <category>Thinking</category>
      </categories>
      <tags>
        <tag>游戏</tag>
        <tag>架构设计</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim、Xshell、远程终端莫名卡死的原因]]></title>
    <url>%2Fblog%2F2018%2F02%2F03%2FVim%E3%80%81Xshell%E3%80%81%E8%BF%9C%E7%A8%8B%E7%BB%88%E7%AB%AF%E8%8E%AB%E5%90%8D%E5%8D%A1%E6%AD%BB%E7%9A%84%E5%8E%9F%E5%9B%A0%2F</url>
    <content type="text"><![CDATA[前言最近通过Xshell连接远程服务器，然后使用Vim修改文件时会莫名其妙的卡死，一开始我还没注意，因为近期的网络一直不太好，经常出现按下一个字母半天才反应过来的情况，所以我没有太在意，直接关闭终端重新打开就好。直到有一天我开着两个终端的时候，Vim又卡着不动了，而另一个终端还以流畅的处理我敲击的命令，我就断定这肯定不是网络原因了。 原因既然是Vim卡住了那就查查Vim本身有什么BUG吧，结果上网搜了一圈发现原来是远程终端的问题，根本就不关Vim的事，它只是躺着中枪了而已(*^▽^*)，实际上就是不小心按下了快捷键 Ctrl+S 导致的，为什么常常是Vim卡住呢？那是因为很多人习惯了在 Windows上 的保存快捷键，写写文档总是习惯性按下快捷键 Ctrl+S 保存一下，来避免程序突然崩溃导致文档丢失，这就解释了为什么出问题的总是Vim，因为使用Vim编辑文本有时会习惯性的按下 Ctrl+S 保存，而在执行Shell命令是很小的概率会按 Ctrl+S，所以大多数人卡住往往是在使用Vim的时候。 可是快捷键 Ctrl+S 为什么会导致终端卡死呢？实际上这个快捷键的含义是“阻断向终端输出内容”，很多人说这个快捷键的作用是暂停终端，我个人感觉这种说法并不准确，实际是上终端并没有暂停，按下 Ctrl+S快捷键后，你依然可以像终端发送命令，终端也会正常执行，只是不会将反馈内容和结果显示在终端上而已，这个特性可以用来暂停显示快速滚动输出的内容，比如在编译大型项目的时候。 解决办法解除这种状态的方法很简单，按下快捷键 Ctrl+Q 就可以“恢复向终端输出内容”，只是很多时候我们并不知道，以为是终端卡死了然后错杀了程序！ 附注关于这个问题，Vim文档中“SECTION 32 - VIM ON UNIX”一节也给出了回答，有兴趣的小伙伴可以自己看一下： 32.1. I am running Vim in a xterm. When I press the CTRL-S key, Vim freezes. What should I do now? vimdoc.sourceforge.net]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>Vim</tag>
        <tag>Xshell</tag>
        <tag>终端卡死</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Vim中简单格式化代码]]></title>
    <url>%2Fblog%2F2018%2F02%2F02%2FVim%E4%B8%AD%E7%AE%80%E5%8D%95%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[前言写这个总结的起因是我在把Windows上VS中的代码粘贴在Linux服务器的Vim中时，代码格式惨不忍睹，我就搞不明白为什么它每一行都要向后缩进，搞得我的代码最后像倒立的楼梯似的，就像这样： 123456789int main(int argc, char *argv[])&#123; int i=0,j=0; if (i != 0) &#123;i++; &#125; else &#123;i--; &#125; for(i=0;i&lt;5;i++)j++; printf("i=%d,j=%d\n",i,j); return 0;&#125; 往常我一般就是切换到插入模式，然后使用删除键删除掉前面多余的空格，可是这一次我决定不再忍受了，我要找到快速格式化的方法，还别说，方法其实很简单，各种格式化方法的核心就是符号=。 何谓“简单”其实一开始我想标题的时候并没有加上“简单”二字，直到我发现了一个求知者看似“无理”的要求，他要求在Vim中把上面格式的代码格式化成下面这样： 123456789101112131415161718int main(int argc, char *argv[])&#123; int i=0,j=0; if (i != 0) &#123; i++; &#125; else &#123; i--; &#125; for(i=0;i&lt;5;i++) j++; printf("i=%d,j=%d\n",i,j); return 0;&#125; 如果你也是这样想的，很抱歉，你可以关掉这个页面了，本文提供的方法无法满足你的要求，这就是我的标题中为什么加上了“简单”二字，而Vim中的简单格式化只能是格式化成下面这样，以行为单位，保证每行的缩进都是正确的： 123456789int main(int argc, char *argv[])&#123; int i=0,j=0; if (i != 0) &#123;i++; &#125; else &#123;i--; &#125; for(i=0;i&lt;5;i++)j++; printf("i=%d,j=%d\n",i,j); return 0;&#125; 如果你确实要把大括号的换行也显示正确，那么只能通过安装插件、编写脚本、或者把源代码中对应的位置敲如回车，变成下面这样格式的代码，然后再使用本文后面叙述的方法来格式化就可以了。 1234567891011121314151617int main(int argc, char *argv[])&#123; int i=0,j=0; if (i != 0) &#123; i++; &#125; else &#123; i--; &#125; for(i=0;i&lt;5;i++) j++; printf("i=%d,j=%d\n",i,j); return 0;&#125; 神奇的=其实格式化的核心内容就是这个 =，其中绝大部分的方法都是 = 的变种，只是让人不容易发觉，甚至有些方法例如 gg=G 包装的让人都无法注意到真正起作用的就是那个 =，格式化的前提是处于命令模式，也就是按完 ESC 时的模式，而格式化时 = 真正起作用的只有两种情况： 先按=，再选区域 先说应用最广泛的全文格式化的方法gg=G，就是这种情况的变种，分析一下命令的含义，先是gg表示回到文档最开始，= 表示要格式化，G 表示到文档末尾，也就是说 gg=G 的含义就是： 跳到文档开头-&gt;开始格式化-&gt;一直格式化到文档末尾 既然明白了原理，假如此时光标就在文档开始处，那么使用命令 =G 也是可以格式化全文的，同理命令 G=gg也可以达到格式化全文的效果，而命令 =100j 就是从文档当前位置向下格式化100行。 先选区域，再按= 这种方式我反正用不习惯，不过也说一下，就是先按 v (可视化编辑)或 shift+v (可视化编辑行模式)或 ctrl+v (可视化编辑块模式)，然后利用方向键 h,j,k,l 选择区域，最后按 = 完成格式化，简单操作例如 vjjj= 就是从当前位置向下格式化3行代码。 直接输入== 不是说两种情况吗，为什么会有第3条呢？其实在命令模式下输入 == ，也就是连着输入两个等号，就是格式化当前行的方法，我感觉它和上两种情况一样，可能是又不知道归入哪一种情况比较好，所以就单列出来咯。 总结 本文中所提到的格式化代码只是很简单的格式化，以行为单位保证缩进正常，无法处理大括号换行等情况。 如果要挑起“大括号换行”的战争，麻烦装一个格式化插件吧，Vim只和Emacs打架，不想参与“大括号换行”战争。 如果要部分格式化，首先保证要格式化的代码之前的内容是格式化好的，否则格式化无效，请选择全文格式化吧！]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>实用工具</tag>
        <tag>Vim</tag>
        <tag>代码格式化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql查询时case when语句的使用]]></title>
    <url>%2Fblog%2F2018%2F02%2F01%2FMysql%E6%9F%A5%E8%AF%A2%E6%97%B6case-when%E8%AF%AD%E5%8F%A5%E7%9A%84%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[前言前几天在技术论坛论坛上发现一个求助帖，大体意思就是要把一个表中的数据按条件分成两类，每一类排序方式不同，然后整体作为查询的结果集，乍一看这问题不是很难，很多人给出的答案是分别查询排序后再 union合并到一起，但是后来楼主明确指出不想使用 union 操作，这时有一位高人巧用 case when 语句解决了问题，其实这是我第一次接触 case when 语句，于是查询了一下具体用法，在此做个小结，方便日后查询使用。 创建示例表格数据库表格结构很简单，马上要期末了，就以学习成绩为数据来建立一张数据表，表中包含唯一ID、学号、姓名、性别、分数等列，其中性别这一列用整数代表，0表示男，1表示女，建立表格的sql语句如下： 123456789CREATE TABLE `grade` ( `id` int(4) NOT NULL AUTO_INCREMENT, `number` int(4) NOT NULL DEFAULT '0', `name` varbinary(32) NOT NULL DEFAULT '', `sex` int(4) NOT NULL DEFAULT '0', `score` int(4) NOT NULL DEFAULT '0', PRIMARY KEY (`id`), KEY `find_index` (`number`,`name`)) ENGINE=InnoDB DEFAULT CHARSET=binary ROW_FORMAT=DYNAMIC; 插入测试数据表格建立完成可以使用可视化工具或者insert语句插入测试数据，插入测试数据后查询结果如下： 123456789101112131415161718mysql&gt; select number,name,sex,score from grade;+----------+----------+-----+-------+| number | name | sex | score |+----------+----------+-----+-------+| 20180001 | xiaoming | 0 | 68 || 20180002 | xiaohong | 1 | 98 || 20180003 | xiaobing | 0 | 78 || 20180004 | xiaoli | 0 | 88 || 20180005 | zhangsan | 0 | 32 || 20180006 | zhaosi | 0 | 58 || 20180007 | marry | 1 | 78 || 20180008 | tom | 0 | 100 || 20180009 | feifei | 1 | 90 || 20180010 | lili | 1 | 92 || 20180011 | xiaozhao | 0 | 52 || 20180012 | xiaowang | 0 | 62 |+----------+----------+-----+-------+12 rows in set (0.00 sec) 获取平均成绩班主任们坐在一起做喜欢做的事就是比一下自己的学生和别人班的差距，谁让他们每个人带的学生都是一届不如一届呢！（你们是我带过的学生中最差的一届！！！）说到比成绩一般都是比较并均分，sql语句可能会写成下面这样： 1234567mysql&gt; select avg(score) as 平均分 from grade;+-----------+| 平均分 |+-----------+| 74.6667 |+-----------+1 row in set (0.02 sec) 是的，很简单就能获得班级的平均分，如果要分组呢？比如分别查一下男生和女生的平均分，因为我们知道表中的sex表示性别，所以直接按照sex分组就可以实现，可以将语句简单写成这样： 12345678mysql&gt; select sex as 性别, avg(score) as 平均分 from grade group by sex;+--------+-----------+| 性别 | 平均分 |+--------+-----------+| 0 | 67.2500 || 1 | 89.5000 |+--------+-----------+2 rows in set (0.00 sec) 是不是很简单？可是性别显示成0和1确实不利于阅读，但是表中又没有保存0、1与男、女的对应关系，应该怎么办呢？这就要用到我们今天所要用到的case when语句了，语法上共有两种写法，看着具体例子体会一下吧。 case when 语句的使用 第一种用法：case后面跟列名，when后面跟对应值 12345CASE case_value WHEN when_value THEN statement_list [WHEN when_value THEN statement_list] ... [ELSE statement_list]END 这种用法正好解决我们刚刚提出的问题，当sex值为0时当前列显示“男”，否则显示“女”，sql写法如下： 123456789mysql&gt; select (case sex when 0 then '男' else '女' end) as 性别, avg(score) as 平均分 -&gt; from grade group by sex;+--------+-----------+| 性别 | 平均分 |+--------+-----------+| 男 | 67.2500 || 女 | 89.5000 |+--------+-----------+2 rows in set (0.00 sec) 第二种用法：case后面空白，when后面跟着判断条件 12345CASE WHEN search_condition THEN statement_list [WHEN search_condition THEN statement_list] ... [ELSE statement_list]END 针对于这种写法，我们考虑这样一种需求，学生成绩是有评分的，大于等于90分的学生是A，小于90分大于等于60分的学生是B， 其余的学生是C，现在要查询评分为A、B、C的学生成绩的平均分分别是多少，因为成绩评分并不是单独的一列，所以不能简单的 使用 group by 来分组实现了，但是可以利用 case when 语句实现，写起来也很简单，看看下面的sql语句就知道了！ 12345678910mysql&gt; select (case when score &gt;= 90 then 'A' when score &lt; 60 then 'C' else 'B' end) as 等级, -&gt; avg(score) as 平均分 from grade group by 等级;+--------+-----------+| 等级 | 平均分 |+--------+-----------+| A | 95.0000 || B | 74.8000 || C | 47.3333 |+--------+-----------+3 rows in set (0.00 sec) 总结 case when 语句共有两种写法，使用时要区别两种用法的差异。 使用 case when 语句可以实现修改数值的对应关系，还可以按照复杂的条件进行分组。 关于 case when 语句的详细用法，有兴趣的同学可以参考一下官方文档：13.6.5.1 CASE Syntax]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>分组查询</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mysql验证联合索引的最左原则]]></title>
    <url>%2Fblog%2F2018%2F01%2F29%2FMysql%E9%AA%8C%E8%AF%81%E8%81%94%E5%90%88%E7%B4%A2%E5%BC%95%E7%9A%84%E6%9C%80%E5%B7%A6%E5%8E%9F%E5%88%99%2F</url>
    <content type="text"><![CDATA[前言如果你接触过数据库，应该听说过在数据库表的某些列上建立索引能够加快查找速度，如果研究更深入一点的人，可能还听说过联合索引，那么索引为什么能够加快查找速度呢？联合索引究竟又是什么呢？下面说说我的简单理解。 索引试想一下，把1~10000这1万个数字打乱顺序存储在数组中，如果要找到5000这个数字在哪，那就得从数组第0个元素开始，依次遍历找到5000这个数字所在的位置，运气好了1次就能找到，运气不好需要查询1万个数，可是如果把这1万个数作为map的key，每个数存在数组中的位置作为value，存储在map结构中很快就能找到，通常情况下要比直接遍历快的多。 其实这里的map充当的是一个索引的作用，我们知道map存储数据时使用树形结构，会根据要查找的值和当前节点比较，来确定继续查找左分支还是右分支，而数据库中的索引充当的也是这样的作用，mysql中的索引是BTree结构（多路搜索树），就是利用建立索引的列中的所有值建立了一棵树，通过有序的树形查找一般要比全局搜索快多了吧！ 联合索引简单了解了一下索引的含义，那么什么是联合索引呢？其实mysql数据库中的索引不止可以建立在一个列上，它可以将一个索引同时建立在说多个列上，也就是我们所说的联合索引，联合索引的作用特别大，有时会超过单列索引，至于什么时候建立单列索引，什么时候建立联合索引同样是个很复杂的问题，在此不做描述。有兴趣的读者可以自行搜索一下。 最左原则当你在多个列上建立一个索引时，怎样的查找才能利用索引加快速度呢？说到这我们先建立一个带有索引的表格，具体的分析一下什么叫做索引的最左原则。 123456789CREATE TABLE IF NOT EXISTS `test_index`( `id` int(4) NOT NULL AUTO_INCREMENT, `a` int(4) NOT NULL DEFAULT '0', `b` int(4) NOT NULL DEFAULT '0', `c` int(4) NOT NULL DEFAULT '0', `data` int(4) NOT NULL DEFAULT '0', PRIMARY KEY (`id`), KEY `union_index` (`a`,`b`,`c`))ENGINE=InnoDB ROW_FORMAT=DYNAMIC DEFAULT CHARSET=binary; 分析上述建表语句，创建了一个名为test_index 的数据库表格，然后在a、b、c三列上建立了联合索引，索引名字为union_index，而最左原则指的就是当你建立了这样一个索引的时候，等于建立了(a)、 (a,b)、 (a,b,c)三个索引，通过条件 (a), (a,b), (a,b,c) 这三种条件查询的时候都可以利用索引加快速度，所以在建立索引的时候要把最常用的条件列放到联合索引的最左边，接下来我们来验证一下，工具就是mysql自带的explain命令。 测试版本 Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 13Server version: 5.7.21-log MySQL Community Server (GPL) Copyright (c) 2000, 2018, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners. 验证过程 首先以列a作为条件查询数据，我们看到 type: ref 表示引用查找， key_len: 4 表示索引长度为4，也就说明利用了索引来进行查找 123456789101112131415mysql&gt; explain select data from test_index where a = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 4 ref: const rows: 70 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.01 sec) 然后以列b作为条件查询数据，可以看到type: ALL表示全表查找， key_len: NULL 表示没有索引，也就说明如果只使用b作为查询条件，不能利用索引来加快查找速度 123456789101112131415mysql&gt; explain select data from test_index where b = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 716173 filtered: 10.00 Extra: Using where1 row in set, 1 warning (0.00 sec) 接着以列c作为条件查询数据，可以看到type: ALL表示全表查找， key_len: NULL 表示没有索引，情况与用b作为条件一样，只使用c作为查询条件也不能利用索引来加快查找速度 123456789101112131415mysql&gt; explain select data from test_index where c = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 716173 filtered: 10.00 Extra: Using where1 row in set, 1 warning (0.00 sec) 现在来测一下使用a、b作为条件的情况，我们看到 type: ref 表示引用查找， key_len: 8 表示索引长度为8，也就是说我们利用上了a、b联合索引来进行查找 123456789101112131415mysql&gt; explain select data from test_index where a = 1 and b = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 8 ref: const,const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 紧接着来测一下使用a、c作为条件的情况，我们看到 type: ref 表示引用查找， key_len: 4 表示索引长度为4，这就奇怪了，按照最左原则来说，a、c上是不会建立索引的，为什么会有索引长度呢？其实与a、b上的索引一比较我们就能发现，a、c上的索引长度只有4，而且单独的c上是没有索引的，所以4字节长度的索引只能是a上的，也就是说这种情况我们只使用了a列上的索引来进行查找 123456789101112131415mysql&gt; explain select data from test_index where a = 1 and c = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 4 ref: const rows: 70 filtered: 10.00 Extra: Using index condition1 row in set, 1 warning (0.00 sec) 为了进一步验证上面的想法，这一次测一下使用b、c作为条件的情况，我们看到 type: ALL 表示全表查找， key_len: NULL 表示没有索引可以使用，按照最左原则来说，b列上没有索引，c列上也没有索引，同时b、c的上也不存在联合索引，所以使用b、c作为查询条件时无法利用联合索引 123456789101112131415mysql&gt; explain select data from test_index where b = 1 and c = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: ALLpossible_keys: NULL key: NULL key_len: NULL ref: NULL rows: 716173 filtered: 1.00 Extra: Using where1 row in set, 1 warning (0.00 sec) 测试完两个条件的情况，接下来测试一下使用a、b、c作为条件的情况，我们看到 type: ref 表示引用查找， key_len: 12 表示索引长度为12，这完全符合联合索引的最左原则，同时使用3个条件查询可以利用联合索引 123456789101112131415mysql&gt; explain select data from test_index where a = 1 and b = 1 and c = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 12 ref: const,const,const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 测试进行到现在，我测试了所有的情况吗？不是的！还可以颠倒顺序啊，我原来一直以为联合索引是有顺序的，结果测试后才发现，利用索引的条件符合“交换律”，也就是下面这种情况也能利用a、b上的联合索引，索引长度为8 123456789101112131415mysql&gt; explain select data from test_index where b = 1 and a = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 8 ref: const,const rows: 1 filtered: 100.00 Extra: NULL1 row in set, 1 warning (0.00 sec) 再来试试这种情况，按照最左原则，c上没有建立索引，a上有索引，c、a没有建立联合索引，所以只能使用a上的索引进行查找，结果索引长度只有4，验证了我们的想法，联合查询条件使用索引时满足“交换律” 123456789101112131415mysql&gt; explain select data from test_index where c = 1 and a = 1\G*************************** 1. row *************************** id: 1 select_type: SIMPLE table: test_index partitions: NULL type: refpossible_keys: union_index key: union_index key_len: 4 ref: const rows: 70 filtered: 10.00 Extra: Using index condition1 row in set, 1 warning (0.00 sec) 接下来几种交换顺序的情况(c,b)、(a,c,b)、(c,b,a)等，大家可以自己进行验证，到此为止，mysql联合索引的最左原则也就验证结束了！ 总结 联合索引的最左原则就是建立索引KEY union_index (a,b,c)时，等于建立了(a)、(a,b)、(a,b,c)三个索引，从形式上看就是索引向左侧聚集，所以叫做最左原则，因此最常用的条件应该放到联合索引的组左侧。 利用联合索引加速查询时，联合查询条件符合“交换律”，也就是where a = 1 and b = 1 等价于 where b = 1 and a = 1，这两种写法都能利用索引KEY union_index (a,b,c)。 遇到这种不确定的问题还是需要实际测试一下，简单的调整一下索引顺序可能会极大的提升效率哦！]]></content>
      <categories>
        <category>Mysql</category>
      </categories>
      <tags>
        <tag>Mysql</tag>
        <tag>实用工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python统计指定号码的历史中奖情况]]></title>
    <url>%2Fblog%2F2018%2F01%2F11%2FPython%E7%BB%9F%E8%AE%A1%E6%8C%87%E5%AE%9A%E5%8F%B7%E7%A0%81%E7%9A%84%E5%8E%86%E5%8F%B2%E4%B8%AD%E5%A5%96%E6%83%85%E5%86%B5%2F</url>
    <content type="text"><![CDATA[前言生活在寸土寸金的帝都，买房变成了一件可遇而不可求的事情，作为一个朝九晚九挣工资的人来说，买房或许只是出现在梦里，但是梦想总是要有的，万一实现了呢？其实真正赚钱的方式都明明白白地写在了刑法里，可是咱可是本分人，不能做哪些违法的事情，想要赚钱买房，还有一种比较随意的方式——买彩票，如今这帝都的房价，不是你中一张500万彩票就能买得起的，如果要买的起，那就需要中两张！ 经历中两张500万的彩票，想想就知道这种概率有多大了，跟你被天上掉下的陨石砸中脑袋差不多，是不是感觉没有希望了，不过不要灰心嘛，万一你要被砸中了呢？ 对于预测彩票号码这件事情，很抱歉，我不是神仙，没有方法可以办到，不过有件事你需要知道一下：那就是双色球自从问世以来，十几年间从未出现过一次号码完全相同的情况，也就是说你买个和历史号码一样的，基本中不了大奖了，但是也不一定，万一就有两颗陨石同时砸中你呢! 对于买彩票这件事，有的人喜欢买一个号，坚持多年从不动摇，一心做着发财梦；而有的人却是很随意，每天机选，靠天吃饭；还有一部分大神就比较高端了，每天窝在彩票投注站里，写写画画，仿佛可以窥探天机一样，每期少则几十，多则几百的砸着自己的血汗钱，我劝你们还是醒醒吧。 而我呢，就属于半个第一种人，坚持着一个号，做着发财梦，偶然间看到彩票投注站就买一张，遇不到就算了，典型的佛系彩票购买者，这样买了一段时间，忽然有个想法，我买的这个号到底在历史上中没中过大奖呢？于是作为程序猿的我决定写个程序查一下不就好了，所以才有了下面这段代码。 代码 引入库函数，其实需要的函数特别简单，就是要处理csv格式的双色球历史开奖数据。 1import csv 定义奖项，也就是中奖号码情况与奖项的对应关系，注意中一个篮球是6等奖哟！ 1234567891011121314151617# list award classifyaward_classify = &#123; (6,1): 1, (6,0): 2, (5,1): 3, (5,0): 4, (4,1): 4, (4,0): 5, (3,1): 5, (3,0): 0, (2,1): 6, (2,0): 0, (1,1): 6, (1,0): 0, (0,1): 6, (0,0): 0&#125; 定义比对函数，这个函数要能判断出我的号码跟一个历史号码相比，中了几个红球和蓝球。 123456789101112131415161718# count red balls and blue ballsdef count_red_blue_balls(my_number, history_number): red_count, blue_count = 0, 0 my_index, history_index = 0, 0 while my_index &lt; 6 and history_index &lt; 6: if my_number[my_index] == history_number[history_index]: my_index += 1 history_index += 1 red_count += 1 elif my_number[my_index] &lt; history_number[history_index]: my_index += 1 else: history_index += 1 if my_number[6] == history_number[6]: blue_count = 1 return red_count, blue_count 查询历史中奖情况，使用我选择的号码和历史开奖情况逐一比对，得到每个奖项中奖次数。 123456789# count award situation of my numberdef count_award_situation(my_number): local_award_statistics = [0,0,0,0,0,0,0] with open('lottery_history_data.csv', 'r') as file: data_content = csv.reader(file) for row_data in data_content: local_award_statistics[award_classify[count_red_blue_balls(my_number, list(map(int, row_data[1:8])))]] += 1 return local_award_statistics 展示查询结果，将统计结果以友好的方式呈现。 1234567# show award statictics for a numberdef show_award_result(my_number, award_statistics): print("my number is %s\n" % my_number) print("history award record list:") for index in range(0,7): print("award %d: %4d times" % (index, award_statistics[index])) 启动函数，读取自己定义的号码，然后进行统计 123456789# main functionif __name__ == '__main__': #my_number = [5,6,10,11,25,30,11] #my_number = [5,8,10,15,26,30,6] print("请输入6个红球和1个蓝球号码，空格分隔：") my_number = list(map(int, input().split())) award_statistics = count_award_situation(my_number) show_award_result(my_number, award_statistics) 运行结果 总结 这段代码只是一时好奇的产物，所以说好奇心带来了生产力。 统计代码只是做简单使用，所以一些特殊情况并未判断，比如输入字母或者未排序的数字。 看到我的号码连个4等奖都没有中过，不知道是该高兴还是难过，是不是这个大奖在等着我啊！ 说到这也该结束了，不好意思上周六(20180113)买的双色球又中了6等奖，明天(20180121)要去领奖喽！ 源码代码传送门(附双色球历史数据)：一触即达]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>实用工具</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python查找文件中包含中文的行]]></title>
    <url>%2Fblog%2F2018%2F01%2F06%2FPython%E6%9F%A5%E6%89%BE%E6%96%87%E4%BB%B6%E4%B8%AD%E5%8C%85%E5%90%AB%E4%B8%AD%E6%96%87%E7%9A%84%E8%A1%8C%2F</url>
    <content type="text"><![CDATA[前言近几天在做多语言版本的时候再次发现，区分各种语言真的是一件比较困难的事情，上一次做中文提取工具的就花了不少时间，这次决定用python试一试，结果写起来发现真是方便不少，自己整理了一下方便以后查找使用。 代码123456789101112131415161718192021222324#!/usr/bin/env python3# -*- coding: utf-8 -*-# find the line of containing chinese in files__author__ = 'AlbertS'import redef start_find_chinese(): find_count = 0; with open('ko_untranslated.txt', 'wb') as outfile: with open('source_ko.txt', 'rb') as infile: while True: content = infile.readline() if re.match(r'(.*[\u4E00-\u9FA5]+)|([\u4E00-\u9FA5]+.*)', content.decode('utf-8')): outfile.write(content) find_count += 1; if not content: return find_count# start to findif __name__ == '__main__': count = start_find_chinese() print("find complete! count =", count) 文件 输入：source_ko.txt 3 캐릭터 Lv.50 달성8 캐릭터 Lv.80 달성10 캐릭터 Lv.90 달성……2840 飞黄腾达4841 同归于尽8848 캐릭터 Lv.50 달 输出：ko_untranslated.txt 2840 飞黄腾达4841 同归于尽 总结 其实这段小小的代码中包含了两个常用的功能，那就是读写文件和正则表达式。 这也是两个重要的知识点，其中with操作可能防止资源泄漏，操作起来更加方便。 正则表达式可是一个文字处理的利器，代码中的正则可能还不太完善，后续我会继续补充更新。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>正则表达式</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2Fblog%2F2018%2F01%2F05%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new "My New Post" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy Picture Watermark1?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9hbGJlcnRnaXRodWJob21lLmdpdGh1Yi5pby9ibG9nL2Fib3V0,size_18,color_FFFFFF,t_70#pic_center) Fans aticlehttps://blog.csdn.net/albertsh/article/details/100594143https://blog.csdn.net/albertsh/article/details/100540338!-- https://blog.csdn.net/albertsh/article/details/52788106 https://blog.csdn.net/albertsh/article/details/52797519 --https://blog.csdn.net/albertsh/article/details/82286999https://blog.csdn.net/albertsh/article/details/90736859 Blog Record博客记录QQ：347070901微信公众号：写代码的苏东坡===============================我的Github：AlbertGithubHome===============================刚刚起步 2013-10-05 08:39 写了第一篇转载博文 2015-11-19 11:20 收到第一条博客评论 2016-12-27 20:18 翻译第一篇英文资料 2017-03-27 09:55 访问第一次突破三万 2017-05-21 09:25 积分第一回到达一仟 2017-05-21 09:25 等级第一次满足四级 2017-09-14 21:00 版式第一次不让更改 2017-11-14 11:59 排名第一次有了数字 2018-07-16 19:39 访问第一次达二十万2018-12-08 10:41 访问第一回破三十万2019-06-22 18:30 访问第一次破四十万2019-09-24 17:04 博客嗖一下到了六级2020-01-02 15:55 访问第一回达五十万2020-02-17 20:17 粉丝第一回超过千人 imgroot More info: Deployment]]></content>
  </entry>
</search>
